"title","abstract","date","source","doi_url","origin_of_life","synthetic_biology","dominant_theme"
"The origin of life as a planetary phenomenon","We advocate an integrative approach between laboratory experiments in prebiotic chemistry  and geologic, geochemical, and astrophysical observations to help assemble a robust _","science.org","Google Scholar","https://www.science.org/doi/abs/10.1126/sciadv.aax3419","2","0","origin_of_life"
"An origin of life on Mars","_ us about the relationship of that life to Earth_s life. To determine that _ life_something that  can only be done on organisms_alive or dead. We would be convinced of a shared origin of life _","cshperspectives.cshlp.org","Google Scholar","https://cshperspectives.cshlp.org/content/2/4/a003509.short","1","0","origin_of_life"
"Peptide amyloids in the origin of life","_ when sustainable life first occurred on our planet [11], a reconstruction of the origin of life must  _ In presenting a hypothesis on the _origin of life,_ we do not mean to imply that life itself is a _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S0022283618305898","1","0","origin_of_life"
"Paradoxes in the origin of life","_ for _not life_ without controversy, as can states of matter that everyone agrees constitute _life_. _  This is illustrated by a recent report on the limits of organic life in the Solar System, whose _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s11084-014-9379-0","1","0","origin_of_life"
"The grayness of the origin of life","_ the favored origin of life model, an inherent _grayness_ blurs the theorized threshold defining  life. Here, we explore the ambiguities between the biotic and the abiotic at the origin of life. _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/11/6/498","1","0","origin_of_life"
"Approaches to the origin of life on earth","I discuss briefly the history of the origin of life field, focusing on the _Miller_ era of prebiotic  synthesis, through the _Orgel_ era seeking enzyme free template replication of single stranded _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/1/1/34","2","1","origin_of_life"
"On the origin of life","_ Because the first cells were so simple, and there was by definition no evolved cell machinery  at the origin of life, we think that a rich and complex environment must have driven growth _","SciELO Argentina","Google Scholar","http://www.scielo.org.ar/scielo.php?pid=S0025-76802016000400001&script=sci_arttext&tlng=en","1","1","multiple"
"The origin of life: models and data","_ Set of life, which is the set of orthologous genes conserved throughout the tree of life and  found _ We also consider the components and properties of the Molecular Toolbox of Life, which _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s00239-017-9783-y","1","0","origin_of_life"
"Iron catalysis at the origin of life","Iron_sulphur proteins are ancient and drive fundamental processes in cells, notably electron  transfer and CO 2 fixation. Iron_sulphur minerals with equivalent structures could have _","Wiley Online Library","Google Scholar","https://iubmb.onlinelibrary.wiley.com/doi/abs/10.1002/iub.1632","1","0","origin_of_life"
"JBS Haldane and the origin of life","In 1929 the British biologist John Burdon Sanderson Haldane published a hypothesis on the  origin of life on earth, which was one of the most emblematic of the interwar period. It was a _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s12041-017-0831-6","1","0","origin_of_life"
"Attempts to define life do not help to understand the origin of life","_ Attempts to define life are irrelevant to scientific efforts to understand the origin of life. Why  is this? Simply put, the study of the _origin of life_ is an effort to understand the transition from _","Taylor & Francis","Google Scholar","https://www.tandfonline.com/doi/pdf/10.1080/073911012010524998","1","0","origin_of_life"
"The role of meteorite impacts in the origin of life","_ setting for the origin of life on Earth and whether life exists _ the emergence of life and frustrated  or extinguished life, we provide a _ proposed environments for the origin of life on Earth, we _","liebertpub.com","Google Scholar","https://www.liebertpub.com/doi/abs/10.1089/ast.2019.2203","2","0","origin_of_life"
"Proton gradients at the origin of life","_ played a role in the origin of life. Alkaline hydrothermal vents _ them attractive models for life's  origin. Their congruence with the _ played any role in the origin of life. Unfortunately, Jackson _","Wiley Online Library","Google Scholar","https://onlinelibrary.wiley.com/doi/abs/10.1002/bies.201600217","1","0","origin_of_life"
"The RNA world as a model system to study the origin of life","_ Understanding how life arose is a fundamental problem of biology. Much progress has _ on  originating life. We present a current view of the biochemistry of the origin of life, focusing on _","cell.com","Google Scholar","https://www.cell.com/current-biology/fulltext/S0960-9822(15)00681-8","2","0","origin_of_life"
"Thermodynamics of evolution and the origin of life","We outline a phenomenological theory of evolution and origin of life by combining the  formalism of classical thermodynamics with a statistical description of learning. The maximum _","National Acad Sciences","Google Scholar","https://www.pnas.org/doi/abs/10.1073/pnas.2120042119","1","1","multiple"
"A ribonucleopeptide world at the origin of life","_ it remains the best explanation for the origin of life. An increasing number of scientists are _  of life. In this review, I propose an enhanced explanation for the appearance of life supported _","Wiley Online Library","Google Scholar","https://onlinelibrary.wiley.com/doi/abs/10.1111/jse.12287","2","1","origin_of_life"
"Thermodynamic dissipation theory for the origin of life","_ Understanding the thermodynamic function of life may shed light on its origin. Life, as are all  _ Here we hypothesize that life began, and persists today, as a catalyst for the absorption and _","esd.copernicus.org","Google Scholar","https://esd.copernicus.org/articles/2/37/2011/","1","0","origin_of_life"
"In retrospect: the origin of life","_ In 1957, a large international meeting (attended by Miller) was held in Moscow to discuss  the origin of life, the proceedings of which make it clear that Oparin's book had had a_","nature.com","Google Scholar","https://www.nature.com/articles/491524a","1","0","origin_of_life"
"Clay minerals and the origin of life","Bernal first suggested the role of clay minerals in the origin of life because of the ordered  arrangement of the clay mineral particles, the large adsorption capacity, shielding against _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/B978008098258800016X","1","0","origin_of_life"
"Beating the acetyl coenzyme A-pathway to the origin of life","_ Attempts to draft plausible scenarios for the origin of life _ life at its origin necessarily  resembled biology in extant organisms, we consider that the only empirical way to deduce how life _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2012.0258","1","1","multiple"
"Viroids and the Origin of Life","_ and may have played a role in evolution since the beginning of life on Earth. They can cleave_  as a likely origin of life on Earth. As such, they may also be considered as models for life on _","mdpi.com","Google Scholar","https://www.mdpi.com/1422-0067/22/7/3476","1","1","multiple"
"The future of origin of life research: bridging decades-old divisions","_ life forms has yet to be found, here we do not exclude their possibility. Throughout this  text we will focus on life _ took part in the 1st Interdisciplinary Origin of Life meeting for early-career _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/10/3/20","1","0","origin_of_life"
"The origin of life: what we know, what we can know and what we will never know","The origin of life (OOL) problem remains one of the more challenging scientific questions of  all time. In this essay, we propose that following recent experimental and theoretical _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rsob.120190","1","0","origin_of_life"
"Autocatalytic sets: From the origin of life to the economy","The origin of life is one of the most important but also one of the most difficult problems in  science. Autocatalytic sets are believed to have played an important role in the origin of life. An _","academic.oup.com","Google Scholar","https://academic.oup.com/bioscience/article-abstract/63/11/877/2389920","1","0","origin_of_life"
"Pumice as a remarkable substrate for the origin of life","_ of life on Earth sometime prior to 3.5 billion years ago is almost as big a puzzle as the definition  of life _ have had a significant role in the origin of life and provided an important habitat for _","liebertpub.com","Google Scholar","https://www.liebertpub.com/doi/abs/10.1089/ast.2010.0546","1","0","origin_of_life"
"An optimal degree of physical and chemical heterogeneity for the origin of life?","_ difficult step on the pathway to the origin of life. However, recent experiments have shown  that _ The question of the origin of life may become less daunting once the constraints of overly _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2011.0140","1","0","origin_of_life"
"Systems protobiology: origin of life in lipid catalytic networks","Life is that which replicates and evolves, but there is no consensus on how life emerged.  We advocate a systems protobiology view, whereby the first replicators were assemblies of _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2018.0159","1","0","origin_of_life"
"Origin of life and living matter in hot mineral water","_ In this review the composition of water and isotopic structure of water during a process of  origin of life is submitted. The data obtained testify that life maintenance depends on physical-_","cyberleninka.ru","Google Scholar","https://cyberleninka.ru/article/n/origin-of-life-and-living-matter-in-hot-mineral-water","2","1","origin_of_life"
"Metal catalysts and the origin of life","Life as we know it is completely dependent on metal ions. Gradients of metal ions drive  metabolism, metal centers often form the active sites of enzymes, and metal-ion coordination is _","pubs.geoscienceworld.org","Google Scholar","https://pubs.geoscienceworld.org/msa/elements/article-abstract/12/6/413/272324","1","2","synthetic_biology"
"Thresholds in origin of life scenarios","Thresholds are widespread in origin of life scenarios, from the emergence of chirality, to the  appearance of vesicles, of autocatalysis, all the way up to Darwinian evolution. Here, we _","cell.com","Google Scholar","https://www.cell.com/iscience/fulltext/S2589-0042(20)30953-6","3","2","origin_of_life"
"The Martian subsurface as a potential window into the origin of life","_ Because the chemical signatures from the dawn of life have been entirely obliterated on _  about the origin of life on Earth, it makes sense to adopt a broader plan to seek signs of life. In _","nature.com","Google Scholar","https://www.nature.com/articles/s41561-017-0015-2","1","0","origin_of_life"
"Many paths to the origin of life","The origin of life remains a daunting mystery in part because rather than knowing too little,  we increasingly know about too many possible mechanisms that might have led to the self-_","science.org","Google Scholar","https://www.science.org/doi/abs/10.1126/science.1246704","1","0","origin_of_life"
"Sporulation, bacterial cell envelopes and the origin of life","_ support the hypothesis that they share a common origin. Mapping the distribution of cell  envelope architectures onto a recent phylogenetic tree of life indicates that the diderm cell plan, _","nature.com","Google Scholar","https://www.nature.com/articles/nrmicro.2016.85","1","0","origin_of_life"
"Origin of life: the point of no return","_ scope of origin of life research _ origin of Darwinian evolution and the origin of life are  inextricably bound and cannot be separated, therefore any reliable hypothesis for the origin of life _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/10/11/269","1","1","multiple"
"The narrow road to the deep past: in search of the chemistry of the origin of life","_ The sequence of events that gave rise to the first life on our _ to a full understanding of the  origin of life, so the future of _ In other words, to understand the origin of cellular life we need _","Wiley Online Library","Google Scholar","https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.201704048","1","0","origin_of_life"
"Origin of life on Mars: Suitability and opportunities","_ favorable to an independent origin of life (OoL) has been _ hypothesized as settings in which  life first arose on Earth. Mars _ of which are elements associated with life as we know it. With _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/11/6/539","1","0","origin_of_life"
"Better than Membranes at the Origin of Life?","_ The origin of life from non-living materials is an example of chemical emergence. As David  _ for the origins of life. Madagascar_s Tsingy Rouge and the origin of life are both unexpected, _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/7/2/28","2","0","origin_of_life"
"Information-theoretic considerations concerning the origin of life","_ From this point of view, the transition from non-life to life has _ for in candidates for origin-of-life  scenarios, characteristics _ Obviously, this constrains potential origin-of-life scenarios, _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s11084-015-9439-0","2","0","origin_of_life"
"Deus or Darwin: Randomness and belief in theories about the origin of life","A simple reminder of the fact that we do not always control life's outcomes reduced people's  belief in Darwin's Theory of Evolution. This control-threat resulted in a relative preference for _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S0022103110001605","1","1","multiple"
"Origin of Evolution versus Origin of Life: A Shift of Paradigm","_ for the origin of evolution, not through the search for the origin of life. There is a major issue  with the concept of life _ If we replace the search for the origin of life by the one for the origin of _","mdpi.com","Google Scholar","https://www.mdpi.com/1422-0067/12/6/3445","1","1","multiple"
"Promotion of protocell self-assembly from mixed amphiphiles at the origin of life","_ an important role in the origin of life. A major criticism of the hypothesis that life arose in an  _ Thus, alkaline hydrothermal conditions not only permit protocell formation at the origin of life _","nature.com","Google Scholar","https://www.nature.com/articles/s41559-019-1015-y","3","2","origin_of_life"
"Pinpointing Conditions for a Metabolic Origin of Life: Underlying Mechanisms and the Role of Coenzymes","_ From this perspective, recreating the origin of life in the lab is _ of the leading frameworks for  the origin of life. A complex self-_ to organic catalysis during the origin of life. Overall, the most _","ACS Publications","Google Scholar","https://pubs.acs.org/doi/abs/10.1021/acs.accounts.4c00423","1","1","multiple"
"A carbonate-rich lake solution to the phosphate problem of the origin of life","Phosphate is central to the origin of life because it is a key component of nucleotides in  genetic molecules, phospholipid cell membranes, and energy transfer molecules such as _","National Acad Sciences","Google Scholar","https://www.pnas.org/doi/abs/10.1073/pnas.1916109117","1","1","multiple"
"Urability: A property of planetary bodies that can support an origin of life","_ can sustain life. Because habitability does not explicitly incorporate the origin of life, this  article proposes a new word_urability_which refers to the conditions that allow life to begin. _","liebertpub.com","Google Scholar","https://www.liebertpub.com/doi/abs/10.1089/ast.2021.0173","1","0","origin_of_life"
"Geoelectrochemical CO production: Implications for the autotrophic origin of life","W_chtersh_user_s proposal of the autotrophic origin of life theory and subsequent laboratory  demonstrations of relevant organic reactions have opened a new gate for the exploration of _","science.org","Google Scholar","https://www.science.org/doi/abs/10.1126/sciadv.aao7265","1","0","origin_of_life"
"Non-equilibrium thermodynamic foundations of the origin of life","_ will be, in fact, a thermodynamic imperative for an origin of life similar to our own based on  carbon. In this case, the origin of life would not have been a single fortuitous chemical event _","mdpi.com","Google Scholar","https://www.mdpi.com/2673-9321/2/1/22","1","0","origin_of_life"
"Serpentinites: essential roles in geodynamics, arc volcanism, sustainable development, and the origin of life","Serpentinites are rocks consisting mostly of the serpentine-group minerals chrysotile, lizardite  and antigorite. They are formed by the hydration of olivine-rich ultramafic rocks and they _","pubs.geoscienceworld.org","Google Scholar","https://pubs.geoscienceworld.org/msa/elements/article-abstract/9/2/95/137949","1","0","origin_of_life"
"Origin of life-forming volatile elements in the inner Solar System","Volatile elements such as hydrogen, carbon, nitrogen and oxygen are essential ingredients  to build habitable worlds like Earth, but their origin and evolution on terrestrial planets _","nature.com","Google Scholar","https://www.nature.com/articles/s41586-022-05276-x","1","1","multiple"
"[LIVRE][B] Origin of Life: What Everyone Needs to Know?","It seems likely that scientists will someday discover how life can emerge on habitable planets  like the early Earth and Mars. In Origin of Life: What Everyone Needs to Know?, David W. _","books.google.com","Google Scholar","https://books.google.com/books?hl=fr&lr=&id=3xP0DwAAQBAJ&oi=fnd&pg=PP1&dq=origin+of+life&ots=z9HoSWtTQZ&sig=97dTyG0FgcIgXDrhRqn96M-Q8CA","1","0","origin_of_life"
"The nitrogen heterocycle content of meteorites and their significance for the origin of life","Carbonaceous chondrites are very primitive meteorites that are rich in carbon. They contain  many soluble organic compounds, including nitrogen heterocycles. These play a crucial role _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/8/3/28","1","0","origin_of_life"
"Chemistry constraints on the origin of life","_ Several research groups are active all around the world to tackle the origin of life, _ origin of  life, namely, the DNA- or RNA-centric view, with the underlying belief in the equation DNA=life_","Wiley Online Library","Google Scholar","https://onlinelibrary.wiley.com/doi/abs/10.1002/ijch.201400177","1","0","origin_of_life"
"[LIVRE][B] Towards Revealing the Origin of life","When we see various kinds of organisms, which prosperously inhabit the present Earth, we  think how such beautiful organisms emerged on this planet. To answer this question, many _","Springer","Google Scholar","https://link.springer.com/content/pdf/10.1007/978-3-030-71087-3.pdf","1","0","origin_of_life"
"The propitious role of solar energetic particles in the origin of life","We carry out 3D numerical simulations to assess the penetration and bombardment effects  of solar energetic particles (SEPs), ie, high-energy particle bursts during large flares and _","iopscience.iop.org","Google Scholar","https://iopscience.iop.org/article/10.3847/1538-4357/aa9fef/meta","1","0","origin_of_life"
"On the origin of life: an RNA-focused synthesis and narrative","Darwin's assertion that _it is mere rubbish thinking, at present, of origin of life_ is no longer  valid. By synthesizing origin of life (OoL) research from its inception to recent findings, with a _","rnajournal.cshlp.org","Google Scholar","https://rnajournal.cshlp.org/content/29/8/1085.short","1","0","origin_of_life"
"[LIVRE][B] The genetic mechanism and the origin of life","_ to life itself. Consequently, it is unrealistic to seek knowledge of the origin of life and its _  where a synthesis of their major details in relation to life's history is feasible. Because of the _","books.google.com","Google Scholar","https://books.google.com/books?hl=fr&lr=&id=pKPqBwAAQBAJ&oi=fnd&pg=PA1&dq=origin+of+life&ots=4DlTSAhEX1&sig=yMUft1l47RJPm2DxUUCoXAaYaaI","1","0","origin_of_life"
"The ineluctable requirement for the trans-iron elements molybdenum and/or tungsten in the origin of life","_ deeply into the distant past of life on Earth. The varying depths _ probably go back to the very  origin of life 2 . Copper enzymes, _ The origin of life on our and any other wet rocky world may _","nature.com","Google Scholar","https://www.nature.com/articles/srep00263","1","1","multiple"
"Alexandr I. Oparin and the origin of life: a historical reassessment of the heterotrophic theory","The heterotrophic origin of life proposed by AI Oparin in the 1920s was part of a Darwinian  framework that assumed that living organisms were the historical outcome of a gradual _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s00239-016-9773-5","1","0","origin_of_life"
"Origin of life: protoribosome forms peptide bonds and links RNA and protein dominated worlds","_ These findings present strong evidence supporting our hypothesis on origin of life and on _  link between the RNA dominated world and the contemporary nucleic acids/proteins life. _","academic.oup.com","Google Scholar","https://academic.oup.com/nar/article-abstract/50/4/1815/6523807","1","0","origin_of_life"
"[HTML][HTML] Evolutionary dynamics of RNA-like replicator systems: a bioinformatic approach to the origin of life","_ , classical group selection, and compartmentalization), and the origin of DNA-like  replicators. In conclusion, we pose a future question for theoretical studies on the origin of life. _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S1571064512000486","1","2","synthetic_biology"
"Amyloid and the origin of life: self-replicating catalytic amyloids as prebiotic informational and protometabolic entities","A crucial stage in the origin of life was the emergence of the first molecular entity that was  able to replicate, transmit information, and evolve on the early Earth. The amyloid world _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s00018-018-2797-9","4","1","origin_of_life"
"Origin-of-life Molecules in the Atmosphere after Big Impacts on the Early Earth","The origin of life on Earth would benefit from a prebiotic atmosphere that produced nitriles,  like HCN, which enable ribonucleotide synthesis. However, geochemical evidence suggests _","iopscience.iop.org","Google Scholar","https://iopscience.iop.org/article/10.3847/PSJ/aced83/meta","2","0","origin_of_life"
"Energy sources, self-organization, and the origin of life","The emergence and early developments of life are considered from the point of view that  contingent events that inevitably marked evolution were accompanied by deterministic driving _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s11084-010-9209-y","2","2","multiple"
"Considering planetary environments in origin of life studies","_ origin of life_ origin of life laboratory experiments to produce end-to-end predictions of  geological environments that lead to that process; the goal should instead be to explore origin of life _","nature.com","Google Scholar","https://www.nature.com/articles/s41467-018-07493-3","1","0","origin_of_life"
"The formation of crystalline minerals and their role in the origin of life on Earth","_ , chemical, and environmental conditions, favored the origin of the first organisms. Based on  _ origin of life has been traced to the start of our planet and its fast evolution. In this way, life _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S0960897422000018","2","1","origin_of_life"
"Factoring origin of life hypotheses into the search for life in the solar system and beyond","_ record of early life on Earth, and can be factored into the search for life elsewhere in the _  the search for life on various habitable worlds. It will discuss the relative probability that life could _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/10/5/52","2","0","origin_of_life"
"The origin of life: The submarine alkaline vent theory at 30","_ the 30th anniversary of the alkaline vent theory of the origin of life (figure 1). This issue  contains selected contributions from that meeting that provide both new theory as well as_","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rsfs.2019.0104","1","0","origin_of_life"
"Protocells models in origin of life and synthetic biology","_ paradigm_[16, 17]_helps shed light on the origin of early cells on earth, and at the same time  it _ It is very peculiar that research on protocells in origin of life scenarios intersects with the _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/5/4/1700","2","2","multiple"
"A peptide_nucleic acid replicator origin for life","Evolution requires self-replication. But, what was the very first self-replicator directly ancestral  to all life? The currently favoured RNA World theory assigns this role to RNA alone but _","cell.com","Google Scholar","https://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(20)30003-3","1","2","synthetic_biology"
"Environmental adaptation from the origin of life to the last universal common ancestor","_ If RNA were a component of life from its origin, limits on the stability and function of RNA  are also limits on the environments in which early life could have originated, especially since _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s11084-017-9542-5","2","1","origin_of_life"
"[LIVRE][B] Chemistry in space: from interstellar matter to the origin of life","_ A topical point to be covered is the query of the origin of life, either on Earth or somewhere _  for complex molecules associated with life and/or representing life. Along with these chemistry_","books.google.com","Google Scholar","https://books.google.com/books?hl=fr&lr=&id=baI91e8lgm0C&oi=fnd&pg=PT5&dq=origin+of+life&ots=O7XIiDhz7z&sig=3la3RZVAYCG4pK9ffpZysCeBUo4","1","0","origin_of_life"
"Setting the geological scene for the origin of life and continuing open questions about its emergence","_ of the geological scene in which life originated on Earth, _ origin of life: did life start organically  or in mineralogical form? If organically, what was the origin of the organic constituents of life_","frontiersin.org","Google Scholar","https://www.frontiersin.org/articles/10.3389/fspas.2022.1095701/full","2","0","origin_of_life"
"Conceptualizing the origin of life in terms of evolution","_ Combining these perspectives, we can conceptualize the origin of life as the origin of evolution  and the evolution of life. Therefore, evolution is at the centre of the origin of life, where the _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2016.0346","1","1","multiple"
"Compartmentalised chemistry: from studies on the origin of life to engineered biochemical systems","The origin of life on Earth has been the subject of inquiry since the early days of philosophical  thought. The main questions are centred around the formation of protocells capable of _","pubs.rsc.org","Google Scholar","https://pubs.rsc.org/en/content/articlehtml/2014/nj/c4nj00894d","3","1","origin_of_life"
"Protein three-dimensional structures at the origin of life","Proteins are relatively easy to synthesize, compared to nucleic acids and it is likely that there  existed a stage prior to the RNA world which can be called the protein world. Some of the _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rsfs.2019.0057","2","0","origin_of_life"
"[PDF][PDF] The transition from constraint to regulation at the origin of life","_ The origin of living dynamics required a local evasion of thermodynamic degradation by  maintaining critical dynamical and structural constraints. Scenarios for life_s origin that fail to_","anthropology.berkeley.edu","Google Scholar","https://anthropology.berkeley.edu/sites/default/files/deacon_et_al_2014_constraint_to_regulation.pdf","1","0","origin_of_life"
"Did cyclic metaphosphates have a role in the origin of life?","How life began still eludes science life, the initial progenote in the context presented herein,  being a chemical aggregate of primordial inorganic and organic molecules capable of self-_","Springer","Google Scholar","https://link.springer.com/article/10.1007/s11084-021-09604-5","1","0","origin_of_life"
"[HTML][HTML] Alkaline lake settings for concentrated prebiotic cyanide and the origin of life","Cyanide plays a critical role in origin of life hypotheses that have received strong experimental  support from cyanide-driven synthesis of amino acids, nucleotides, and lipid precursors. _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S0016703719303801","2","0","origin_of_life"
"Autocatalytic sets and chemical organizations: modeling self-sustaining reaction networks at the origin of life","_ Both formalisms have been argued to be relevant to the origin of life. RAF sets and chemical  _ how closed RAFs could be important in the context of the origin and early evolution of life. _","iopscience.iop.org","Google Scholar","https://iopscience.iop.org/article/10.1088/1367-2630/aa9fcd/meta","1","2","synthetic_biology"
"[LIVRE][B] The origin of life patterns: In the natural inclusion of space in flux","_ in paintings, such as this one, _Future Present_, in which I sought to feature every major  group of life forms currently resident on planet Earth and their watery origin as expressions of _","Springer","Google Scholar","https://link.springer.com/content/pdf/10.1007/978-3-319-54606-3.pdf","1","0","origin_of_life"
"Data-driven astrochemistry: One step further within the origin of life puzzle","_ the origin and chemical evolution of our Galaxy up to possible implications on the origin of  life, not _ Astrobiology focuses on questions on the origin of life or questioning the habitability _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/8/2/18","2","1","origin_of_life"
"Thermodynamics, disequilibrium, evolution: Far-from-equilibrium geological and chemical considerations for origin-of-life research","_ Here we refer to _emergence_ of life, rather than _origin_, in order to better underline the fact  that life is the last in a long line of emergent entropy generators beginning with the Big Bang. _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s11084-016-9508-z","1","1","multiple"
"Flexible proteins at the origin of life","Almost all modern proteins possess well-defined, relatively rigid scaffolds that provide  structural preorganization for desired functions. Such scaffolds require the sufficient length of a _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/7/2/23","1","0","origin_of_life"
"The epigenetic origin of life history transitions in plants and algae","_ Despite the mesmerizing array of life histories described in plants and algae, we are only _  impact on the life history strategy of plants and algae. Here, we trace the origin and function of _","Springer","Google Scholar","https://link.springer.com/article/10.1007/s00497-021-00422-3","1","0","origin_of_life"
"Environmental boundary conditions for the origin of life converge to an organo-sulfur metabolism","It has been suggested that a deep memory of early life is hidden in the architecture of metabolic  networks, whose reactions could have been catalyzed by small molecules or minerals _","nature.com","Google Scholar","https://www.nature.com/articles/s41559-019-1018-8","2","1","origin_of_life"
"A Bayesian Analysis of the Probability of the Origin of Life Per Site Conducive to Abiogenesis","The emergence of life from nonlife, or abiogenesis, remains a fundamental question in scientific  inquiry. In this article, we investigate the probability of the origin of life (per conducive site_","liebertpub.com","Google Scholar","https://www.liebertpub.com/doi/abs/10.1089/ast.2024.0037","3","0","origin_of_life"
"Macrobiont: Cradle for the Origin of Life and Creation of a Biosphere","Although the cellular microorganism is the fundamental unit of biology, the origin of life (OoL)  itself is unlikely to have occurred in a microscale environment. The macrobiont (MB) is the _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/10/11/278","1","0","origin_of_life"
"[LIVRE][B] The origin of life and evolutionary biochemistry","Historical Introduction: AI Oparin and the Origin of Life.-Chapters in Honor of' Proiskhozhdenie  Zhizni' and A. I, Oparin.-Protein Structure and the Molecular Evolution of Biological _","books.google.com","Google Scholar","https://books.google.com/books?hl=fr&lr=&id=g53TBwAAQBAJ&oi=fnd&pg=PA3&dq=origin+of+life&ots=Yi4tpAvTLT&sig=AdmmoiwH7NjEHjvNy0s2Fz-hNqU","1","1","multiple"
"Modeling of possible processes for origin of life and living matter in hot mineral and seawater with deuterium","The isotopic compositions of water its temperature and pH value were analyzed in experiments  with modeling of primary hydrosphere. We performed experiments for the research of hot _","medicalbiophysics.bg","Google Scholar","http://www.medicalbiophysics.bg/en/9903.html","1","0","origin_of_life"
"Molecules, information and the origin of life: what is next?","_ chance and necessity in the origin of life we intend to address further on in this manuscript.  _ In this focused review, we tried to shed light on new incoming theories about the origin of life, _","mdpi.com","Google Scholar","https://www.mdpi.com/1420-3049/26/4/1003","3","1","origin_of_life"
"Experimentally testing hydrothermal vent origin of life on Enceladus and other icy/ocean worlds","We review various laboratory strategies and methods that can be utilized to simulate prebiotic  processes and origin of life in hydrothermal vent systems on icy/ocean worlds. Crucial _","liebertpub.com","Google Scholar","https://www.liebertpub.com/doi/abs/10.1089/ast.2016.1633","3","1","origin_of_life"
"What does _the RNA world_ mean to _the origin of life_?","_ self-sustainment, the origin of life should also split into two issues: the origin of Darwinian _  origin of life should also imply two distinct issues: the origin of the life form_or say, the origin _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/7/4/49","2","0","origin_of_life"
"Mariana serpentinite mud volcanism exhumes subducted seamount materials: implications for the origin of life","_ with life, were discovered, the focus on a chemosynthetic, hydrothermal origin for life on Earth  _ the environmental conditions conducive for life's origin has increasingly suggested these _","royalsocietypublishing.org","Google Scholar","https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2018.0425","1","0","origin_of_life"
"The origin of life and the crystallization of aspartic acid in water","The unusual molecular complexation of the enantiomers of aspartic acid in water was  discovered and proven by a solubility test, solution freezing point, crystallization kinetics, and the _","ACS Publications","Google Scholar","https://pubs.acs.org/doi/abs/10.1021/cg901219f","1","0","origin_of_life"
"Reactive oxygen species at the oxide/water interface: Formation mechanisms and implications for prebiotic chemistry and the origin of life","The goal of our study is to identify free radical formation pathways on mineral surfaces. Organic  molecules on early Earth might have been modified or decomposed by such pathways, _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S0012821X12006942","3","0","origin_of_life"
"Catalytic/protective properties of martian minerals and implications for possible origin of life on Mars","Minerals might have played critical roles for the origin and evolution of possible life forms on  Mars. The study of the interactions between the _building blocks of life_ and minerals _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/8/4/56","1","1","multiple"
"'Whole Organism', systems biology, and top-down criteria for evaluating scenarios for the origin of life","_ explain the origin of life and the path from there to life on Earth as _ In this paper when we say  the origin of life, we mean it in _ to pre-Darwinian life, to the origin of the IDA, the origin of the _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/11/7/690","1","0","origin_of_life"
"Ligand field theory and the origin of life as an emergent feature of the periodic table of elements","_ on developments in the origin of life domain have tended to _ in prebiotic synthesis experiments,  life_or at least network _ planet in the origin and continuance of the life that we know. _","journals.uchicago.edu","Google Scholar","https://www.journals.uchicago.edu/doi/abs/10.1086/BBLv219n1p1","2","0","origin_of_life"
"Geochemistry and the origin of life: From extraterrestrial processes, chemical evolution on earth, fossilized life's records, to natures of the extant life","_ , ranging from the extraterrestrial inputs of life_s building blocks, _ findings for the origin and  early evolution of life, we propose _ the role of water molecules in the life_s function, focusing on _","mdpi.com","Google Scholar","https://www.mdpi.com/2075-1729/8/4/39","2","1","origin_of_life"
"A symbiogenic way in the origin of life","_ origin and evolution of life, with applicability to life_s initial stages, and capable of being a  fundamental rule in life_s _ We suggest a naturalistic explanation for the origin of life, through the _","Springer","Google Scholar","https://link.springer.com/chapter/10.1007/978-94-007-2941-4_36","1","1","multiple"
"Milestones at the Origin of Life","Abstract:                _and genetics, and they are mortal. The molecular structures and chemical reactions underlying these features are common from the simplest bacteria to human beings. The origin of_         _ More           Living organisms have some common structures, chemical reactions and molecular structures. The organisms consist of cells with cell division, they have homochirality of protein and carbohydrate units, and metabolism, and genetics, and they are mortal. The molecular structures and chemical reactions underlying these features are common from the simplest bacteria to human beings. The origin of life is evolutionary with the emergence of a network of spontaneous biochemical reactions, and the evolution has taken place over a very long time. The evolution contains, however some 'landmarks' and bottlenecks, which in a revolutionary manner directed the evolution, and the article tries to establish the order of these events. The article advocates that a possible order in the emergence of life is that the first milestone in prebiotic evolution is at the emergence of homochirality in proteins. The homochirality of peptides is, however, with instability and racemization which causes aging of the peptides and mortality. The metabolism and genetics are established through homochiral enzymes in the Earth's crust for $\\approx$ 4 Gyr ago. Finally, the cells with cell division are established in the Hot Springs environment at the interface between the crust and the Hadean Ocean.         _ Less","","arXiv","https://arxiv.org/abs/2412.14754","3","3","multiple"
"Fool's gold: ligand-receptor interactions and the origins of life","Abstract:                The origins of_         _ More           The origins of life is a question that continues to intrigue scientists across disciplines. One theory - the iron-sulphur theory - suggests that reactions essential to the synthesis of biological materials got their catalytic 'spark' from mineral surfaces such as iron pyrite, commonly known as fool's gold. Additionally, the binding affinity of the ligands synthesised in this 'surface metabolism' acted as an early version of natural selection: more strongly-binding ligands were accumulated into further autocatalytic reactions and the aggregation of complex biological materials. Ligand-receptor binding is thus fundamental to the origins of life. In this paper, we use the iron-sulphur theory as a lens through which to review ligand-receptor interactions as they are more commonly understood today. In particular we focus on the electron tunnelling theory of receptor activation that has emerged from research into quantum biology. We revisit criticism against this theory, particularly the lack of evidence for electron transfer in receptors, to see what insights might be offered by ligand-receptor interactions mediated by iron pyrite at the origins of life. What emerges from this comparison is the central importance of redox activity in receptors, in particular with respect to the recurring presence of the disulphide bond. While the paper is a speculative exercise, we conclude that conductivity in biomolecules, particularly the selective conductivity conferred by appropriate ligand-receptor binding, is a powerful tool for understanding diverse phenomena such as pharmacological potency and viral infection. As such it deserves further investigation.         _ Less","","arXiv","https://arxiv.org/abs/2412.13836","1","2","synthetic_biology"
"A technical solution for the rule of law, peace, security, and evolvability of global cyberspace -- solve the three genetic defects of IP network","Abstract:                Since its inception in the 1960s, the internet has profoundly transformed human life. However, its original design now struggles to meet the evolving demands of modern society. Three primary defects have emerged: First, the concentration of power among a few dominant entities has intensified international conflicts and_         _ More           Since its inception in the 1960s, the internet has profoundly transformed human life. However, its original design now struggles to meet the evolving demands of modern society. Three primary defects have emerged: First, the concentration of power among a few dominant entities has intensified international conflicts and widened the technological divide. Second, the Internet Protocol (IP)-based system lacks inherent security, leading to frequent global cybersecurity incidents. Third, the rigidity of the IP protocol has hindered the sustainable development of cyberspace, as it resists necessary adaptations and innovations. Addressing these issues is crucial for the future resilience and security of the global digital landscape.   To address these challenges, we propose the Co-governed Multi-Identifier Network (CoG-MIN briefly as MIN), a novel network architecture that leverages blockchain technology to ensure equal participation of countries worldwide in cyberspace governance and the rule of law. As a next-generation network system, CoG-MIN integrates mechanisms such as user authentication, data signatures, and encryption to significantly enhance network security. In testing environments, CoG-MIN has consistently withstood extensive attacks during various international cybersecurity competitions. Additionally, CoG-MIN supports the evolution and interoperability of different identifier systems, remains IP-compatible, and facilitates a gradual transition away from IP, providing an adaptable ecosystem for diverse network architectures. This adaptability fosters the development and evolution of diverse network architectures within CoG-MIN, making it a natural progression for the internet's future development.   We further introduce a trilogy of cyberspace security theorems... (Due to character limitations, the full abstract is available in the paper PDF.)         _ Less","","arXiv","https://arxiv.org/abs/2412.10722","0","2","synthetic_biology"
"A New Strategy for the Exploration of Venus","Abstract:                The 2023-2032 Planetary Science and Astrobiology Decadal Survey Origins, Worlds, and_         _ More           The 2023-2032 Planetary Science and Astrobiology Decadal Survey Origins, Worlds, and Life recommended that 'NASA develop scientific exploration strategies, as it has for Mars, in areas of broad scientific importance, e.g., Venus... that have an increasing number of U.S. missions and international collaboration opportunities' (OWL, p.22-10). In NASA's initial responses to that Decadal Survey, the agency asserted that '...specific scientific exploration strategies should be community generated by bodies such as the Analysis Groups,' thus placing the onus on the planetary community to generate and support these exploration strategies. In late 2022, the Venus Exploration Analysis Group began a project to develop a new exploration strategy for Venus, reflecting the 2021 selections of the VERITAS, DAVINCI, and EnVision missions and the sweeping comparative planetology recommendations relevant to Venus in Origins, Worlds, and Life.   This is that strategy.   Taking a broad look at the scientific, technological, and programmatic advances required to address the key outstanding questions that Venus poses, and predicated on VERITAS, DAVINCI, and EnVision flying as planned in the early 2030s, this report outlines a set of actions available to NASA, VEXAG, and the planetary science community at large to establish a sustained program of Venus exploration in the years and decades ahead. Key to this approach is recognizing Venus as a unique setting where multiple, cross-disciplinary, Decadal-level planetary, Earth, heliophysics, and exoplanet science questions can be addressed, as well as being a worthy target of exploration in its own right.   This report offers Assessments of the current state of Venus exploration, and Actions for the U.S. and international Venus community, as well as NASA, to consider. This strategy is a living document and should be updated as warranted.         _ Less","","arXiv","https://arxiv.org/abs/2412.06830","1","1","multiple"
"An RNA condensate model for the origin of life","Abstract:                _widespread support for the RNA World, self-replicating RNAs have yet to be identified in a natural context, leaving a key 'missing link' for this explanation of the origin of_         _ More           The RNA World hypothesis predicts that self-replicating RNAs evolved before DNA genomes and coded proteins. Despite widespread support for the RNA World, self-replicating RNAs have yet to be identified in a natural context, leaving a key 'missing link' for this explanation of the origin of life. Inspired by recent work showing that condensates of charged polymers can create electrochemical gradients capable of catalyzing hydrolysis, we consider a catalytic RNA condensate as a candidate for the self-replicating RNA. We develop a theoretical framework where an RNA condensate formed by the spontaneous demixing of disordered RNA sequences undergoes self-replicative amplification. Our theory addresses two central problems in the origins of life: (i) the origin of compartmentalization and (ii) the error threshold for the accuracy of templated replication. We show that many of the needed properties of this self-replicating RNA condensate have been realized experimentally in recent studies and can be formalized within a standard polymer physics framework. Specifically, we propose that short, low-complexity RNA polymers formed catalytic condensates capable of templated RNA polymerization. Because the condensate properties depend on the RNA sequences, RNAs that formed condensates with improved polymerization and demixing capacity would be amplified, leading to a 'condensate chain reaction' and evolution by natural selection. We believe this prediction could be tested with current experimental and theoretical tools. Furthermore, we note that the extant nucleolus appears to satisfy many of the requirements of an evolutionary relic for the model we propose. More generally, we suggest that future work on the origin of life would benefit from condensate-centric biophysical models of RNA evolution.         _ Less","","arXiv","https://arxiv.org/abs/2412.05396","2","3","synthetic_biology"
"Chikungunya: The Silent Threat in the Shadows","Abstract:                _infections by intense arthralgia, which can persist for months or even years in some individuals. The virus has re-emerged as a global health threat in recent decades, originating in Africa and spreading across Asia and America, leading to widespread outbreaks affecting millions. Despite more than 50 years of research on CHIKV pathogenesis, no drugs or vacci_         _ More           Chikungunya virus (CHIKV) is one of the most relevant arboviruses affecting public health today. It belongs to the Togaviridae family and alphavirus genus, causing an arthritogenic disease known as Chikungunya fever (CHIKF). This multifaceted disease is distinguished from other arbovirus infections by intense arthralgia, which can persist for months or even years in some individuals. The virus has re-emerged as a global health threat in recent decades, originating in Africa and spreading across Asia and America, leading to widespread outbreaks affecting millions. Despite more than 50 years of research on CHIKV pathogenesis, no drugs or vaccines are available. Current management focuses on supportive care to alleviate symptoms and improve patient's quality of life. The ongoing threat posed by CHIKV highlights the need to understand its pathogenesis better. This review provides a comprehensive overview of CHIKV, focusing on host factors, vector-related factors, and complex viral genetic interactions. By exploring these intricate connections, we aim to offer insights that may lead to more effective strategies for preventing and managing this re-emerging global health threat.         _ Less","","arXiv","https://arxiv.org/abs/2411.12779","3","3","multiple"
"Low-Energy Cosmic Rays and Associated MeV Gamma-Ray Emissions in the Protoplanetary System","Abstract:                _environment at that time. This method, supported by further theoretical developments and observations, will fundamentally enhance our understanding of the impact of CRs on the origin and evolution of planetary systems and address significant scientific questions regarding the cosmic ray environment at the_         _ More           Low-energy cosmic rays (LECRs) play a crucial role in the formation of planetary systems, and detecting and reconstructing the properties of early LECRs is essential for understanding the mechanisms of planetary system formation. Given that LECRs interact with the surrounding medium to produce nuclear de-excitation line emissions, which are gamma-ray emissions with energy mainly within 0.1--10 MeV and are unaffected by stellar wind modulation, these emissions can accurately reflect the properties of LECRs. This study introduces an innovative method for using gamma-ray emissions to infer LECR properties. We employed the Parker transport equation to simulate the propagation and spectral evolution of LECRs in a protoplanetary disk and calculated the characteristic gamma-ray emissions resulting from interactions between LECRs and disk material. These gamma-ray emissions encapsulate the spectral information of LECRs, providing a powerful tool to reconstruct the cosmic ray environment at that time. This method, supported by further theoretical developments and observations, will fundamentally enhance our understanding of the impact of CRs on the origin and evolution of planetary systems and address significant scientific questions regarding the cosmic ray environment at the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2411.09369","2","1","origin_of_life"
"Quantum evolution: terrestrial fine-tuning of magnetic parameters","Abstract:                _might conceivably begin to imagine itself as a multi-planetary species. This goal will entail technical innovation in a number of contexts, including that of healthcare. All life on Earth shares an evolution that is coupled to specific environmental conditions, including gravitational and magnetic fields. While the human body may be able to adjust to short t_         _ More           For the first time in history, humankind might conceivably begin to imagine itself as a multi-planetary species. This goal will entail technical innovation in a number of contexts, including that of healthcare. All life on Earth shares an evolution that is coupled to specific environmental conditions, including gravitational and magnetic fields. While the human body may be able to adjust to short term disruption of these fields during space flights, any long term settlement would have to take into consideration the effects that different fields will have on biological systems, within the space of one lifetime, but also across generations. Magnetic fields, for example, influence the growth of stem cells in regenerative processes. Circadian rhythms are profoundly influenced by magnetic fields, a fact that will likely have an effect on mental as well as physical health. Even the brain responds to small perturbations of this field. One possible mechanism for the effects of weak magnetic fields on biological systems has been suggested to be the radical pair mechanism. The radical pair mechanism originated in the context of spin chemistry to describe how magnetic fields influence the yields of chemical reactions. This mechanism was subsequently incorporated into the field of quantum biology. Quantum biology, most generally, is the study of whether non-trivial quantum effects play any meaningful role in biological systems. The radical pair mechanism has been used most consistently in this context to describe the avian compass. Recently, however, a number of studies have investigated other biological contexts in which the radical pair might play a role, from the action of anaesthetics and antidepressants, to microtubule development and the proper function of the circadian clock... (full abstract in the manuscript)         _ Less","","arXiv","https://arxiv.org/abs/2411.03316","0","2","synthetic_biology"
"Setting the stage: Building and maintaining a habitable world and the early conditions that could favor life's beginnings on Earth and beyond","Abstract:                The Hadean, once thought to be uninhabitable and tumultuous, has more recently been recontextualized as a clement time in which oceans, land, and life likely appeared on Earth. This non-exhaustive chapter follows multiple threads from planet formation to the_         _ More           The Hadean, once thought to be uninhabitable and tumultuous, has more recently been recontextualized as a clement time in which oceans, land, and life likely appeared on Earth. This non-exhaustive chapter follows multiple threads from planet formation to the origin of life. We place significant emphasis on the solar system context for the Earth, the timing and nature of crustal formation and the evolution of the surface and atmosphere. Several scenarios for prebiotic chemistry are also discussed including atmospheric photochemistry, wet-dry and freeze-thaw cycles, and hydrothermal vent systems. We attempt to draw connections between the large-scale, planetary processes and various origin of life pathways to illustrate possible overlaps and correlations. In detail, we conclude with and discuss the 'impact of impacts' to show how asteroid and comet impacts during the Hadean may have affected many of these processes and scenarios, from generating land to altering the chemical composition and oxidation state of the early Earth's atmosphere and surface.         _ Less","","arXiv","https://arxiv.org/abs/2410.23344","3","1","origin_of_life"
"Modifications of SPH towards three-dimensional simulations of an icy moon with internal ocean","Abstract:                _icy moons, such as the vapor plumes of Europa and Enceladus. This implies a region of liquid water beneath the surface ice shell. Since liquid water would be essential for the origin of life, it is important to understand the development of these internal oceans, particularly their temperature distribution and evolutio_         _ More           There are some traces of the existence of internal ocean in some icy moons, such as the vapor plumes of Europa and Enceladus. This implies a region of liquid water beneath the surface ice shell. Since liquid water would be essential for the origin of life, it is important to understand the development of these internal oceans, particularly their temperature distribution and evolution. The balance between tidal heating and radiative cooling is believed to sustain liquid water beneath an icy moon's surface. We aim to simulate the tidal heating of an internal ocean in an icy moon using 3-dimensional numerical fluid calculations with the Smoothed Particle Hydrodynamics (SPH) method. We incorporated viscosity and thermal conduction terms into the governing equations of SPH. However, we encountered two issues while calculating rigid body rotation using SPH with a viscous term: (1) conventional viscosity formulations generated unphysical forces that hindered rotation, and (2) there was artificial internal energy partitioning within the layered structure, which was due to the standard SPH formulations. To address the first issue, we modified the viscosity formulation.For the second, we adopted Density Independent SPH (DISPH) developed in previous studies to improve behavior at discontinuous surfaces. Additionally, we implemented radiative cooling using an algorithm to define fluid surfaces via the particle method. We also introduced an equation of state accounting for phase transitions. With these modifications, we have refined the SPH method to encompass all necessary physical processes for simulating the evolution of icy moons with internal oceans.         _ Less","","arXiv","https://arxiv.org/abs/2410.20433","1","1","multiple"
"BRITE nascent binaries","Abstract:                _secondary is a star contracting onto the main sequence. NBs are of interest because they can help to understand the formation of small-mass ratio systems and shed light on the origin of low-mass X-ray binaries, millisecond pulsars and type Ia supernovae. In photometry, short-period NBs show a strong irradiation effect due to the large difference between the_         _ More           Nascent binaries (NBs) are binary systems with very low mass ratios, less than ~0.2, in which the more massive component is an O- or B-type main-sequence star, while the secondary is a star contracting onto the main sequence. NBs are of interest because they can help to understand the formation of small-mass ratio systems and shed light on the origin of low-mass X-ray binaries, millisecond pulsars and type Ia supernovae. In photometry, short-period NBs show a strong irradiation effect due to the large difference between the effective temperatures of the components and the strong irradiation of a cool secondary by a hot primary. In spectroscopy, they usually appear as single-lined spectroscopic binaries. In the present paper, we summarize the status of our knowledge of Galactic nascent binaries and characterize two new members of this group, c2 Sco and V390 Pup, for which photometric data were obtained by the BRIght Target Explorer (BRITE) nano-satellite mission.         _ Less","","arXiv","https://arxiv.org/abs/2410.19120","1","0","origin_of_life"
"Large Interferometer For Exoplanets (LIFE). XIV. Finding terrestrial protoplanets in the galactic neighborhood","Abstract:                _to distances from the solar system far greater than thermally equilibrated terrestrial exoplanets, offering observational opportunities for unique insights into the origin of secondary atmospheres and the near surface conditions of prebiotic environments. The Large Interferometer For Exoplanets (_         _ More           The increased brightness temperature of young rocky protoplanets during their magma ocean epoch makes them potentially amenable to atmospheric characterization to distances from the solar system far greater than thermally equilibrated terrestrial exoplanets, offering observational opportunities for unique insights into the origin of secondary atmospheres and the near surface conditions of prebiotic environments. The Large Interferometer For Exoplanets (LIFE) mission will employ a space-based mid-infrared nulling interferometer to directly measure the thermal emission of terrestrial exoplanets. Here, we seek to assess the capabilities of various instrumental design choices of the LIFE mission concept for the detection of cooling protoplanets with transient high-temperature magma ocean atmospheres, in young stellar associations in particular. Using the LIFE mission instrument simulator (LIFEsim) we assess how specific instrumental parameters and design choices, such as wavelength coverage, aperture diameter, and photon throughput, facilitate or disadvantage the detection of protoplanets. We focus on the observational sensitivities of distance to the observed planetary system, protoplanet brightness temperature using a blackbody assumption, and orbital distance of the potential protoplanets around both G- and M-dwarf stars. Our simulations suggest that LIFE will be able to detect (S/N $\\geq$ 7) hot protoplanets in young stellar associations up to distances of $\\approx$100 pc from the solar system for reasonable integration times (up to $\\sim$hours). Detection of an Earth-sized protoplanet orbiting a solar-sized host star at 1 AU requires less than 30 minutes of integration time. M-dwarfs generally need shorter integration times. The contribution from wavelength regions $<$6 $_$m is important for decreasing the detection threshold and discriminating emission temperatures.         _ Less","","arXiv","https://arxiv.org/abs/2410.13457","1","0","origin_of_life"
"Theory for sequence selection via phase separation and oligomerization","Abstract:                _highlight that out-of-equilibrium condensed phases could provide versatile hubs for Darwinian-like evolution toward functional sequences, both relevant for the molecular origin of life and de novo life.         _ More           Non-equilibrium selection pressures were proposed for the formation of oligonucleotides with rich functionalities encoded in their sequences, such as catalysis. Since phase separation was shown to direct various chemical processes, we ask whether condensed phases can provide mechanisms for sequence selection. To answer this question, we use non-equilibrium thermodynamics and describe the reversible oligomerization of different monomers to sequences at non-dilute conditions prone to phase separation. We find that when sequences oligomerize, their interactions give rise to phase separation, boosting specific sequences' enrichment and depletion. Our key result is that phase separation gives rise to a selection pressure for the oligomerization of specific sequence patterns when fragmentation maintains the system away from equilibrium. Specifically, slow fragmentation favors alternating sequences that interact well with their environment (more cooperative), while fast fragmentation selects sequences with extended motifs capable of specific sequence interactions (less cooperative). Our results highlight that out-of-equilibrium condensed phases could provide versatile hubs for Darwinian-like evolution toward functional sequences, both relevant for the molecular origin of life and de novo life.         _ Less","","arXiv","https://arxiv.org/abs/2410.08778","2","1","origin_of_life"
"Systematic Feature Design for Cycle Life Prediction of Lithium-Ion Batteries During Formation","Abstract:                _manufacturing is challenging due to limited physical understanding of solid electrolyte interphase formation and the long testing time (~100 days) for cells to reach the end of life. We propose a systematic feature design framework that requires minimal domain knowledge for accurate cycle_         _ More           Optimization of the formation step in lithium-ion battery manufacturing is challenging due to limited physical understanding of solid electrolyte interphase formation and the long testing time (~100 days) for cells to reach the end of life. We propose a systematic feature design framework that requires minimal domain knowledge for accurate cycle life prediction during formation. Two simple Q(V) features designed from our framework, extracted from formation data without any additional diagnostic cycles, achieved a median of 9.20% error for cycle life prediction, outperforming thousands of autoML models using pre-defined features. We attribute the strong performance of our designed features to their physical origins - the voltage ranges identified by our framework capture the effects of formation temperature and microscopic particle resistance heterogeneity. By designing highly interpretable features, our approach can accelerate formation research, leveraging the interplay between data-driven feature design and mechanistic understanding.         _ Less","","arXiv","https://arxiv.org/abs/2410.07458","1","0","origin_of_life"
"Extragalactic fast X-ray transient from a weak relativistic jet associated with a Type Ic-BL supernova","Abstract:                Massive stars end their life as core-collapse supernovae, amongst which some extremes are Type Ic broad-lined supernovae associated with long-duration gamma-ray bursts (LGRBs) having powerful relativistic jets. Their less-extreme brethren make unsuccessful jets that are choked inside the stars, appearing as X-ray flashes or low-luminosity GRBs. On the other_         _ More           Massive stars end their life as core-collapse supernovae, amongst which some extremes are Type Ic broad-lined supernovae associated with long-duration gamma-ray bursts (LGRBs) having powerful relativistic jets. Their less-extreme brethren make unsuccessful jets that are choked inside the stars, appearing as X-ray flashes or low-luminosity GRBs. On the other hand, there exists a population of extragalactic fast X-ray transients (EFXTs) with timescales ranging from seconds to thousands of seconds, whose origins remain obscure. Known sources that contribute to the observed EFXT population include the softer analogs of LGRBs, shock breakouts of supernovae, or unsuccessful jets. Here, we report the discovery of the bright X-ray transient EP240414a detected by the Einstein Probe (EP), which is associated with the Type Ic supernova SN 2024gsa at a redshift of 0.401. The X-ray emission evolution is characterised by a very soft energy spectrum peaking at < 1.3 keV, which makes it distinct from known LGRBs, X-ray flashes, or low-luminosity GRBs. Follow-up observations at optical and radio bands revealed the existence of a weak relativistic jet that interacts with an extended shell surrounding the progenitor star. Located on the outskirts of a massive galaxy, this event reveals a new population of explosions of Wolf-Rayet stars characterised by a less powerful engine that drives a successful but weak jet, possibly owing to a progenitor star with a smaller core angular momentum than in traditional LGRB progenitors.         _ Less","","arXiv","https://arxiv.org/abs/2410.02315","0","1","synthetic_biology"
"The Lonely Runner Conjecture turns 60","Abstract:                The Lonely Runner Conjecture originated in Diophantine approximation will turn 60 in 2028. Even if the conjecture is still widely open, the flow of partial results, innovative tools and connections to different problems and applications has been steady on its long_         _ More           The Lonely Runner Conjecture originated in Diophantine approximation will turn 60 in 2028. Even if the conjecture is still widely open, the flow of partial results, innovative tools and connections to different problems and applications has been steady on its long life. This survey attempts to give a panoramic view of the status of the problem, trying to highlight the contributions of the many papers that it has originated.         _ Less","","arXiv","https://arxiv.org/abs/2409.20160","1","1","multiple"
"The GALAH Survey: Data Release 4","Abstract:                _satellite. For the first time, these elements include life-essential nitrogen to complement carbon, and oxygen as well as more measurements of rare-earth elements critical to modern-life electronics, offering unparalleled insights into the chemical composition of the Milky Way.   For this release, we use neural networ_         _ More           The stars of the Milky Way carry the chemical history of our Galaxy in their atmospheres as they journey through its vast expanse. Like barcodes, we can extract the chemical fingerprints of stars from high-resolution spectroscopy. The fourth data release (DR4) of the Galactic Archaeology with HERMES (GALAH) Survey, based on a decade of observations, provides the chemical abundances of up to 32 elements for 917 588 stars that also have exquisite astrometric data from the $Gaia$ satellite. For the first time, these elements include life-essential nitrogen to complement carbon, and oxygen as well as more measurements of rare-earth elements critical to modern-life electronics, offering unparalleled insights into the chemical composition of the Milky Way.   For this release, we use neural networks to simultaneously fit stellar parameters and abundances across the full spectrum, leveraging synthetic grids computed with Spectroscopy Made Easy. These grids account for atomic line formation in non-local thermodynamic equilibrium for 14 elements. In a two-iteration process, we first fit stellar labels for all 1 085 520 spectra, then co-add repeated observations and refine these labels using astrometric data from $Gaia$ and 2MASS photometry, improving the accuracy and precision of stellar parameters and abundances. Our validation thoroughly assesses the reliability of spectroscopic measurements and highlights key caveats for catalogue users.   GALAH DR4 represents yet another milestone in Galactic archaeology, combining detailed chemical compositions from multiple nucleosynthetic channels with kinematic information and age estimates. The resulting dataset, covering nearly a million stars, opens new avenues for understanding not only the chemical and dynamical history of the Milky Way, but also the broader questions of the origin of elements and the evolution of planets, stars, and galaxies.         _ Less","","arXiv","https://arxiv.org/abs/2409.19858","2","2","multiple"
"Venus Phosphine: Updates and lessons learned","Abstract:                The discovery of phosphine in Venus' atmosphere provides lessons for the search for life. The detection has survived all challenges and has acquired independent support from archival data from PVP. The presence of phosphine in Venus' oxidising environment is perplexing, and comprehensive studies rule out all known abiotic sources. More data is needed_         _ More           The discovery of phosphine in Venus' atmosphere provides lessons for the search for life. The detection has survived all challenges and has acquired independent support from archival data from PVP. The presence of phosphine in Venus' oxidising environment is perplexing, and comprehensive studies rule out all known abiotic sources. More data is needed to understand the origin of phosphine, leading to JCMT-Venus, a long term atmospheric monitoring programme. This can find how phosphine varies in relation to other species providing clues to its origin. We present the latest JCMT-Venus results. The discovery and subsequent papers were explicit that they did not constitute evidence for life, only of phosphine. Media and public reaction to the discovery and its implications provide lessons for future life searches, as does the reaction of the scientific community. How this was handled by the team, media, and general public will be reviewed.         _ Less","","arXiv","https://arxiv.org/abs/2409.13438","2","2","multiple"
"Life in the Bubble: How a nearby supernova left ephemeral footprints on the cosmic-ray spectrum and indelible imprints on life","Abstract:                _crust have been interpreted by the imprints left by the ejecta of supernova explosions occurring about 2-3 and 5-6 Myr ago. It is likely that the 60Fe peak at about 2-3 Myr originated from a supernova occurring in the Upper Centaurus Lupus association in Scorpius Centaurus (140 pc) or the Tucana Horologium association (70 pc). Whereas, the 5-6 Myr peak is li_         _ More           The Earth sits inside a 300pc-wide void that was carved by a series of supernova explosions that went off tens of millions of years ago, pushing away interstellar gas and creating a bubble-like structure. The 60Fe peak deposits found in the deep-sea crust have been interpreted by the imprints left by the ejecta of supernova explosions occurring about 2-3 and 5-6 Myr ago. It is likely that the 60Fe peak at about 2-3 Myr originated from a supernova occurring in the Upper Centaurus Lupus association in Scorpius Centaurus (140 pc) or the Tucana Horologium association (70 pc). Whereas, the 5-6 Myr peak is likely attributed to the solar system's entrance into the bubble. In this Letter, we show that the supernova source responsible for synthesizing the 60Fe peak deposits 2-3 Myr ago was also likely a Galactic PeVatron source. We demonstrate that this supernova can consistently explain the 'knee' in the cosmic-ray spectrum and the large-scale anisotropy between 100 TeV and 100 PeV. Matching the intensity and shape of the cosmic-ray spectrum allows us to place stringent constraints on the cosmic-ray energy content from the supernova as well as on the cosmic-ray diffusion coefficient. Making use of such constraints we provide a robust estimate of the temporal variation of terrestrial ionizing cosmic radiation levels and discuss their implications in the development of early life on Earth by plausibly influencing the mutation rate and, as such, conceivably assisting in the evolution of complex organisms.         _ Less","","arXiv","https://arxiv.org/abs/2409.12307","1","1","multiple"
"Self-oxidation of the atmospheres of rocky planets with implications for the origin of life","Abstract:                _which dissolves as nitrate in the oceans, and interplanetary dust particles may be the main sources of fixed nitrogen to emerging biospheres. Our results highlight the need for origin-of-life scenarios where the first metabolism fixes its C from CO$_2$, rather than from HCN and CO.         _ More           Rocky planets may acquire a primordial atmosphere by outgassing of volatiles from their magma ocean. The distribution of O between H$_2$O, CO and CO$_2$ in chemical equilibrium subsequently changes significantly with decreasing temperature. We explore here two chemical models: one where CH$_4$ and NH$_3$ are assumed to be irrevocably destroyed by photolysis, and one where these molecules persist. In the first case, we show that CO cannot co-exist with H$_2$O, since CO oxidizes at low temperatures to form CO$_2$ and H$_2$. In both cases, H escapes from the thermosphere within a few ten million years by absorption of stellar XUV radiation. This escape drives an atmospheric self-oxidation process whereby rocky planet atmospheres become dominated by CO$_2$ and H$_2$O, regardless of their initial oxidation state at outgassing. HCN is considered a potential precursor of prebiotic compounds and RNA. Our oxidizing atmospheres are inefficient at producing HCN by lightning. Instead, we demonstrate that lightning-produced NO, which dissolves as nitrate in the oceans, and interplanetary dust particles may be the main sources of fixed nitrogen to emerging biospheres. Our results highlight the need for origin-of-life scenarios where the first metabolism fixes its C from CO$_2$, rather than from HCN and CO.         _ Less","","arXiv","https://arxiv.org/abs/2409.11070","2","1","origin_of_life"
"Minor planets, asteroids, comets and interplanetary dust within 30 au","Abstract:                _collectively known as the small Solar System bodies. Small bodies are relics from the birth of the Solar System and offer valuable insights into planetary formation and the origins of life. This chapter explores this important component of our Solar System, discussing the formation and evolution of key small body popu_         _ More           Our Solar System includes the Sun, eight major planets and their moons, along with numerous asteroids, comets, and dust particles, collectively known as the small Solar System bodies. Small bodies are relics from the birth of the Solar System and offer valuable insights into planetary formation and the origins of life. This chapter explores this important component of our Solar System, discussing the formation and evolution of key small body populations and their interrelations.         _ Less","","arXiv","https://arxiv.org/abs/2409.09540","1","1","multiple"
"Why aphids are not pests in cacao? An approach based on a predator-prey model with aging","Abstract:                _farms in Ilheus, Bahia. Based on   the classical predator-prey model, we \\mbox{propose} a system of   differential equations with three rate equations. \\mbox{Unlike} the   original Lotka-Volterra model, our model includes two aphid   population classes: juveniles (non-breeding) and adult females   (asexually breeding). We obtained steady-state solutions for_         _ More           We studied a mean-field predator-prey model with aging to simulate   the \\mbox{interaction} between aphids (\\textit{Toxoptera aurantii})   and syrphid larvae in \\mbox{cacao} farms in Ilheus, Bahia. Based on   the classical predator-prey model, we \\mbox{propose} a system of   differential equations with three rate equations. \\mbox{Unlike} the   original Lotka-Volterra model, our model includes two aphid   population classes: juveniles (non-breeding) and adult females   (asexually breeding). We obtained steady-state solutions for   juvenile and adult populations by \\mbox{analyzing} the stability of   the fixed points as a function of model \\mbox{parameters}. The   results show that the absorbing state (zero prey population) is   always possible, but not consistently stable. A nonzero stationary   solution is achievable with appropriate parameter values. Using   phase diagrams, we analyzed the \\mbox{stationary} solution,   providing a comprehensive understanding of the \\mbox{dynamics}   involved. Simulations on complete graphs yielded \\mbox{results}   closely matching the differential equations. We also   \\mbox{performed} simulations on \\mbox{random} networks to highlight   the influence of \\mbox{network} topology on \\mbox{system}   behavior. Our findings highlight the critical role of life-stage   structure, \\mbox{predation}, and spatial variation in stabilizing   predator-prey \\mbox{systems}. This emphasizes the importance of   network effects in population dynamics and refines the framework for   biological pest control in agriculture. Ultimately, our research   contributes to sustainable agricultural practices.         _ Less","","arXiv","https://arxiv.org/abs/2409.06861","1","1","multiple"
"The Spatial Distribution of $\\rm CH_4$ and $\\rm CO_2$ Ice around Protostars IRAS 16253-2429 and IRAS 23385+6053","Abstract:                The origin and evolution of organic molecules represent a pivotal issue in the fields of astrobiology and astrochemistry, potentially shedding light on the origins of life. The James Webb Space Telescope (JWST), with its exceptional sensitivity and spectral resolution, is well su_         _ More           The origin and evolution of organic molecules represent a pivotal issue in the fields of astrobiology and astrochemistry, potentially shedding light on the origins of life. The James Webb Space Telescope (JWST), with its exceptional sensitivity and spectral resolution, is well suitable to observe molecules such as methane ($\\rm CH_4$). Our analysis focused on the distribution of $\\rm CH_4$, $\\rm CO_2$, $\\rm H_2O$, $\\rm{CH_3OH+NH_4^+}$ ice and silicate absorption dips at approximately 7.7, 15.0, 6.0, 6.7 and 10.0 micrometres in two protostars: IRAS 16253-2429 and IRAS 23385+6053. We extract the $\\rm CH_4$, $\\rm CO_2$, $\\rm H_2O$, $\\rm{CH_3OH+NH_4^+}$ ice equivalent width (EW) maps and silicate extinction maps of the two sources. Our results reveal that the spatial distribution of $\\rm CH_4$ in the protostellar system IRAS 16253-2429 closely mirrors that of its $\\rm CO_2$ ice, forming a surrounded distribution that encircles the central protostar. This alignment suggests a common formation mechanism and subsequent trapping within the protostellar envelope, which is consistent with the 'Classical' dark-cloud chemistry with ion-molecule reaction. In contrast, the spatial distributions of various molecules in the system IRAS 23385+6053 exhibit low similarities, which may be attributed to the dynamic influences of outflows or accretion processes. These discrepancies highlight the complex interplay between physical processes and chemical evolution in protostellar environments.         _ Less","","arXiv","https://arxiv.org/abs/2409.04217","2","1","origin_of_life"
"Feature Compression for Cloud-Edge Multimodal 3D Object Detection","Abstract:                Machine vision systems, which can efficiently manage extensive visual perception tasks, are becoming increasingly popular in industrial production and daily life. Due to the challenge of simultaneously obtaining accurate depth and texture information with a single sensor, multimodal data captured by cameras and LiDAR is commonly used to enhance performance._         _ More           Machine vision systems, which can efficiently manage extensive visual perception tasks, are becoming increasingly popular in industrial production and daily life. Due to the challenge of simultaneously obtaining accurate depth and texture information with a single sensor, multimodal data captured by cameras and LiDAR is commonly used to enhance performance. Additionally, cloud-edge cooperation has emerged as a novel computing approach to improve user experience and ensure data security in machine vision systems. This paper proposes a pioneering solution to address the feature compression problem in multimodal 3D object detection. Given a sparse tensor-based object detection network at the edge device, we introduce two modes to accommodate different application requirements: Transmission-Friendly Feature Compression (T-FFC) and Accuracy-Friendly Feature Compression (A-FFC). In T-FFC mode, only the output of the last layer of the network's backbone is transmitted from the edge device. The received feature is processed at the cloud device through a channel expansion module and two spatial upsampling modules to generate multi-scale features. In A-FFC mode, we expand upon the T-FFC mode by transmitting two additional types of features. These added features enable the cloud device to generate more accurate multi-scale features. Experimental results on the KITTI dataset using the VirConv-L detection network showed that T-FFC was able to compress the features by a factor of 6061 with less than a 3% reduction in detection performance. On the other hand, A-FFC compressed the features by a factor of about 901 with almost no degradation in detection performance. We also designed optional residual extraction and 3D object reconstruction modules to facilitate the reconstruction of detected objects. The reconstructed objects effectively reflected details of the original objects.         _ Less","","arXiv","https://arxiv.org/abs/2409.04123","1","0","origin_of_life"
"Transformations to simplify phylogenetic networks","Abstract:                _However, a tree fails to capture ancestral reticulate processes, such as the formation of hybrid species or lateral gene transfer events between lineages, and so the history of life is more accurately described by a rooted phylogenetic network. Nevertheless, phylogenetic networks may be complex and difficult to interpret, so biologists sometimes prefer a tr_         _ More           The evolutionary relationships between species are typically represented in the biological literature by rooted phylogenetic trees. However, a tree fails to capture ancestral reticulate processes, such as the formation of hybrid species or lateral gene transfer events between lineages, and so the history of life is more accurately described by a rooted phylogenetic network. Nevertheless, phylogenetic networks may be complex and difficult to interpret, so biologists sometimes prefer a tree that summarises the central tree-like trend of evolution. In this paper, we formally investigate methods for transforming an arbitrary phylogenetic network into a tree (on the same set of leaves) and ask which ones (if any) satisfy a simple consistency condition. This consistency condition states that if we add additional species into a phylogenetic network (without otherwise changing this original network) then transforming this enlarged network into a rooted phylogenetic tree induces the same tree on the original set of species as transforming the original network. We show that the LSA (lowest stable ancestor) tree method satisfies this consistency property, whereas several other commonly used methods (and a new one we introduce) do not. We also briefly consider transformations that convert arbitrary phylogenetic networks to another simpler class, namely normal networks.         _ Less","","arXiv","https://arxiv.org/abs/2408.16156","1","2","synthetic_biology"
"Key Science Goals for the Next Generation Very Large Array (ngVLA): Update from the ngVLA Science Advisory Council (2024)","Abstract:                _by any other facility, represent a small subset of the broad range of astrophysical problems that the ngVLA will be able address. This document presents an update to the original ngVLA KSGs, taking account of new results and progress in the 7+ years since their initial presentation, again drawing on the expertise of the ngVLA Science Advisory Council and the_         _ More           In 2017, the next generation Very Large Array (ngVLA) Science Advisory Council, together with the international astronomy community, developed a set of five Key Science Goals (KSGs) to inform, prioritize and refine the technical capabilities of a future radio telescope array for high angular resolution operation from 1.2 - 116 GHz with 10 times the sensitivity of the Jansky VLA and ALMA. The resulting KSGs, which require observations at centimeter and millimeter wavelengths that cannot be achieved by any other facility, represent a small subset of the broad range of astrophysical problems that the ngVLA will be able address. This document presents an update to the original ngVLA KSGs, taking account of new results and progress in the 7+ years since their initial presentation, again drawing on the expertise of the ngVLA Science Advisory Council and the broader community in the ngVLA Science Working Groups. As the design of the ngVLA has also matured substantially in this period, this document also briefly addresses initial expectations for ngVLA data products and processing that will be needed to achieve the KSGs. The original ngVLA KSGs endure as outstanding problems of high priority. In brief, they are: (1) Unveiling the Formation of Solar System Analogues; (2) Probing the Initial Conditions for Planetary Systems and Life with Astrochemistry; (3) Charting the Assembly, Structure, and Evolution of Galaxies from the First Billion Years to the Present; (4) Science at the Extremes: Pulsars as Laboratories for Fundamental Physics; (5) Understanding the Formation and Evolution of Stellar and Supermassive Black Holes in the Era of Multi-Messenger Astronomy.         _ Less","","arXiv","https://arxiv.org/abs/2408.14497","1","1","multiple"
"Unveiling the chemical fingerprint of phosphorus-rich stars II. Heavy-element abundances from UVES/VLT spectra","Abstract:                The atmospheres of phosphorus-rich stars have been shown to contain between 10 and 100 times more P than our Sun. Given its crucial role as an essential element for life, it is especially necessary to uncover the_         _ More           The atmospheres of phosphorus-rich stars have been shown to contain between 10 and 100 times more P than our Sun. Given its crucial role as an essential element for life, it is especially necessary to uncover the origin of P-rich stars to gain insights into the still unknown nucleosynthetic formation pathways of P in our Galaxy. Our objective is to obtain the extensive chemical abundance inventory of four P-rich stars, covering a large range of heavy elements. This characterization will serve as a milestone for the nuclear astrophysics community to uncover the processes that form the unique chemical fingerprint of P-rich stars. We performed a detailed 1D local thermodynamic equilibrium abundance analysis on the optical UVES spectra of four P-rich stars. Our focus lay on the neutron-capture elements, in particular, on the elements between Sr and Ba, as well as on Pb, as they provide valuable constraints to nucleosynthesis calculations. We compare the obtained abundances with three different nucleosynthetic scenarios: a single i-process, a double i-process, and a combination of s- and i-processes. We have performed the most extensive abundance analysis of P-rich stars to date, including the elements between Sr and Ba, such as Ag, which are rarely measured in any type of stars. We found overabundances with respect to solar in the s-process peak elements, accompanied by an extremely high Ba abundance and slight enhancements in some elements between Rb and Sn. No global solution explaining all four stars could be found for the nucleosynthetic origin of the pattern. The model that produces the least number of discrepancies in three of the four stars is a combination of s- and i-processes, but the current lack of extensive multidimensional hydrodynamic simulations to follow the occurrence of the i-process in different types of stars makes this scenario highly uncertain.         _ Less","","arXiv","https://arxiv.org/abs/2408.12938","1","0","origin_of_life"
"Self-Organization in Computation & Chemistry: Return to AlChemy","Abstract:                How do complex adaptive systems, such as life, emerge from simple constituent parts? In the 1990s Walter Fontana and Leo Buss proposed a novel modeling approach to this question, based on a formal model of computation known as $_$ calculus. The model demonstrated how simple rules, embedded in a combinatorially large space of possibilities, could yield comple_         _ More           How do complex adaptive systems, such as life, emerge from simple constituent parts? In the 1990s Walter Fontana and Leo Buss proposed a novel modeling approach to this question, based on a formal model of computation known as $_$ calculus. The model demonstrated how simple rules, embedded in a combinatorially large space of possibilities, could yield complex, dynamically stable organizations, reminiscent of biochemical reaction networks. Here, we revisit this classic model, called AlChemy, which has been understudied over the past thirty years. We reproduce the original results and study the robustness of those results using the greater computing resources available today. Our analysis reveals several unanticipated features of the system, demonstrating a surprising mix of dynamical robustness and fragility. Specifically, we find that complex, stable organizations emerge more frequently than previously expected, that these organizations are robust against collapse into trivial fixed-points, but that these stable organizations cannot be easily combined into higher order entities. We also study the role played by the random generators used in the model, characterizing the initial distribution of objects produced by two random expression generators, and their consequences on the results. Finally, we provide a constructive proof that shows how an extension of the model, based on typed $_$ calculus, could simulate transitions between arbitrary states in any possible chemical reaction network, thus indicating a concrete connection between AlChemy and chemical reaction networks. We conclude with a discussion of possible applications of AlChemy to self-organization in modern programming languages and quantitative approaches to the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2408.12137","1","2","synthetic_biology"
"A dynamical systems perspective on the celestial mechanical contribution to the emergence of life","Abstract:                Biological activities are often seen entrained onto the day-night and other celestial mechanical cycles (e.g., seasonal and lunar), but studies on the origin of_         _ More           Biological activities are often seen entrained onto the day-night and other celestial mechanical cycles (e.g., seasonal and lunar), but studies on the origin of life have largely not accounted for such periodic external environmental variations. We argue that this may be an important omission, because the signature replication behaviour of life represents temporal memory in the dynamics of ecosystems, that signifies the absence of mixing properties (i.e., the dynamics are not fully chaotic), and entrainment onto regular, periodic external perturbative influences has been proven capable of suppressing chaos, and thus may bring otherwise unstable chemical reaction sets into viability, as precursors to abiogenesis. As well, external perturbations may be necessary to prevent an open dissipative (bio)chemical system from collapsing into the opposite extreme -- the point attractor of thermal equilibrium. In short, life may precariously rest on the edge of chaos, and open-loop periodic perturbation rooted in celestial mechanics (and should be simulated in laboratory experiments in origin-of-life studies) may help with the balancing. Such considerations, if pertinent, would also be consequential to exobiology, e.g., in regard to tidal-locking properties of potential host worlds.         _ Less","","arXiv","https://arxiv.org/abs/2408.10544","3","0","origin_of_life"
"A reassessment of the 'hard-steps' model for the evolution of intelligent life","Abstract:                According to the 'hard-steps' model, the origin of humanity required 'successful passage through a number of intermediate steps' (so-called 'hard' or 'critical' steps) that were intrinsically improbable with respect to the total time available for biological evolution on Earth. This model similarly predicts that technological_         _ More           According to the 'hard-steps' model, the origin of humanity required 'successful passage through a number of intermediate steps' (so-called 'hard' or 'critical' steps) that were intrinsically improbable with respect to the total time available for biological evolution on Earth. This model similarly predicts that technological life analogous to human life on Earth is 'exceedingly rare' in the universe. Here, we critically reevaluate the core assumptions of the hard-steps model in light of recent advances in the Earth and life sciences. Specifically, we advance a potential alternative model where there are no hard steps, and evolutionary novelties (or singularities) required for human origins can be explained via mechanisms outside of intrinsic improbability. Furthermore, if Earth's surface environment was initially inhospitable not only to human life, but also to certain key intermediate steps in human evolution (e.g., the origin of eukaryotic cells, multicellular animals), then the 'delay' in the appearance of humans can be best explained through the sequential opening of new global environmental windows of habitability over Earth history, with humanity arising relatively quickly once the right conditions were established. In this co-evolutionary (or geobiological) scenario, humans did not evolve 'early' or 'late' with respect to the total lifespan of the biosphere, but 'on time.'         _ Less","","arXiv","https://arxiv.org/abs/2408.10293","0","1","synthetic_biology"
"AutoML-guided Fusion of Entity and LLM-based Representations for Document Classification","Abstract:                _learning (AutoML) with the fused representation space, we demonstrate it is possible to improve classification accuracy even if we use low-dimensional projections of the original representation space obtained via efficient matrix factorization. This result shows that significantly faster classifiers can be achieved with minimal or no loss in predictive perfo_         _ More           Large semantic knowledge bases are grounded in factual knowledge. However, recent approaches to dense text representations (i.e. embeddings) do not efficiently exploit these resources. Dense and robust representations of documents are essential for effectively solving downstream classification and retrieval tasks. This work demonstrates that injecting embedded information from knowledge bases can augment the performance of contemporary Large Language Model (LLM)-based representations for the task of text classification. Further, by considering automated machine learning (AutoML) with the fused representation space, we demonstrate it is possible to improve classification accuracy even if we use low-dimensional projections of the original representation space obtained via efficient matrix factorization. This result shows that significantly faster classifiers can be achieved with minimal or no loss in predictive performance, as demonstrated using five strong LLM baselines on six diverse real-life datasets. The code is freely available at \\url{https://github.com/bkolosk1/bablfusion.git}.         _ Less","","arXiv","https://arxiv.org/abs/2408.09794","1","0","origin_of_life"
"Formation of the interstellar sugar precursor, (Z)-1,2-ethenediol, through radical reactions on dust grains","Abstract:                In recent years, the continued detection of complex organic molecules of prebiotic interest has refueled the interest on a panspermic origin of life. The prebiotic molecule glyceraldehyde is proposed to be formed from (Z)-1,2-ethenediol, a molecule recently detected towards the G+0.693-0.027 molecular cloud at the gala_         _ More           In recent years, the continued detection of complex organic molecules of prebiotic interest has refueled the interest on a panspermic origin of life. The prebiotic molecule glyceraldehyde is proposed to be formed from (Z)-1,2-ethenediol, a molecule recently detected towards the G+0.693-0.027 molecular cloud at the galactic center. In this work, we computationally simulate the formation of (Z)-1,2-ethenediol from vinyl alcohol on the surface of amorphous solid water in a two-step synthesis involving a OH addition and a H abstraction reaction. In total, we considered all reaction possibilities of the 1,1 and 1,2-OH addition to vinyl alcohol followed by H-abstraction or H-addition reactions on the resulting radicals. The combination of these reactions is capable of explaining the formation of (Z)-1,2-ethenediol provided a suprathermal diffusion of OH. We also conclude that our proposed formation pathway is not selective and also yields other abstraction and addition products. Key in our findings is the connection between the adsorption modes of the reactants and intermediates and the stereoselectivity of the reactions.         _ Less","","arXiv","https://arxiv.org/abs/2408.08608","3","0","origin_of_life"
"A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites","Abstract:                _a limited view of LLMs' performance in real-world software development scenarios. Moreover, previous studies do not approach the problem at a suitable scale for real-life applications. Generated unit tests are often evaluated via manual integration into the_         _ More           Unit tests represent the most basic level of testing within the software testing lifecycle and are crucial to ensuring software correctness. Designing and creating unit tests is a costly and labor-intensive process that is ripe for automation. Recently, Large Language Models (LLMs) have been applied to various aspects of software development, including unit test generation. Although several empirical studies evaluating LLMs' capabilities in test code generation exist, they primarily focus on simple scenarios, such as the straightforward generation of unit tests for individual methods. These evaluations often involve independent and small-scale test units, providing a limited view of LLMs' performance in real-world software development scenarios. Moreover, previous studies do not approach the problem at a suitable scale for real-life applications. Generated unit tests are often evaluated via manual integration into the original projects, a process that limits the number of tests executed and reduces overall efficiency. To address these gaps, we have developed an approach for generating and evaluating more real-life complexity test suites. Our approach focuses on class-level test code generation and automates the entire process from test generation to test assessment. In this work, we present AgoneTest: an automated system for generating test suites for Java projects and a comprehensive and principled methodology for evaluating the generated test suites. Starting from a state-of-the-art dataset (i.e., Methods2Test), we built a new dataset for comparing human-written tests with those generated by LLMs. Our key contributions include a scalable automated software system, a new dataset, and a detailed methodology for evaluating test quality.         _ Less","","arXiv","https://arxiv.org/abs/2408.07846","1","1","multiple"
"Dwellers in the Deep: Biological Consequences of Dark Oxygen","Abstract:                _km depth raises the intriguing scenario that complex (i.e., animal-like) life could exist in underwater environments sans oxygenic photosynthesis. In this work, we thus explore the possible (astro)biological implications of this discovery. From the available data, we roughly estimate the concentration of dissolved O$_2$ and the corresponding O$_2$ partial p_         _ More           The striking recent putative detection of 'dark oxygen' (dark O$_2$) sources on the abyssal ocean floor in the Pacific at $\\sim 4$ km depth raises the intriguing scenario that complex (i.e., animal-like) life could exist in underwater environments sans oxygenic photosynthesis. In this work, we thus explore the possible (astro)biological implications of this discovery. From the available data, we roughly estimate the concentration of dissolved O$_2$ and the corresponding O$_2$ partial pressure, as well as the flux of O$_2$ production, associated with dark oxygen sources. Based on these values, we infer that organisms limited by internal diffusion may reach maximal sizes of $\\sim 0.1-1$ mm in habitats with dark O$_2$, while those with circulatory systems might achieve sizes of $\\sim 0.1-10$ cm. Optimistically, the estimated dark oxygen flux can potentially support biomass densities up to $\\sim 3-30$ g m$^{-2}$, perhaps surpassing typical reported densities at similar depths in global deep-sea surveys. Finally, we outline how oceanic settings with dark O$_2$ may facilitate the origin(s) of life via the emergence of electrotrophy. Our findings indicate that complex life fueled by dark oxygen is plausibly capable of inhabiting submarine environments devoid of photosynthesis on Earth, conceivably extending likewise to extraterrestrial locations such as icy worlds with subsurface oceans (e.g., Enceladus and Europa), which are likely common throughout the Universe.         _ Less","","arXiv","https://arxiv.org/abs/2408.06841","2","1","origin_of_life"
"On the decay properties of the neutron-deficient isotope 242Es","Abstract:                _Au. A half-life of 16.9(8)~s was deduced from 662 $_$ decays of $^{242}$Es, resulting in an $_$-decay branching of 41(3)\\%. Twenty-six fission events with a half-life of 18.2$^{+4.5}_{-3.0}$~s were assigned to originate from the electron-capture delayed fission of $^{242}$Es. The_         _ More           The radioactive decay properties of $^{242}$Es were studied with significantly improved statistics compared to available literature data. This isotope was produced in the 3n evaporation channel of the fusion reaction of $^{48}$Ca+$^{197}$Au. A half-life of 16.9(8)~s was deduced from 662 $_$ decays of $^{242}$Es, resulting in an $_$-decay branching of 41(3)\\%. Twenty-six fission events with a half-life of 18.2$^{+4.5}_{-3.0}$~s were assigned to originate from the electron-capture delayed fission of $^{242}$Es. The probability for the electron-capture delayed fission was measured to be 0.015(4), which improves and resolves ambiguities in available experimental data. We discuss all known cases for electron-capture delayed fission in Es, Bk, and Am isotopes and compare experimental data with predictions from a recent semi-empirical model. A cross section of 27(3)~nb was measured for the production of $^{242}$Es.         _ Less","","arXiv","https://arxiv.org/abs/2408.01714","0","1","synthetic_biology"
"Data-driven physics-based modeling of pedestrian dynamics","Abstract:                _statistical properties of pedestrian dynamics in simple settings, such as almost straight trajectories. However, modeling more complex dynamics, e.g. when multiple routes and origin-destinations are involved, remains a significant challenge. In this work, we introduce a novel and generic framework to describe the dynamics of pedestrians in any geometric sett_         _ More           Pedestrian crowds encompass a complex interplay of intentional movements aimed at reaching specific destinations, fluctuations due to personal and interpersonal variability, and interactions with each other and the environment. Previous work showed the effectiveness of Langevin-like equations in capturing the statistical properties of pedestrian dynamics in simple settings, such as almost straight trajectories. However, modeling more complex dynamics, e.g. when multiple routes and origin-destinations are involved, remains a significant challenge. In this work, we introduce a novel and generic framework to describe the dynamics of pedestrians in any geometric setting, significantly extending previous works. Our model is based on Langevin dynamics with two timescales. The fast timescale corresponds to the stochastic fluctuations present when a pedestrian is walking. The slow timescale is associated with the dynamics that a pedestrian plans to follow, thus a smoother path. Employing a data-driven approach inspired by statistical field theories, we learn the complex potentials directly from the data, namely a high-statistics database of real-life pedestrian trajectories. This approach makes the model generic as the potentials can be read from any trajectory data set and the underlying Langevin structure enables physics-based insights. We validate our model through a comprehensive statistical analysis, comparing simulated trajectories with actual pedestrian measurements across five complementary settings, including a real-life train platform scenario, underscoring its practical societal relevance. We show that our model effectively captures fluctuation statistics in pedestrian motion. Beyond providing fundamental insights and predictive capabilities in pedestrian dynamics, our model could be used to investigate generic active dynamics such as vehicular traffic and collective animal behavior.         _ Less","","arXiv","https://arxiv.org/abs/2407.20794","1","1","multiple"
"Multi-Modal CLIP-Informed Protein Editing","Abstract:                Proteins govern most biological functions essential for life, but achieving controllable protein discovery and optimization remains challenging. Recently, machine learning-assisted protein editing (MLPE) has shown promise in accelerating optimization cycles and reducing experimental workloads. However, current methods struggle with the vast combinatorial spa_         _ More           Proteins govern most biological functions essential for life, but achieving controllable protein discovery and optimization remains challenging. Recently, machine learning-assisted protein editing (MLPE) has shown promise in accelerating optimization cycles and reducing experimental workloads. However, current methods struggle with the vast combinatorial space of potential protein edits and cannot explicitly conduct protein editing using biotext instructions, limiting their interactivity with human feedback. To fill these gaps, we propose a novel method called ProtET for efficient CLIP-informed protein editing through multi-modality learning. Our approach comprises two stages: in the pretraining stage, contrastive learning aligns protein-biotext representations encoded by two large language models (LLMs), respectively. Subsequently, during the protein editing stage, the fused features from editing instruction texts and original protein sequences serve as the final editing condition for generating target protein sequences. Comprehensive experiments demonstrated the superiority of ProtET in editing proteins to enhance human-expected functionality across multiple attribute domains, including enzyme catalytic activity, protein stability and antibody specific binding ability. And ProtET improves the state-of-the-art results by a large margin, leading to significant stability improvements of 16.67% and 16.90%. This capability positions ProtET to advance real-world artificial protein editing, potentially addressing unmet academic, industrial, and clinical needs.         _ Less","","arXiv","https://arxiv.org/abs/2407.19296","1","2","synthetic_biology"
"Statistics and Habitability of F-type Star--Planet Systems","Abstract:                _exolife. Examples of the latter include the increased widths of stellar habitable zones as well as the presence of enhanced UV flux, which in moderation may have added to the origin of life in the Universe. In this study, we pursue a detailed statistical analysis of the currently known planet-hosting F-type stars by ma_         _ More           F-type star--planet systems represent an intriguing case for habitability studies. Although F-type stars spend considerably less time on the main-sequence than G, K, and M-type stars, they still offer a unique set of features, allowing for the principal possibility of exolife. Examples of the latter include the increased widths of stellar habitable zones as well as the presence of enhanced UV flux, which in moderation may have added to the origin of life in the Universe. In this study, we pursue a detailed statistical analysis of the currently known planet-hosting F-type stars by making use of the NASA Exoplanet Archive. After disregarding systems with little or no information on the planet(s), we identify 206 systems of interest. We also evaluate whether the stars are on the main-sequence based on various criteria. In one approach, we use the stellar evolution code MESA. Depending on the adopted criterion, about 60 to 80 stars have been identified as main-sequence stars. In 18 systems, the planet spends at least part of its orbit within the stellar habitable zone. In one case, i.e., HD 111998, commonly known as 38 Vir, the planet is situated in the habitable zone at all times. Our work may serve as a basis for future studies, including studies on the existence of Earth-mass planets in F-type systems, as well as investigations of possibly habitable exomoons hosted by exo-Jupiters as the lowest-mass habitable zone planet currently identified has a mass estimate of 143 Earth masses.         _ Less","","arXiv","https://arxiv.org/abs/2407.15826","2","1","origin_of_life"
"Computational Astrochemistry Journey towards the molecular universe","Abstract:                _questions. Interstellar molecules profoundly influence the chemistry and physics of the interstellar medium (ISM), playing pivotal roles in planet formation and the emergence of life. Understanding their chemistry relies on theoretical approaches such as Density Functional Theory (DFT) and post-Hartree-Fock methods, which are essential for exploring pathways_         _ More           In astrochemistry, computational methods play a crucial role in addressing fundamental astronomical questions. Interstellar molecules profoundly influence the chemistry and physics of the interstellar medium (ISM), playing pivotal roles in planet formation and the emergence of life. Understanding their chemistry relies on theoretical approaches such as Density Functional Theory (DFT) and post-Hartree-Fock methods, which are essential for exploring pathways to molecular complexity and determining their interstellar abundances. Various theoretical methods investigate the formation of interstellar molecules in both gaseous and solid states. Molecules in interstellar space may originate from bottom-up processes (building up from CO molecules) or top-down processes (polycyclic aromatic hydrocarbon fragmentation). Here, we present a journey of theoretical investigations aimed at studying the reactivity of interstellar molecules in space.         _ Less","","arXiv","https://arxiv.org/abs/2407.15204","2","1","origin_of_life"
"The evolution of complexity and the transition to biochemical life","Abstract:                While modern physics and biology satisfactorily explain the passage from the Big Bang to the formation of Earth and the first cells to present-day life, respectively, the_         _ More           While modern physics and biology satisfactorily explain the passage from the Big Bang to the formation of Earth and the first cells to present-day life, respectively, the origins of biochemical life still remain an open question. Since life, as we know it, requires extremely long genetic polymers, any answer to the question must explain how an evolving system of polymers of ever-increasing length could come about on a planet that otherwise consisted only of small molecular building blocks. In this work, we show that, under realistic constraints, an abstract polymer model can exhibit dynamics such that attractors in the polymer population space with a higher average polymer length are also more probable. We generalize from the model and formalize the notions of complexity and evolution for chemical reaction networks with multiple attractors. The complexity of a species is defined as the minimum number of reactions needed to produce it from a set of building blocks, which in turn is used to define a measure of complexity for an attractor. A transition between attractors is considered to be a progressive evolution if the attractor with the higher probability also has a higher complexity. In an environment where only monomers are readily available, the attractor with a higher average polymer length is more complex. Thus, our abstract polymer model can exhibit progressive evolution for a range of thermodynamically plausible rate constants. We also formalize criteria for open-ended and historically-contingent evolution and explain the role of autocatalysis in obtaining them. Our work provides a basis for searching for prebiotically plausible scenarios in which long polymers can emerge and yield populations with even longer polymers.         _ Less","","arXiv","https://arxiv.org/abs/2407.11728","2","2","multiple"
"A Review of AI and Machine Learning Contribution in Predictive Business Process Management (Process Enhancement and Process Improvement Approaches)","Abstract:                _a systematic review of academic literature to investigate the integration of AI/ML in business process management (BPM). We categorize the literature according to the BPM life-cycle and employ bibliometric and objective-oriented methodology, to analyze related papers.   Findings- In business process management and process map, AI/ML has made significant impr_         _ More           Purpose- The significance of business processes has fostered a close collaboration between academia and industry. Moreover, the business landscape has witnessed continuous transformation, closely intertwined with technological advancements. Our main goal is to offer researchers and process analysts insights into the latest developments concerning Artificial Intelligence (AI) and Machine Learning (ML) to optimize their processes in an organization and identify research gaps and future directions in the field. Design/methodology/approach- In this study, we perform a systematic review of academic literature to investigate the integration of AI/ML in business process management (BPM). We categorize the literature according to the BPM life-cycle and employ bibliometric and objective-oriented methodology, to analyze related papers.   Findings- In business process management and process map, AI/ML has made significant improvements using operational data on process metrics. These developments involve two distinct stages: (1) process enhancement, which emphasizes analyzing process information and adding descriptions to process models, and (2) process improvement, which focuses on redesigning processes based on insights derived from analysis. Research limitations/implications- While this review paper serves to provide an overview of different approaches for addressing process-related challenges, it does not delve deeply into the intricacies of fine-grained technical details of each method. This work focuses on recent papers conducted between 2010 and 2024. Originality/value- This paper adopts a pioneering approach by conducting an extensive examination of the integration of AI/ML techniques across the entire process management lifecycle. Additionally, it presents groundbreaking research and introduces AI/ML-enabled integrated tools, further enhancing the insights for future research.         _ Less","","arXiv","https://arxiv.org/abs/2407.11043","3","2","origin_of_life"
"From Text to Life: On the Reciprocal Relationship between Artificial Life and Large Language Models","Abstract:                Large Language Models (LLMs) have taken the field of AI by storm, but their adoption in the field of Artificial Life (ALife) has been, so far, relatively reserved. In this work we investigate the potential synergies between LLMs and ALife, drawing on a large body of research in the two fields. We explore the potential of LLMs as tools for ALife research, for_         _ More           Large Language Models (LLMs) have taken the field of AI by storm, but their adoption in the field of Artificial Life (ALife) has been, so far, relatively reserved. In this work we investigate the potential synergies between LLMs and ALife, drawing on a large body of research in the two fields. We explore the potential of LLMs as tools for ALife research, for example, as operators for evolutionary computation or the generation of open-ended environments. Reciprocally, principles of ALife, such as self-organization, collective intelligence and evolvability can provide an opportunity for shaping the development and functionalities of LLMs, leading to more adaptive and responsive models. By investigating this dynamic interplay, the paper aims to inspire innovative crossover approaches for both ALife and LLM research. Along the way, we examine the extent to which LLMs appear to increasingly exhibit properties such as emergence or collective intelligence, expanding beyond their original goal of generating text, and potentially redefining our perception of lifelike intelligence in artificial systems.         _ Less","","arXiv","https://arxiv.org/abs/2407.09502","1","2","synthetic_biology"
"Novel second-order model for tumor evolution: description of cytostatic and cytotoxic effects","Abstract:                Cancer is a disease that takes millions of lives every year. Then, to propose treatments, avoid recurrence, and improve the patient's life quality, we need to analyze this disease from a biophysical perspective with a solid mathematical formulation. In this paper we introduce a novel deterministic model for the evolution of tumors under several condition_         _ More           Cancer is a disease that takes millions of lives every year. Then, to propose treatments, avoid recurrence, and improve the patient's life quality, we need to analyze this disease from a biophysical perspective with a solid mathematical formulation. In this paper we introduce a novel deterministic model for the evolution of tumors under several conditions (untreated tumors and treated tumors using chemotherapy). Our model is characterized by a second-order differential equation, whose origin and interpretation are presented by exploiting our understanding of fluid mechanics (via continuity equations) and the theory of differential equations. Additionally, we show that our model can fit various experimental data sets. Thus, we prove that our nuanced and general model can describe accelerated growth, as well as cytostatic and cytotoxic effects. All in all, our model opens up a new window in the understanding of tumor evolution and represents a promising connection between the macroscopic and microscopic descriptions of cancer.         _ Less","","arXiv","https://arxiv.org/abs/2407.05143","0","2","synthetic_biology"
"Novel Fuzzy Centrality Measures in Vague Social Networks","Abstract:                _individuals, these relationships are often imprecise, and identifying them with simple scalars leads to information loss. Indeed, social relationships are often vague in real life, and although previous research has proposed the use of fuzzy networks, these are typically characterized by crisp ties. The use of weighted links does not align with the_         _ More           Social network analysis (SNA) helps us understand the relationships and interactions between individuals, groups, organizations, or other social entities. In the literature, ties are generally considered binary or weighted based on their strength. Nonetheless, when the actors are individuals, these relationships are often imprecise, and identifying them with simple scalars leads to information loss. Indeed, social relationships are often vague in real life, and although previous research has proposed the use of fuzzy networks, these are typically characterized by crisp ties. The use of weighted links does not align with the original philosophy of fuzzy logic, which instead aims to preserve the vagueness inherent in human language and real life. For this reason, this paper proposes a generalization of the so-called Fuzzy Social Network Analysis (FSNA) to the context of imprecise relationships among actors. Dealing with imprecise ties and introducing fuzziness in the definition of relationships requires an extension of social network analysis, defining ties as fuzzy numbers instead of crisp values and extending classical centrality indices to fuzzy centrality indexes. The article presents the theory and application of real data collected through a fascinating mouse-tracking technique to study the fuzzy relationships in a collaboration network among the members of a university department.         _ Less","","arXiv","https://arxiv.org/abs/2407.02401","1","0","origin_of_life"
"Emergent Crowd Grouping via Heuristic Self-Organization","Abstract:                Modeling crowds has many important applications in games and computer animation. Inspired by the emergent following effect in real-life crowd scenarios, in this work, we develop a method for implicitly grouping moving agents. We achieve this by analyzing local information around each agent and rotating its preferred velocity accordingly. Each agent could aut_         _ More           Modeling crowds has many important applications in games and computer animation. Inspired by the emergent following effect in real-life crowd scenarios, in this work, we develop a method for implicitly grouping moving agents. We achieve this by analyzing local information around each agent and rotating its preferred velocity accordingly. Each agent could automatically form an implicit group with its neighboring agents that have similar directions. In contrast to an explicit group, there are no strict boundaries for an implicit group. If an agent's direction deviates from its group as a result of positional changes, it will autonomously exit the group or join another implicitly formed neighboring group. This implicit grouping is autonomously emergent among agents rather than deliberately controlled by the algorithm. The proposed method is compared with many crowd simulation models, and the experimental results indicate that our approach achieves the lowest congestion levels in some classic scenarios. In addition, we demonstrate that adjusting the preferred velocity of agents can actually reduce the dissimilarity between their actual velocity and the original preferred velocity. Our work is available online.         _ Less","","arXiv","https://arxiv.org/abs/2407.00674","1","1","multiple"
"Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction","Abstract:                The fields of Origin of_         _ More           The fields of Origin of Life and Artificial Life both question what life is and how it emerges from a distinct set of 'pre-life' dynamics. One common feature of most substrates where life emerges is a marked shift in dynamics when self-replication appears. While there are some hypotheses regarding how self-replicators arose in nature, we know very little about the general dynamics, computational principles, and necessary conditions for self-replicators to emerge. This is especially true on 'computational substrates' where interactions involve logical, mathematical, or programming rules. In this paper we take a step towards understanding how self-replicators arise by studying several computational substrates based on various simple programming languages and machine instruction sets. We show that when random, non self-replicating programs are placed in an environment lacking any explicit fitness landscape, self-replicators tend to arise. We demonstrate how this occurs due to random interactions and self-modification, and can happen with and without background random mutations. We also show how increasingly complex dynamics continue to emerge following the rise of self-replicators. Finally, we show a counterexample of a minimalistic programming language where self-replicators are possible, but so far have not been observed to arise.         _ Less","","arXiv","https://arxiv.org/abs/2406.19108","1","2","synthetic_biology"
"Consistent community detection in multi-layer networks with heterogeneous differential privacy","Abstract:                _of attention has been paid to the privacy issue in publishing network data. One of the critical challenges for data publishers is to preserve the topological structures of the original network while protecting sensitive information. In this paper, we propose a personalized edge flipping mechanism that allows data publishers to protect edge information based_         _ More           As network data has become increasingly prevalent, a substantial amount of attention has been paid to the privacy issue in publishing network data. One of the critical challenges for data publishers is to preserve the topological structures of the original network while protecting sensitive information. In this paper, we propose a personalized edge flipping mechanism that allows data publishers to protect edge information based on each node's privacy preference. It can achieve differential privacy while preserving the community structure under the multi-layer degree-corrected stochastic block model after appropriately debiasing, and thus consistent community detection in the privatized multi-layer networks is achievable. Theoretically, we establish the consistency of community detection in the privatized multi-layer network and show that better privacy protection of edges can be obtained for a proportion of nodes while allowing other nodes to give up their privacy. Furthermore, the advantage of the proposed personalized edge-flipping mechanism is also supported by its numerical performance on various synthetic networks and a real-life multi-layer network.         _ Less","","arXiv","https://arxiv.org/abs/2406.14772","1","0","origin_of_life"
"Multi-modal Transfer Learning between Biological Foundation Models","Abstract:                Biological sequences encode fundamental instructions for the building blocks of life, in the form of DNA, RNA, and proteins. Modeling these sequences is key to understand disease mechanisms and is an active research area in computational biology. Recently, Large Language Models have shown great promise in solving certain biological tasks but current approach_         _ More           Biological sequences encode fundamental instructions for the building blocks of life, in the form of DNA, RNA, and proteins. Modeling these sequences is key to understand disease mechanisms and is an active research area in computational biology. Recently, Large Language Models have shown great promise in solving certain biological tasks but current approaches are limited to a single sequence modality (DNA, RNA, or protein). Key problems in genomics intrinsically involve multiple modalities, but it remains unclear how to adapt general-purpose sequence models to those cases. In this work we propose a multi-modal model that connects DNA, RNA, and proteins by leveraging information from different pre-trained modality-specific encoders. We demonstrate its capabilities by applying it to the largely unsolved problem of predicting how multiple RNA transcript isoforms originate from the same gene (i.e. same DNA sequence) and map to different transcription expression levels across various human tissues. We show that our model, dubbed IsoFormer, is able to accurately predict differential transcript expression, outperforming existing methods and leveraging the use of multiple modalities. Our framework also achieves efficient transfer knowledge from the encoders pre-training as well as in between modalities. We open-source our model, paving the way for new multi-modal gene expression approaches.         _ Less","","arXiv","https://arxiv.org/abs/2406.14150","1","0","origin_of_life"
"Meta-Learning an Evolvable Developmental Encoding","Abstract:                _biological organisms, which is at the hear of biological complexity and evolvability. Additionally, the core of this process is fundamentally the same across nearly all forms of life, reflecting their shared evolutionary origin. Generative models have shown promise in being learnable representations for black-box optim_         _ More           Representations for black-box optimisation methods (such as evolutionary algorithms) are traditionally constructed using a delicate manual process. This is in contrast to the representation that maps DNAs to phenotypes in biological organisms, which is at the hear of biological complexity and evolvability. Additionally, the core of this process is fundamentally the same across nearly all forms of life, reflecting their shared evolutionary origin. Generative models have shown promise in being learnable representations for black-box optimisation but they are not per se designed to be easily searchable. Here we present a system that can meta-learn such representation by directly optimising for a representation's ability to generate quality-diversity. In more detail, we show our meta-learning approach can find one Neural Cellular Automata, in which cells can attend to different parts of a 'DNA' string genome during development, enabling it to grow different solvable 2D maze structures. We show that the evolved genotype-to-phenotype mappings become more and more evolvable, not only resulting in a faster search but also increasing the quality and diversity of grown artefacts.         _ Less","","arXiv","https://arxiv.org/abs/2406.09020","0","1","synthetic_biology"
"Familiar biological, chemical and physical events credibly evolve the Standard Genetic Code","Abstract:                The genetic code is profoundly shaped by an origin in ancient RNA-mediated interactions, needing an extended development to reach the Standard Genetic Code (SGC). That development can serially use RNA specificities, a ribonucleopeptide transition (RNPT), finally code escape and diaspora. An index of evolutionary plausibility based on least selection takes si_         _ More           The genetic code is profoundly shaped by an origin in ancient RNA-mediated interactions, needing an extended development to reach the Standard Genetic Code (SGC). That development can serially use RNA specificities, a ribonucleopeptide transition (RNPT), finally code escape and diaspora. An index of evolutionary plausibility based on least selection takes simultaneous account of speed and accuracy of evolution, identifying favored evolutions. Combining RNA world specificities allowed convergence of early coding to SGC assignments. Secondly, this was sufficient to launch a post-RNA-world RNPT. The RNPT allowed biosynthesis of complex amino acids, depending heavily on late code fusions between coexisting independent codes. Thirdly, escape from fluctuating, but highly-evolved codes of the RNPT applied a near-ideal selection for fastest-evolving and most accurate/useful genetic codes. Concurrently, a code and its microbial carrier suited to a free-living existence necessarily evolved. The established unity of life on Earth likely traces to SGC ascendancy during escape from the RNPT, and code diaspora.         _ Less","","arXiv","https://arxiv.org/abs/2406.08302","1","2","synthetic_biology"
"A Census of Sun's Ancestors and their Contributions to the Solar System Chemical Composition","Abstract:                _born up to the formation of the Solar System with a mass and metallicity like the Sun. This latter number will account for all the possible existing Solar Systems which can host life in the solar vicinity. We conclude that, among all the stars (from 0.8 to 100 M$_{\\odot}$) born and died from the beginning up to the Solar System formation epoch, which contrib_         _ More           In this work we compute the rates and numbers of different types of stars and phenomena (supernovae, novae, white dwarfs, merging neutron stars, black holes) that contributed to the chemical composition of the Solar System. This process is called 'chemical evolution'. In particular, we analyse the death rates of stars of all masses, dying either quiescently or explosively. These rates and total star numbers are computed in the context of a revised version of the two-infall model for the chemical evolution of the Milky Way, which reproduces fairly well the observed abundance patterns of several chemical species, the global solar metallicity, and the current gas, stellar, and total surface mass densities. We compute also the total number of stars ever born and still alive as well as the number of stars born up to the formation of the Solar System with a mass and metallicity like the Sun. This latter number will account for all the possible existing Solar Systems which can host life in the solar vicinity. We conclude that, among all the stars (from 0.8 to 100 M$_{\\odot}$) born and died from the beginning up to the Solar System formation epoch, which contributed to its chemical composition, 93.00\\% are represented by stars dying as single white dwarfs (without interacting significantly with a companion star) and originating in the mass range 0.8-8 M$_{\\odot}$, while 5.24$\\%$ are neutron stars and 0.73$\\%$ are black holes, both originating from supernovae core-collapse (M > 8 M$_{\\odot}$); 0.64$\\%$ are Type Ia supernovae and 0.40$\\%$ are nova systems, both originating from the same mass range as the white dwarfs. The number of stars similar to the Sun born from the beginning up to the Solar System formation, with metallicity in the range 12+log(Fe/H)= 7.50 $\\pm$ 0.04 dex is $ \\sim 31 \\cdot$ 10$^{7}$, and in particular our Sun is the $\\sim 2.61 \\cdot$ 10$^7$-th star of this kind.         _ Less","","arXiv","https://arxiv.org/abs/2406.08036","2","1","origin_of_life"
"Deep Search for Phosphine in a Prestellar Core","Abstract:                _in which chemical forms phosphorus exists in star- and planet-forming regions and how phosphorus is delivered to planets are of great interest from the viewpoint of the origin of life on Earth. Phosphine (PH3) is thought to be a key species to understanding phosphorus chemistry, but never has been detected in star- and_         _ More           Understanding in which chemical forms phosphorus exists in star- and planet-forming regions and how phosphorus is delivered to planets are of great interest from the viewpoint of the origin of life on Earth. Phosphine (PH3) is thought to be a key species to understanding phosphorus chemistry, but never has been detected in star- and planet-forming regions. We performed sensitive observations of the ortho-PH3 $1_0-0_0$ transition (266.944 GHz) toward the low-mass prestellar core L1544 with the ACA stand-alone mode of ALMA. The line was not detected down to 3$_$ levels in 0.07 km s$^{-1}$ channels of 18 mK. The non-detection provides the upper limit to the gas-phase PH3 abundance of $5\\times10^{-12}$ with respect to H2 in the central part of the core. Based on the gas-ice astrochemical modeling, we find the scaling relationship between the gas-phase PH3 abundance and the volatile (gas and ice with larger volatility than water) P elemental abundance for given physical conditions. This characteristic and well-constrained physical properties of L1544 allow us to constrain the upper limit to the volatile P elemental abundance of $5\\times10^{-9}$, which is a factor of 60 lower than the overall P abundance in the ISM. Then the majority of P should exist in refractory forms. The volatile P elemental abundance of L1544 is smaller than that in the coma of comet 67P/C-G, implying that the conversion of refractory phosphorus to volatile phosphorus could have occurred along the trail from the presolar core to the protosolar disk through e.g., sputtering by accretion/outflow shocks.         _ Less","","arXiv","https://arxiv.org/abs/2406.05978","1","0","origin_of_life"
"Towards Naturalistic Voice Conversion: NaturalVoices Dataset with an Automatic Processing Pipeline","Abstract:                Voice conversion (VC) research traditionally depends on scripted or acted speech, which lacks the natural spontaneity of real-life conversations. While natural speech data is limited for VC, our study focuses on filling in this gap. We introduce a novel data-sourcing pipeline that makes the release of a natural speech dataset for VC, named NaturalVoices. The_         _ More           Voice conversion (VC) research traditionally depends on scripted or acted speech, which lacks the natural spontaneity of real-life conversations. While natural speech data is limited for VC, our study focuses on filling in this gap. We introduce a novel data-sourcing pipeline that makes the release of a natural speech dataset for VC, named NaturalVoices. The pipeline extracts rich information in speech such as emotion and signal-to-noise ratio (SNR) from raw podcast data, utilizing recent deep learning methods and providing flexibility and ease of use. NaturalVoices marks a large-scale, spontaneous, expressive, and emotional speech dataset, comprising over 3,800 hours speech sourced from the original podcasts in the MSP-Podcast dataset. Objective and subjective evaluations demonstrate the effectiveness of using our pipeline for providing natural and expressive data for VC, suggesting the potential of NaturalVoices for broader speech generation tasks.         _ Less","","arXiv","https://arxiv.org/abs/2406.04494","1","0","origin_of_life"
"The potential fluctuation and its interfacial phenomena in molecular, micro, macro, and cosmic flow instabilities","Abstract:                _formation of clouds in sky, waves on ocean, to inertial confinement fusion capsules, making fusion energy a viable alternative energy source in the future. The potential for life is directly related to flow instability mixing as well. Previous researchers have focused on developed stages of flow instabilities by assuming sine wave interface between fluids i_         _ More           Flow instabilities play important roles in a wide range of engineering, geophysical, and astrophysical flows, ranging from supernova explosion in crab nebula, formation of clouds in sky, waves on ocean, to inertial confinement fusion capsules, making fusion energy a viable alternative energy source in the future. The potential for life is directly related to flow instability mixing as well. Previous researchers have focused on developed stages of flow instabilities by assuming sine wave interface between fluids in the flow instabilities. No scientific research has been reported to investigate the origin of flow instabilities. The paper advances a new physics concept, potential fluctuation in flow based on the conservation of mass, which presents potential oscillatory sine wave surface in the spatial and temporal dimensions at the interface of flow instabilities. Potential fluctuation is decided by the two densities and velocities in the flow as indicated by the relation of continuity. Even before the flow instabilities start to develop, potential fluctuation has already internally existed in flow. It is only decided by the densities and velocities of the two moving fluids and is not related to the surface topography of the boundary of flows in the flow instability. It is the gene of flow instability. The paper presents breakthrough of understanding of micro, macro, and cosmic flow instabilities.         _ Less","","arXiv","https://arxiv.org/abs/2406.02586","1","0","origin_of_life"
"What no one has seen before: gravitational waveforms from warp drive collapse","Abstract:                Despite originating in science fiction, warp drives have a concrete description in general relativity, with Alcubierre first proposing a spacetime metric that supported faster-than-light travel. Whilst there are numerous practical barriers to their implementation in real_         _ More           Despite originating in science fiction, warp drives have a concrete description in general relativity, with Alcubierre first proposing a spacetime metric that supported faster-than-light travel. Whilst there are numerous practical barriers to their implementation in real life, including a requirement for negative energy, computationally, one can simulate their evolution in time given an equation of state describing the matter. In this work, we study the signatures arising from a warp drive 'containment failure', assuming a stiff equation of state for the fluid. We compute the emitted gravitational-wave signal and track the energy fluxes of the fluid. Apart from its rather speculative application to the search for extraterrestrial life in gravitational-wave detector data, this work is interesting as a study of the dynamical evolution and stability of spacetimes that violate the null energy condition. Our work highlights the importance of exploring strange new spacetimes, to (boldly) simulate what no one has seen before.         _ Less","","arXiv","https://arxiv.org/abs/2406.02466","0","1","synthetic_biology"
"On the Origin of Llamas: Model Tree Heritage Recovery","Abstract:                _data modality. However, this information is underutilized as the weights are uninterpretable, and publicly available models are disorganized. Inspired by Darwin's tree of life, we define the Model Tree which describes the origin of models i.e., the parent model that was used to fine-tune the target model. Similarly_         _ More           The rapid growth of neural network models shared on the internet has made model weights an important data modality. However, this information is underutilized as the weights are uninterpretable, and publicly available models are disorganized. Inspired by Darwin's tree of life, we define the Model Tree which describes the origin of models i.e., the parent model that was used to fine-tune the target model. Similarly to the natural world, the tree structure is unknown. In this paper, we introduce the task of Model Tree Heritage Recovery (MoTHer Recovery) for discovering Model Trees in the ever-growing universe of neural networks. Our hypothesis is that model weights encode this information, the challenge is to decode the underlying tree structure given the weights. Beyond the immediate application of model authorship attribution, MoTHer recovery holds exciting long-term applications akin to indexing the internet by search engines. Practically, for each pair of models, this task requires: i) determining if they are related, and ii) establishing the direction of the relationship. We find that certain distributional properties of the weights evolve monotonically during training, which enables us to classify the relationship between two given models. MoTHer recovery reconstructs entire model hierarchies, represented by a directed tree, where a parent model gives rise to multiple child models through additional training. Our approach successfully reconstructs complex Model Trees, as well as the structure of 'in-the-wild' model families such as Llama 2 and Stable Diffusion.         _ Less","","arXiv","https://arxiv.org/abs/2405.18432","1","1","multiple"
"The expected evolution of the binary system PTF J2238+743015.1","Abstract:                _which the entire accreted matter is lost from the system. Due to mixing of chemicals by rotation-induced instabilities during the accretion phase, H-flashes occur inside the original WD. Hence, pulse-by pulse, the accretor mass is reduced down to 0.7453Msun. When He-rich matter is transferred, He-detonation does not occur in the rotating WD, which undergoes_         _ More           Binary systems made by a low-mass CO WD and a He-donor represent possible progenitors of explosive events via He-detonation, producing low-luminosity thermonuclear Supernovae with a peculiar nucleosynthetis. Recently, the binary system PTF J223857.11+743015.1 has been suggested as one. We investigate the evolution of the PTF J223857.11+743015.1 system, composed by a 0.75Msun CO WD and a 0.390Msun subdwarf, capped by a thin H-rich layer, considering rotation of the WD component. We compute the evolution of two stars simultaneously, accounting for the possible evolution of the orbital parameters, as determined by mass transfer between components and by mass ejection from the system during RLOF episodes. We consider that the WD gains angular momentum due to accretion and we follow the evolution of the angular velocity profile as due to angular momentum transport via convection and rotation-induced instabilities. As the donor H-rich envelope is transferred, the WD experiences recurrent very strong H-flashes triggering RLOF episodes during which the entire accreted matter is lost from the system. Due to mixing of chemicals by rotation-induced instabilities during the accretion phase, H-flashes occur inside the original WD. Hence, pulse-by pulse, the accretor mass is reduced down to 0.7453Msun. When He-rich matter is transferred, He-detonation does not occur in the rotating WD, which undergoes 6 very strong He-flashes and subsequent RLOF episodes. Also in this case, due to rotation-induced mixing of the accreted layers with the underlying core, the WD is eroded. Finally, when the mass transfer rate from the donor decreases, a massive He-buffer is piled-up onto the accretor which ends its life as a cooling WD. The binary system PTF J2238+743015.1 as all those binaries having similar components masses and orbital parameters are not good candidates as thermonuclear explosions progenitors.         _ Less","","arXiv","https://arxiv.org/abs/2405.17896","0","1","synthetic_biology"
"Single Aperture Large Telescope for Universe Studies (SALTUS): Science Overview","Abstract:                The SALTUS Probe mission will provide a powerful far-infrared (far-IR) pointed space observatory to explore our cosmic origins and the possibility of life elsewhere. The observatory employs an innovative deployable 14-m aperture, with a sunshield that will radiatively cool the off-axis primary to <45K. This cooled p_         _ More           The SALTUS Probe mission will provide a powerful far-infrared (far-IR) pointed space observatory to explore our cosmic origins and the possibility of life elsewhere. The observatory employs an innovative deployable 14-m aperture, with a sunshield that will radiatively cool the off-axis primary to <45K. This cooled primary reflector works in tandem with cryogenic coherent and incoherent instruments that span the 34 to 660 micron far-IR range at both high and moderate spectral resolutions.         _ Less","","arXiv","https://arxiv.org/abs/2405.12829","1","1","multiple"
"A minimal scenario for the origin of non-equilibrium order","Abstract:                Extant life contains numerous non-equilibrium mechanisms to create order not achievable at equilibrium; it is generally assumed that these mechanisms evolved because the resulting order was sufficiently beneficial to overcome associated costs of time and energy. Here, we identify a broad range of conditions under which non-equilibrium order-creating mechanis_         _ More           Extant life contains numerous non-equilibrium mechanisms to create order not achievable at equilibrium; it is generally assumed that these mechanisms evolved because the resulting order was sufficiently beneficial to overcome associated costs of time and energy. Here, we identify a broad range of conditions under which non-equilibrium order-creating mechanisms will evolve as an inevitable consequence of self-replication, even if the order is not directly functional. We show that models of polymerases, when expanded to include known stalling effects, can evolve kinetic proofreading through selection for fast replication alone, consistent with data from recent mutational screens. Similarly, replication contingent on fast self-assembly can select for non-equilibrium instabilities and result in more ordered structures without any direct selection for order. We abstract these results into a framework that predicts that self-replication intrinsically amplifies dissipative order-enhancing mechanisms if the distribution of replication times is wide enough. Our work suggests the intriguing possibility that non-equilibrium order can arise more easily than assumed, even before that order is directly functional, with consequences impacting such diverse phenomena as the evolution of mutation rates, kinetic traps in self-assembly, and the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2405.10911","1","3","synthetic_biology"
"Formation of extraterrestrial peptides and their derivatives","Abstract:                _precursors, due to the condensation of atomic carbon under the low-temperature conditions of the molecular phases of the interstellar medium, opens alternative pathways for the origin of life. We perform peptide synthesis under conditions prevailing in space and provide a comprehensive analytic characterization of its_         _ More           The formation of protein precursors, due to the condensation of atomic carbon under the low-temperature conditions of the molecular phases of the interstellar medium, opens alternative pathways for the origin of life. We perform peptide synthesis under conditions prevailing in space and provide a comprehensive analytic characterization of its products. The application of 13C allowed us to confirm the suggested pathway of peptide formation that proceeds due to the polymerization of aminoketene molecules that are formed in the C + CO + NH3 reaction. Here, we address the question of how the efficiency of peptide production is modified by the presence of water molecules. We demonstrate that although water slightly reduces the efficiency of polymerization of aminoketene, it does not prevent the formation of peptides.         _ Less","","arXiv","https://arxiv.org/abs/2405.00744","3","1","origin_of_life"
"Service Level Agreements and Security SLA: A Comprehensive Survey","Abstract:                _mitigating risks, and building trust. This survey paper identifies state of the art covering concepts, approaches, and open problems of SLA management with a distinctive and original focus on the recent development of Security SLA (SecSLA). It contributes by carrying out a comprehensive review and covering the gap between the analyses proposed in existing s_         _ More           A Service Level Agreement (SLA) is a formal contract between a service provider and a consumer, representing a crucial instrument to define, manage, and maintain relationships between these two parties. The SLA's ability to define the Quality of Service (QoS) expectations, standards, and accountability helps to deliver high-quality services and increase client confidence in disparate application domains, such as Cloud computing and the Internet of Things. An open research direction in this context is related to the possible integration of new metrics to address the security and privacy aspects of services, thus providing protection of sensitive information, mitigating risks, and building trust. This survey paper identifies state of the art covering concepts, approaches, and open problems of SLA management with a distinctive and original focus on the recent development of Security SLA (SecSLA). It contributes by carrying out a comprehensive review and covering the gap between the analyses proposed in existing surveys and the most recent literature on this topic, spanning from 2017 to 2023. Moreover, it proposes a novel classification criterium to organize the analysis based on SLA life cycle phases. This original point of view can help both academics and industrial practitioners to understand and properly locate existing contributions in the advancement of the different aspects of SLA technology. The present work highlights the importance of the covered topics and the need for new research improvements to tackle present and demanding challenges.         _ Less","","arXiv","https://arxiv.org/abs/2405.00009","5","4","origin_of_life"
"Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment","Abstract:                _Anomaly Detection (VAD) identifies unusual activities in video streams, a key technology with broad applications ranging from surveillance to healthcare. Tackling VAD in real-life settings poses significant challenges due to the dynamic nature of human actions, environmental variations, and domain shifts. Many research initiatives neglect these complexities,_         _ More           Video Anomaly Detection (VAD) identifies unusual activities in video streams, a key technology with broad applications ranging from surveillance to healthcare. Tackling VAD in real-life settings poses significant challenges due to the dynamic nature of human actions, environmental variations, and domain shifts. Many research initiatives neglect these complexities, often concentrating on traditional testing methods that fail to account for performance on unseen datasets, creating a gap between theoretical models and their real-world utility. Online learning is a potential strategy to mitigate this issue by allowing models to adapt to new information continuously. This paper assesses how well current VAD algorithms can adjust to real-life conditions through an online learning framework, particularly those based on pose analysis, for their efficiency and privacy advantages. Our proposed framework enables continuous model updates with streaming data from novel environments, thus mirroring actual world challenges and evaluating the models' ability to adapt in real-time while maintaining accuracy. We investigate three state-of-the-art models in this setting, focusing on their adaptability across different domains. Our findings indicate that, even under the most challenging conditions, our online learning approach allows a model to preserve 89.39% of its original effectiveness compared to its offline-trained counterpart in a specific target domain.         _ Less","","arXiv","https://arxiv.org/abs/2404.18747","1","0","origin_of_life"
"Non-Spatial Hash Chemistry as a Minimalistic Open-Ended Evolutionary System","Abstract:                There is an increasing level of interest in open-endedness in the recent literature of Artificial Life and Artificial Intelligence. We previously proposed the cardinality leap of possibility spaces as a promising mechanism to facilitate open-endedness in artificial evolutionary systems, and demonstrated its effectiveness using Hash Chemistry, an artificial c_         _ More           There is an increasing level of interest in open-endedness in the recent literature of Artificial Life and Artificial Intelligence. We previously proposed the cardinality leap of possibility spaces as a promising mechanism to facilitate open-endedness in artificial evolutionary systems, and demonstrated its effectiveness using Hash Chemistry, an artificial chemistry model that used a hash function as a universal fitness evaluator. However, the spatial nature of Hash Chemistry came with extensive computational costs involved in its simulation, and the particle density limit imposed to prevent explosion of computational costs prevented unbounded growth in complexity of higher-order entities. To address these limitations, here we propose a simpler non-spatial variant of Hash Chemistry in which spatial proximity of particles are represented explicitly in the form of multisets. This model modification achieved a significant reduction of computational costs in simulating the model. Results of numerical simulations showed much more significant unbounded growth in both maximal and average sizes of replicating higher-order entities than the original model, demonstrating the effectiveness of this non-spatial model as a minimalistic example of open-ended evolutionary systems.         _ Less","","arXiv","https://arxiv.org/abs/2404.18027","0","2","synthetic_biology"
"Catalytic Coagulation","Abstract:                _event and is available to either participate in or catalyze subsequent reactions. This model is meant to mimic the self-replicating reactions that occur in models for the origin of life. We solve the kinetics of this catalytic coagulation model for the case of mass-independent rates and show that the total cluster dens_         _ More           We introduce an autocatalytic aggregation model in which the rate at which two clusters merge to form a cluster is controlled by the presence of a third 'catalytic' cluster whose mass must equal to the mass of one of the reaction partners. The catalyst is unaffected by the joining event and is available to either participate in or catalyze subsequent reactions. This model is meant to mimic the self-replicating reactions that occur in models for the origin of life. We solve the kinetics of this catalytic coagulation model for the case of mass-independent rates and show that the total cluster density decays as $t^{-1/3}$, while the density of clusters of any fixed mass decays as $t^{-2/3}$. These behaviors contrast with the corresponding $t^{-1}$ and $t^{-2}$ scalings for classic aggregation. We extend our model to mass-dependent reaction rates, to situations where only 'magic' mass clusters can catalyze reactions, and to include steady monomer input.         _ Less","","arXiv","https://arxiv.org/abs/2404.17026","1","1","multiple"
"The early Earth as an analogue for exoplanetary biogeochemistry","Abstract:                _increasing complexity over time. A rich record of this geobiological evolution over most of Earth's history provides insights into the remote detectability of microbial life under a variety of planetary conditions. We leverage Earth's geobiological record with the aim of a) illustrating the current state of knowledge and key knowledge gaps about the_         _ More           Planet Earth has evolved from an entirely anoxic planet with possibly a different tectonic regime to the oxygenated world with horizontal plate tectonics that we know today. For most of this time, Earth has been inhabited by a purely microbial biosphere albeit with seemingly increasing complexity over time. A rich record of this geobiological evolution over most of Earth's history provides insights into the remote detectability of microbial life under a variety of planetary conditions. We leverage Earth's geobiological record with the aim of a) illustrating the current state of knowledge and key knowledge gaps about the early Earth as a reference point in exoplanet science research; b) compiling biotic and abiotic mechanisms that controlled the evolution of the atmosphere over time; and c) reviewing current constraints on the detectability of Earth's early biosphere with state-of-the-art telescope technology. We highlight that life may have originated on a planet with a different tectonic regime and strong hydrothermal activity, and under these conditions, biogenic CH$_4$ gas was perhaps the most detectable atmospheric biosignature. Oxygenic photosynthesis, which is responsible for essentially all O$_2$ gas in the modern atmosphere, appears to have emerged concurrently with the establishment of modern plate tectonics and the continental crust, but O$_2$ accumulation to modern levels only occurred late in Earth's history, perhaps tied to the rise of land plants. Nutrient limitation in anoxic oceans, promoted by hydrothermal Fe = fluxes, may have limited biological productivity and O$_2$ production. N$_2$O is an alternative biosignature that was perhaps significant on the redox-stratified Proterozoic Earth. We conclude that the detectability of atmospheric biosignatures on Earth was not only dependent on biological evolution but also strongly controlled by the evolving tectonic context.         _ Less","","arXiv","https://arxiv.org/abs/2404.15432","1","2","synthetic_biology"
"Insights into the defect-driven heterogeneous structural evolution of Ni-rich layered cathode in lithium-ion batteries","Abstract:                _Li/Ni disordering and microcracks, which should be inhibited by assembling appropriate anode to avoid potential threaten on cell performance. The present work unveils the origin of inhomogeneity in Ni-rich lithium-ion batteries and highlights the significance of kinetics control in electrodes for batteries with higher capacity and longer_         _ More           Recently, considerable efforts have been made on research and improvement for Ni-rich lithium-ion batteries to meet the demand from vehicles and grid-level large-scale energy storage. Development of next-generation high-performance lithium-ion batteries requires a comprehensive understanding on the underlying electrochemical mechanisms associated with its structural evolution. In this work, advanced operando neutron diffraction and four-dimensional scanning transmission electron microscopy techniques are applied to clarify the structural evolution of electrodes in two distinct full cells with identical LiNi0.8Co0.1Mn0.1O2 cathode but different anode counterparts. It is found that both of cathodes in two cells exhibit non-intrinsic two-phase-like behavior at the early charge stage, indicating selective Li+ extraction from cathodes. But the heterogeneous evolution of cathode is less serious with graphite-silicon blended anode than that with graphite anode due to the different delithiation rate. Moreover, it is revealed that the formation of heterogeneous structure is led by the distribution of defects including Li/Ni disordering and microcracks, which should be inhibited by assembling appropriate anode to avoid potential threaten on cell performance. The present work unveils the origin of inhomogeneity in Ni-rich lithium-ion batteries and highlights the significance of kinetics control in electrodes for batteries with higher capacity and longer life.         _ Less","","arXiv","https://arxiv.org/abs/2404.15237","2","2","multiple"
"Gradient-Regularized Out-of-Distribution Detection","Abstract:                One of the challenges for neural networks in real-life applications is the overconfident errors these models make when the data is not from the original training distribution.   Addressing this issue is known as Out-of-Distribution (OOD) detection.   Many state-of-the-art OOD methods employ an auxiliary dataset as a su_         _ More           One of the challenges for neural networks in real-life applications is the overconfident errors these models make when the data is not from the original training distribution.   Addressing this issue is known as Out-of-Distribution (OOD) detection.   Many state-of-the-art OOD methods employ an auxiliary dataset as a surrogate for OOD data during training to achieve improved performance.   However, these methods fail to fully exploit the local information embedded in the auxiliary dataset.   In this work, we propose the idea of leveraging the information embedded in the gradient of the loss function during training to enable the network to not only learn a desired OOD score for each sample but also to exhibit similar behavior in a local neighborhood around each sample.   We also develop a novel energy-based sampling method to allow the network to be exposed to more informative OOD samples during the training phase. This is especially important when the auxiliary dataset is large. We demonstrate the effectiveness of our method through extensive experiments on several OOD benchmarks, improving the existing state-of-the-art FPR95 by 4% on our ImageNet experiment.   We further provide a theoretical analysis through the lens of certified robustness and Lipschitz analysis to showcase the theoretical foundation of our work. Our code is available at https://github.com/o4lc/Greg-OOD.         _ Less","","arXiv","https://arxiv.org/abs/2404.12368","1","0","origin_of_life"
"Impact of non-reciprocal interactions on colloidal self-assembly with tunable anisotropy","Abstract:                _and pattern formation, but can also influence aggregation processes on the particle scale. Here we focus on the impact of non-reciprocity on the self-assembly of an (originally passive) colloidal system with anisotropic interactions whose character is tunable by external fields. In the absence of non-reciprocity, that is, under equilibrium conditions, the co_         _ More           Non-reciprocal (NR) effective interactions violating Newton's third law occur in many biological systems, but can also be engineered in synthetic, colloidal systems. Recent research has shown that such NR interactions can have tremendous effects on the overall collective behaviour and pattern formation, but can also influence aggregation processes on the particle scale. Here we focus on the impact of non-reciprocity on the self-assembly of an (originally passive) colloidal system with anisotropic interactions whose character is tunable by external fields. In the absence of non-reciprocity, that is, under equilibrium conditions, the colloids form aggregates with extremely long life times [Kogler et al., Soft Matter 11, 7356 (2015)], indicating kinetic trapping. Here we study, based on Brownian Dynamics (BD) simulations in 2D, a NR version of this model consisting of two species with reciprocal isotropic, but NR anisotropic interactions. We find that NR induces an effective propulsion of particle pairs and small aggregates forming at initial stages of self-assembly, an indication of the NR-induced non-equilibrium. The shape and stability of these initial clusters strongly depends on the degree of anisotropy. At longer times we find, for weak NR interactions, large (even system-spanning) clusters where single particles can escape and enter at the boundaries, in stark contrast to the small rigid aggregates appearing at the same time in the passive case. In this sense, weak NR shortcuts the aggregation. Increasing the degree of NR (and thus, propulsion), we even observe large-scale phase separation if the interactions are weakly anisotropic. In contrast, system with strong NR and anisotropy remain essentially disordered. Overall, NR interactions are shown to destabilize the rigid aggregates interrupting self-assembly in the passive case, helping the system to overcome kinetic barriers.         _ Less","","arXiv","https://arxiv.org/abs/2404.12108","1","1","multiple"
"Large-scale semi-organized rolls in a sheared convective turbulence: Mean-field simulations","Abstract:                _of this effect, there is an excitation of large-scale convective-shear instability, which causes the formation of large-scale semi-organized structures in the form of rolls. The life-times and spatial scales of these structures are much larger compared to the turbulent scales. By means of MFS performed for stress-free and no-slip vertical boundary conditions_         _ More           Based on a mean-field theory of a non-rotating turbulent convection (Phys. Rev. E {\\bf 66}, 066305, 2002), we perform mean-field simulations (MFS) of sheared convection which takes into account an effect of modification of the turbulent heat flux by the non-uniform large-scale motions. As the result of this effect, there is an excitation of large-scale convective-shear instability, which causes the formation of large-scale semi-organized structures in the form of rolls. The life-times and spatial scales of these structures are much larger compared to the turbulent scales. By means of MFS performed for stress-free and no-slip vertical boundary conditions, we determine the spatial and temporal characteristics of these structures. Our study demonstrates that the modification of the turbulent heat flux by non-uniform flows leads to a strong reduction of the critical effective Rayleigh number (based on the eddy viscosity and turbulent temperature diffusivity) required for the formation of the large-scale rolls. During the nonlinear stage of the convective-shear instability, there is a transition from the two-layer vertical structure with two roles in the vertical direction before the system reaches steady-state to the one-layer vertical structure with one role after the system reaches steady-state. This effect is observed for all effective Rayleigh numbers. We find that inside the convective rolls, the spatial distribution of the mean potential temperature includes regions with a positive vertical gradient of the potential temperature caused by the mean heat flux of the convective rolls. This study might be useful for understanding of the origin of large-scale rolls observed in atmospheric convective boundary layers as well as in numerical simulations and laboratory experiments.         _ Less","","arXiv","https://arxiv.org/abs/2404.11690","1","0","origin_of_life"
"Breaking of Time Translation Symmetry and Ergodicity, and Entropy decrease in a Continuous Time Crystal Driven by Nonreciprocal Optical Forces","Abstract:                Nonreciprocal nonequilibrium process are attracting growing interest in sociology, animal behaviour, chemistry, and nanotechnology, and may have played a role in the origin of_         _ More           Nonreciprocal nonequilibrium process are attracting growing interest in sociology, animal behaviour, chemistry, and nanotechnology, and may have played a role in the origin of life. It is less widely recognized, however, that in open systems light can induce nonreciprocal predator-prey like forces between nanoparticles. Such forces provide access to the continuous time crystal state of matter, which has been demonstrated in a plasmonic metamaterial array of nanowires wherein light triggers a spontaneous mobilization transition to the robust oscillatory state, breaking time translation symmetry. Here, we report on the first experimental study of the transient dynamics of light-induced mobilization and demobilization in a time crystal. By analysing time resolved phase trajectories of the system of nanowires, we show that the mobilization transition is accompanied by breaking of continuous time translation symmetry and ergodicity, and a decrease in the entropy of motion. This insight into the transient dynamics of a nonreciprocity-driven time crystal is relevant to optical timetronics, an information and communications technology paradigm relying on the unique functionalities of time crystals, and applications of the interacting nanowire oscillator platform to modelling a wide range of nonreciprocal processes from many-body dynamics to the early stages of matter-to-life transitions.         _ Less","","arXiv","https://arxiv.org/abs/2404.10525","2","0","origin_of_life"
"Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning","Abstract:                Many complex problems encountered in both production and daily life can be conceptualized as combinatorial optimization problems (COPs) over graphs. Recent years, reinforcement learning (RL) based models have emerged as a promising direction, which treat the COPs solving as a heuristic learning problem. However, current finite-horizon-MDP based RL models hav_         _ More           Many complex problems encountered in both production and daily life can be conceptualized as combinatorial optimization problems (COPs) over graphs. Recent years, reinforcement learning (RL) based models have emerged as a promising direction, which treat the COPs solving as a heuristic learning problem. However, current finite-horizon-MDP based RL models have inherent limitations. They are not allowed to explore adquately for improving solutions at test time, which may be necessary given the complexity of NP-hard optimization tasks. Some recent attempts solve this issue by focusing on reward design and state feature engineering, which are tedious and ad-hoc. In this work, we instead propose a much simpler but more effective technique, named gauge transformation (GT). The technique is originated from physics, but is very effective in enabling RL agents to explore to continuously improve the solutions during test. Morever, GT is very simple, which can be implemented with less than 10 lines of Python codes, and can be applied to a vast majority of RL models. Experimentally, we show that traditional RL models with GT technique produce the state-of-the-art performances on the MaxCut problem. Furthermore, since GT is independent of any RL models, it can be seamlessly integrated into various RL frameworks, paving the way of these models for more effective explorations in the solving of general COPs.         _ Less","","arXiv","https://arxiv.org/abs/2404.04661","1","0","origin_of_life"
"The Origin and Evolution of Information Handling","Abstract:                A major challenge when describing the origin of_         _ More           A major challenge when describing the origin of life is to explain 'how instructional information control systems emerge naturally and spontaneously from mere molecular dynamics'. So far, no one has clarified how information control emerged ab initio and how primitive control mechanisms in life might have evolved, becoming increasingly refined. Based on recent experimental results showing that chemical computation does not require the presence of life-related chemistry, we elucidate the origin and early evolution of information handling by chemical automata, from information processing (computation) to information storage (memory) and information transmission (communication) and later digital messengers, covering at the same time its syntactic, semantic and pragmatic flavors. In contrast to other theories that assume the existence of initial complex structures, our representation starts from trivial self-replicators whose interaction leads to the arising of more powerful molecular machines. By describing precisely the primordial transitions in chemistry-based computation, our framework is capable of explaining the above-mentioned gaps and can be translated to other models of computation, which allow us to explore biological phenomena at multiple spatial and temporal scales. Being compatible with the free energy principle, we have developed a computational enactivist theoretical framework that could be able to describe from the origin of life to high-level cognition, as if it were a purely constructivist narrative. At the end of our manuscript, we propose some ways to extend our ideas, including experimental validation of our theory (both in vitro and in silico).         _ Less","","arXiv","https://arxiv.org/abs/2404.04374","2","2","multiple"
"Nonequilibrium properties of autocatalytic networks","Abstract:                Autocatalysis, the ability of a chemical system to make more of itself, is a crucial feature in metabolism and is speculated to have played a decisive role in the origin of life. Nevertheless, how autocatalytic systems behave far from equilibrium remains unexplored. In this work, we elaborate on recent advances regardi_         _ More           Autocatalysis, the ability of a chemical system to make more of itself, is a crucial feature in metabolism and is speculated to have played a decisive role in the origin of life. Nevertheless, how autocatalytic systems behave far from equilibrium remains unexplored. In this work, we elaborate on recent advances regarding the stoichiometric characterization of autocatalytic networks, particularly their absence of mass-like conservation laws, to study how this topological feature influences their nonequilibrium behavior. Building upon the peculiar topology of autocatalytic networks, we derive a decomposition of the chemical fluxes, which highlights the existence of productive modes in their dynamics. These modes produce the autocatalysts in net excess and require the presence of external fuel/waste species to operate. Relying solely on topology, the fluxes decomposition holds under broad conditions and, in particular, do not require steady-state or elementary reactions. Additionally, we show that once externally controlled, the non-conservative forces brought by the external species do not act on these productive modes. This must be considered when one is interested in the thermodynamics of open autocatalytic networks. Specifically, we show that an additional term must be added to the semigrand free-energy. Finally, from the thermodynamic potential, we derive the thermodynamic cost associated with the production of autocatalysts.         _ Less","","arXiv","https://arxiv.org/abs/2404.03347","1","1","multiple"
"Design principles, growth laws, and competition of minimal autocatalysts","Abstract:                _reach these conclusions by developing a general theoretical framework based on kinetic barrier diagrams. Besides challenging commonly accepted assumptions in the field of the origin of life, our results provide a blueprint for the experimental realization of elementary autocatalysts exhibiting a form of natural selecti_         _ More           The apparent difficulty of designing simple autocatalysts that grow exponentially in the absence of enzymes, external drives or ingenious internal mechanisms severely constrains scenarios for the emergence of evolution by natural selection in chemical and physical systems. Here, we systematically analyze these difficulties in the context of one of the simplest and most generic autocatalysts: a dimeric molecule that duplicates by templated ligation. We show that despite its simplicity, such an autocatalyst can achieve exponential growth autonomously. This only requires that the rate of the spontaneous dimerization, the interactions between molecules, and the concentrations of substrates and products are in appropriate ranges. We also show, however, that it is possible to design as simple sub-exponential autocatalysts that have an advantage over exponential autocatalysts when competing for a common resource. We reach these conclusions by developing a general theoretical framework based on kinetic barrier diagrams. Besides challenging commonly accepted assumptions in the field of the origin of life, our results provide a blueprint for the experimental realization of elementary autocatalysts exhibiting a form of natural selection, whether on a molecular or colloidal scale.         _ Less","","arXiv","https://arxiv.org/abs/2403.19047","2","3","synthetic_biology"
"Stability distillation hypothesis for the origin of life","Abstract:                Through in-depth thinking and reasoning about the conditions required for cells to maintain unchanged material distribution, it is concluded that life metabolic reactions require high information content. However, the self-replication of a few macromolecules such as RNA and DNA can only retain information, but cannot generate information. When thinking about_         _ More           Through in-depth thinking and reasoning about the conditions required for cells to maintain unchanged material distribution, it is concluded that life metabolic reactions require high information content. However, the self-replication of a few macromolecules such as RNA and DNA can only retain information, but cannot generate information. When thinking about the possible ways in which this information is generated, one possible way is to maintain the distribution of substances in the cell through selective permeability and active transport of membranes. This mechanism still plays an important role in today's cells but it is difficult to generate enough information. Another possible way is to generate information through stability-distillation, which continuously changes the molecular frequency distribution in the system through periodic changes in the environment and generates information from a consequentialist perspective. Unlike the RNA world hypothesis, under this hypothesis, life does not need to originate from a few self-replicating macromolecules, making the entire hypothesis more reasonable.         _ Less","","arXiv","https://arxiv.org/abs/2403.17072","3","2","origin_of_life"
"Cosmic hide and seek: the volumetric rate of X-ray quasi-periodic eruptions","Abstract:                _. Since the exact lifetime of QPEs ($__{\\rm life}$) is currently not better defined than between a few years or few decades, we convert this to a formation rate of $\\mathscr{R}_{\\rm vol}/__{\\rm life}\\approx 0.6 \\times 10^{-7} (__{\\rm life}/10\\,\\mathrm{y})^{-1}\\,$Mpc$^{-3}\\,$year$^{-1}$. As a comparison, this value is a_         _ More           Multi-wavelength extragalactic nuclear transients, particularly those detectable as multi-messengers, are among the primary drivers for the next-generation observatories. X-ray quasi-periodic eruptions (QPEs) are the most recent and perhaps most peculiar addition to this group. Here, we report a first estimate of the volumetric rate of QPEs based on the first four discoveries with the eROSITA X-ray telescope onboard the Spectrum Roentgen Gamma observatory. Under the assumption, supported by a suite of simulated light curves, that these four sources sample the intrinsic population somewhat homogeneously, we correct for their detection efficiency and compute a QPE abundance of $\\mathscr{R}_{\\rm vol} = 0.60_{-0.43}^{+4.73} \\times 10^{-6}\\,$Mpc$^{-3}$ above an intrinsic average $\\log L_{\\rm 0.5-2.0\\,keV}^{\\rm peak} > 41.7$. Since the exact lifetime of QPEs ($__{\\rm life}$) is currently not better defined than between a few years or few decades, we convert this to a formation rate of $\\mathscr{R}_{\\rm vol}/__{\\rm life}\\approx 0.6 \\times 10^{-7} (__{\\rm life}/10\\,\\mathrm{y})^{-1}\\,$Mpc$^{-3}\\,$year$^{-1}$. As a comparison, this value is a factor $\\sim10\\,__{\\rm life}$ times smaller than the formation rate of tidal disruption events. The origin of QPEs is still debated, although lately most models suggest that they are the electromagnetic counterpart of extreme mass ratio inspirals (EMRIs). In this scenario, the QPE rate would thus be the first-ever constraint (i.e. a lower limit) to the EMRI rate from observations alone. Future discoveries of QPEs and advances in their theoretical modeling will consolidate or rule out their use for constraining the number of EMRIs detectable by the LISA mission.         _ Less","","arXiv","https://arxiv.org/abs/2403.17059","1","0","origin_of_life"
"Abiogenesis: a possible quantum interpretation of the telepoietic conjecture","Abstract:                In the research on the origin of life, topics that can be considered reasonably shared by the generality of researchers are initially identified. It is then shown that the application of these principles to the results obtained with the IdLE-IdLA mathematical model for the simulation of aggregative processes, leads to_         _ More           In the research on the origin of life, topics that can be considered reasonably shared by the generality of researchers are initially identified. It is then shown that the application of these principles to the results obtained with the IdLE-IdLA mathematical model for the simulation of aggregative processes, leads to the conclusion that the primordial formation of self-replicating structures is difficult to reconcile with deterministic aggregative dynamics in the classical sense. Regardless of the extent to which the process itself is governed by chance or by aggregative codes written in the laws of chemistry, no conventional causality is likely. The model itself suggests only one possible way out, consistent with thermodynamics: the existence of information sets rushing into the system in a different way from the perceived time stream. The possibilities offered by quantum mechanics and its most recent interpretations are consequently investigated to try to interpret, at the level of particle physics, the suggestion of IdLE-IdLA model. The attempt leads to a mutual accreditation of macroscopic telepoiesis and a kind of quantum retrocausality. The result is a vision of the natural world in which the coexistence of causal and retrocausal dynamics is presented as a possible interpretative key of the whole complex of vital manifestations.         _ Less","","arXiv","https://arxiv.org/abs/2403.12955","3","1","origin_of_life"
"FROST-CLUSTERS -- I. Hierarchical star cluster assembly boosts intermediate-mass black hole formation","Abstract:                _the collapse of very massive stars (VMSs) assembled through repeated collisions of massive stars followed by growth through tidal disruption events and BH mergers. No IMBHs originate from the stars in the initially most massive clusters. We explain this by suppression of hard massive star binary formation at high velocity dispersions and the competition betw_         _ More           Observations and high-resolution hydrodynamical simulations indicate that massive star clusters assemble hierarchically from sub-clusters with a universal power-law cluster mass function. We study the consequences of such assembly for the formation of intermediate-mass black holes (IMBHs) at low metallicities ($Z=0.01\\;Z_\\mathrm{\\odot}$) with our updated N-body code BIFROST based on the hierarchical fourth-order forward integrator. BIFROST integrates few-body systems using secular and regularized techniques including post-Newtonian equations of motion up to order PN3.5 and gravitational-wave recoil kicks for BHs. Single stellar evolution is treated using the fast population synthesis code SEVN. We evolve three cluster assembly regions with $N_\\mathrm{tot} = 1.70$--$2.35 \\times 10^6$ stars following a realistic IMF in $\\sim$1000 sub-clusters for $t=50$ Myr. IMBHs with masses up to $m_\\bullet \\sim 2200\\:M_\\mathrm{\\odot}$ form rapidly mainly via the collapse of very massive stars (VMSs) assembled through repeated collisions of massive stars followed by growth through tidal disruption events and BH mergers. No IMBHs originate from the stars in the initially most massive clusters. We explain this by suppression of hard massive star binary formation at high velocity dispersions and the competition between core collapse and massive star life-times. Later the IMBHs form subsystems resulting in gravitational-wave BH-BH, IMBH-BH and IMBH-IMBH mergers with a $m_\\bullet\\sim1000\\:M_\\mathrm{\\odot}$ gravitational-wave detection being the observable prediction. Our simulations indicate that the hierarchical formation of massive star clusters in metal poor environments naturally results in formation of potential seeds for supermassive black holes.         _ Less","","arXiv","https://arxiv.org/abs/2403.10602","1","2","synthetic_biology"
"GTP before ATP: The energy currency at the origin of genes","Abstract:        Life is an exergonic chemical reaction. Many individual reactions in metabolism entail slightly endergonic processes that are coupled to free energy release, typically as ATP hydrolysis, in order to go forward. ATP is almost always supplied by the rotor-stator ATP synthetase (the ATPase), which harnesses chemiosmotic ion gradients. Because the ATPase is a pr_         _ More   Life is an exergonic chemical reaction. Many individual reactions in metabolism entail slightly endergonic processes that are coupled to free energy release, typically as ATP hydrolysis, in order to go forward. ATP is almost always supplied by the rotor-stator ATP synthetase (the ATPase), which harnesses chemiosmotic ion gradients. Because the ATPase is a protein, it arose after the ribosome did. Here we address two questions using comparative physiology: What was the energy currency of metabolism before the origin of the ATPase? How (and why) did ATP come to be the universal energy currency? About 27 percent of a cell's energy budget is consumed as GTP during translation. The universality of GTP-dependence in ribosome function indicates that GTP was the ancestral energy currency of protein synthesis. The use of GTP in translation and ATP in small molecule synthesis are conserved across all lineages, representing energetic compartments that arose in the last universal common ancestor, LUCA.         _ Less","","arXiv","https://arxiv.org/abs/2403.08744","1","2","synthetic_biology"
"Giant impact on early Ganymede and its subsequent reorientation","Abstract:                The origin and early evolution of the Jovian moon Ganymede, known to have an internal ocean, have garnered considerable interest in the field of origin of satellites and life. Ganymede has an ancient impact structure, called a furrow system. The furrow system is the largest impac_         _ More           The origin and early evolution of the Jovian moon Ganymede, known to have an internal ocean, have garnered considerable interest in the field of origin of satellites and life. Ganymede has an ancient impact structure, called a furrow system. The furrow system is the largest impact structures in the outer solar system and the impact should have significantly affected Ganymede's early history; however, its impact is poorly understood. Here we show that mass redistribution induced by the furrow-forming impact caused a reorientation (true polar wander) of Ganymede. The center of the furrow system is located close to the tidal axis, indicating that the impact created a positive mass anomaly that reoriented the impact site toward the tidal axis. We found that an impactor with a radius of 150 km and an incidence angle between 60 degree and 90 degree can reproduce the current location of the furrow system. Furthermore, this ejecta model is adoptable in Pluto's reorientation. Although it is proposed that Pluto's reorientation indicates the presence of a global ocean, our model indicates that it occurs even if no ocean.         _ Less","","arXiv","https://arxiv.org/abs/2403.03371","0","1","synthetic_biology"
"Atacama Large Aperture Submillimeter Telescope (AtLAST) Science: Planetary and Cometary Atmospheres","Abstract:                _planets, moons, and comets provide insights into the past and present-day habitability of planetary environments, and the availability of the chemical ingredients for life. While prior and existing (sub)millimeter observations have led to major advances in these areas, progress is hindered by limitations in the dynamic range, spatial and temporal coverage, a_         _ More           The study of planets and small bodies within our Solar System is fundamental for understanding the formation and evolution the Earth and other planets. Compositional and meteorological studies of the giant planets provide a foundation for understanding the nature of the most commonly observed exoplanets, while spectroscopic observations of the atmospheres of terrestrial planets, moons, and comets provide insights into the past and present-day habitability of planetary environments, and the availability of the chemical ingredients for life. While prior and existing (sub)millimeter observations have led to major advances in these areas, progress is hindered by limitations in the dynamic range, spatial and temporal coverage, as well as sensitivity of existing telescopes and interferometers. Here, we summarize some of the key planetary science use cases that factor into the design of the Atacama Large Aperture Submillimeter Telescope (AtLAST), a proposed 50-m class single dish facility: (1) to more fully characterize planetary wind fields and atmospheric thermal structures, (2) to measure the compositions of icy moon atmospheres and plumes, (3) to obtain detections of new, astrobiologically relevant gases and perform isotopic surveys of comets, and (4) to perform synergistic, temporally-resolved measurements in support of dedicated interplanetary space missions. The improved spatial coverage (several arcminutes), resolution ($\\sim1.2''-12''$), bandwidth (several tens of GHz), dynamic range ($\\sim10^5$) and sensitivity ($\\sim1$ mK km s$^{-1}$) required by these science cases would enable new insights into the chemistry and physics of planetary environments, the origins of prebiotic molecules and the habitability of planetary systems in general.         _ Less","","arXiv","https://arxiv.org/abs/2403.02258","3","2","origin_of_life"
"Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients","Abstract:                _yet 9 out of 10 of these individuals are unaware of their condition due to the absence of symptoms in the early stages. It has a significant impact on patients' quality of life, particularly when it progresses to the need for dialysis. Early prediction of dialysis is crucial as it can significantly improve patient outcomes and assist healthcare provider_         _ More           The Center for Disease Control estimates that over 37 million US adults suffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals are unaware of their condition due to the absence of symptoms in the early stages. It has a significant impact on patients' quality of life, particularly when it progresses to the need for dialysis. Early prediction of dialysis is crucial as it can significantly improve patient outcomes and assist healthcare providers in making timely and informed decisions. However, developing an effective machine learning (ML)-based Clinical Decision Support System (CDSS) for early dialysis prediction poses a key challenge due to the imbalanced nature of data. To address this challenge, this study evaluates various data augmentation techniques to understand their effectiveness on real-world datasets. We propose a new approach named Binary Gaussian Copula Synthesis (BGCS). BGCS is tailored for binary medical datasets and excels in generating synthetic minority data that mirrors the distribution of the original data. BGCS enhances early dialysis prediction by outperforming traditional methods in detecting dialysis patients. For the best ML model, Random Forest, BCGS achieved a 72% improvement, surpassing the state-of-the-art augmentation approaches. Also, we present a ML-based CDSS, designed to aid clinicians in making informed decisions. CDSS, which utilizes decision tree models, is developed to improve patient outcomes, identify critical variables, and thereby enable clinicians to make proactive decisions, and strategize treatment plans effectively for CKD patients who are more likely to require dialysis in the near future. Through comprehensive feature analysis and meticulous data preparation, we ensure that the CDSS's dialysis predictions are not only accurate but also actionable, providing a valuable tool in the management and treatment of CKD.         _ Less","","arXiv","https://arxiv.org/abs/2403.00965","1","1","multiple"
"Detection of possible glycine precursor molecule methylamine towards the hot molecular core G358.93$-$0.03 MM1","Abstract:                _medium (ISM), has become a never-ending story for astrochemistry and astrophysics researchers because that molecule plays a possible connection between the Universe and the origin of life. In the last forty years, all searches for NH$_{2}$CH$_{2}$COOH in the ISM at millimeter and submillimeter wavelengths have failed._         _ More           The search for the simplest amino acid, glycine (NH$_{2}$CH$_{2}$COOH), in the interstellar medium (ISM), has become a never-ending story for astrochemistry and astrophysics researchers because that molecule plays a possible connection between the Universe and the origin of life. In the last forty years, all searches for NH$_{2}$CH$_{2}$COOH in the ISM at millimeter and submillimeter wavelengths have failed. Since the detection of NH$_{2}$CH$_{2}$COOH in the ISM was extremely difficult, we aimed to search for the possible precursors of NH$_{2}$CH$_{2}$COOH. Earlier, many laboratory experiments have suggested that methylamine (CH$_{3}$NH$_{2}$) plays an important role in the ISM as a possible precursor of NH$_{2}$CH$_{2}$COOH. After spectral analysis using the local thermodynamic equilibrium (LTE) model, we identified the rotational emission lines of CH$_{3}$NH$_{2}$ towards the hot molecular core G358.93$-$0.03 MM1 using the Atacama Large Millimeter/Submillimeter Array (ALMA). The column density of CH$_{3}$NH$_{2}$ towards the G358.93$-$0.03 MM1 was estimated to be (1.10$\\pm$0.31)$\\times$10$^{17}$ cm$^{-2}$ with an excitation temperature of 180.8$\\pm$25.5 K. The fractional abundance of CH$_{3}$NH$_{2}$ with respect to H$_{2}$ towards the G358.93$-$0.03 MM1 was (8.80$\\pm$2.60)$\\times$10$^{-8}$. The column density ratio of CH$_{3}$NH$_{2}$ and NH$_{2}$CN towards G358.93$-$0.03 MM1 was (1.86$\\pm$0.95)$\\times$10$^{2}$. The estimated fractional abundance of CH$_{3}$NH$_{2}$ towards the G358.93$-$0.03 MM1 agrees fairly well with the previous three-phase warm-up chemical modelling abundance of CH$_{3}$NH$_{2}$. We also discussed the possible formation mechanism of CH$_{3}$NH$_{2}$, and we find that CH$_{3}$NH$_{2}$ is most probably formed via the reactions of radical CH$_{3}$ and radical NH$_{2}$ on the grain surface of G358.93$-$0.03 MM1.         _ Less","","arXiv","https://arxiv.org/abs/2402.16798","2","0","origin_of_life"
"Rebuildable biochronometer: inferences and hypothesis on eukaryotic timing system","Abstract:                _rejuvenation and makes the organism younger. In addition, the rebuilding of biochronometers can also lead to the acceleration of biochronometers and the shortening of the original timing time of biochronometers, thus shortening the_         _ More           The biochronometers used to keep time in eukaryotes include short-period biochronometer (SPB) and long-period biochronometer (LPB). Because the circadian clock reflects the biological time rhythm of a day, it is considered as SPB. Telomere shortening, which reflects the decreasing of telomere DNA length of chromosomes with the increase of cell division times, can be used to time the lifespan of organisms, so it is regarded as LPB. It is confirmed that SPB and LPB exist in most eukaryotes, and it is speculated that SPB and LPB are closely related. In this paper, based on existing studies, it is speculated that SPB and LPB of most eukaryotes can be co-attenuated with cell division in the process of aging. Due to the attenuated phenomenon of key components in the biochronometers during the growth and development of organisms, the biochronometers attenuate with the aging. Based on existing research results, it is preliminarily determined that the biochronometers can be rebuilt in the co-attenuated process. When the key components of biochronometers are reversed and increased in the organism, it can lead to the reversal of biochronometers, which further leads to the phenomenon of biological rejuvenation and makes the organism younger. In addition, the rebuilding of biochronometers can also lead to the acceleration of biochronometers and the shortening of the original timing time of biochronometers, thus shortening the life span of organisms. The rebuilding of biochronometers includes the reversal of biochronometers, the truncation of biochronometers timing and Uncoordinated co-attenuation of biochronometer and so on. The reversal of the biochronometers, which leads to rejuvenation, can give us a whole new understanding of life expectancy to be different from anti-aging.         _ Less","","arXiv","https://arxiv.org/abs/2402.16271","0","1","synthetic_biology"
"HunFlair2 in a cross-corpus evaluation of biomedical named entity recognition and normalization tools","Abstract:                With the exponential growth of the life science literature, biomedical text mining (BTM) has become an essential technology for accelerating the extraction of insights from publications. Identifying named entities (e.g., diseases, drugs, or genes) in texts and their linkage to reference knowledge bases are crucial steps in BTM pipelines to enable information_         _ More           With the exponential growth of the life science literature, biomedical text mining (BTM) has become an essential technology for accelerating the extraction of insights from publications. Identifying named entities (e.g., diseases, drugs, or genes) in texts and their linkage to reference knowledge bases are crucial steps in BTM pipelines to enable information aggregation from different documents. However, tools for these two steps are rarely applied in the same context in which they were developed. Instead, they are applied in the wild, i.e., on application-dependent text collections different from those used for the tools' training, varying, e.g., in focus, genre, style, and text type. This raises the question of whether the reported performance of BTM tools can be trusted for downstream applications. Here, we report on the results of a carefully designed cross-corpus benchmark for named entity extraction, where tools were applied systematically to corpora not used during their training. Based on a survey of 28 published systems, we selected five for an in-depth analysis on three publicly available corpora encompassing four different entity types. Comparison between tools results in a mixed picture and shows that, in a cross-corpus setting, the performance is significantly lower than the one reported in an in-corpus setting. HunFlair2 showed the best performance on average, being closely followed by PubTator. Our results indicate that users of BTM tools should expect diminishing performances when applying them in the wild compared to original publications and show that further research is necessary to make BTM tools more robust.         _ Less","","arXiv","https://arxiv.org/abs/2402.12372","2","2","multiple"
"Analysis and Mortality Prediction using Multiclass Classification for Older Adults with Type 2 Diabetes","Abstract:                Designing proper treatment plans to manage diabetes requires health practitioners to pay heed to the individuals remaining life along with the comorbidities affecting them. Older adults with Type 2 Diabetes Mellitus (T2DM) are prone to experience premature death or even hypoglycaemia. The structured dataset utilized has 68 potential mortality predictors for_         _ More           Designing proper treatment plans to manage diabetes requires health practitioners to pay heed to the individuals remaining life along with the comorbidities affecting them. Older adults with Type 2 Diabetes Mellitus (T2DM) are prone to experience premature death or even hypoglycaemia. The structured dataset utilized has 68 potential mortality predictors for 275,190 diabetic U.S. military Veterans aged 65 years or older. A new target variable is invented by combining the two original target variables. Outliers are handled by discretizing the continuous variables. Categorical variables have been dummy encoded. Class balancing is achieved by random under-sampling. A benchmark regression model is built using Multinomial Logistic Regression with LASSO. Chi-Squared and Information Gain are the filter-based feature selection techniques utilized. Classifiers such as Multinomial Logistic Regression, Random Forest, Extreme Gradient Boosting (XGBoost), and One-vs-Rest classifier are employed to build various models. Contrary to expectations, all the models have constantly underperformed. XGBoost has given the highest accuracy of 53.03 percent with Chi-Squared feature selection. All the models have consistently shown an acceptable performance for Class 3 (remaining life is more than 10 years), significantly low for Class 1 (remaining life is up to 5 years), and the worst for Class 2 (remaining life is more than 5 but up to 10 years). Features analysis has deduced that almost all input variables are associated with multiple target classes. The high dimensionality of the input data after dummy encoding seems to have confused the models, leading to misclassifications. The approach taken in this study is ineffective in producing a high-performing predictive model but lays a foundation as this problem has never been viewed from a multiclass classification perspective.         _ Less","","arXiv","https://arxiv.org/abs/2402.10999","1","0","origin_of_life"
"Three Decades of Activations: A Comprehensive Survey of 400 Activation Functions for Neural Networks","Abstract:                Neural networks have proven to be a highly effective tool for solving complex problems in many areas of life. Recently, their importance and practical usability have further been reinforced with the advent of deep learning. One of the important conditions for the success of neural networks is the choice of an appropriate activation function introducing non-l_         _ More           Neural networks have proven to be a highly effective tool for solving complex problems in many areas of life. Recently, their importance and practical usability have further been reinforced with the advent of deep learning. One of the important conditions for the success of neural networks is the choice of an appropriate activation function introducing non-linearity into the model. Many types of these functions have been proposed in the literature in the past, but there is no single comprehensive source containing their exhaustive overview. The absence of this overview, even in our experience, leads to redundancy and the unintentional rediscovery of already existing activation functions. To bridge this gap, our paper presents an extensive survey involving 400 activation functions, which is several times larger in scale than previous surveys. Our comprehensive compilation also references these surveys; however, its main goal is to provide the most comprehensive overview and systematization of previously published activation functions with links to their original sources. The secondary aim is to update the current understanding of this family of functions.         _ Less","","arXiv","https://arxiv.org/abs/2402.09092","3","3","multiple"
"Optimizing the Design of an Artificial Pancreas to Improve Diabetes Management","Abstract:                _carbohydrates, basal pumping levels, and bolus injections. Evolution discovered a Pareto front that reduced deviation from the target and number of injections compared to the original data, thus improving patients' quality of life. To make the system easier to adopt, a language interface was developed with a large_         _ More           Diabetes, a chronic condition that impairs how the body turns food into energy, i.e. blood glucose, affects 38 million people in the US alone. The standard treatment is to supplement carbohydrate intake with an artificial pancreas, i.e. a continuous insulin pump (basal shots), as well as occasional insulin injections (bolus shots). The goal of the treatment is to keep blood glucose at the center of an acceptable range, as measured through a continuous glucose meter. A secondary goal is to minimize injections, which are unpleasant and difficult for some patients to implement. In this study, neuroevolution was used to discover an optimal strategy for the treatment. Based on a dataset of 30 days of treatment and measurements of a single patient, a random forest was first trained to predict future glucose levels. A neural network was then evolved to prescribe carbohydrates, basal pumping levels, and bolus injections. Evolution discovered a Pareto front that reduced deviation from the target and number of injections compared to the original data, thus improving patients' quality of life. To make the system easier to adopt, a language interface was developed with a large language model. Thus, these technologies not only improve patient care but also adoption in a broader population.         _ Less","","arXiv","https://arxiv.org/abs/2402.07949","0","1","synthetic_biology"
"Stellar flares","Abstract:                _to radio wavelengths, and they occur on most stars with outer convection zones. They are analogous to the events on the Sun known as solar flares, which impact our everyday life and modern technological society. Stellar flares, however, can attain much greater energies than those on the Sun. Despite this, we think that these phenomena are rather similar in_         _ More           Magnetic storms on stars manifest as remarkable, randomly occurring changes of the luminosity over durations that are tiny in comparison to the normal evolution of stars. These stellar flares are bursts of electromagnetic radiation from X-ray to radio wavelengths, and they occur on most stars with outer convection zones. They are analogous to the events on the Sun known as solar flares, which impact our everyday life and modern technological society. Stellar flares, however, can attain much greater energies than those on the Sun. Despite this, we think that these phenomena are rather similar in origin to solar flares, which result from a catastrophic conversion of latent magnetic field energy into atmospheric heating within a region that is relatively small in comparison to normal stellar sizes. We review the last several decades of stellar flare research. We summarize multi-wavelength observational results and the associated thermal and nonthermal processes in flaring stellar atmospheres. Static and hydrodynamic models are reviewed with an emphasis on recent progress in radiation-hydrodynamics and the physical diagnostics in flare spectra. Thanks to their effects on the space weather of exoplanetary systems (and thus in our search for life elsewhere in the universe) and their preponderance in \\emph{Kepler} mission data, white-light stellar flares have re-emerged in the last decade as a widely-impactful area of study within astrophysics. Yet, there is still much we do not understand, both empirically and theoretically, about the spectrum of flare radiation, its origin, and its time evolution. We conclude with several big-picture questions that are fundamental in our pursuit toward a greater understanding of these enigmatic stellar phonemena and, by extension, those on the Sun.         _ Less","","arXiv","https://arxiv.org/abs/2402.07885","1","2","synthetic_biology"
"Synthetic Dialogue Dataset Generation using LLM Agents","Abstract:                Linear programming (LP) problems are pervasive in real-life applications. However, despite their apparent simplicity, an untrained user may find it difficult to determine the linear model of their specific problem. We envisage the creation of a goal-oriented conversational agent that will engage in conversation with the user to elicit all information require_         _ More           Linear programming (LP) problems are pervasive in real-life applications. However, despite their apparent simplicity, an untrained user may find it difficult to determine the linear model of their specific problem. We envisage the creation of a goal-oriented conversational agent that will engage in conversation with the user to elicit all information required so that a subsequent agent can generate the linear model. In this paper, we present an approach for the generation of sample dialogues that can be used to develop and train such a conversational agent. Using prompt engineering, we develop two agents that 'talk' to each other, one acting as the conversational agent, and the other acting as the user. Using a set of text descriptions of linear problems from NL4Opt available to the user only, the agent and the user engage in conversation until the agent has retrieved all key information from the original problem description. We also propose an extrinsic evaluation of the dialogues by assessing how well the summaries generated by the dialogues match the original problem descriptions. We conduct human and automatic evaluations, including an evaluation approach that uses GPT-4 to mimic the human evaluation metrics. The evaluation results show an overall good quality of the dialogues, though research is still needed to improve the quality of the GPT-4 evaluation metrics. The resulting dialogues, including the human annotations of a subset, are available to the research community. The conversational agent used for the generation of the dialogues can be used as a baseline.         _ Less","","arXiv","https://arxiv.org/abs/2401.17461","1","0","origin_of_life"
"Text Image Inpainting via Global Structure-Guided Diffusion Models","Abstract:                _so, we establish two specific text inpainting datasets which contain scene text images and handwritten text images, respectively. Each of them includes images revamped by real-life and synthetic datasets, featuring pairs of original images, corrupted images, and other assistant information. On top of the datasets, we f_         _ More           Real-world text can be damaged by corrosion issues caused by environmental or human factors, which hinder the preservation of the complete styles of texts, e.g., texture and structure. These corrosion issues, such as graffiti signs and incomplete signatures, bring difficulties in understanding the texts, thereby posing significant challenges to downstream applications, e.g., scene text recognition and signature identification. Notably, current inpainting techniques often fail to adequately address this problem and have difficulties restoring accurate text images along with reasonable and consistent styles. Formulating this as an open problem of text image inpainting, this paper aims to build a benchmark to facilitate its study. In doing so, we establish two specific text inpainting datasets which contain scene text images and handwritten text images, respectively. Each of them includes images revamped by real-life and synthetic datasets, featuring pairs of original images, corrupted images, and other assistant information. On top of the datasets, we further develop a novel neural framework, Global Structure-guided Diffusion Model (GSDM), as a potential solution. Leveraging the global structure of the text as a prior, the proposed GSDM develops an efficient diffusion model to recover clean texts. The efficacy of our approach is demonstrated by thorough empirical study, including a substantial boost in both recognition accuracy and image quality. These findings not only highlight the effectiveness of our method but also underscore its potential to enhance the broader field of text image understanding and processing. Code and datasets are available at: https://github.com/blackprotoss/GSDM.         _ Less","","arXiv","https://arxiv.org/abs/2401.14832","1","0","origin_of_life"
"Small-scale radio jets and tidal disruption events: A theory of high-luminosity compact symmetric objects","Abstract:                _size. It has been argued that the vast majority of high-luminosity CSOs (CSO 2s) represent a distinct class of active galactic nuclei with its own morphological structure and life-cycle. In this work, we present theoretical considerations regarding CSO 2s. We develop a semi-analytic evolutionary model, inspired by the results of large-scale numerical simulat_         _ More           Double lobe radio sources associated with active galactic nuclei represent one of the longest studied groups in radio astronomy. A particular sub-group of double radio sources comprises the compact symmetric objects (CSOs). CSOs are distinguished by their prominent double structure and sub-kpc total size. It has been argued that the vast majority of high-luminosity CSOs (CSO 2s) represent a distinct class of active galactic nuclei with its own morphological structure and life-cycle. In this work, we present theoretical considerations regarding CSO 2s. We develop a semi-analytic evolutionary model, inspired by the results of large-scale numerical simulations of relativistic jets, that reproduces the features of the radio source population. We show that CSO 2s may be generated by finite energy injections and propose stellar tidal disruption events as a possible cause. We find that tidal disruption events of giant branch stars with masses $\\gtrsim1$ M$_\\odot$ can fuel these sources and discuss possible approaches to confirming this hypothesis. We predict that if the tidal disruption scenario holds, CSO 2s with sizes less than 400 pc should outnumber larger sources by more than a factor of $10$. Our results motivate future numerical studies to determine whether the scenarios we consider for fueling and source evolution can explain the observed radio morphologies. Multiwavelength observational campaigns directed at these sources will also provide critical insight into the origins of these objects, their environments, and their lifespans.         _ Less","","arXiv","https://arxiv.org/abs/2401.14399","0","1","synthetic_biology"
"Label-free detection of exosomes from different cellular sources based on surface-enhanced Raman spectroscopy combined with machine learning models","Abstract:                _By integrating Principal Component Analysis with Support Vector Machine (PCA-SVM) models, our analysis achieved a high accuracy rate of 94.4% in predicting exosomes originating from various cellular sources. In comparison to other machine learning analysis, our method used small amount of SERS data to allow a simple and rapid exosome detection, which enable_         _ More           Exosomes are significant facilitators of inter-cellular communication that can unveil cell-cell interactions, signaling pathways, regulatory mechanisms and disease diagnostics. Nonetheless, current analysis required large amount of data for exosome identification that it hampers efficient and timely mechanism study and diagnostics. Here, we used a machine-learning assisted Surface-enhanced Raman spectroscopy (SERS) method to detect exosomes derived from six distinct cell lines (HepG2, Hela, 143B, LO-2, BMSC, and H8) with small amount of data. By employing sodium borohydride-reduced silver nanoparticles and sodium borohydride solution as an aggregating agent, 100 SERS spectra of the each types of exosomes were collected and then subjected to multivariate and machine learning analysis. By integrating Principal Component Analysis with Support Vector Machine (PCA-SVM) models, our analysis achieved a high accuracy rate of 94.4% in predicting exosomes originating from various cellular sources. In comparison to other machine learning analysis, our method used small amount of SERS data to allow a simple and rapid exosome detection, which enables a timely subsequent study of cell-cell interactions, communication mechanisms, and disease mechanisms in life sciences.         _ Less","","arXiv","https://arxiv.org/abs/2401.14104","0","1","synthetic_biology"
"Privacy-Preserving Face Recognition in Hybrid Frequency-Color Domain","Abstract:                Face recognition technology has been deployed in various real-life applications. The most sophisticated deep learning-based face recognition systems rely on training millions of face images through complex deep neural networks to achieve high accuracy. It is quite common for clients to upload face images to the service provider in order to access the model i_         _ More           Face recognition technology has been deployed in various real-life applications. The most sophisticated deep learning-based face recognition systems rely on training millions of face images through complex deep neural networks to achieve high accuracy. It is quite common for clients to upload face images to the service provider in order to access the model inference. However, the face image is a type of sensitive biometric attribute tied to the identity information of each user. Directly exposing the raw face image to the service provider poses a threat to the user's privacy. Current privacy-preserving approaches to face recognition focus on either concealing visual information on model input or protecting model output face embedding. The noticeable drop in recognition accuracy is a pitfall for most methods. This paper proposes a hybrid frequency-color fusion approach to reduce the input dimensionality of face recognition in the frequency domain. Moreover, sparse color information is also introduced to alleviate significant accuracy degradation after adding differential privacy noise. Besides, an identity-specific embedding mapping scheme is applied to protect original face embedding by enlarging the distance among identities. Lastly, secure multiparty computation is implemented for safely computing the embedding distance during model inference. The proposed method performs well on multiple widely used verification datasets. Moreover, it has around 2.6% to 4.2% higher accuracy than the state-of-the-art in the 1:N verification scenario.         _ Less","","arXiv","https://arxiv.org/abs/2401.13386","1","0","origin_of_life"
"Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data","Abstract:                _to be realized, quality-assured image data must be shared among labs at a global scale to be compared, pooled, and reanalyzed, thus unleashing untold potential beyond the original purpose for which the data was generated. There are two broad sets of requirements to enable image data sharing in the_         _ More           Together with the molecular knowledge of genes and proteins, biological images promise to significantly enhance the scientific understanding of complex cellular systems and to advance predictive and personalized therapeutic products for human health. For this potential to be realized, quality-assured image data must be shared among labs at a global scale to be compared, pooled, and reanalyzed, thus unleashing untold potential beyond the original purpose for which the data was generated. There are two broad sets of requirements to enable image data sharing in the life sciences. One set of requirements is articulated in the companion White Paper entitled Enabling Global Image Data Sharing in the Life Sciences, which is published in parallel and addresses the need to build the cyberinfrastructure for sharing the digital array data. In this White Paper, we detail a broad set of requirements, which involves collecting, managing, presenting, and propagating contextual information essential to assess the quality, understand the content, interpret the scientific implications, and reuse image data in the context of the experimental details. We start by providing an overview of the main lessons learned to date through international community activities, which have recently made considerable progress toward generating community standard practices for imaging Quality Control (QC) and metadata. We then provide a clear set of recommendations for amplifying this work. The driving goal is to address remaining challenges and democratize access to everyday practices and tools for a spectrum of biomedical researchers, regardless of their expertise, access to resources, and geographical location.         _ Less","","arXiv","https://arxiv.org/abs/2401.13022","2","1","origin_of_life"
"Detection and chemical modelling of complex prebiotic molecule cyanamide in the hot molecular core G31.41+0.31","Abstract:                _CN is important for understanding the hypothesis of the pre-solar origin of life in the universe. We present the detection of the rotational emission lines of NH$_{2}$CN with vibrational states $v$ = 0 and 1 towards the hot molecular core G31.41+0.31 using the high-resolution twelve-meter array of Atacama Large Millime_         _ More           In the interstellar medium (ISM), the complex prebiotic molecule cyanamide (NH$_{2}$CN) plays a key role in producing adenine (C$_{5}$H$_{5}$N$_{5}$), purines (C$_{5}$H$_{4}$N$_{4}$), pyrimidines (C$_{4}$H$_{4}$N$_{2}$), and other biomolecules via a series of reactions. Therefore, studying the emission lines of NH$_{2}$CN is important for understanding the hypothesis of the pre-solar origin of life in the universe. We present the detection of the rotational emission lines of NH$_{2}$CN with vibrational states $v$ = 0 and 1 towards the hot molecular core G31.41+0.31 using the high-resolution twelve-meter array of Atacama Large Millimeter/Submillimeter Array (ALMA) band 3. The estimated column density of NH$_{2}$CN towards G31.41+0.31 using the local thermodynamic equilibrium (LTE) model is (7.21$\\pm$0.25)$\\times$10$^{15}$ cm$^{-2}$ with an excitation temperature of 250$\\pm$25 K. The abundance of NH$_{2}$CN with respect to H$_{2}$ towards G31.41+0.31 is (7.21$\\pm$1.46)$\\times$10$^{-10}$. The NH$_{2}$CN and NH$_{2}$CHO column density ratio towards G31.41+0.31 is 0.13$\\pm$0.02. We compare the estimated abundance of NH$_{2}$CN with that of other hot cores and corinos and observed that the abundance of NH$_{2}$CN towards G31.41+0.31 is nearly similar to that of the hot molecular core G358.93$-$0.03 MM1, the hot corinos IRAS 16293-2422 B, and NGC 1333 IRAS4A2. We compute the two-phase warm-up chemical model of NH$_{2}$CN using the gas-grain chemical code UCLCHEM, and after chemical modelling, we notice that the observed and modelled abundances are nearly similar. After chemical modelling, we conclude that the neutral-neutral reaction between NH$_{2}$ and CN is responsible for the production of NH$_{2}$CN on the grain surface of G31.41+0.31.         _ Less","","arXiv","https://arxiv.org/abs/2401.12879","2","0","origin_of_life"
"A Payne-Whitham model of urban traffic networks in the presence of traffic lights and its application to traffic optimisation","Abstract:                Urban road transport is a major civilisational and economic challenge, affecting the quality of life and economic activity. Addressing these challenges requires a multidisciplinary approach and sustainable urban planning strategies to mitigate the negative effects of traffic in cities. In this paper, we introduce an extension of one of the most popular macro_         _ More           Urban road transport is a major civilisational and economic challenge, affecting the quality of life and economic activity. Addressing these challenges requires a multidisciplinary approach and sustainable urban planning strategies to mitigate the negative effects of traffic in cities. In this paper, we introduce an extension of one of the most popular macroscopic traffic simulation models, the Payne-Whitham model. We investigate how this model, originally designed to model highway traffic on straight road segments, can be adapted to more realistic conditions with arbitrary road network graphs and multiple intersections with traffic signals. Furthermore, we showcase the practical application of this extension in experiments aimed at optimising traffic signal settings. For computational reasons, these experiments involve the adoption of surrogate models for approximating our extended Payne-Whitham model, and subsequently, we utilise the Differential Evolution optimization algorithm, resulting in the identification of traffic signal settings that enhance the average speed of cars and decrease the total length of queues, thereby facilitating smoother traffic flow.         _ Less","","arXiv","https://arxiv.org/abs/2401.04436","0","1","synthetic_biology"
"The Implications of 'Oumuamua on Panspermia","Abstract:                Panspermia is the hypothesis that life_         _ More           Panspermia is the hypothesis that life originated on Earth from the bombardment of foreign interstellar ejecta harboring polyextremophile microorganisms. Since the 2017 discovery of the interstellar body 'Oumuamua (1I/2017 U1) by the Pans-STARRS telescope, various studies have re-examined panspermia based on updated number density models that accommodate for 'Oumuamua's properties. By utilizing 'Oumuamua's properties as an anchor, we estimate the mass and number density of ejecta in the ISM (rho_m [kg au^-3] and rho_n [au^-3]). We build upon prior work by first accounting for the minimum ejecta size to shield microbes from supernova radiation. Second, we estimate the total number of impact events C_n on Earth after its formation and prior to the emergence of life (~0.8Gyr). We derive a conditional probability relation for the likelihood of panspermia for Earth specifically of <10^-5, given a number of factors including f_B, the fraction of ejecta harboring extremophiles and other factors that are poorly constrained. However, we find that panspermia is a plausible potential life-seeding mechanism for (optimistically) potentially up to ~10^5 of the ~10^9 Earth-sized habitable zone worlds in our Galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2401.02390","2","0","origin_of_life"
"The Role of Low-energy (< 20 eV) Secondary Electrons in the Extraterrestrial Synthesis of Prebiotic Molecules","Abstract:                _be a significant contributor to the interstellar synthesis of prebiotic molecules whose delivery by comets, meteorites, and interplanetary dust particles may have kick-started life on Earth. We explore the relative importance of low-energy (< 20 eV) secondary electrons--agents of radiation chemistry--and low-energy (< 10 eV), non-ionizing photons--inst_         _ More           We demonstrate for the first time that Galactic cosmic rays with energies as high as 1e10 eV can trigger a cascade of low-energy (< 20 eV) secondary electrons that could be a significant contributor to the interstellar synthesis of prebiotic molecules whose delivery by comets, meteorites, and interplanetary dust particles may have kick-started life on Earth. We explore the relative importance of low-energy (< 20 eV) secondary electrons--agents of radiation chemistry--and low-energy (< 10 eV), non-ionizing photons--instigators of photochemistry. Our calculations indicate fluxes of 100 electrons/cm2/s for low-energy secondary electrons produced within interstellar ices due to incident attenuated Galactic cosmic-ray (CR) protons. Consequently, in certain star-forming regions where internal high-energy radiation sources produce ionization rates that are observed to be a thousand times greater than the typical interstellar Galactic ionization rate, the flux of low-energy secondary electrons should far exceed that of non-ionizing photons. Because reaction cross-sections can be several orders of magnitude larger for electrons than for photons, even in the absence of such enhancement our calculations indicate that secondary low-energy electrons are at least as significant as low-energy (< 10 eV) non-ionizing photons in the interstellar synthesis of prebiotic molecules. Most importantly, our results demonstrate the pressing need for explicitly incorporating low-energy electrons in current and future astrochemical simulations of cosmic ices. Such models are critically important for interpreting James Webb Space Telescope infrared measurements, which are currently being used to probe the origins of life by studying complex organic molecules found in ices near star-forming regions.         _ Less","","arXiv","https://arxiv.org/abs/2312.02180","1","0","origin_of_life"
"Self-consistent Conditions for $^{26}$Al Injection into Protosolar Disk from a Nearby Supernova","Abstract:                _Al (its half-life time $t_{1/2} = 0.7$ Myr). The decay energy $^{26}$Al is thought to have controlled the thermal evolution of planetesimals and, possibly, the water contents of planets. Many hypotheses have been proposed for the origin of $^{26}$Al in the solar system. One of the possible hypotheses is the `disk injec_         _ More           The early solar system contained a short-lived radionuclide, $^{26}$Al (its half-life time $t_{1/2} = 0.7$ Myr). The decay energy $^{26}$Al is thought to have controlled the thermal evolution of planetesimals and, possibly, the water contents of planets. Many hypotheses have been proposed for the origin of $^{26}$Al in the solar system. One of the possible hypotheses is the `disk injection scenario'; when the protoplanetary disk of the solar system had already formed, a nearby $(<1 \\,\\mathrm{pc})$ supernova injected radioactive material directly into the disk. Such a $^{26}$Al injection hypothesis has been tested so far with limited setups for disk structure and supernova distance, and treated disk disruption and $^{26}$Al injection separately. Here, we revisit this problem to investigate whether there are self-consistent conditions under which the surviving disk radius can receive enough $^{26}$Al which can account for the abundance in the early solar system. We also consider a range of disk mass and structure, $^{26}$Al yields from supernova, and a large dust mass fraction $__\\mathrm{d}$. We find that $^{26}$Al yields of supernova are required as $\\gtrsim 2.1\\times10^{-3}M_\\odot(__\\mathrm{d}/0.2)^{-1}$, challenging to achieve with known possible $^{26}$Al ejection and dust mass fraction ranges. Furthermore, we find that even if the above conditions are met, the supernova flow changes the disk temperature, which may not be consistent with the solar-system record. Our results place a strong constraint on the disk injection scenario. Rather, we suggest that the fresh $^{26}$Al of the early solar system must have been synthesized/injected in other ways.         _ Less","","arXiv","https://arxiv.org/abs/2312.01948","0","1","synthetic_biology"
"With Great Humor Comes Great Developer Engagement","Abstract:                _create. Engaged developers, such as Margaret Hamilton programming Apollo 11, can succeed in tackling the most difficult engineering tasks. In this paper, we dive deep into an original vector of engagement - humor - and study how it fuels developer engagement. First, we collect qualitative and quantitative data about the humorous elements present within three_         _ More           The worldwide collaborative effort for the creation of software is technically and socially demanding. The more engaged developers are, the more value they impart to the software they create. Engaged developers, such as Margaret Hamilton programming Apollo 11, can succeed in tackling the most difficult engineering tasks. In this paper, we dive deep into an original vector of engagement - humor - and study how it fuels developer engagement. First, we collect qualitative and quantitative data about the humorous elements present within three significant, real-world software projects: faker, which helps developers introduce humor within their tests; lolcommits, which captures a photograph after each contribution made by a developer; and volkswagen, an exercise in satire, which accidentally led to the invention of an impactful software tool. Second, through a developer survey, we receive unique insights from 125 developers, who share their real-life experiences with humor in software. Our analysis of the three case studies highlights the prevalence of humor in software, and unveils the worldwide community of developers who are enthusiastic about both software and humor. We also learn about the caveats of humor in software through the valuable insights shared by our survey respondents. We report clear evidence that, when practiced responsibly, humor increases developer engagement and supports them in addressing hard engineering and cognitive tasks. The most actionable highlight of our work is that software tests and documentation are the best locations in code to practice humor.         _ Less","","arXiv","https://arxiv.org/abs/2312.01680","1","1","multiple"
"The prebiotic emergence of biological evolution","Abstract:                The origin of life must have been preceded by Darwin-like evolutionary dynamics that could propagate it. How did that adaptive dynamics arise? And from what prebiotic molecules? Using evolutionary invasion analysis, we develop a universal framework for describing any origin story_         _ More           The origin of life must have been preceded by Darwin-like evolutionary dynamics that could propagate it. How did that adaptive dynamics arise? And from what prebiotic molecules? Using evolutionary invasion analysis, we develop a universal framework for describing any origin story for evolutionary dynamics. We find that cooperative autocatalysts, i.e. autocatalysts whose per-unit reproductive rate grows as their population increases, have the special property of being able to cross a barrier that separates their initial degradation-dominated state from a growth-dominated state with evolutionary dynamics. For some model parameters, this leap to persistent propagation is likely, not rare. We apply this analysis to the Foldcat Mechanism, wherein peptides fold and help catalyze the elongation of each other. Foldcats are found to have cooperative autocatalysis and be capable of emergent evolutionary dynamics.         _ Less","","arXiv","https://arxiv.org/abs/2311.13650","3","2","origin_of_life"
"Decoding the Molecular Universe -- Workshop Report","Abstract:                _Human Genome Project by developing new capabilities and technologies to measure small molecules (defined as non-protein, non-polymer molecules less than 1500 Daltons) of any origin and generated in biological systems or produced abiotically. Workshop attendees 1) explored what new understanding of biological and environmental systems could be revealed throug_         _ More           On August 9-10, 2023, a workshop was convened at the Pacific Northwest National Laboratory (PNNL) in Richland, WA that brought together a group of internationally recognized experts in metabolomics, natural products discovery, chemical ecology, chemical and biological threat assessment, cheminformatics, computational chemistry, cloud computing, artificial intelligence, and novel technology development. These experts were invited to assess the value and feasibility of a grand-scale project to create new technologies that would allow the identification and quantification of all small molecules, or to decode the molecular universe. The Decoding the Molecular Universe project would extend and complement the success of the Human Genome Project by developing new capabilities and technologies to measure small molecules (defined as non-protein, non-polymer molecules less than 1500 Daltons) of any origin and generated in biological systems or produced abiotically. Workshop attendees 1) explored what new understanding of biological and environmental systems could be revealed through the lens of small molecules; 2) characterized the similarities in current needs and technical challenges between each science or mission area for unambiguous and comprehensive determination of the composition and quantities of small molecules of any sample; 3) determined the extent to which technologies or methods currently exist for unambiguously and comprehensively determining the small molecule composition of any sample and in a reasonable time; and 4) identified the attributes of the ideal technology or approach for universal small molecule measurement and identification. The workshop concluded with a discussion of how a project of this scale could be undertaken, possible thrusts for the project, early proof-of-principle applications, and similar efforts upon which the project could be modeled.         _ Less","","arXiv","https://arxiv.org/abs/2311.11437","1","1","multiple"
"Images Connect Us Together: Navigating a COVID-19 Local Outbreak in China Through Social Media Images","Abstract:                _of a pandemic which is characterized by uncertain local situations and emotional fatigue. To fill this gap, this work collected 345,423 crisis-related posts and 65,376 original images during the Xi'an COVID-19 local outbreak in China, and adopted a mixed-methods approach to understanding themes, goals, and strategies of crisis imagery. Image clustering c_         _ More           Social media images, curated or casual, have become a crucial component of communicating situational information and emotions during health crises. Despite its prevalence and significance in informational dissemination and emotional connection, there lacks a comprehensive understanding of visual crisis communication in the aftermath of a pandemic which is characterized by uncertain local situations and emotional fatigue. To fill this gap, this work collected 345,423 crisis-related posts and 65,376 original images during the Xi'an COVID-19 local outbreak in China, and adopted a mixed-methods approach to understanding themes, goals, and strategies of crisis imagery. Image clustering captured the diversity of visual themes during the outbreak, such as text images embedding authoritative guidelines and ``visual diaries'' recording and sharing the quarantine life. Through text classification of the post that visuals were situated in, we found that different visual themes highly correlated with the informational and emotional goals of the post text, such as adopting text images to convey the latest policies and sharing food images to express anxiety. We further unpacked nuanced strategies of crisis image use through inductive coding, such as signifying authority and triggering empathy. We discuss the opportunities and challenges of crisis imagery and provide design implications to facilitate effective visual crisis communication.         _ Less","","arXiv","https://arxiv.org/abs/2311.10977","2","1","origin_of_life"
"Radioactive Decay of Specific Heavy Elements as an Energy Source for Late-Time Kilonovae and Potential JWST Observations","Abstract:                Revealing the temporal evolution of individual heavy elements synthesized in the merger ejecta from binary neutron star mergers not only improves our understanding of the origin of heavy elements beyond iron but also clarifies the energy sources of kilonovae. In this work, we present a comprehensive analysis of the temporal evolution of the energy fraction o_         _ More           Revealing the temporal evolution of individual heavy elements synthesized in the merger ejecta from binary neutron star mergers not only improves our understanding of the origin of heavy elements beyond iron but also clarifies the energy sources of kilonovae. In this work, we present a comprehensive analysis of the temporal evolution of the energy fraction of each nuclide based on the $r$-process nucleosynthesis simulations. The heavy elements dominating the kilonova emission within $\\sim100$~days are identified, including $^{127}$Sb, $^{128}$Sb, $^{129}$Sb, $^{130}$Sb, $^{129}$Te, $^{132}$I, $^{222}$Rn, $^{223}$Ra, $^{224}$Ra, and $^{225}$Ac. It is found that the late-time kilonova light curve ($t\\gtrsim20$~days) is highly sensitive to the presence of the heavy element $^{225}$Ac (with a half-life of 10.0~days). Our analysis shows that the James Webb Space Telescope (JWST), with its high sensitivity in the near-infrared band, is a powerful instrument for the identification of these specific heavy elements.         _ Less","","arXiv","https://arxiv.org/abs/2311.08260","1","2","synthetic_biology"
"Cross-subject dual-domain fusion network with task-related and task-discriminant component analysis enhancing one-shot SSVEP classification","Abstract:                _templates, thereby mitigating inter-individual variability and benefiting transfer learning. Subsequently, the transformed data in the sine-cosine templates domain and the original domain data are separately utilized to train a convolutional neural network (CNN) model, with the adequate fusion of their feature maps occurring at distinct network layers. To fu_         _ More           This study addresses the significant challenge of developing efficient decoding algorithms for classifying steady-state visual evoked potentials (SSVEPs) in scenarios characterized by extreme scarcity of calibration data, where only one calibration is available for each stimulus target. To tackle this problem, we introduce a novel cross-subject dual-domain fusion network (CSDuDoFN) incorporating task-related and task-discriminant component analysis (TRCA and TDCA) for one-shot SSVEP classification. The CSDuDoFN framework is designed to comprehensively transfer information from source subjects, while TRCA and TDCA are employed to exploit the single available calibration of the target subject. Specifically, we develop multi-reference least-squares transformation (MLST) to map data from both source subjects and the target subject into the domain of sine-cosine templates, thereby mitigating inter-individual variability and benefiting transfer learning. Subsequently, the transformed data in the sine-cosine templates domain and the original domain data are separately utilized to train a convolutional neural network (CNN) model, with the adequate fusion of their feature maps occurring at distinct network layers. To further capitalize on the calibration of the target subject, source aliasing matrix estimation (SAME) data augmentation is incorporated into the training process of the ensemble TRCA (eTRCA) and TDCA models. Ultimately, the outputs of the CSDuDoFN, eTRCA, and TDCA are combined for SSVEP classification. The effectiveness of our proposed approach is comprehensively evaluated on three publicly available SSVEP datasets, achieving the best performance on two datasets and competitive performance on one. This underscores the potential for integrating brain-computer interface (BCI) into daily life.         _ Less","","arXiv","https://arxiv.org/abs/2311.07932","2","1","origin_of_life"
"Scaling of average trapping time and average weighted shortest path on a residual multi-weighted crystal network","Abstract:                This article constructs the residual network after some regions were damaged and detached from the original crystal network. This residual crystal network simulates the situation where parts of a computer system or power system failed after been attacked in real life. Furthermore, we assign multiple weight factors to t_         _ More           This article constructs the residual network after some regions were damaged and detached from the original crystal network. This residual crystal network simulates the situation where parts of a computer system or power system failed after been attacked in real life. Furthermore, we assign multiple weight factors to the edges in the network, exhibiting mixed weight growth. By using the symmetry and self-similarity of the network structure, the analytical expression for the average trapping time and the average weighted shortest path on this network are solved, and the numerical results are given by taking the residual hexagonal crystal network as an example. By analyzing the network and studying the topological properties, we show the robustness of the network structure and find the residual network is more efficient for communication between nodes.         _ Less","","arXiv","https://arxiv.org/abs/2311.06301","0","1","synthetic_biology"
"Explainable artificial intelligence for Healthcare applications using Random Forest Classifier with LIME and SHAP","Abstract:                With the advances in computationally efficient artificial Intelligence (AI) techniques and their numerous applications in our everyday life, there is a pressing need to understand the computational details hidden in black box AI techniques such as most popular machine learning and deep learning techniques; through more detailed explanations. The_         _ More           With the advances in computationally efficient artificial Intelligence (AI) techniques and their numerous applications in our everyday life, there is a pressing need to understand the computational details hidden in black box AI techniques such as most popular machine learning and deep learning techniques; through more detailed explanations. The origin of explainable AI (xAI) is coined from these challenges and recently gained more attention by the researchers by adding explainability comprehensively in traditional AI systems. This leads to develop an appropriate framework for successful applications of xAI in real life scenarios with respect to innovations, risk mitigation, ethical issues and logical values to the users. In this book chapter, an in-depth analysis of several xAI frameworks and methods including LIME (Local Interpretable Model-agnostic Explanations) and SHAP (SHapley Additive exPlanations) are provided. Random Forest Classifier as black box AI is used on a publicly available Diabetes symptoms dataset with LIME and SHAP for better interpretations. The results obtained are interesting in terms of transparency, valid and trustworthiness in diabetes disease prediction.         _ Less","","arXiv","https://arxiv.org/abs/2311.05665","1","1","multiple"
"Efficient Vision Transformer for Accurate Traffic Sign Detection","Abstract:                _systems. The development of reliable and highly accurate algorithms is crucial for the widespread adoption of traffic sign recognition and detection (TSRD) in diverse real-life scenarios. However, this task is complicated by suboptimal traffic images affected by factors such as camera movement, adverse weather conditions, and inadequate lighting. This study_         _ More           This research paper addresses the challenges associated with traffic sign detection in self-driving vehicles and driver assistance systems. The development of reliable and highly accurate algorithms is crucial for the widespread adoption of traffic sign recognition and detection (TSRD) in diverse real-life scenarios. However, this task is complicated by suboptimal traffic images affected by factors such as camera movement, adverse weather conditions, and inadequate lighting. This study specifically focuses on traffic sign detection methods and introduces the application of the Transformer model, particularly the Vision Transformer variants, to tackle this task. The Transformer's attention mechanism, originally designed for natural language processing, offers improved parallel efficiency. Vision Transformers have demonstrated success in various domains, including autonomous driving, object detection, healthcare, and defense-related applications. To enhance the efficiency of the Transformer model, the research proposes a novel strategy that integrates a locality inductive bias and a transformer module. This includes the introduction of the Efficient Convolution Block and the Local Transformer Block, which effectively capture short-term and long-term dependency information, thereby improving both detection speed and accuracy. Experimental evaluations demonstrate the significant advancements achieved by this approach, particularly when applied to the GTSDB dataset.         _ Less","","arXiv","https://arxiv.org/abs/2311.01429","1","0","origin_of_life"
"Characterization and Exploitation of the Rotational Memory Effect in Multimode Fibers","Abstract:                _(RME), remains independent of the typically unknown output profile. The RME thus offers significant potential for imaging and telecommunication applications. However, in real-life fibers, this effect is degraded by intrinsic imperfections and external perturbations, and is challenging to observe because of its acute sensitivity to misalignments and aberratio_         _ More           In an ideal perfectly straight multimode fiber with a circular-core, the symmetry ensures that rotating the input wavefront leads to a corresponding rotation of the output wavefront. This invariant property, known as the rotational memory effect (RME), remains independent of the typically unknown output profile. The RME thus offers significant potential for imaging and telecommunication applications. However, in real-life fibers, this effect is degraded by intrinsic imperfections and external perturbations, and is challenging to observe because of its acute sensitivity to misalignments and aberrations in the optical setup. Thanks to processing involving a spatial light modulator, we efficiently overcome these measurement biases, allowing for precise quantification of the RME. We establish an experimental and theoretical framework for studying and manipulating the RME in multimode fibers. Theoretical predictions are consistent with experimental data and simulations, connecting the shape of the angular-dependent correlation of the RME to the geometrical properties of the core deformation. This work opens the road for accurate characterization of the distributed disorder originating from the fabrication process and calibration-less imaging in multimode fibers.         _ Less","","arXiv","https://arxiv.org/abs/2310.19337","1","0","origin_of_life"
"Mapping Observations of Peptide-like molecules around Sagittarius B2","Abstract:                Peptide-like molecule, which has a close connection with the origin of life, has been detected in universe. Mapping observations of HCONH$_2$ and CH$_3$CONH$_2$, two simplest peptide-like molecules, are performed towards Sagittarius B2 (Sgr B2) complex with the IRAM 30m telescope. Seven transitions of HCONH$_2$ and fiv_         _ More           Peptide-like molecule, which has a close connection with the origin of life, has been detected in universe. Mapping observations of HCONH$_2$ and CH$_3$CONH$_2$, two simplest peptide-like molecules, are performed towards Sagittarius B2 (Sgr B2) complex with the IRAM 30m telescope. Seven transitions of HCONH$_2$ and five transitions of CH$_3$CONH$_2$ are used in analysis. The spatial distribution of excitation temperature and column density of HCONH$_2$ in the molecular envelope of Sgr B2 are obtained by the rotation diagrams. Assuming the same excitation temperature as HCONH$_2$, the column densities of CH$_3$CONH$_2$ are also calculated. The results show that excitation temperature ranges from 6 K to 46 K in the molecular envelope of Sgr B2. The abundance ratio between HCONH$_2$ and CH$_3$CONH$_2$ are calculated to explore the relationship among them, as well as HNCO mentioned in our pervious research. The abundance ratio of CH$_3$CONH$_2$/HCONH$_2$ varies from 10% to 20%, while that of HCONH$_2$/HNCO ranges from 1.5% to 10%. CH$_3$CONH$_2$ is enhanced with respect to HCONH$_2$ in the northwest region of Sgr B2. One transition of H$^{13}$CONH$_2$ is detected toward 12 positions of Sgr B2, from which a $^{12}$C/$^{13}$C ratio of 28.7 is obtained. A time-dependent chemical model with a short duration of X-ray burst is used to explain the observed abundances of HCONH$_2$ and CH$_3$CONH$_2$, with the best fitting result at T$\\rm_{dust}$ = 53-56 K. More chemical reactions are required to be included into the model since the modeled abundance is lower than the observed one at the observed T$\\rm_{dust}$.         _ Less","","arXiv","https://arxiv.org/abs/2310.16664","1","0","origin_of_life"
"Radio Frequency Fingerprinting via Deep Learning: Challenges and Opportunities","Abstract:                _that make up the device-specific fingerprint. However, integrating DL techniques with RFF and operating the system in real-world scenarios presents numerous challenges, originating from the embedded systems and the DL research domains. This paper systematically identifies and analyzes the essential considerations and challenges encountered in the creation of_         _ More           Radio Frequency Fingerprinting (RFF) techniques promise to authenticate wireless devices at the physical layer based on inherent hardware imperfections introduced during manufacturing. Such RF transmitter imperfections are reflected into over-the-air signals, allowing receivers to accurately identify the RF transmitting source. Recent advances in Machine Learning, particularly in Deep Learning (DL), have improved the ability of RFF systems to extract and learn complex features that make up the device-specific fingerprint. However, integrating DL techniques with RFF and operating the system in real-world scenarios presents numerous challenges, originating from the embedded systems and the DL research domains. This paper systematically identifies and analyzes the essential considerations and challenges encountered in the creation of DL-based RFF systems across their typical development life-cycle, which include (i) data collection and preprocessing, (ii) training, and finally, (iii) deployment. Our investigation provides a comprehensive overview of the current open problems that prevent real deployment of DL-based RFF systems while also discussing promising research opportunities to enhance the overall accuracy, robustness, and privacy of these systems.         _ Less","","arXiv","https://arxiv.org/abs/2310.16406","2","2","multiple"
"Xeno Amino Acids: A look into biochemistry as we don't know it","Abstract:                Would another origin of_         _ More           Would another origin of life resemble Earth's biochemical use of amino acids? Here we review current knowledge at three levels: 1) Could other classes of chemical structure serve as building blocks for biopolymer structure and catalysis? Amino acids now seem both readily available to, and a plausible chemical attractor for, life as we don't know it. Amino acids thus remain important and tractable targets for astrobiological research. 2) If amino acids are used, would we expect the same L-alpha-structural subclass used by life? Despite numerous ideas, it is not clear why life favors L-enantiomers. It seems clearer, however, why life on Earth uses the shortest possible (alpha-) amino acid backbone, and why each carries only one side chain. However, assertions that other backbones are physicochemically impossible have relaxed into arguments that they are disadvantageous. 3) Would we expect a similar set of side chains to those within the genetic code? Not only do many plausible alternatives exist and evidence exists for both evolutionary advantage and physicochemical constraint for those encoded by life. Overall, as focus shifts from amino acids as a chemical class to specific side chains used by post-LUCA biology, the probable role of physicochemical constraint diminishes relative to that of biological evolution. Exciting opportunities now present themselves for laboratory work and computing to explore how changing the amino acid alphabet alters the universe of protein folds. Near-term milestones include: a) expanding evidence about amino acids as attractors within chemical evolution; b) extending characterization of other backbones relative to biological proteins; c) merging computing and laboratory explorations of structures and functions unlocked by xeno peptides.         _ Less","","arXiv","https://arxiv.org/abs/2310.15857","4","2","origin_of_life"
"Can comets deliver prebiotic molecules to rocky exoplanets?","Abstract:                In this work we consider the potential of cometary impacts to deliver complex organic molecules and the prebiotic building blocks required for life to rocky exoplanets. Numerical experiments have demonstrated that for these molecules to survive, impacts at very low velocities are required. This work shows that for comets scattered from beyond the snow-line i_         _ More           In this work we consider the potential of cometary impacts to deliver complex organic molecules and the prebiotic building blocks required for life to rocky exoplanets. Numerical experiments have demonstrated that for these molecules to survive, impacts at very low velocities are required. This work shows that for comets scattered from beyond the snow-line into the habitable zone, the minimum impact velocity is always lower for planets orbiting Solar-type stars than M-dwarfs. Using both an analytical model and numerical N-body simulations, we show that the lowest velocity impacts occur onto planets in tightly-packed planetary systems around high-mass (i.e. Solar-mass) stars, enabling the intact delivery of complex organic molecules. Impacts onto planets around low-mass stars are found to be very sensitive to the planetary architecture, with the survival of complex prebiotic molecules potentially impossible in loosely-packed systems. Rocky planets around M-dwarfs also suffer significantly more high velocity impacts, potentially posing unique challenges for life on these planets. In the scenario that cometary delivery is important for the origins of life, this study predicts the presence of biosignatures will be correlated with i) decreasing planetary mass (i.e. escape velocity), ii) increasing stellar-mass, and iii) decreasing planetary separation (i.e. exoplanets in tightly-packed systems).         _ Less","","arXiv","https://arxiv.org/abs/2310.12906","1","0","origin_of_life"
"Prebiotic Vitamin B$_3$ Synthesis in Carbonaceous Planetesimals","Abstract:                Aqueous chemistry within carbonaceous planetesimals is promising for synthesizing prebiotic organic matter essential to all life. Meteorites derived from these planetesimals delivered these_         _ More           Aqueous chemistry within carbonaceous planetesimals is promising for synthesizing prebiotic organic matter essential to all life. Meteorites derived from these planetesimals delivered these life building blocks to the early Earth, potentially facilitating the origins of life. Here, we studied the formation of vitamin B$_3$ as it is an important precursor of the coenzyme NAD(P)(H), which is essential for the metabolism of all life as we know it. We propose a new reaction mechanism based on known experiments in the literature that explains the synthesis of vitamin B$_3$. It combines the sugar precursors glyceraldehyde or dihydroxyacetone with the amino acids aspartic acid or asparagine in aqueous solution without oxygen or other oxidizing agents. We performed thermochemical equilibrium calculations to test the thermodynamic favorability. The predicted vitamin B$_3$ abundances resulting from this new pathway were compared with measured values in asteroids and meteorites. We conclude that competition for reactants and decomposition by hydrolysis are necessary to explain the prebiotic content of meteorites. In sum, our model fits well into the complex network of chemical pathways active in this environment.         _ Less","","arXiv","https://arxiv.org/abs/2310.11433","2","2","multiple"
"The Qitai Radio Telescope","Abstract:                _(nanoHertz) gravitational waves through pulsar timing array (PTA) techniques, pulsar surveys, the discovery of binary black-hole systems, and exploring dark matter and the origin of life in the universe.         _ More           This study presents a general outline of the Qitai radio telescope (QTT) project. Qitai, the site of the telescope, is a county of Xinjiang Uygur Autonomous Region of China, located in the east Tianshan Mountains at an elevation of about 1800 m. The QTT is a fully steerable, Gregorian type telescope with a standard parabolic main reflector of 110 m diameter. The QTT has adopted an um-brella support, homology-symmetric lightweight design. The main reflector is active so that the deformation caused by gravity can be corrected. The structural design aims to ultimately allow high-sensitivity observations from 150 MHz up to 115 GHz. To satisfy the requirements for early scientific goals, the QTT will be equipped with ultra-wideband receivers and large field-of-view mul-ti-beam receivers. A multi-function signal-processing system based on RFSoC and GPU processor chips will be developed. These will enable the QTT to operate in pulsar, spectral line, continuum and Very Long Baseline Interferometer (VLBI) observing modes. Electromagnetic compatibility (EMC) and radio frequency interference (RFI) control techniques are adopted throughout the system design. The QTT will form a world-class observational platform for the detection of low-frequency (nanoHertz) gravitational waves through pulsar timing array (PTA) techniques, pulsar surveys, the discovery of binary black-hole systems, and exploring dark matter and the origin of life in the universe.         _ Less","","arXiv","https://arxiv.org/abs/2310.07163","3","1","origin_of_life"
"Relative abundances of CO2, CO, and CH4 in atmospheres of Earth-like lifeless planets","Abstract:                Carbon is an essential element for life on Earth, and the relative abundances of major carbon species (CO2, CO, and CH4) in the atmosphere exert fundamental controls on planetary climate and biogeochemistry. Here, we employed a theoretical model of atmospheric chemistry to investigate diversity in the atmospheric abundances of CO2, CO, and CH4 on Earth-like_         _ More           Carbon is an essential element for life on Earth, and the relative abundances of major carbon species (CO2, CO, and CH4) in the atmosphere exert fundamental controls on planetary climate and biogeochemistry. Here, we employed a theoretical model of atmospheric chemistry to investigate diversity in the atmospheric abundances of CO2, CO, and CH4 on Earth-like lifeless planets orbiting Sun-like (F-, G-, and K-type) stars. We focused on the conditions for the formation of a CO-rich atmosphere, which would be favorable for the origin of life. Results demonstrated that elevated atmospheric CO2 levels trigger photochemical instability of the CO budget in the atmosphere (i.e., CO runaway) owing to enhanced CO2 photolysis relative to H2O photolysis. Higher volcanic outgassing fluxes of reduced C (CO and CH4) also tend to initiate CO runaway. Our systematic examinations revealed that anoxic atmospheres of Earth-like lifeless planets could be classified in the phase space of CH4/CO2 versus CO/CO2, where a distinct gap in atmospheric carbon chemistry is expected to be observed. Our findings indicate that the gap structure is a general feature of Earth-like lifeless planets with reducing atmospheres orbiting Sun-like (F-, G-, and K-type) stars.         _ Less","","arXiv","https://arxiv.org/abs/2309.13538","2","0","origin_of_life"
"Patient-perceived progression in multiple system atrophy: natural history of quality of life","Abstract:                Health-related quality of life (Hr-QoL) scales provide crucial information on neurodegenerative disease progression, help improving patient care, and constitute a meaningful endpoint for therapeutic research. However, Hr-QoL progression is usually poorly documented, as for multiple system atrophy (MSA), a rare and rapidly progressing alpha-synucleinopathy. T_         _ More           Health-related quality of life (Hr-QoL) scales provide crucial information on neurodegenerative disease progression, help improving patient care, and constitute a meaningful endpoint for therapeutic research. However, Hr-QoL progression is usually poorly documented, as for multiple system atrophy (MSA), a rare and rapidly progressing alpha-synucleinopathy. This work aimed to describe Hr-QoL progression during the natural course of MSA, explore disparities between patients, and identify informative items using a four-step statistical strategy.We leveraged the data of the French MSA cohort comprising annual assessments with the MSA-QoL questionnaire for more than 500 patients over up to 11 years. The four-step strategy (1) determined the subdimensions of Hr-QoL in MSA; (2) modelled the subdimension trajectories over time, accounting for the risk of death; (3) mapped the sequence of item impairments with disease stages; and (4) identified the most informative items specific to each disease stage.Among the 536 patients included, 50% were women and they were aged on average 65.1 years old at entry. Among them, 63.1% died during the follow-up. Four dimensions were identified. In addition to the original motor, nonmotor, and emotional domains, an oropharyngeal component was highlighted. While the motor and oropharyngeal domains deteriorated rapidly, the nonmotor and emotional aspects were already slightly to moderately impaired at cohort entry and deteriorated slowly over the course of the disease. Impairments were associated with sex, diagnosis subtype, and delay since symptom onset. Except for the emotional domain, each dimension was driven by key identified items.Hr-QoL is a multidimensional concept that deteriorates progressively over the course of MSA and brings essential knowledge for improving patient care. As exemplified with MSA, the thorough description of Hr-QoL using the 4-step original analysis can provide new perspectives on neurodegenerative diseases' management to ultimately deliver better support focused on the patient's perspective.         _ Less","","arXiv","https://arxiv.org/abs/2309.13089","1","0","origin_of_life"
"Information Transmission via Molecular Communication in Astrobiological Environments","Abstract:                _of information transmission via molecular communication between cells is comprehensively documented on Earth; this phenomenon might even have played a vital role in the origin(s) and early evolution of life. Motivated by these considerations, a simple model for molecular communication entailing the diffusion of signali_         _ More           The ubiquity of information transmission via molecular communication between cells is comprehensively documented on Earth; this phenomenon might even have played a vital role in the origin(s) and early evolution of life. Motivated by these considerations, a simple model for molecular communication entailing the diffusion of signaling molecules from transmitter to receiver is elucidated. The channel capacity $C$ (maximal rate of information transmission) and an optimistic heuristic estimate of the actual information transmission rate $\\mathcal{I}$ are derived for this communication system; the two quantities, especially the latter, are demonstrated to be broadly consistent with laboratory experiments and more sophisticated theoretical models. The channel capacity exhibits a potentially weak dependence on environmental parameters, whereas the actual information transmission rate may scale with the intercellular distance $d$ as $\\mathcal{I} \\propto d^{-4}$ and could vary substantially across settings. These two variables are roughly calculated for diverse astrobiological environments, ranging from Earth's upper oceans ($C \\sim 3.1 \\times 10^3$ bits/s; $\\mathcal{I} \\sim 4.7 \\times 10^{-2}$ bits/s) and deep sea hydrothermal vents ($C \\sim 4.2 \\times 10^3$ bits/s; $\\mathcal{I} \\sim 1.2 \\times 10^{-1}$ bits/s) to the hydrocarbon lakes and seas of Titan ($C \\sim 3.8 \\times 10^3$ bits/s; $\\mathcal{I} \\sim 2.6 \\times 10^{-1}$ bits/s).         _ Less","","arXiv","https://arxiv.org/abs/2309.01924","2","2","multiple"
"Adaptation Speed Analysis for Fairness-aware Causal Models","Abstract:                _two models with opposite directions. The question of which one can adapt most quickly to a domain shift is of significant importance in many fields. Specifically, consider an original distribution p that changes due to an unknown intervention, resulting in a modified distribution p*. In aligning p with p*, several factors can affect the adaptation rate, incl_         _ More           For example, in machine translation tasks, to achieve bidirectional translation between two languages, the source corpus is often used as the target corpus, which involves the training of two models with opposite directions. The question of which one can adapt most quickly to a domain shift is of significant importance in many fields. Specifically, consider an original distribution p that changes due to an unknown intervention, resulting in a modified distribution p*. In aligning p with p*, several factors can affect the adaptation rate, including the causal dependencies between variables in p. In real-life scenarios, however, we have to consider the fairness of the training process, and it is particularly crucial to involve a sensitive variable (bias) present between a cause and an effect variable. To explore this scenario, we examine a simple structural causal model (SCM) with a cause-bias-effect structure, where variable A acts as a sensitive variable between cause (X) and effect (Y). The two models, respectively, exhibit consistent and contrary cause-effect directions in the cause-bias-effect SCM. After conducting unknown interventions on variables within the SCM, we can simulate some kinds of domain shifts for analysis. We then compare the adaptation speeds of two models across four shift scenarios. Additionally, we prove the connection between the adaptation speeds of the two models across all interventions.         _ Less","","arXiv","https://arxiv.org/abs/2308.16879","0","1","synthetic_biology"
"Identification of the simplest sugar-like molecule glycolaldehyde towards the hot molecular core G358.93-0.03 MM1","Abstract:                _OHCHO) is the simplest monosaccharide sugar in the interstellar medium, and it is directly involved in the origin of life via the 'RNA world' hypothesis. We present the first detection of glycolaldehyde (CH$_{2}$OHCHO) towards the hot molecular core G358.93-0.03 MM1 using the Atacama Large Millimeter/Submillime_         _ More           Glycolaldehyde (CH$_{2}$OHCHO) is the simplest monosaccharide sugar in the interstellar medium, and it is directly involved in the origin of life via the 'RNA world' hypothesis. We present the first detection of glycolaldehyde (CH$_{2}$OHCHO) towards the hot molecular core G358.93-0.03 MM1 using the Atacama Large Millimeter/Submillimeter Array (ALMA). The calculated column density of CH$_{2}$OHCHO towards G358.93-0.03 MM1 is (1.52$\\pm$0.9)$\\times$10$^{16}$ cm$^{-2}$ with an excitation temperature of 300$\\pm$68.5 K. The derived fractional abundance of CH$_{2}$OHCHO with respect to H$_{2}$ is (4.90$\\pm$2.92)$\\times$10$^{-9}$, which is consistent with that estimated by existing two-phase warm-up chemical models. We discuss the possible formation pathways of CH$_{2}$OHCHO within the context of hot molecular cores and hot corinos and find that CH$_{2}$OHCHO is likely formed via the reactions of radical HCO and radical CH$_{2}$OH on the grain surface of G358.93-0.03 MM1.         _ Less","","arXiv","https://arxiv.org/abs/2308.14454","3","0","origin_of_life"
"What it takes to solve the Origin(s) of Life: An integrated review of techniques","Abstract:                Understanding the origin(s) of_         _ More           Understanding the origin(s) of life (OoL) is a fundamental challenge for science in the 21st century. Research on OoL spans many disciplines, including chemistry, physics, biology, planetary sciences, computer science, mathematics and philosophy. The sheer number of different scientific perspectives relevant to the problem has resulted in the coexistence of diverse tools, techniques, data, and software in OoL studies. This has made communication between the disciplines relevant to the OoL extremely difficult because the interpretation of data, analyses, or standards of evidence can vary dramatically. Here, we hope to bridge this wide field of study by providing common ground via the consolidation of tools and techniques rather than positing a unifying view on how life emerges. We review the common tools and techniques that have been used significantly in OoL studies in recent years. In particular, we aim to identify which information is most relevant for comparing and integrating the results of experimental analyses into mathematical and computational models. This review aims to provide a baseline expectation and understanding of technical aspects of origins research, rather than being a primer on any particular topic. As such, it spans broadly -- from analytical chemistry to mathematical models -- and highlights areas of future work that will benefit from a multidisciplinary approach to tackling the mystery of life's origin. Ultimately, we hope to empower a new generation of OoL scientists by reviewing how they can investigate life's origin, rather than dictating how to think about the problem.         _ Less","","arXiv","https://arxiv.org/abs/2308.11665","2","1","origin_of_life"
"Identification and validation of periodic autoregressive model with additive noise: finite-variance case","Abstract:                _time series and additive noise. In most cases, the data are processed assuming a noise-free model (i.e., without additive noise), which is not a realistic assumption in real life. The first two steps in PAR model identification are order selection and period estimation, so the main focus is on these issues. Finally, the model should be validated, so a proced_         _ More           In this paper, we address the problem of modeling data with periodic autoregressive (PAR) time series and additive noise. In most cases, the data are processed assuming a noise-free model (i.e., without additive noise), which is not a realistic assumption in real life. The first two steps in PAR model identification are order selection and period estimation, so the main focus is on these issues. Finally, the model should be validated, so a procedure for analyzing the residuals, which are considered here as multidimensional vectors, is proposed. Both order and period selection, as well as model validation, are addressed by using the characteristic function (CF) of the residual series. The CF is used to obtain the probability density function, which is utilized in the information criterion and for residuals distribution testing. To complete the PAR model analysis, the procedure for estimating the coefficients is necessary. However, this issue is only mentioned here as it is a separate task (under consideration in parallel). The presented methodology can be considered as the general framework for analyzing data with periodically non-stationary characteristics disturbed by finite-variance external noise. The original contribution is in the selection of the optimal model order and period identification, as well as the analysis of residuals. All these findings have been inspired by our previous work on machine condition monitoring that used PAR modeling         _ Less","","arXiv","https://arxiv.org/abs/2308.11265","1","0","origin_of_life"
"Test-Time Poisoning Attacks Against Test-Time Adaptation Models","Abstract:                Deploying machine learning (ML) models in the wild is challenging as it suffers from distribution shifts, where the model trained on an original domain cannot generalize well to unforeseen diverse transfer domains. To address this challenge, several test-time adaptation (TTA) methods have been proposed to improve the generalization ability of the target pre-_         _ More           Deploying machine learning (ML) models in the wild is challenging as it suffers from distribution shifts, where the model trained on an original domain cannot generalize well to unforeseen diverse transfer domains. To address this challenge, several test-time adaptation (TTA) methods have been proposed to improve the generalization ability of the target pre-trained models under test data to cope with the shifted distribution. The success of TTA can be credited to the continuous fine-tuning of the target model according to the distributional hint from the test samples during test time. Despite being powerful, it also opens a new attack surface, i.e., test-time poisoning attacks, which are substantially different from previous poisoning attacks that occur during the training time of ML models (i.e., adversaries cannot intervene in the training process). In this paper, we perform the first test-time poisoning attack against four mainstream TTA methods, including TTT, DUA, TENT, and RPL. Concretely, we generate poisoned samples based on the surrogate models and feed them to the target TTA models. Experimental results show that the TTA methods are generally vulnerable to test-time poisoning attacks. For instance, the adversary can feed as few as 10 poisoned samples to degrade the performance of the target model from 76.20% to 41.83%. Our results demonstrate that TTA algorithms lacking a rigorous security assessment are unsuitable for deployment in real-life scenarios. As such, we advocate for the integration of defenses against test-time poisoning attacks into the design of TTA methods.         _ Less","","arXiv","https://arxiv.org/abs/2308.08505","0","1","synthetic_biology"
"Neural Categorical Priors for Physics-Based Character Control","Abstract:                _significantly improved motion quality and diversity over existing state-of-the-art methods. The proposed method uses reinforcement learning (RL) to initially track and imitate life-like movements from unstructured motion clips using the discrete information bottleneck, as adopted in the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure compre_         _ More           Recent advances in learning reusable motion priors have demonstrated their effectiveness in generating naturalistic behaviors. In this paper, we propose a new learning framework in this paradigm for controlling physics-based characters with significantly improved motion quality and diversity over existing state-of-the-art methods. The proposed method uses reinforcement learning (RL) to initially track and imitate life-like movements from unstructured motion clips using the discrete information bottleneck, as adopted in the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure compresses the most relevant information from the motion clips into a compact yet informative latent space, i.e., a discrete space over vector quantized codes. By sampling codes in the space from a trained categorical prior distribution, high-quality life-like behaviors can be generated, similar to the usage of VQ-VAE in computer vision. Although this prior distribution can be trained with the supervision of the encoder's output, it follows the original motion clip distribution in the dataset and could lead to imbalanced behaviors in our setting. To address the issue, we further propose a technique named prior shifting to adjust the prior distribution using curiosity-driven RL. The outcome distribution is demonstrated to offer sufficient behavioral diversity and significantly facilitates upper-level policy learning for downstream tasks. We conduct comprehensive experiments using humanoid characters on two challenging downstream tasks, sword-shield striking and two-player boxing game. Our results demonstrate that the proposed framework is capable of controlling the character to perform considerably high-quality movements in terms of behavioral strategies, diversity, and realism. Videos, codes, and data are available at https://tencent-roboticsx.github.io/NCP/.         _ Less","","arXiv","https://arxiv.org/abs/2308.07200","2","1","origin_of_life"
"Exotic swarming dynamics of high-dimensional swarmalators","Abstract:                _the manoeuvers of the school of fish and traveling waves of gene expression, both qualitatively and quantitatively, embryonic cell sorting, microrobot collectives, and various life stages of slime mold by a suitable extension of the original model to incorporate appropriate features besides a gallery of its intrinsic s_         _ More           Swarmalators are oscillators that can swarm as well as sync via a dynamic balance between their spatial proximity and phase similarity. We present a generalized D-dimensional swarmalator model, which is more realistic and versatile, that captures the self-organizing behaviors of a plethora of real-world collectives. This allows for modeling complicated processes such as flocking, schooling of fish, cell sorting during embryonic development, residential segregation, and opinion dynamics in social groups. We demonstrate its versatility by capturing the manoeuvers of the school of fish and traveling waves of gene expression, both qualitatively and quantitatively, embryonic cell sorting, microrobot collectives, and various life stages of slime mold by a suitable extension of the original model to incorporate appropriate features besides a gallery of its intrinsic self-organizations for various interactions. We expect this high-dimensional model to be potentially useful in describing swarming systems in a wide range of disciplines including physics of active matter, developmental biology, sociology, and engineering.         _ Less","","arXiv","https://arxiv.org/abs/2308.03803","0","1","synthetic_biology"
"Fine structures of Intrinsically Disordered Proteins","Abstract:                _> as a function of salt concentration provides another important metric to bring out finer characteristics of the IDPs which may carry relevant information for the origin of life.         _ More           We report simulation studies of 33 single intrinsically disordered proteins (IDPs) using coarse-grained (CG) bead-spring models where interactions among different amino acids are introduced through a hydropathy matrix and additional screened Coulomb interaction for the charged amino acid beads. Our simulation studies of two different hydropathy scales (HPS1, HPS2) [Dignon et al., PLOS Comp. Biology, 14, 2018, Tesei et al. PNAS, 118, 2021] and the comparison with the existing experimental data indicates an optimal interaction parameter $_= 0.1$ kcal/mol and $0.2$ kcal/mol for the HPS1 and HPS2 hydropathy scales. We use these best-fit parameters to investigate both the universal aspects as well as the fine structures of the individual IDPs by introducing additional characteristics.(i) First, we investigate the polymer specific scaling relations of the IDPs in comparison to the universal scaling relations [Bair et al., J. Chem. Phys. 158, 204902 (2023)] for the homopolymers and we demonstrate that IDPs are broadly characterized with a Flory exponent of 0.56 with the conclusion that conformations of the IDPs interpolate between Gaussian and 3DSAW chains. (ii) Then we introduce Wilson charge index W that captures the essential features of charge interactions and distribution in the sequence space, and (iii) a skewness parameter S that captures the finer shape variation of the gyration radii distribution related to the charge asymmetry. Finally, our study of the variation of <$R_g$> as a function of salt concentration provides another important metric to bring out finer characteristics of the IDPs which may carry relevant information for the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2307.16383","2","0","origin_of_life"
"Gravity through the prism of condensed matter physics","Abstract:                In the paper 'Life, the Universe, and everything--42 fundamental questions', Roland Allen and Suzy Lidstr_m presented personal selection of the fundamental questions. Here, based on the condensed matter experience, we suggest the answers to some questions concerning the vacuum energy, black hole entropy and the_         _ More           In the paper 'Life, the Universe, and everything--42 fundamental questions', Roland Allen and Suzy Lidstr_m presented personal selection of the fundamental questions. Here, based on the condensed matter experience, we suggest the answers to some questions concerning the vacuum energy, black hole entropy and the origin of gravity. In condensed matter we know both the many-body phenomena emerging on the macroscopic level and the microscopic (atomic) physics, which generates this emergence. It appears that the same macroscopic phenomenon may be generated by essentially different microscopic backgrounds. This points to various possible directions in study of the deep quantum vacuum of our Universe.         _ Less","","arXiv","https://arxiv.org/abs/2307.14370","1","0","origin_of_life"
"Thermal Behavior of Astrophysical Amorphous Molecular Ices","Abstract:                _protoplanetary disks to evolved solar systems. Ice and complex organic matter coexist in these environments as well, and it is thought primordial ice brought the molecules of life to Earth four billion years ago, which could have kickstarted the_         _ More           Ice is a major component of astrophysical environment - from interstellar molecular clouds through protoplanetary disks to evolved solar systems. Ice and complex organic matter coexist in these environments as well, and it is thought primordial ice brought the molecules of life to Earth four billion years ago, which could have kickstarted the origin of life on Earth. To understand the journey of ice and organics from their origins to becoming a part of evolved planetary systems, it is important to complement high spatial and spectral resolution telescopes such as JWST with laboratory experimental studies that provide deeper insight into the processes that occur in these astrophysical environments. Our laboratory studies are aimed at providing this knowledge. In this article we present simultaneous mass spectrometric and infrared spectroscopic investigation on how molecular ice mixtures behave at different temperatures and how this information is critical to interpret observational data from protoplanetary disks as well as comets. We find that amorphous to crystalline water ice transformation is the most critical phenomenon that differentiates between outgassing of trapped volatiles such as CO2 vs. outgassing of pure molecular ice domains of the same in a mixed molecular ice. Crystalline water ice is found to trap only a small fraction of other volatiles (<5%), indicating ice grain composition in astrophysical and planetary environments must be different depending on whether the ice is in amorphous phase or transformed into crystalline phase, even if the crystalline ice undergoes radiation-induced amorphization subsequently. Crystallization of water ice is a key differentiator for many ices in astronomical environments as well as in our Solar System.         _ Less","","arXiv","https://arxiv.org/abs/2307.11275","2","0","origin_of_life"
"Origin of Life Molecules in the Atmosphere After Big Impacts on the Early Earth","Abstract:                The origin of life on Earth would benefit from a prebiotic atmosphere that produced nitriles, like HCN, which enable ribonucleotide synthesis. However, geochemical evidence suggests that Hadean air was relatively oxidizing with negligible photochemical production of prebiotic molecules. These paradoxes are resolved by_         _ More           The origin of life on Earth would benefit from a prebiotic atmosphere that produced nitriles, like HCN, which enable ribonucleotide synthesis. However, geochemical evidence suggests that Hadean air was relatively oxidizing with negligible photochemical production of prebiotic molecules. These paradoxes are resolved by iron-rich asteroid impacts that transiently reduced the entire atmosphere, allowing nitriles to form in subsequent photochemistry. Here, we investigate impact-generated reducing atmospheres using new time-dependent, coupled atmospheric chemistry and climate models, which account for gas-phase reactions and surface-catalysis. The resulting H$_2$-, CH$_4$- and NH$_3$-rich atmospheres persist for millions of years, until hydrogen escapes to space. HCN and HCCCN production and rainout to the surface can reach $10^9$ molecules cm$^{-2}$ s$^{-1}$ in hazy atmospheres with a mole ratio of $\\mathrm{CH_4} / \\mathrm{CO_2} > 0.1$. Smaller $\\mathrm{CH_4} / \\mathrm{CO_2}$ ratios produce HCN rainout rates $< 10^5$ molecules cm$^{-2}$ s$^{-1}$, and negligible HCCCN. The minimum impactor mass that creates atmospheric $\\mathrm{CH_4} / \\mathrm{CO_2} > 0.1$ is $4 \\times 10^{20}$ to $5 \\times 10^{21}$ kg (570 to 1330 km diameter), depending on how efficiently iron reacts with a steam atmosphere, the extent of atmospheric equilibration with an impact-induced melt pond, and the surface area of nickel that catalyzes CH$_4$ production. Alternatively, if steam permeates and deeply oxidizes crust, impactors $\\sim 10^{20}$ kg could be effective. Atmospheres with copious nitriles have $> 360$ K surface temperatures, perhaps posing a challenge for RNA longevity, although cloud albedo can produce cooler climates. Regardless, post-impact cyanide can be stockpiled and used in prebiotic schemes after hydrogen has escaped to space.         _ Less","","arXiv","https://arxiv.org/abs/2307.09761","2","0","origin_of_life"
"The blood currency of suicidal mass shooters: 60 years of U.S. evidence","Abstract:                _of 194 mass shooters (incidents with four or more victims killed) from 1966 to 2023 in the United States (U.S.). The data were retrieved from The Violence Project Database, originally supported by the National Institute of Justice, U.S. Department of Justice. Based on the statistical analysis, we discovered that mass shooters with suicidal ideation were more_         _ More           When looking at mass shooting incidents, suicidal shooters seem to carry an even more extreme sense of terror and brutality. The current study aimed to examine how mass shooters suicidality and suicide behavioral threshold influence the severity of the mass shooting. We employed Bayesian Mindsponge Framework (BMF) analytics on a dataset of 194 mass shooters (incidents with four or more victims killed) from 1966 to 2023 in the United States (U.S.). The data were retrieved from The Violence Project Database, originally supported by the National Institute of Justice, U.S. Department of Justice. Based on the statistical analysis, we discovered that mass shooters with suicidal ideation were more likely to kill two more victims on average than their non-suicidal counterparts. For suicidal mass shooters found dead on the scene (either by self-killing or suicide by cop), their victim count rises by around four on average when compared to non-suicidal mass shooters. The findings were reasoned through the information-processing perspective of the Mindsponge Theory. Based on the findings and reasoning, we suggest that mass shootings should be considered within larger socio-cultural settings instead of attributing it to be driven primarily by diagnosable psychopathology. Also, promoting an appropriate interpretation of the values of life and death can be an effective way to alleviate the effects of suicidality on mass shooting severity.         _ Less","","arXiv","https://arxiv.org/abs/2306.14230","1","0","origin_of_life"
"Chemical Conditions on Hycean Worlds","Abstract:                Traditionally, the search for life on exoplanets has been predominantly focused on rocky exoplanets. Hycean worlds are a class of habitable sub-Neptunes with planet-wide oceans and H2-rich atmospheres. Their broad range of possible sizes and temperatures lead to a wide habitable zone and high potential for discovery and atmospheric characterization using tra_         _ More           Traditionally, the search for life on exoplanets has been predominantly focused on rocky exoplanets. Hycean worlds are a class of habitable sub-Neptunes with planet-wide oceans and H2-rich atmospheres. Their broad range of possible sizes and temperatures lead to a wide habitable zone and high potential for discovery and atmospheric characterization using transit spectroscopy. Over a dozen candidate Hycean planets are already known to be transiting nearby M dwarfs, making them promising targets for atmospheric characterization with the James Webb Space Telescope (JWST). In this work, we investigate possible chemical conditions on a canonical Hycean world, focusing on (a) the present and primordial molecular composition of the atmosphere, and (b) the inventory of bioessential elements for the origin and sustenance of life in the ocean. Based on photochemical and kinetic modeling for a range of conditions, we discuss the possible chemical evolution and observable present-day composition of its atmosphere. In particular, for reduced primordial conditions the early atmospheric evolution passes through a phase that is rich in organic molecules that could provide important feedstock for prebiotic chemistry. We investigate avenues for delivering bioessential metals to the ocean, considering the challenging lack of weathering from a rocky surface and the ocean separated from the rocky core by a thick icy mantle. Based on ocean depths from internal structure modelling and elemental estimates for the early Earth's oceans, we estimate the requirements for bioessential metals in such a planet. We find that the requirements can be met for plausible assumptions about impact history and atmospheric sedimentation, and supplemented by other steady state sources. We discuss the observational prospects for atmospheric characterisation of Hycean worlds.         _ Less","","arXiv","https://arxiv.org/abs/2306.13706","2","1","origin_of_life"
"Generation of high circular polarization of interstellar Lyman $_$ radiation triggering biological homochirality","Abstract:                The homochirality of biological molecules on the Earth is a long-standing mystery regarding the origin of life. Circularly polarized ultraviolet (UV) light could induce the enantiomeric excess of biological molecules in the interstellar medium, leading to the homochirality on the earth. By performing 3D radiation trans_         _ More           The homochirality of biological molecules on the Earth is a long-standing mystery regarding the origin of life. Circularly polarized ultraviolet (UV) light could induce the enantiomeric excess of biological molecules in the interstellar medium, leading to the homochirality on the earth. By performing 3D radiation transfer simulations with multiple scattering processes in interstellar dusty slabs, we study the generation of circular polarization (CP) of ultraviolet light at Lyman $_$ ($_= 0.1216~{\\rm _m}$) as well as in the near-infrared (NIR, $_= 2.14~{\\rm _m}$) wavelengths. Our simulations show that the distributions of CP exhibit a symmetric quadrupole pattern, regardless of wavelength and viewing angle. The CP degree of scattered light from a dusty slab composed of aligned grains is $\\sim 15$ percent for Ly$_$ and $\\sim 3$ percent at NIR wavelengths in the case of oblate grains with an MRN size distribution. We find that the CP degree of Ly$_$ is well correlated with that in the NIR regardless of viewing angles, whilst being a factor of $\\sim 5$ higher. Thus, high CP of Ly$_$ is expected in sites where NIR CP is detected. We suggest that such circularly polarized Ly$_$ may initiate the enantiomeric excess of biological molecules in space.         _ Less","","arXiv","https://arxiv.org/abs/2306.12101","1","0","origin_of_life"
"Anisotropic Ionizing Illumination from an M-type Pre-main Sequence Star, DM Tau","Abstract:                _that a detailed theoretical model of the high-energy protostellar emission is essential in the understanding of the space weather around the extra-solar planets and the origin of life.         _ More           The powerful, high-energy magnetic activities of young stars play important roles in the magnetohydrodynamics in the innermost parts of the protoplanetary disks. In addition, the associated UV and X-ray emission dictates the photochemistry; moreover, the corona activities can affect the atmosphere of a newborn extra-solar planet. How the UV and X-ray photons are generated, and how they illuminate the disks, are not well understood. Here we report the analyses of the optical and infrared (OIR) photometric monitoring observations and the high angular-resolution centimeter band images of the low-mass (M1 type) pre-main sequence star, DM Tau. We found that the OIR photometric light curves present periodic variations, which is consistent with that the host young star is rotating in the same direction as the natal disk and is hosting at least one giant cold spot. In addition, we resolved that the ionized gas in the DM Tau disk is localized, and its spatial distribution is varying with time. All the present observations can be coherently interpreted, if the giant cold spot is the dominant anisotropic UV and/or X-ray source that illuminates the ambient cone-like region. These results indicate that a detailed theoretical model of the high-energy protostellar emission is essential in the understanding of the space weather around the extra-solar planets and the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2306.09013","1","0","origin_of_life"
"Frequency-Based Vulnerability Analysis of Deep Learning Models against Image Corruptions","Abstract:                _of deep neural networks in handling such corruptions. However, these datasets have a significant limitation: they do not account for all corruptions encountered in real-life scenarios. To address this gap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed to identify the specific types of corruptions that can cause models to fail. Our al_         _ More           Deep learning models often face challenges when handling real-world image corruptions. In response, researchers have developed image corruption datasets to evaluate the performance of deep neural networks in handling such corruptions. However, these datasets have a significant limitation: they do not account for all corruptions encountered in real-life scenarios. To address this gap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed to identify the specific types of corruptions that can cause models to fail. Our algorithm identifies the combination of image frequency components that render a model susceptible to misclassification while preserving the semantic similarity to the original image. We find that even state-of-the-art models trained to be robust against known common corruptions struggle against the low visibility-based corruptions crafted by MUFIA. This highlights the need for more comprehensive approaches to enhance model robustness against a wider range of real-world image corruptions.         _ Less","","arXiv","https://arxiv.org/abs/2306.07178","1","1","multiple"
"Prebiosignature Molecules Can Be Detected in Temperate Exoplanet Atmospheres with JWST","Abstract:                _solar system. Here we focus on a complementary aspect of exoplanet characterisation connecting astronomy to prebiotic chemistry: the search for molecules associated with the origin of_         _ More           The search for biosignatures on exoplanets connects the fields of biology and biochemistry to astronomical observation, with the hope that we might detect evidence of active biological processes on worlds outside the solar system. Here we focus on a complementary aspect of exoplanet characterisation connecting astronomy to prebiotic chemistry: the search for molecules associated with the origin of life, prebiosignatures. Prebiosignature surveys in planetary atmospheres offer the potential to both constrain the ubiquity of life in the galaxy and provide important tests of current prebiotic syntheses outside of the laboratory setting. Here, we quantify the minimum abundance of identified prebiosignature molecules that would be required for detection by transmission spectroscopy using JWST. We consider prebiosignatures on five classes of terrestrial planet: an ocean planet, a volcanic planet, a post-impact planet, a super-Earth, and an early Earth analogue. Using a novel modelling and detection test pipeline, with simulated JWST noise, we find the detection thresholds of hydrogen cyanide (HCN), hydrogen sulfide (H2S), cyanoacetylene (HC3N), ammonia (NH3), methane (CH4), acetylene (C2H2), sulfur dioxide (SO2), nitric oxide (NO), formaldehyde (CH2O), and carbon monoxide (CO) in a variety of low mean molecular weight (<5) atmospheres. We test the dependence of these detection thresholds on M dwarf target star and the number of observed transits, finding that a modest number of transits (1-10) are required to detect prebiosignatures in numerous candidate planets, including TRAPPIST-1e with a high mean molecular weight atmosphere. We find that the NIRSpec G395M/H instrument is best suited for detecting most prebiosignatures.         _ Less","","arXiv","https://arxiv.org/abs/2306.02897","3","1","origin_of_life"
"LonXplain: Lonesomeness as a Consequence of Mental Disturbance in Reddit Posts","Abstract:                Social media is a potential source of information that infers latent mental states through Natural Language Processing (NLP). While narrating real-life experiences, social media users convey their feeling of loneliness or isolated lifestyle, impacting their mental well-being. Existing literature on psychological theories points to loneliness as the major con_         _ More           Social media is a potential source of information that infers latent mental states through Natural Language Processing (NLP). While narrating real-life experiences, social media users convey their feeling of loneliness or isolated lifestyle, impacting their mental well-being. Existing literature on psychological theories points to loneliness as the major consequence of interpersonal risk factors, propounding the need to investigate loneliness as a major aspect of mental disturbance. We formulate lonesomeness detection in social media posts as an explainable binary classification problem, discovering the users at-risk, suggesting the need of resilience for early control. To the best of our knowledge, there is no existing explainable dataset, i.e., one with human-readable, annotated text spans, to facilitate further research and development in loneliness detection causing mental disturbance. In this work, three experts: a senior clinical psychologist, a rehabilitation counselor, and a social NLP researcher define annotation schemes and perplexity guidelines to mark the presence or absence of lonesomeness, along with the marking of text-spans in original posts as explanation, in 3,521 Reddit posts. We expect the public release of our dataset, LonXplain, and traditional classifiers as baselines via GitHub.         _ Less","","arXiv","https://arxiv.org/abs/2305.18736","1","0","origin_of_life"
"Amides inventory towards the G+0.693-0.027 molecular cloud","Abstract:                Interstellar amides have attracted significant attentions as they are potential precursors for a wide variety of organics essential to life. However, our current understanding of their formation in space is heavily based on observations in star-forming regions and hence the chemical networks lack the constraints on their early_         _ More           Interstellar amides have attracted significant attentions as they are potential precursors for a wide variety of organics essential to life. However, our current understanding of their formation in space is heavily based on observations in star-forming regions and hence the chemical networks lack the constraints on their early origin. In this work, unbiased sensitive spectral surveys with IRAM 30m and Yebes 40m telescopes are used to systematically study a number of amides towards a quiescent Galactic Centre molecular cloud, G+0.693-0.027. We report the first detection of acetamide (CH3C(O)NH2) and trans-N-methylformamide (CH3NHCHO) towards this cloud. In addition, with the wider frequency coverage of the survey, we revisited the detection of formamide (NH2CHO) and urea (carbamide; NH2C(O)NH2), which had been reported previously towards G+0.693-0.027. Our results are compared with those present in the literature including recent laboratory experiments and chemical models. We find constant abundance ratios independently of the evolutionary stages, suggesting that amides related chemistry is triggered in early evolutionary stages of molecular cloud and remain unaffected by the warm-up phase during the star formation process. Although a correlation between more complex amides and NH2CHO have been suggested, alternative formation routes involving other precursors such as acetaldehyde (CH3CHO), methyl isocyanate (CH3NCO) and methylamine (CH3NH2) may also contribute to the production of amides. Observations of amides together with these species towards a larger sample of sources can help to constrain the amide chemistry in the interstellar medium.         _ Less","","arXiv","https://arxiv.org/abs/2305.18715","2","2","multiple"
"New filamentary remnant radio emission and duty cycle constraints in the radio galaxy NGC 6086","Abstract:                _a subclass of active galactic nuclei in which accretion onto the supermassive black hole releases energy via relativistic jets. The jets are not constantly active throughout the life of the host galaxy and alternate between active and quiescent phases. Remnant radio galaxies are detected during a quiescent phase and define a class of unique sources to constr_         _ More           Radio galaxies are a subclass of active galactic nuclei in which accretion onto the supermassive black hole releases energy via relativistic jets. The jets are not constantly active throughout the life of the host galaxy and alternate between active and quiescent phases. Remnant radio galaxies are detected during a quiescent phase and define a class of unique sources to constrain the AGN duty cycle. We present, a spatially resolved radio analysis of the radio galaxy associated with NGC 6086 and constraints on the spectral age of the diffuse emission to investigate the duty cycle and evolution of the source. We use three new low-frequency, high-sensitivity observations, performed with the Low Frequency Array at 144 MHz and with the upgraded Giant Metrewave Radio Telescope at 400 MHz and 675 MHz. To these, we add two Very Large Array archival observations at 1400 and 4700 MHz. In the new observations, we detect a second pair of larger lobes and three regions with a filamentary morphology. We analyse the spectral index trend in the inner remnant lobes and see systematic steeper values at the lower frequencies compared to the GHz ones. Steeper spectral indices are found in the newly detected outer lobes (up to 2.1), as expected if they trace a previous phase of activity of the AGN. However, the differences between the spectra suggest different dynamical evolution within the intragroup medium during their expansion and/or different magnetic field values. We place constraints on the age of the inner and outer lobes and derive the duty cycle of the source. This results in a total active time of $\\sim$39%. The filamentary structures have a steep spectral index ($\\sim$1) without any spectral index trend and only one of them shows a steepening in the spectrum. Their origin is not yet clear, but they may have formed due to the compression of the plasma or due to magnetic field substructures.         _ Less","","arXiv","https://arxiv.org/abs/2305.18077","0","1","synthetic_biology"
"BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance","Abstract:                _include the reported weight, age, and biological sex of a patient, a set of drugs taken by the patient, the drug dosages, the reactions experienced, and whether the reaction was life threatening. In this work, we consider the task of predicting the core information of the report given its originating paper. We estimate_         _ More           Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical literature is paramount for public safety, but involves slow and costly manual labor. We set out to improve drug safety monitoring (pharmacovigilance, PV) through the use of Natural Language Processing (NLP). We introduce BioDEX, a large-scale resource for Biomedical adverse Drug Event Extraction, rooted in the historical output of drug safety reporting in the U.S. BioDEX consists of 65k abstracts and 19k full-text biomedical papers with 256k associated document-level safety reports created by medical experts. The core features of these reports include the reported weight, age, and biological sex of a patient, a set of drugs taken by the patient, the drug dosages, the reactions experienced, and whether the reaction was life threatening. In this work, we consider the task of predicting the core information of the report given its originating paper. We estimate human performance to be 72.0% F1, whereas our best model achieves 62.3% F1, indicating significant headroom on this task. We also begin to explore ways in which these models could help professional PV reviewers. Our code and data are available: https://github.com/KarelDO/BioDEX.         _ Less","","arXiv","https://arxiv.org/abs/2305.13395","2","1","origin_of_life"
"Life of PII -- A PII Obfuscation Transformer","Abstract:                _its statistical and semantic properties. Data perturbation methods often result in significant information loss, making them impractical for use. In this paper, we propose 'Life of PII', a novel Obfuscation Transformer framework for transforming PII into faux-PII while preserving the_         _ More           Protecting sensitive information is crucial in today's world of Large Language Models (LLMs) and data-driven services. One common method used to preserve privacy is by using data perturbation techniques to reduce overreaching utility of (sensitive) Personal Identifiable Information (PII) data while maintaining its statistical and semantic properties. Data perturbation methods often result in significant information loss, making them impractical for use. In this paper, we propose 'Life of PII', a novel Obfuscation Transformer framework for transforming PII into faux-PII while preserving the original information, intent, and context as much as possible. Our approach includes an API to interface with the given document, a configuration-based obfuscator, and a model based on the Transformer architecture, which has shown high context preservation and performance in natural language processing tasks and LLMs.   Our Transformer-based approach learns mapping between the original PII and its transformed faux-PII representation, which we call 'obfuscated' data. Our experiments demonstrate that our method, called Life of PII, outperforms traditional data perturbation techniques in terms of both utility preservation and privacy protection. We show that our approach can effectively reduce utility loss while preserving the original information, offering greater flexibility in the trade-off between privacy protection and data utility. Our work provides a solution for protecting PII in various real-world applications.         _ Less","","arXiv","https://arxiv.org/abs/2305.09550","1","0","origin_of_life"
"Close Encounters of the Interstellar Kind: Examining the Capture of Interstellar Objects in Near Earth Orbit","Abstract:                _orbits with high eccentricities and low inclinations. We also investigate the stability of captured ISOs and find that they are generally unstable and have an average survival life time of $\\sim 1$ Myr, consistent with lifetime of NEOs originating from outer asteroid belt, and are ejected from the solar system due to i_         _ More           Recent observations and detections of interstellar objects (ISOs) passing through the solar system have sparked a wave of interest into these objects. Although rare, these ISOs can be captured into bound orbits around the Sun. In this study, we investigate the novel idea of capture of ISOs into near-Earth orbits and find that a steady population of ISOs exists among the current population of Near Earth Objects (NEOs). Using numerical simulations, we find that the capture of ISOs into near-Earth orbits is dominated by Jupiter which is $10^4\\times$ more efficient in capturing ISOs compared to Earth. Captured ISOs are more likely to be in orbits with high eccentricities and low inclinations. We also investigate the stability of captured ISOs and find that they are generally unstable and have an average survival life time of $\\sim 1$ Myr, consistent with lifetime of NEOs originating from outer asteroid belt, and are ejected from the solar system due to interactions with other planets or the Sun. Our results have important implications for understanding the population of ISOs in the solar system and possible future detection. We find that about one to a few $50-70$ m sized captured ISOs among NEOs would be detectable by LSST over its lifetime. By detecting and studying captured interstellar objects, we can learn about the properties and origins of such objects, and the formation and evolution of exoplanetary systems and even our solar system.         _ Less","","arXiv","https://arxiv.org/abs/2305.08915","1","1","multiple"
"Could AI be the Great Filter? What Astrobiology can Teach the Intelligence Community about Anthropogenic Risks","Abstract:                Where is everybody? This phrase distills the foreboding of what has come to be known as the Fermi Paradox - the disquieting idea that, if extraterrestrial life is probable in the Universe, then why have we not encountered it? This conundrum has puzzled scholars for decades, and many hypotheses have been proposed suggesting both naturalistic and sociological_         _ More           Where is everybody? This phrase distills the foreboding of what has come to be known as the Fermi Paradox - the disquieting idea that, if extraterrestrial life is probable in the Universe, then why have we not encountered it? This conundrum has puzzled scholars for decades, and many hypotheses have been proposed suggesting both naturalistic and sociological explanations. One intriguing hypothesis is known as the Great Filter, which suggests that some event required for the emergence of intelligent life is extremely unlikely, hence the cosmic silence. A logically equivalent version of this hypothesis -- and one that should give us pause -- suggests that some catastrophic event is likely to occur that prevents life's expansion throughout the cosmos. This could be a naturally occurring event, or more disconcertingly, something that intelligent beings do to themselves that leads to their own extinction. From an intelligence perspective, framing global catastrophic risk (particularly risks of anthropogenic origin) within the context of the Great Filter can provide insight into the long-term futures of technologies that we don't fully understand, like artificial intelligence. For the intelligence professional concerned with global catastrophic risk, this has significant implications for how these risks ought to be prioritized.         _ Less","","arXiv","https://arxiv.org/abs/2305.05653","1","0","origin_of_life"
"Beyond Mediocrity: How Common is Life?","Abstract:                The probability that life spontaneously emerges in a suitable environment (abiogenesis) is one of the major unknowns in astrobiology. Assessing its value is impeded by the lack of an accepted theory for the_         _ More           The probability that life spontaneously emerges in a suitable environment (abiogenesis) is one of the major unknowns in astrobiology. Assessing its value is impeded by the lack of an accepted theory for the origin of life, and is further complicated by the existence of selection biases. Appealing uncritically to some version of the ``Principle of Mediocrity'' -- namely, the supposed typicality of what transpired on Earth -- is problematic on empirical or logical grounds. In this paper, we adopt a Bayesian statistical approach to put on rigorous footing the inference of lower bounds for the probability of abiogenesis, based on current and future evidence. We demonstrate that the single datum that life has appeared at least once on Earth merely sets weak constraints on the minimal probability of abiogenesis. In fact, the {\\it a priori} probability assigned to this event (viz., optimistic, pessimistic or agnostic prior) exerts the strongest influence on the final result. We also show that the existence of a large number of habitable worlds does not necessarily imply, by itself, a high probability that life should be common in the universe. Instead, as delineated before, the choice of prior, which is subject to uncertainty (i.e., admits multiple scenarios), strongly influences the likelihood of life being common. If habitable worlds are uncommon, for an agnostic prior, a deterministic scenario for the origin of life might be favoured over one where abiogenesis is a fluke event.         _ Less","","arXiv","https://arxiv.org/abs/2305.05395","2","0","origin_of_life"
"Whats next? Forecasting scientific research trends","Abstract:                _and patents. We demonstrate that scientific topic popularity levels and changes (trends) can be predicted five years in advance across 40 years and 125 diverse topics, including life-science concepts, biomedical, anatomy, and other science, technology, and engineering topics. Preceding publications and future patents are leading indicators for emerging scien_         _ More           Scientific research trends and interests evolve over time. The ability to identify and forecast these trends is vital for educational institutions, practitioners, investors, and funding organizations. In this study, we predict future trends in scientific publications using heterogeneous sources, including historical publication time series from PubMed, research and review articles, pre-trained language models, and patents. We demonstrate that scientific topic popularity levels and changes (trends) can be predicted five years in advance across 40 years and 125 diverse topics, including life-science concepts, biomedical, anatomy, and other science, technology, and engineering topics. Preceding publications and future patents are leading indicators for emerging scientific topics. We find the ratio of reviews to original research articles informative for identifying increasing or declining topics, with declining topics having an excess of reviews. We find that language models provide improved insights and predictions into temporal dynamics. In temporal validation, our models substantially outperform the historical baseline. Our findings suggest that similar dynamics apply across other scientific and engineering research topics. We present SciTrends, a user-friendly webtool for predicting scientific topics trends: https://hadasakaufman.shinyapps.io/SciTrend         _ Less","","arXiv","https://arxiv.org/abs/2305.04133","1","1","multiple"
"Medical records condensation: a roadmap towards healthcare data democratisation","Abstract:                The prevalence of artificial intelligence (AI) has envisioned an era of healthcare democratisation that promises every stakeholder a new and better way of life. However, the advancement of clinical AI research is significantly hurdled by the dearth of data democratisation in healthcare. To truly democratise data for AI studies, challenges are two-fold: 1. th_         _ More           The prevalence of artificial intelligence (AI) has envisioned an era of healthcare democratisation that promises every stakeholder a new and better way of life. However, the advancement of clinical AI research is significantly hurdled by the dearth of data democratisation in healthcare. To truly democratise data for AI studies, challenges are two-fold: 1. the sensitive information in clinical data should be anonymised appropriately, and 2. AI-oriented clinical knowledge should flow freely across organisations. This paper considers a recent deep-learning advent, dataset condensation (DC), as a stone that kills two birds in democratising healthcare data. The condensed data after DC, which can be viewed as statistical metadata, abstracts original clinical records and irreversibly conceals sensitive information at individual levels; nevertheless, it still preserves adequate knowledge for learning deep neural networks (DNNs). More favourably, the compressed volumes and the accelerated model learnings of condensed data portray a more efficient clinical knowledge sharing and flowing system, as necessitated by data democratisation. We underline DC's prospects for democratising clinical data, specifically electrical healthcare records (EHRs), for AI research through experimental results and analysis across three healthcare datasets of varying data types.         _ Less","","arXiv","https://arxiv.org/abs/2305.03711","1","0","origin_of_life"
"Brain Tumor Segmentation from MRI Images using Deep Learning Techniques","Abstract:                A brain tumor, whether benign or malignant, can potentially be life threatening and requires painstaking efforts in order to identify the type, origin and location, let alone cure one. Manual segmentation by medical specialists can be time-consuming, which calls out for the involvement of technology to hasten the proce_         _ More           A brain tumor, whether benign or malignant, can potentially be life threatening and requires painstaking efforts in order to identify the type, origin and location, let alone cure one. Manual segmentation by medical specialists can be time-consuming, which calls out for the involvement of technology to hasten the process with high accuracy. For the purpose of medical image segmentation, we inspected and identified the capable deep learning model, which shows consistent results in the dataset used for brain tumor segmentation. In this study, a public MRI imaging dataset contains 3064 TI-weighted images from 233 patients with three variants of brain tumor, viz. meningioma, glioma, and pituitary tumor. The dataset files were converted and preprocessed before indulging into the methodology which employs implementation and training of some well-known image segmentation deep learning models like U-Net & Attention U-Net with various backbones, Deep Residual U-Net, ResUnet++ and Recurrent Residual U-Net. with varying parameters, acquired from our review of the literature related to human brain tumor classification and segmentation. The experimental findings showed that among all the applied approaches, the recurrent residual U-Net which uses Adam optimizer reaches a Mean Intersection Over Union of 0.8665 and outperforms other compared state-of-the-art deep learning models. The visual findings also show the remarkable results of the brain tumor segmentation from MRI scans and demonstrates how useful the algorithm will be for physicians to extract the brain cancers automatically from MRI scans and serve humanity.         _ Less","","arXiv","https://arxiv.org/abs/2305.00257","1","1","multiple"
"Self-Organization, Evolutionary Entropy and Directionality Theory","Abstract:                _to the self-assembly of structures ranging from the folding of proteins, to branching morphogenesis, and the emergence of social organization. The principle also elucidates the origin of cellular life: the transition from inorganic matter to the emergence of cells, capable of replication and metabolism.         _ More           Self-organization is the autonomous assembly of a network of interacting components into a stable, organized pattern. This article shows that the process of self-assembly can be encoded in terms of evolutionary entropy, a statistical measure of the cooperativity of the interacting components. Evolutionary entropy describes the rate at which a network of interacting metabolic units convert an external energy source into mechanical energy and work. We invoke Directionality Theory, an analytic model of Darwinian evolution to analyze self-assembly as a variation-selection process, and to derive a general tenet, namely, the Entropic Principle of Self-Organization: The equilibrium states of a self-organizing process are states which maximize evolutionary entropy, contingent on the production rate of the external energy source. This principle is a universal rule, applicable to the self-assembly of structures ranging from the folding of proteins, to branching morphogenesis, and the emergence of social organization. The principle also elucidates the origin of cellular life: the transition from inorganic matter to the emergence of cells, capable of replication and metabolism.         _ Less","","arXiv","https://arxiv.org/abs/2304.14877","1","4","synthetic_biology"
"Directionality Theory and the Origin of Life","Abstract:                The origin of cellular_         _ More           The origin of cellular life can be described in terms of the transition from inorganic matter: solids, liquids and gases, to the emergence of cooperative assemblies of organic matter, DNA and proteins,capable of replication and metabolism. Directionality Theory is a mathematical model of the collective behavior of populations of organic matter: cells and higher organisms. Evolutionary entropy, the cornerstone of the theory, is a statistical measure of the cooperativity of the interacting components that comprise the population. The main tenet of Directionality Theory is the Entropic Principle of Collective Behavior: The collective behavior of aggregates of organic matter is contingent on the population size and the external energy source, and characterized by extremal states of evolutionary entropy. This article invokes Directionality Theory to provide an evolutionary rationale for the following sequence of transformations which define the emergence of cellular life: 1. The self-assembly of activated macromolecules from inorganic matter 2. The emergence of an RNA world, defined by RNA molecules with catalytic and replicative properties 3. The origin of cellular life, the integration of the three carbon-based polymers: DNA, proteins and lipids, to generate a metabolic and replicative unit.         _ Less","","arXiv","https://arxiv.org/abs/2304.14873","4","3","origin_of_life"
"CEDR-API: Productive, Performant Programming of Domain-Specific Embedded Systems","Abstract:                _study the impact of increase in workload complexity and growth in the pool of compute resources on execution time of dynamically arriving workloads composed of real-life applications executed over architectures emulated on Xilinx ZCU102 MPSoC and Nvidia Jetson AGX Xavier. We expand CEDR into the application domain of autonomous vehicles, and we find that API_         _ More           As the computing landscape evolves, system designers continue to explore design methodologies that leverage increased levels of heterogeneity to push performance within limited size, weight, power, and cost budgets. One such methodology is to build Domain-Specific System on Chips (DSSoCs) that promise increased productivity through narrowed scope of their target application domain. In previous works, we have proposed CEDR, an open source, unified compilation and runtime framework for DSSoC architectures that allows applications, scheduling heuristics, and accelerators to be co-designed in a cohesive manner that maximizes system performance. In this work, we present changes to the application development workflow that enable a more productive and expressive API-based programming methodology. These changes allow for more rapid integration of new applications without sacrificing application performance. Towards the design of heterogeneous SoCs with rich set of accelerators, in this study we experimentally study the impact of increase in workload complexity and growth in the pool of compute resources on execution time of dynamically arriving workloads composed of real-life applications executed over architectures emulated on Xilinx ZCU102 MPSoC and Nvidia Jetson AGX Xavier. We expand CEDR into the application domain of autonomous vehicles, and we find that API-based CEDR achieves a runtime overhead reduction of 19.5% with respect to the original CEDR.         _ Less","","arXiv","https://arxiv.org/abs/2304.12396","0","1","synthetic_biology"
"Chirality-Induced Magnetization of Magnetite by an RNA Precursor","Abstract:        Life is homochiral and homochirality is a fundamental feature of living systems on Earth. While the exact mechanism that led to homochirality is still not fully understood, any realistic scenario on the origins of life needs to address the emergence of homochirality. In order to_         _ More   Life is homochiral and homochirality is a fundamental feature of living systems on Earth. While the exact mechanism that led to homochirality is still not fully understood, any realistic scenario on the origins of life needs to address the emergence of homochirality. In order to impose and maintain chirality in a prebiotic network, an environmental factor functioning as a chiral agent is demanded. Magnetized surfaces are prebiotically plausible chiral agents, shown to be effective in enantioseparation of ribose-aminooxazoline (RAO), a ribonucleic acid (RNA) precursor, due to the chiral-induced spin selectivity (CISS) effect. As such, mechanisms for breaking the magnetic symmetry of magnetic minerals are of the utmost importance. Here we report the avalanche magnetization of magnetite $(Fe_{3}O_{4})$ by the crystallization of enantiopure RAO. The observed breaking of the magnetic symmetry is induced by the chiral molecules due to the CISS effect and spreads out across the magnetic surface like an avalanche, providing a way to uniformly magnetize a magnetic surface without fully covering it. Considered together with our previous results on enantioseparation by crystallization on a magnetic surface, chirality-induced avalanche magnetization paves the way for a cooperative feedback between chiral molecules and magnetic surfaces. With this feedback, a weak natural bias in the net magnetization can be amplified and spin-selective processes can be accommodated on magnetic minerals on a persistent basis.         _ Less","","arXiv","https://arxiv.org/abs/2304.09095","2","0","origin_of_life"
"On the balance between Emigration and Immigration as Random Walks on the non-negative integers","Abstract:        Life is on the razor's edge as resulting from competitive birth and death random forces. We illustrate this aphorism in the context of three Markov chain population models where systematic random immigration events promoting growth are simultaneously balanced with random emigration ones provoking thinning. The_         _ More   Life is on the razor's edge as resulting from competitive birth and death random forces. We illustrate this aphorism in the context of three Markov chain population models where systematic random immigration events promoting growth are simultaneously balanced with random emigration ones provoking thinning. The origin of mass removals are either determined by external demands or by aging leading to different conditions of stability.         _ Less","","arXiv","https://arxiv.org/abs/2304.08060","0","1","synthetic_biology"
"PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling","Abstract:                _finite realisations, can be encoded using deep generative models such as variational autoencoders (VAEs). These learned generators can serve as drop-in replacements for the original priors during MCMC inference. While this approach enables efficient inference, it loses information about the hyperparameters of the_         _ More           Recent advances have shown that GP priors, or their finite realisations, can be encoded using deep generative models such as variational autoencoders (VAEs). These learned generators can serve as drop-in replacements for the original priors during MCMC inference. While this approach enables efficient inference, it loses information about the hyperparameters of the original models, and consequently makes inference over hyperparameters impossible and the learned priors indistinct. To overcome this limitation, we condition the VAE on stochastic process hyperparameters. This allows the joint encoding of hyperparameters with GP realizations and their subsequent estimation during inference. Further, we demonstrate that our proposed method, PriorCVAE, is agnostic to the nature of the models which it approximates, and can be used, for instance, to encode solutions of ODEs. It provides a practical tool for approximate inference and shows potential in real-life spatial and spatiotemporal applications.         _ Less","","arXiv","https://arxiv.org/abs/2304.04307","1","0","origin_of_life"
"HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation","Abstract:                Controllable human image generation (HIG) has numerous real-life applications. State-of-the-art solutions, such as ControlNet and T2I-Adapter, introduce an additional learnable branch on top of the frozen pre-trained stable diffusion (SD) model, which can enforce various conditions, including skeleton guidance of HIG. While such a plug-and-play approach is a_         _ More           Controllable human image generation (HIG) has numerous real-life applications. State-of-the-art solutions, such as ControlNet and T2I-Adapter, introduce an additional learnable branch on top of the frozen pre-trained stable diffusion (SD) model, which can enforce various conditions, including skeleton guidance of HIG. While such a plug-and-play approach is appealing, the inevitable and uncertain conflicts between the original images produced from the frozen SD branch and the given condition incur significant challenges for the learnable branch, which essentially conducts image feature editing for condition enforcement. In this work, we propose a native skeleton-guided diffusion model for controllable HIG called HumanSD. Instead of performing image editing with dual-branch diffusion, we fine-tune the original SD model using a novel heatmap-guided denoising loss. This strategy effectively and efficiently strengthens the given skeleton condition during model training while mitigating the catastrophic forgetting effects. HumanSD is fine-tuned on the assembly of three large-scale human-centric datasets with text-image-pose information, two of which are established in this work. As shown in Figure 1, HumanSD outperforms ControlNet in terms of accurate pose control and image quality, particularly when the given skeleton guidance is sophisticated.         _ Less","","arXiv","https://arxiv.org/abs/2304.04269","1","0","origin_of_life"
"An Optimal, Universal and Agnostic Decoding Method for Message Reconstruction, Bio and Technosignature Detection","Abstract:                _how non-random messages may encode information about the physical properties, such as dimension and length scales of the space in which a signal or message may have been originally encoded, embedded, or generated. We argue that our results have applications to life and technosignature detection and to coding theory in_         _ More           We present a signal reconstruction method for zero-knowledge one-way communication channels in which a receiver aims to interpret a message sent by an unknown source about which no prior knowledge is available and to which no return message can be sent. Our reconstruction method is agnostic vis-_-vis the arbitrarily chosen encoding-decoding scheme and other observer-dependent characteristics, such as the arbitrarily chosen computation model or underlying mathematical theory. We investigate how non-random messages may encode information about the physical properties, such as dimension and length scales of the space in which a signal or message may have been originally encoded, embedded, or generated. We argue that our results have applications to life and technosignature detection and to coding theory in general.         _ Less","","arXiv","https://arxiv.org/abs/2303.16045","1","1","multiple"
"Scaling Multi-Objective Security Games Provably via Space Discretization Based Evolutionary Search","Abstract:                _games (MOSGs) allow defenders to simultaneously protect targets from multiple heterogeneous attackers. MOSGs aim to simultaneously maximize all the heterogeneous payoffs, e.g., life, money, and crime rate, without merging heterogeneous attackers. In real-world scenarios, the number of heterogeneous attackers and targets to be protected may exceed the capabil_         _ More           In the field of security, multi-objective security games (MOSGs) allow defenders to simultaneously protect targets from multiple heterogeneous attackers. MOSGs aim to simultaneously maximize all the heterogeneous payoffs, e.g., life, money, and crime rate, without merging heterogeneous attackers. In real-world scenarios, the number of heterogeneous attackers and targets to be protected may exceed the capability of most existing state-of-the-art methods, i.e., MOSGs are limited by the issue of scalability. To this end, this paper proposes a general framework called SDES based on many-objective evolutionary search to scale up MOSGs to large-scale targets and heterogeneous attackers. SDES consists of four consecutive key components, i.e., discretization, optimization, evaluation, and refinement. Specifically, SDES first discretizes the originally high-dimensional continuous solution space to the low-dimensional discrete one by the maximal indifference property in game theory. This property helps evolutionary algorithms (EAs) bypass the high-dimensional step function and ensure a well-convergent Pareto front. Then, a many-objective EA is used for optimization in the low-dimensional discrete solution space to obtain a well-spaced Pareto front. To evaluate solutions, SDES restores solutions back to the original space via greedily optimizing a novel divergence measurement. Finally, the refinement in SDES boosts the optimization performance with acceptable cost. Theoretically, we prove the optimization consistency and convergence of SDES. Experiment results show that SDES is the first linear-time MOSG algorithm for both large-scale attackers and targets. SDES is able to solve up to 20 attackers and 100 targets MOSG problems, while the state-of-the-art (SOTA) methods can only solve up to 8 attackers and 25 targets ones. Ablation study verifies the necessity of all components in SDES.         _ Less","","arXiv","https://arxiv.org/abs/2303.15821","0","1","synthetic_biology"
"Insights on the Sun birth environment in the context of star-cluster formation in hub-filament systems","Abstract:                _the junction of multiple filaments. The role of hub-filament configurations has not been discussed yet in relation to the birth environment of the solar system and to infer the origin of isotopic ratios of Short-Lived Radionuclides (SLR, such as $^{26}$Al) of Calcium-Aluminum-rich Inclusions (CAIs) observed in meteorites. In this work, we present simple anal_         _ More           Cylindrical molecular filaments are observed to be the main sites of Sun-like star formation, while massive stars form in dense hubs, at the junction of multiple filaments. The role of hub-filament configurations has not been discussed yet in relation to the birth environment of the solar system and to infer the origin of isotopic ratios of Short-Lived Radionuclides (SLR, such as $^{26}$Al) of Calcium-Aluminum-rich Inclusions (CAIs) observed in meteorites. In this work, we present simple analytical estimates of the impact of stellar feedback on the young solar system forming along a filament of a hub-filament system. We find that the host filament can shield the young solar system from the stellar feedback, both during the formation and evolution of stars (stellar outflow, wind, and radiation) and at the end of their life (supernovae). We show that the young solar system formed along a dense filament can be enriched with supernova ejecta (e.g., $^{26}$Al) during the formation timescale of CAIs. We also propose that the streamers recently observed around protostars may be channeling the SLR-rich material onto the young solar system. We conclude that considering hub-filament configurations as the birth environment of the Sun is important when deriving theoretical models explaining the observed properties of the solar system.         _ Less","","arXiv","https://arxiv.org/abs/2303.15695","1","1","multiple"
"Unveiling the chemical fingerprint of phosphorus-rich stars I. In the infrared region of APOGEE-2","Abstract:                The origin of phosphorus, one of the essential elements for life on Earth, is currently unknown. Prevalent models of Galactic chemical evolution (GCE) underestimate the amount of P compared to observations. The recently discovered P-rich ([P/Fe] > 1 dex) and metal-poor giants further challenge current theories on st_         _ More           The origin of phosphorus, one of the essential elements for life on Earth, is currently unknown. Prevalent models of Galactic chemical evolution (GCE) underestimate the amount of P compared to observations. The recently discovered P-rich ([P/Fe] > 1 dex) and metal-poor giants further challenge current theories on stellar nucleosynthesis. Since the observed stars are low-mass giants, our primary goal is to find clues on their progenitor. By increasing the number of known P-rich stars, we aim to narrow down a reliable chemical abundance pattern and to place robust constraints on the responsible nucleosynthetic mechanism. In the long term, identifying the progenitor of the P-rich stars may contribute to the search for the source of P in our Galaxy. We performed a detailed chemical abundance analysis based on the H-band spectra from APOGEE-2 (DR17). Employing the BACCHUS code, we measured the abundances of 13 elements in the sample, which is mainly composed of a recent collection of Si-enhanced giants. We also analyzed the orbital motions and compared the abundance results to possible nucleosynthetic formation scenarios, and also to detailed GCE models. We enlarged the sample of confirmed P-rich stars from 16 to 78 giants, which represents the largest sample of P-rich stars to date. Significant enhancements in O, Al, Si and Ce, as well as systematic correlations among the elements, unveil the chemical fingerprint of the P-rich stars. The high Mg and C+N found in some of the P-rich stars with respect to P-normal stars is not confirmed over the full sample. Strikingly, the strong over-abundance in the $_$-element Si is accompanied by normal Ca and S abundances. Our analysis of the orbital motion showed that the P-rich stars do not belong to a specific sub-population. In addition, we confirm that the majority of the sample stars are not part of binary systems.         _ Less","","arXiv","https://arxiv.org/abs/2303.12590","2","1","origin_of_life"
"Alkaline vents recreated in two dimensions to study pH gradients, precipitation morphology and molecule accumulation","Abstract:                Alkaline vents (AV) are hypothesized to have been a setting for the emergence of life, by creating strong gradients across inorganic membranes within chimney structures. In the past, 3-dimensional chimney structures were formed under laboratory conditions, however, no in situ visualisation or testing of the gradients was possible. We develop a quasi-2-dimens_         _ More           Alkaline vents (AV) are hypothesized to have been a setting for the emergence of life, by creating strong gradients across inorganic membranes within chimney structures. In the past, 3-dimensional chimney structures were formed under laboratory conditions, however, no in situ visualisation or testing of the gradients was possible. We develop a quasi-2-dimensional microfluidic model of alkaline vents that allows spatio-temporal visualisation of mineral precipitation in low volume experiments. Upon injection of an alkaline fluid into an acidic, iron-rich solution, we observe a diverse set of precipitation morphologies, mainly controlled by flow-rate and ion-concentration. Using microscope imaging and pH dependent dyes, we show that finger-like precipitates can facilitate formation and maintenance of microscale pH gradients and accumulation of dispersed particles in confined geometries. Our findings establish a model to investigate the potential of gradients across a semi-permeable boundary for early compartmentalisation, accumulation and chemical reactions at the origins of life.         _ Less","","arXiv","https://arxiv.org/abs/2303.10156","2","0","origin_of_life"
"Gate Recurrent Unit Network based on Hilbert-Schmidt Independence Criterion for State-of-Health Estimation","Abstract:                _masking network is used to transform all battery data measured with varying lengths every cycle into sequences of the same length, while still retaining information about the original data size in each cycle. Second, the Hilbert-Schmidt Independence Criterion (HSIC) bottleneck, which evolved from Information Bottleneck (IB) theory, is extended to GRU to comp_         _ More           State-of-health (SOH) estimation is a key step in ensuring the safe and reliable operation of batteries. Due to issues such as varying data distribution and sequence length in different cycles, most existing methods require health feature extraction technique, which can be time-consuming and labor-intensive. GRU can well solve this problem due to the simple structure and superior performance, receiving widespread attentions. However, redundant information still exists within the network and impacts the accuracy of SOH estimation. To address this issue, a new GRU network based on Hilbert-Schmidt Independence Criterion (GRU-HSIC) is proposed. First, a zero masking network is used to transform all battery data measured with varying lengths every cycle into sequences of the same length, while still retaining information about the original data size in each cycle. Second, the Hilbert-Schmidt Independence Criterion (HSIC) bottleneck, which evolved from Information Bottleneck (IB) theory, is extended to GRU to compress the information from hidden layers. To evaluate the proposed method, we conducted experiments on datasets from the Center for Advanced Life Cycle Engineering (CALCE) of the University of Maryland and NASA Ames Prognostics Center of Excellence. Experimental results demonstrate that our model achieves higher accuracy than other recurrent models.         _ Less","","arXiv","https://arxiv.org/abs/2303.09497","1","0","origin_of_life"
"Emergence, Construction, or Unlikely? Navigating the Space of Questions regarding Life's Origins","Abstract:                We survey some of the philosophical challenges and pitfalls within origins research. Several of these challenges exhibit circularities, paradoxes, or anthropic biases. We present_         _ More           We survey some of the philosophical challenges and pitfalls within origins research. Several of these challenges exhibit circularities, paradoxes, or anthropic biases. We present origins approaches in terms of three broad categories: unlikely (life's origin was a chance event), construction (life's origin was a stepwise series of synthesis and assembly processes), and emergence (life was always an amalgam of many parallel processes from which the living state emerged as a natural outcome of physical driving forces). We critically examine some of the founding and possibly misleading assumptions in these categories. Such assumptions need not be detrimental to scientific progress as long as their limits are respected. We conclude by attempting to concisely state the most significant enigmas still remaining in the origins field and suggest routes to solve them.         _ Less","","arXiv","https://arxiv.org/abs/2303.08018","2","1","origin_of_life"
"When Optical Microscopy Meets All-Optical Analog Computing: A Brief Review","Abstract:                As a revolutionary observation tool in life science, biomedical, and material science, optical microscopy allows imaging of samples with high spatial resolution and a wide field of view. However, conventional microscopy methods are limited to single imaging and cannot accomplish real-time image processing. The edge detection, image enhancement and phase visu_         _ More           As a revolutionary observation tool in life science, biomedical, and material science, optical microscopy allows imaging of samples with high spatial resolution and a wide field of view. However, conventional microscopy methods are limited to single imaging and cannot accomplish real-time image processing. The edge detection, image enhancement and phase visualization schemes have attracted great interest with the rapid development of optical analog computing. The two main physical mechanisms that enable optical analog computing originate from two geometric phases: the spin-redirection Rytov-Vlasimirskii-Berry (RVB) phase and the Pancharatnam-Berry (PB) phase. Here, we review the basic principles and recent research progress of the RVB phase and PB phase based optical differentiators. Then we focus on the innovative and emerging applications of optical analog computing in microscopic imaging. Optical analog computing is accelerating the transformation of information processing from classical imaging to quantum techniques. Its intersection with optical microscopy opens opportunities for the development of versatile and compact optical microscopy systems.         _ Less","","arXiv","https://arxiv.org/abs/2303.04988","2","3","synthetic_biology"
"Multiverse Predictions for Habitability: Origin of Life Scenarios","Abstract:                If the origin of_         _ More           If the origin of life is rare and sensitive to the local conditions at the site of its emergence, then, using the principle of mediocrity within a multiverse framework, we may expect to find ourselves in a universe that is better than usual at creating these necessary conditions. We use this reasoning to investigate several origin of life scenarios to determine whether they are compatible with the multiverse, including the prebiotic soup scenario, hydrothermal vents, delivery of prebiotic material from impacts, and panspermia. We find that most of these scenarios induce a preference toward weaker-gravity universes, and that panspermia and scenarios involving solar radiation or large impacts as a disequilibrium source are disfavored. Additionally, we show that several hypothesized habitability criteria which are disfavored when the origin of life is not taken into account become compatible with the multiverse, and that the emergence of life and emergence of intelligence cannot both be sensitive to disequilibrium production conditions.         _ Less","","arXiv","https://arxiv.org/abs/2303.02678","3","0","origin_of_life"
"Chemical models of adenine precursors cyanamide and carbodiimide in the interstellar medium","Abstract:                _carbodiimide (HNCNH), may form adenine in the interstellar medium (ISM) via a series of reactions. Therefore, they are considered key prebiotic molecules in the study of the origin of life. We used the three-phase NAUTILUS chemical code, which includes the gas, the dust surface, and the icy mantle, to investigate the_         _ More           Cyanamide (NH2CN) and its isomer, carbodiimide (HNCNH), may form adenine in the interstellar medium (ISM) via a series of reactions. Therefore, they are considered key prebiotic molecules in the study of the origin of life. We used the three-phase NAUTILUS chemical code, which includes the gas, the dust surface, and the icy mantle, to investigate the formation and destruction of cyanamide and carbodiimide. We added over 200 new chemical reactions of the two isomers and related species, and established a relatively complete network. We applied cold core, hot corino/core and shock models to simulate the different physical environments, and found that the two isomers are mainly produced by the free radical reactions on grain surfaces. Our simulated results suggest that cyanamide and carbodiimide molecules come from surface chemistry at early evolutionary stages. Then they are released back to the gas phase, either by thermal process (in hot cores, hot corinos) or shock-induced desorption (in shock regions).We speculate that it is an inefficient route to form a tautomer of adenine by starting from molecules cyanoacetylene (C3NH), cyanamide and carbodiimide in ISM.         _ Less","","arXiv","https://arxiv.org/abs/2303.01854","3","1","origin_of_life"
"A Concise and Formal Definition of RAF Sets and the RAF Algorithm","Abstract:                Autocatalytic sets are self-catalyzing and self-sustaining chemical reaction networks that are believed to have played an important role in the origin of life. They have been studied extensively both theoretically as well as experimentally. This short note provides (1) a complete and formal definition of autocatalytic_         _ More           Autocatalytic sets are self-catalyzing and self-sustaining chemical reaction networks that are believed to have played an important role in the origin of life. They have been studied extensively both theoretically as well as experimentally. This short note provides (1) a complete and formal definition of autocatalytic sets (or RAF sets), and (2) an efficient algorithm to detect such sets in arbitrary reaction networks. Although both have been presented in various forms in earlier publications, this note serves as a concise and convenient reference.         _ Less","","arXiv","https://arxiv.org/abs/2303.01809","1","1","multiple"
"Origin of Biological Homochirality by Crystallization of an RNA Precursor on a Magnetic Surface","Abstract:                Homochirality is a signature of life on Earth yet its origins remain an unsolved puzzle. Achieving homochirality is essential for a high-yielding prebiotic network capable of producing functional polymers like ribonucleic acid (RNA) and peptides. However, a prebiotically plausible and robust mechanism to reach homochir_         _ More           Homochirality is a signature of life on Earth yet its origins remain an unsolved puzzle. Achieving homochirality is essential for a high-yielding prebiotic network capable of producing functional polymers like ribonucleic acid (RNA) and peptides. However, a prebiotically plausible and robust mechanism to reach homochirality has not been shown to this date. The chiral-induced spin selectivity (CISS) effect has established a strong coupling between electron spin and molecular chirality and this coupling paves the way for breaking the chiral molecular symmetry by spin-selective processes. Magnetic surfaces can act as chiral agents due to the CISS effect and they can be templates for the enantioselective crystallization of chiral molecules. Here we studied the spin-selective crystallization of racemic ribo aminooxazoline (RAO), an RNA precursor, on magnetite ($Fe_3O_4$) surfaces, achieving an unprecedented enantiomeric excess of about 60$\\%$. Following the initial enrichment, we then obtained homochiral crystals of RAO after a subsequent crystallization. Our work combines two necessary features for reaching homochirality: chiral symmetry-breaking induced by the magnetic surface and self-amplification by conglomerate crystallization of RAO. Our results demonstrate a prebiotically plausible way of achieving systems level homochirality from completely racemic starting materials.         _ Less","","arXiv","https://arxiv.org/abs/2303.01394","1","0","origin_of_life"
"Oxygenic photosynthetic responses of cyanobacteria exposed under an M-dwarf starlight simulator: Implications for exoplanet's habitability","Abstract:                Introduction: The search for life on distant exoplanets is expected to rely on atmospheric biosignatures detection, such as oxygen of biological origin. However, it is not demonstrated how much oxygenic photosynthesis, which on Earth depends on visible light, could work under spectral conditions simulating exoplanets o_         _ More           Introduction: The search for life on distant exoplanets is expected to rely on atmospheric biosignatures detection, such as oxygen of biological origin. However, it is not demonstrated how much oxygenic photosynthesis, which on Earth depends on visible light, could work under spectral conditions simulating exoplanets orbiting the Habitable Zone of M-dwarf stars, which have low light emission in the visible and high light emission in the far-red/near-infrared. By utilizing cyanobacteria, the first organisms to evolve oxygenic photosynthesis on our planet, and a starlight simulator capable of accurately reproducing the emission spectrum of an M-dwarf in the range 350-900 nm, we could answer this question. Methods: We performed experiments with the cyanobacterium Chlorogloeopsis fritschii PCC6912, capable of Far-Red Light Photoacclimation (FaRLiP), which allows the strain to harvest far-red in addition to visible light for photosynthesis, and Synechocystis sp. PCC6803, a species unable to perform this photoacclimation, comparing their responses when exposed to three simulated light spectra: M-dwarf, solar and far-red. We analysed growth and photosynthetic acclimation features in terms of pigment composition and photosystems organization. Finally, we determined the oxygen production of the strains directly exposed to the different spectra. Results: Both cyanobacteria were shown to grow and photosynthesize similarly under M-dwarf and solar light conditions: Synechocystis sp. by utilizing the few photons in the visible, C. fritschii by harvesting both visible and far-red light, activating the FaRLiP response.         _ Less","","arXiv","https://arxiv.org/abs/2302.09396","0","1","synthetic_biology"
"The Agent-based Modelling for Human Behaviour Special Issue","Abstract:                If human societies are so complex, then how can we hope to understand them? Artificial Life gives us one answer. The field of Artificial_         _ More           If human societies are so complex, then how can we hope to understand them? Artificial Life gives us one answer. The field of Artificial Life comprises a diverse set of introspective studies that largely ask the same questions, albeit from many different perspectives: Why are we here? Who are we? Why do we behave as we do? Starting with the origins of life provides us with fascinating answers to some of these questions. However, some researchers choose to bring their studies closer to the present day. We are after all, human. It has been a few billion years since our ancestors were self-replicating molecules. Thus, more direct studies of ourselves and our human societies can reveal truths that may lead to practical knowledge. The papers in this special issue bring together scientists who choose to perform this kind of research.         _ Less","","arXiv","https://arxiv.org/abs/2302.01789","0","1","synthetic_biology"
"Learning to Unlearn: Instance-wise Unlearning for Pre-trained Classifiers","Abstract:                _instance-wise unlearning, of which the goal is to delete information on a set of instances from a pre-trained model, by either misclassifying each instance away from its original prediction or relabeling the instance to a different label. We also propose two methods that reduce forgetting on the remaining data: 1) utilizing adversarial examples to overcome f_         _ More           Since the recent advent of regulations for data protection (e.g., the General Data Protection Regulation), there has been increasing demand in deleting information learned from sensitive data in pre-trained models without retraining from scratch. The inherent vulnerability of neural networks towards adversarial attacks and unfairness also calls for a robust method to remove or correct information in an instance-wise fashion, while retaining the predictive performance across remaining data. To this end, we consider instance-wise unlearning, of which the goal is to delete information on a set of instances from a pre-trained model, by either misclassifying each instance away from its original prediction or relabeling the instance to a different label. We also propose two methods that reduce forgetting on the remaining data: 1) utilizing adversarial examples to overcome forgetting at the representation-level and 2) leveraging weight importance metrics to pinpoint network parameters guilty of propagating unwanted information. Both methods only require the pre-trained model and data instances to forget, allowing painless application to real-life settings where the entire training set is unavailable. Through extensive experimentation on various image classification benchmarks, we show that our approach effectively preserves knowledge of remaining data while unlearning given instances in both single-task and continual unlearning scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2301.11578","1","0","origin_of_life"
"SOLIS XVII: Jet candidate unveiled in OMC-2 and its possible link to the enhanced cosmic-ray ionisation rate","Abstract:                _chemical history of stellar systems such as our own. In particular, protostars born in rich clusters are prototypes of the young Solar System. In the framework of the Seeds Of Life In Space (SOLIS) large observational project, the aim of the present work is to investigate the_         _ More           The study of the early phases of star and planet formation is important to understand the physical and chemical history of stellar systems such as our own. In particular, protostars born in rich clusters are prototypes of the young Solar System. In the framework of the Seeds Of Life In Space (SOLIS) large observational project, the aim of the present work is to investigate the origin of the previously inferred high flux of energetic particles in the protocluster FIR4 of the Orion Molecular Cloud 2 (OMC-2), which appears asymmetric within the protocluster itself. Interferometric observations carried out with the IRAM NOEMA interferometer were used to map the silicon monoxide (SiO) emission around the FIR4 protocluster. Complementary archival data from the ALMA interferometer were also employed to help constrain excitation conditions. A physical-chemical model was implemented to characterise the particle acceleration along the protostellar jet candidate, along with a non-LTE analysis of the SiO emission along the jet. The emission morphology of the SiO rotational transitions hints for the first time at the presence of a collimated jet originating very close to the brightest protostar in the cluster, HOPS-108. The NOEMA observations unveiled a possible jet in the OMC-2 FIR4 protocluster propagating towards a previously measured enhanced cosmic-ray ionisation rate. This suggests that energetic particle acceleration by the jet shock close to the protostar might be at the origin of the enhanced cosmic-ray ionisation rate, as confirmed by modelling the protostellar jet.         _ Less","","arXiv","https://arxiv.org/abs/2301.10267","1","0","origin_of_life"
"Proton and electron irradiations of CH4:H2O mixed ices","Abstract:                The organic chemistry occurring in interstellar environments may lead to the production of complex molecules that are relevant to the emergence of life. Therefore, in order to understand the origins of life itself, it is necessary to probe the chemistry of carbon-bearing molecule_         _ More           The organic chemistry occurring in interstellar environments may lead to the production of complex molecules that are relevant to the emergence of life. Therefore, in order to understand the origins of life itself, it is necessary to probe the chemistry of carbon-bearing molecules under conditions that simulate interstellar space. Several of these regions, such as dense molecular cores, are exposed to ionizing radiation in the form of galactic cosmic rays, which may act as an important driver of molecular destruction and synthesis. In this paper, we report the results of a comparative and systematic study of the irradiation of CH4:H2O ice mixtures by 1 MeV protons and 2 keV electrons at 20 K.We demonstrate that our irradiations result in the formation of a number of new products, including both simple and complex daughter molecules such as C2H6, C3H8, C2H2, CH3OH, CO, CO2, and probably also H2CO. A comparison of the different irradiation regimes has also revealed that proton irradiation resulted in a greater abundance of radiolytic daughter molecules compared to electron irradiation, despite a lower radiation dose having been administered. These results are important in the context of the radiation astrochemistry occurring within the molecular cores of dense interstellar clouds, as well as on outer Solar System objects.         _ Less","","arXiv","https://arxiv.org/abs/2301.09102","2","0","origin_of_life"
"Glycine amino acid transformation under impacts by small solar system bodies, simulated via high-pressure torsion method","Abstract:                _hypothesis that impacts by astronomical bodies could contribute to delivery and polymerization of amino acids in the early Earth to generate proteins as essential molecules for life. Besides the possibility of abiotic polymerization of glycine, its decomposition by impacts could generate reactive groups to form other essential organic biomolecules. In this s_         _ More           Impacts by small solar system bodies (meteoroids, asteroids, comets and transitional objects) are characterized by a combination of energy dynamics and chemical modification on both terrestrial and small solar system bodies. In this context, the discovery of glycine amino acid in meteorites and comets has led to a hypothesis that impacts by astronomical bodies could contribute to delivery and polymerization of amino acids in the early Earth to generate proteins as essential molecules for life. Besides the possibility of abiotic polymerization of glycine, its decomposition by impacts could generate reactive groups to form other essential organic biomolecules. In this study, the high-pressure torsion (HPT) method, as a new platform for simulation of impacts by small solar system bodies, was applied to glycine. In comparison with high-pressure shock experiments, the HPT method simultaneously introduces high pressure and deformation strain. It was found that glycine was not polymerized in the experimental condition assayed, but partially decomposed to ethanol under pressures of 1 and 6 GPa and shear strains of <120 m/m. The detection of ethanol implies the inherent availability of remaining nitrogen-containing groups, which can incorporate to the formation of other organic molecules at the impact site. In addition, this finding highlights a possibility of the origin of ethanol previously detected in comets.         _ Less","","arXiv","https://arxiv.org/abs/2301.06927","1","0","origin_of_life"
"Formation of Fast-spinning Neutron Stars in Close Binaries and Magnetar-driven Stripped-envelope Supernovae","Abstract:                _which can lose its rotational energy via spin-down processes to accelerate and heat the ejecta. The progenitor(s) of these magnetar-driven SESNe, and the origin of considerable angular momentum (AM) in the cores of massive stars to finally produce such fast-spinning magnetars upon core-collapse are still under debate. Popular proposed scenarios in the liter_         _ More           Extreme stripped-envelope supernovae (SESNe), including Type Ic superluminous supernovae (SLSNe-I), broad-line Type Ic SNe (SNe Ic-BL), and fast blue optical transients (FBOTs), are widely believed to harbor a newborn fast-spinning highly-magnetized neutron star (``magnetar''), which can lose its rotational energy via spin-down processes to accelerate and heat the ejecta. The progenitor(s) of these magnetar-driven SESNe, and the origin of considerable angular momentum (AM) in the cores of massive stars to finally produce such fast-spinning magnetars upon core-collapse are still under debate. Popular proposed scenarios in the literature cannot simultaneously explain their event rate density, SN and magnetar parameters, and the observed metallicity. Here, we perform a detailed binary evolution simulation that demonstrates that tidal spin-up helium stars with efficient AM transport mechanism in close binaries can form fast-spinning magnetars at the end of stars' life to naturally reproduce the universal energy-mass correlation of these magnetar-driven SESNe. Our models are consistent with the event rate densities, host environments, ejecta masses, and energetics of these different kinds of magnetar-driven SESNe, supporting that the isolated common-envelope formation channel could be a major common origin of magnetar-driven SESNe. The remnant compact binary systems of magnetar-driven SESNe are progenitors of some gravitational-wave transients and galactic systems.         _ Less","","arXiv","https://arxiv.org/abs/2301.06402","1","2","synthetic_biology"
"Detection of HCN and diverse redox chemistry in the plume of Enceladus","Abstract:                _and redox gradients derived from surface radiolysis, these compounds could potentially support extant microbial communities or drive complex organic synthesis leading to the origin of life.         _ More           The Cassini spacecraft observed that Saturn's moon Enceladus possesses a series of jets erupting from its South Polar Terrain. Previous studies of in situ data collected by Cassini's Ion and Neutral Mass Spectrometer (INMS) have identified H$_2$O, CO$_2$, CH$_4$, NH$_3$, and H$_2$ within the plume of ejected material. Identification of minor species in the plume remains an ongoing challenge, owing to the large number of possible combinations that can be used to fit the INMS data. Here, we present the detection of several new compounds of strong importance to the habitability of Enceladus, including HCN, C$_2$H$_2$, C$_3$H$_6$, and C$_2$H$_6$. Our analyses of the low velocity INMS data, coupled with our detailed statistical framework, enable discrimination between previously ambiguous species in the plume by alleviating the effects of high dimensional model fitting. Together with plausible mineralogical catalysts and redox gradients derived from surface radiolysis, these compounds could potentially support extant microbial communities or drive complex organic synthesis leading to the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2301.05259","1","0","origin_of_life"
"Venus, Phosphine and the Possibility of Life","Abstract:                The search for life elsewhere in the universe is one of the central aims of science in the 21st century. While most of this work is aimed at planets orbiting other stars, the search for_         _ More           The search for life elsewhere in the universe is one of the central aims of science in the 21st century. While most of this work is aimed at planets orbiting other stars, the search for life in our own Solar System is an important part of this endeavour. Venus is often thought to have too harsh an environment for life, but it may have been a more hospitable place in the distant past. If life evolved there in the past then the cloud decks of Venus are the only remaining niche where life as we know it might survive today. The discovery of the molecule phosphine, PH$_3$, in these clouds has reinvigorated research looking into the possibility of life in the clouds. In this review we examine the background to studies of the possibility of life on Venus, discuss the discovery of phosphine, review conflicting and confirming observations and analyses, and then look forward to future observations and space missions that will hopefully provide definitive answers as to the origin of phosphine on Venus and to the question of whether life might exist there.         _ Less","","arXiv","https://arxiv.org/abs/2301.05160","1","1","multiple"
"Meteorite Parent Body Aqueous Alteration Simulations of Interstellar Residue Analogs","Abstract:                Some families of carbonaceous chondrites are rich in prebiotic organics that may have contributed to the origin of life on Earth and elsewhere. However, the formation and chemical evolution of complex soluble organic molecules from interstellar precursors under relevant parent body conditions has not been thoroughly in_         _ More           Some families of carbonaceous chondrites are rich in prebiotic organics that may have contributed to the origin of life on Earth and elsewhere. However, the formation and chemical evolution of complex soluble organic molecules from interstellar precursors under relevant parent body conditions has not been thoroughly investigated. In this study, we approach this topic by simulating meteorite parent body aqueous alteration of interstellar residue analogs. The distributions of amines and amino acids are qualitatively and quantitatively investigated and linked to closing the gap between interstellar and meteoritic prebiotic organic abundances. We find that the abundance trend of methylamine > ethylamine> glycine > serine > alanine > \\b{eta}-alanine does not change from pre- to post-aqueous alteration, suggesting that certain cloud conditions have an influential role on the distributions of interstellar-inherited meteoritic organics. However, the abundances for most of the amines and amino acids studied here varied by about 2-fold when aqueously processed for 7 days at 125 _C, and the changes in the _- to \\b{eta}-alanine ratio were consistent with those of aqueously altered carbonaceous chondrites, pointing to an influential role of meteorite parent body processing on the distributions of interstellar-inherited meteoritic organics. We detected higher abundances of _- over \\b{eta}-alanine, which is opposite to what is typically observed in aqueously altered carbonaceous chondrites; these results may be explained by at least the lack of minerals and insoluble organic matter-relevant materials in the experiments. The high abundance of volatile amines in the non-aqueously altered samples suggests that these types of interstellar volatiles can be efficiently transferred to asteroids and comets, supporting the idea of the presence of interstellar organics in solar system objects.         _ Less","","arXiv","https://arxiv.org/abs/2301.04103","4","1","origin_of_life"
"Origin of heterogeneous stripping of lithium in liquid electrolytes","Abstract:                Lithium metal batteries suffer from low cycle life. During discharge, parts of the lithium are not stripped reversibly and remain isolated from the current collector. This isolated lithium is trapped in the insulating remaining solid-electrolyte interphase (SEI) shell and contributes to the capacity loss. However, a fundamental understanding of why isolated_         _ More           Lithium metal batteries suffer from low cycle life. During discharge, parts of the lithium are not stripped reversibly and remain isolated from the current collector. This isolated lithium is trapped in the insulating remaining solid-electrolyte interphase (SEI) shell and contributes to the capacity loss. However, a fundamental understanding of why isolated lithium forms and how it can be mitigated is lacking. In this article, we perform a combined theoretical and experimental study to understand isolated lithium formation during stripping. We derive a thermodynamic consistent model of lithium dissolution and find that the interaction between lithium and SEI leads to locally preferred stripping and isolated lithium formation. Based on a cryogenic transmission electron microscopy (TEM) setup, we reveal that these local effects are particularly pronounced at kinks of lithium whiskers. We find that lithium stripping can be heterogeneous both on a nanoscale and on a larger scale. Cryo TEM observations confirm our theoretical prediction that isolated lithium occurs less at higher stripping current densities. The origin of isolated lithium lies in local effects, such as heterogeneous SEI, stress fields, or the geometric shape of the deposits. We conclude that in order to mitigate isolated lithium, a uniform lithium morphology during plating and a homogeneous SEI is indispensable.         _ Less","","arXiv","https://arxiv.org/abs/2301.04018","1","0","origin_of_life"
"Predicting Drivers' Route Trajectories in Last-Mile Delivery Using A Pair-wise Attention-based Pointer Neural Network","Abstract:                _service areas. Hence, the actual stop sequences chosen by an experienced human driver may be potentially preferable to the theoretical shortest-distance routing under real-life operational conditions. Thus, being able to predict the actual stop sequence that a human driver would follow can help to improve route planning in last-mile delivery. This paper prop_         _ More           In last-mile delivery, drivers frequently deviate from planned delivery routes because of their tacit knowledge of the road and curbside infrastructure, customer availability, and other characteristics of the respective service areas. Hence, the actual stop sequences chosen by an experienced human driver may be potentially preferable to the theoretical shortest-distance routing under real-life operational conditions. Thus, being able to predict the actual stop sequence that a human driver would follow can help to improve route planning in last-mile delivery. This paper proposes a pair-wise attention-based pointer neural network for this prediction task using drivers' historical delivery trajectory data. In addition to the commonly used encoder-decoder architecture for sequence-to-sequence prediction, we propose a new attention mechanism based on an alternative specific neural network to capture the local pair-wise information for each pair of stops. To further capture the global efficiency of the route, we propose a new iterative sequence generation algorithm that is used after model training to identify the first stop of a route that yields the lowest operational cost. Results from an extensive case study on real operational data from Amazon's last-mile delivery operations in the US show that our proposed method can significantly outperform traditional optimization-based approaches and other machine learning methods (such as the Long Short-Term Memory encoder-decoder and the original pointer network) in finding stop sequences that are closer to high-quality routes executed by experienced drivers in the field. Compared to benchmark models, the proposed model can increase the average prediction accuracy of the first four stops from around 0.2 to 0.312, and reduce the disparity between the predicted route and the actual route by around 15%.         _ Less","","arXiv","https://arxiv.org/abs/2301.03802","1","0","origin_of_life"
"The formation and stability of homochiral peptides in aqueous prebiological environment in the Earth's crust","Abstract:                The oldest forms of living organisms on Earth are about 3.5 billion years old, and they are found in hydrothermal deposits, and it is often hypothesized that life_         _ More           The oldest forms of living organisms on Earth are about 3.5 billion years old, and they are found in hydrothermal deposits, and it is often hypothesized that life originated there. But the hydrothermal systems with a fairly strong flow of chemical components are not the optimal place for the prebiological self-assembly of biomolecules and for the emergence of homochirality. This article examines the possibility for that the self-assembly of homochiral molecules took place in an aqueous environment in the Earth's crust. Based on the latest literature regarding the conditions in the lithosphere there are several factors that point to that the crust could be the location for the prebiological self-assembly of biomolecules, and there is nothing against it. The crust and the mantle contain a substantial amount of water, and at the time prior to the emergence of life the crust contained most likely the necessary chemical substances for the synthesis of the biomolecules and an aqueous environments where the homochirality could be established.         _ Less","","arXiv","https://arxiv.org/abs/2301.03271","2","1","origin_of_life"
"Modeling Virus Transmission Risks in Commuting with Emerging Mobility Services: A Case Study of COVID-19","Abstract:                Commuting is an important part of daily life. With the gradual recovery from COVID-19 and more people returning to work from the office, the transmission of COVID-19 during commuting becomes a concern. Recent emerging mobility services (such as ride-hailing and bike-sharing) further deteriorate the infection risks due to shared vehicles or spaces during trav_         _ More           Commuting is an important part of daily life. With the gradual recovery from COVID-19 and more people returning to work from the office, the transmission of COVID-19 during commuting becomes a concern. Recent emerging mobility services (such as ride-hailing and bike-sharing) further deteriorate the infection risks due to shared vehicles or spaces during travel. Hence, it is important to quantify the infection risks in commuting. This paper proposes a probabilistic framework to estimate the risk of infection during an individual's commute considering different travel modes, including public transit, ride-share, bike, and walking. The objective is to evaluate the probability of infection as well as the estimation errors (i.e., uncertainty quantification) given the origin-destination (OD), departure time, and travel mode. We first define a general trip planning function to generate trip trajectories and probabilities of choosing different paths according to the OD, departure time, and travel mode. Then, we consider two channels of infections: 1) infection by close contact and 2) infection by touching surfaces. The infection risks are calculated on a trip segment basis. Different sources of data (such as smart card data, travel surveys, and population data) are used to estimate the potential interactions between the individual and the infectious environment. The model is implemented in the MIT community as a case study. We evaluate the commute infection risks for employees and students. Results show that most of the individuals have an infection probability close to zero. The maximum infection probability is around 0.8%, implying that the probability of getting infected during the commuting process is low. Individuals with larger travel distances, traveling in transit, and traveling during peak hours are more likely to get infected.         _ Less","","arXiv","https://arxiv.org/abs/2301.02594","1","1","multiple"
"On the degree of stochastic asymmetry in the tidal tails of star clusters","Abstract:                _work. Methods: For each star cluster 1000 configurations of test particles are integrated in the combined potential of a Plummer sphere and the Galactic tidal field over the life time of the particular star cluster. For each of the four star clusters the distribution function of the stochastic asymmetry is determined and compared with the observed asymmetry._         _ More           Context: Tidal tails of star clusters are commonly understood to be populated symmetrically. Recently, the analysis of Gaia data revealed large asymmetries between the leading and trailing tidal tail arms of the four open star clusters Hyades, Praesepe, Coma Berenices and NGC 752. Aims: As the evaporation of stars from star clusters into the tidal tails is a stochastic process, the degree of stochastic asymmetry is quantified in this work. Methods: For each star cluster 1000 configurations of test particles are integrated in the combined potential of a Plummer sphere and the Galactic tidal field over the life time of the particular star cluster. For each of the four star clusters the distribution function of the stochastic asymmetry is determined and compared with the observed asymmetry. Results: The probabilities for a stochastic origin of the observed asymmetry of the four star clusters are: Praesepe ~1.7 sigma, Coma Berenices ~2.4 sigma, Hyades ~6.7 sigma, NGC 752 ~1.6 sigma. Conclusions: In the case of Praesepe, Coma Berenices and NGC 752 the observed asymmetry can be interpreted as a stochastic evaporation event. However, for the formation of the asymmetric tidal tails of the Hyades additional dynamical processes beyond a pure statistical evaporation effect are required.         _ Less","","arXiv","https://arxiv.org/abs/2301.02251","1","0","origin_of_life"
"Spatial Structure Supports Diversity in Prebiotic Autocatalytic Chemical Ecosystems","Abstract:                Autocatalysis is thought to have played an important role in the earliest stages of the origin of life. An autocatalytic cycle (AC) is a set of reactions that results in stoichiometric increase in its constituent chemicals. When the reactions of multiple interacting ACs are active in a region of space, they can have in_         _ More           Autocatalysis is thought to have played an important role in the earliest stages of the origin of life. An autocatalytic cycle (AC) is a set of reactions that results in stoichiometric increase in its constituent chemicals. When the reactions of multiple interacting ACs are active in a region of space, they can have interactions analogous to those between species in biological ecosystems. Prior studies of autocatalytic chemical ecosystems (ACEs) have suggested avenues for accumulating complexity, such as ecological succession, as well as obstacles such as competitive exclusion. We extend this ecological framework to investigate the effects of surface adsorption, desorption, and diffusion on ACE ecology. Simulating ACEs as particle-based stochastic reaction-diffusion systems in spatial environments-including open, two-dimensional reaction-diffusion systems and adsorptive mineral surfaces-we demonstrate that spatial structure can enhance ACE diversity by i) permitting otherwise mutually exclusive ACs to coexist and ii) subjecting new AC traits to selection.         _ Less","","arXiv","https://arxiv.org/abs/2212.14445","2","0","origin_of_life"
"ReCode: Robustness Evaluation of Code Generation Models","Abstract:                _they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted_         _ More           Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model's robustness performance. With human annotators, we verified that over 90% of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.         _ Less","","arXiv","https://arxiv.org/abs/2212.10264","2","1","origin_of_life"
"A review on the protocols for the synthesis of proteinoids","Abstract:                _protocol for the preparation of proteinoids can be hard to find, given that the literature for proteinoid is widely distributed across different scientific subdisciplines - origin of_         _ More           Protocells are a type of synthetic cells, which, if engineered to have properties similar to a natural cell, can have immense applications in synthetic biology and bioengineering communities. Proteinoids are one of the leading contenders for protocells discovered by Sidney H. Fox in 1950s as the protein-like molecules which are made out of amino acids. Proteinoids, if made in a right way, can show electrical excitability patterns on its surface with inflow and outflow of acidic and basic ions giving rise to a oscillatory charge behaviour similar to a neuronal spiking potential. The right protocol for the preparation of proteinoids can be hard to find, given that the literature for proteinoid is widely distributed across different scientific subdisciplines - origin of life, synthetic cell engineering, application of proteinoid NPs etc. This review attempts to enlist most of the relevant protocols published in the literature, each catering to different application, whether motivated by fundamental sciences or basic sciences perspective. The article also suggests the best set of protocol that could be followed by the readers to synthesise proteinoid powder as a potential experimental system for proto-cognitive, cosmetic, biomedical, or synthetic biology applications. An overarching picture of proteinoid as a potential system to study the chemical evolution during the transition from abiotic to prebiotic life, in the history of Earth, is also presented in the end.         _ Less","","arXiv","https://arxiv.org/abs/2212.02261","5","5","multiple"
"Properties of condensed matter from fundamental physical constants","Abstract:                _and can routinely measure, including viscosity, thermal conductivity, elasticity and sound. Here, we review this work. We start with the lower bound on liquid viscosity, its origin and show how to relate the bound to fundamental physical constants. The lower bound of kinematic viscosity represents the global minimum on the phase diagram. We show how this res_         _ More           Fundamental physical constants play a profound role in physics. For example, they govern nuclear reactions, formation of stars, nuclear synthesis and stability of biologically vital elements. These are high-energy processes discussed in particle physics, astronomy and cosmology. More recently, it was realised that fundamental physical constants extend their governing reach to low-energy processes and properties operating in condensed matter systems, often in an unexpected way. These properties are those we experience daily and can routinely measure, including viscosity, thermal conductivity, elasticity and sound. Here, we review this work. We start with the lower bound on liquid viscosity, its origin and show how to relate the bound to fundamental physical constants. The lower bound of kinematic viscosity represents the global minimum on the phase diagram. We show how this result answers the long-standing question considered by Purcell and Weisskopf, namely why viscosity never falls below a certain value. An accompanying insight is that water viscosity and water-based life are well attuned to fundamental constants, adding another higher-level layer to the anthropic principle. We then discuss viscosity minima in liquid He above and below the $_$-point. We subsequently consider a very different property, thermal diffusivity, and show that it has the same minimum fixed by fundamental physical constants as viscosity. We also discuss bounds related to elastic properties, elastic moduli and their analogues in low-dimensional systems, and show how these bounds are related to the upper bound for the speed of sound. We conclude with listing ways in which the discussion of fundamental constants and bounds advance physical theories.         _ Less","","arXiv","https://arxiv.org/abs/2211.13342","2","1","origin_of_life"
"Rank-One Editing of Encoder-Decoder Models","Abstract:                Large sequence to sequence models for tasks such as Neural Machine Translation (NMT) are usually trained over hundreds of millions of samples. However, training is just the origin of a model's life-cycle. Real-world deployments of models require further behavioral adaptations as new requirements emerge or shortcomi_         _ More           Large sequence to sequence models for tasks such as Neural Machine Translation (NMT) are usually trained over hundreds of millions of samples. However, training is just the origin of a model's life-cycle. Real-world deployments of models require further behavioral adaptations as new requirements emerge or shortcomings become known. Typically, in the space of model behaviors, behavior deletion requests are addressed through model retrainings whereas model finetuning is done to address behavior addition requests, both procedures being instances of data-based model intervention. In this work, we present a preliminary study investigating rank-one editing as a direct intervention method for behavior deletion requests in encoder-decoder transformer models. We propose four editing tasks for NMT and show that the proposed editing algorithm achieves high efficacy, while requiring only a single instance of positive example to fix an erroneous (negative) model behavior.         _ Less","","arXiv","https://arxiv.org/abs/2211.13317","0","1","synthetic_biology"
"Improving CME evolution and arrival predictions with AMR and grid stretching in Icarus","Abstract:                _directed towards the Earth, cause geo-magnetic storms upon interacting with the magnetic field of the Earthand can cause significant damage to our planet and affect everyday life. As such, efficient space weather prediction tools are necessary to forecast the arrival and impact of CME eruptions. Recently, a new heliospheric model Icarus was developed based o_         _ More           Coronal Mass Ejections (CMEs) are one of the main drivers of disturbances in the interplanetary space. Strong CMEs, when directed towards the Earth, cause geo-magnetic storms upon interacting with the magnetic field of the Earthand can cause significant damage to our planet and affect everyday life. As such, efficient space weather prediction tools are necessary to forecast the arrival and impact of CME eruptions. Recently, a new heliospheric model Icarus was developed based on MPI-AMRVAC, which is a 3D ideal MHD model for the solar wind and CME propagation, and it introduces advanced numerical techniques to make the simulations more efficient. A cone model is used to study the evolution of the CME through the background solar wind and its arrival and impact at Earth. Grid stretching and AMR are combined in the simulations by using multiple refinement criteria. We compare simulation results to the EUFHORIA model. As a result, the simulations were sped up by a factor of 17 for the most optimal configuration in Icarus. For the cone CME model, we found that limiting the AMR to the region around the CME-driven shock yields the best results. The results modelled by the simulations with radial grid stretching and AMR level 4 are similar to the results provided by the original EUHFORIA and Icarus simulations with the 'standard' resolution and equidistant grids. The simulations with 5 AMR levels yielded better results than the simulations with an equidistant grid and standard resolution. Solution AMR is flexible and provides the user the freedom to modify and locally increase the grid resolution according to the purpose of the simulation. The advanced techniques implemented in Icarus can be further used to improve the forecasting procedures, since the reduced simulation time is essential to make physics-based forecasts less computationally expensive.         _ Less","","arXiv","https://arxiv.org/abs/2211.12867","0","1","synthetic_biology"
"T-linear resistivity, optical conductivity and Planckian transport for a holographic local quantum critical metal in a periodic potential","Abstract:                _from the onset of superconductivity to the crystal melting temperature, indicative of a Planckian dissipation life time $__{\\hbar}\\simeq \\hbar /(k_B T)$. At the same time, the optical conductivity ceases to be of Drude form at high temperatures, suggesting a change of the underlying dynamics that surprisingly leaves the $T$-linear DC-resistivity unaffected._         _ More           High $T_c$ cuprate strange metals are noted for a DC-resistivity that scales linearly with $T$ from the onset of superconductivity to the crystal melting temperature, indicative of a Planckian dissipation life time $__{\\hbar}\\simeq \\hbar /(k_B T)$. At the same time, the optical conductivity ceases to be of Drude form at high temperatures, suggesting a change of the underlying dynamics that surprisingly leaves the $T$-linear DC-resistivity unaffected. We use the AdS/CFT correspondence that describes strongly coupled, densely entangled metals to study DC thermo-electrical transport and the optical conductivities of the local quantum critical Gubser-Rocha holographic strange metal in the presence of a lattice potential, a prime candidate to compare with experiment. We find that the DC-resistivity is linear in $T$ at low temperatures for a range of lattice strengths and wavevectors, even as it transitions between different dissipative regimes. At weak lattice potential the optical conductivity evolves with increasing temperature from a Drude form to a bad-metal characterized by a mid-IR resonance without changing the DC transport, similar to that seen in cuprate strange metals. This mid-IR peak and its temperature evolution can be understood as a consequence of Umklapp hydrodynamics: hydrodynamic perturbations are Bloch modes in the presence of a lattice. At strong lattice potential an incoherent metal is realized instead where momentum conservation no longer plays a role in transport. In this regime the thermal diffusivity can be explained by Planckian dissipation originating in universal microscopic chaos, similar to holographic metals with strong homogeneous momentum relaxation. The charge diffusivity does not submit to this chaos explanation, even though the continuing linear-in-$T$ DC resistivity saturates to an apparent universal slope, numerically equal to a Planckian rate.         _ Less","","arXiv","https://arxiv.org/abs/2211.05492","0","1","synthetic_biology"
"Planetary Exploration Horizon 2061 Report, Chapter 3: From science questions to Solar System exploration","Abstract:                This chapter of the Planetary Exploration Horizon 2061 Report reviews the way the six key questions about planetary systems, from their origins to the way they work and their habitability, identified in chapter 1, can be addressed by means of solar system exploration, and how one can find partial answers to these six questions by flying to the different prov_         _ More           This chapter of the Planetary Exploration Horizon 2061 Report reviews the way the six key questions about planetary systems, from their origins to the way they work and their habitability, identified in chapter 1, can be addressed by means of solar system exploration, and how one can find partial answers to these six questions by flying to the different provinces to the solar system: terrestrial planets, giant planets, small bodies, and up to its interface with the local interstellar medium. It derives from this analysis a synthetic description of the most important space observations to be performed at the different solar system objects by future planetary exploration missions. These observation requirements illustrate the diversity of measurement techniques to be used as well as the diversity of destinations where these observations must be made. They constitute the base for the identification of the future planetary missions we need to fly by 2061, which are described in chapter 4. Q1- How well do we understand the diversity of planetary systems objects? Q2- How well do we understand the diversity of planetary system architectures? Q3- What are the origins and formation scenarios for planetary systems? Q4- How do planetary systems work? Q5- Do planetary systems host potential habitats? Q6- Where and how to search for life?         _ Less","","arXiv","https://arxiv.org/abs/2211.04474","2","1","origin_of_life"
"Experimental Characterization of the Energetics of Low-temperature Surface Reactions","Abstract:                Astrochemical surface reactions are thought to be responsible for the formation of complex organic molecules, which are of potential importance for the origin of life. In a situation, when the chemical composition of dust surfaces is not precisely known, the fundamental knowledge concerning such reactions gains signifi_         _ More           Astrochemical surface reactions are thought to be responsible for the formation of complex organic molecules, which are of potential importance for the origin of life. In a situation, when the chemical composition of dust surfaces is not precisely known, the fundamental knowledge concerning such reactions gains significance. We describe an experimental technique, which can be used to measure the energy released in reactions of a single pair of reactants. These data can be directly compared with the results of quantum chemical computations leading to unequivocal conclusions regarding the reaction pathways and the presence of energy barriers. It allows for predicting the outcomes of astrochemical surface reactions with higher accuracy compared to that achieved based on gas-phase studies. However, for the highest accuracy, some understanding of the catalytic influence of specific surfaces on the reactions is required. The new method was applied to study the reactions of C atoms with H2, O2, and C2H2. The formation of HCH, CO + O, and triplet cyclic-C3H2 products has been revealed, correspondingly.         _ Less","","arXiv","https://arxiv.org/abs/2211.04437","2","0","origin_of_life"
"Robustness of compositional heredity to the growth and division dynamics of prebiotic compartments","Abstract:                An important transition after the origin of life was the first emergence of a Darwinian population, self-reproducing entities exhibiting differential reproduction, phenotypic variation, and inheritance of phenotypic traits. The simplest system we can imagine to have these properties would consist of a compartmentalized_         _ More           An important transition after the origin of life was the first emergence of a Darwinian population, self-reproducing entities exhibiting differential reproduction, phenotypic variation, and inheritance of phenotypic traits. The simplest system we can imagine to have these properties would consist of a compartmentalized autocatalytic reaction system that exhibits two growth states with different chemical compositions. Identifying the chemical composition as the phenotype, this accounts for two of the properties. However, it is not clear what are the necessary conditions for such a chemical system to exhibit inheritance of the compositional states upon growth and division of the compartment. We show that for a general class of autocatalytic chemical systems subject to serial dilution, the inheritance of compositional information only occurs when the time interval between dilutions is below a critical threshold that depends on the efficiency of the catalytic reactions. Further, we show that these thresholds provide rigorous bounds on the properties required for the inheritance of the chemical compositional state for general growth and division cycles. Our result suggests that a serial dilution experiment, which is much easier to set up in a laboratory, can be used to test whether a given autocatalytic chemical system can exhibit heredity. Lastly, we apply our results to a realistic autocatalytic system based on the Azoarcus ribozyme and suggest a protocol to experimentally test whether this system can exhibit heredity.         _ Less","","arXiv","https://arxiv.org/abs/2211.03155","4","3","origin_of_life"
"On the Role of $^{40}$K in the Origin of Terrestrial Life","Abstract:                _K fits well in dry--wet scenarios of life's origins and should be considered in realistic simulations of prebiotic chemical pathways.         _ More           The abundance and biological role of potassium suggest that its unstable nuclide was present in all stages of terrestrial biogenesis. With its enhanced isotopic ratio in the Archean eon, $^{40}$K may have contributed to the special, perhaps unique, biogenetic conditions that were present in the primitive Earth. Compared to the U and Th radionuclides, $^{40}$K has a less disruptive radiochemical impact, which may drive a moderate, but persistent evolution of the structural and functional properties of proto-biological molecules. In the main $_$-decay route of $^{40}$K, the radiation dose generated by an Archean solution with potassium ions can be larger than the present background radiation on Earth by one to two orders of magnitude. Estimates of the rates of organic molecules indirectly affected by $_$ decays are provided for two schematic models of the propagation of secondary events in the solvent of prebiotic solutions. The left-handed $_^-$ particles emitted by $^{40}$K are the best candidates to trigger an enantiomeric excess of L-type amino acids via weak nuclear forces in the primitive Earth. The concentration-dependent radiation dose of $^{40}$K fits well in dry--wet scenarios of life's origins and should be considered in realistic simulations of prebiotic chemical pathways.         _ Less","","arXiv","https://arxiv.org/abs/2210.13995","1","1","multiple"
"BIM can help decarbonize the construction sector: life cycle evidence from Pavement Management Systems","Abstract:                _BIM to plan road maintenance, a Pavement Management System (PMS), are evaluated using field data from France. The related carbon footprints are calculated following a life cycle approach, using different sources of data, including ecoinvent v3.6, and the IPCC 2013 GWP 100a characterization factors. Three design-build-maintain pavement alternatives are compar_         _ More           Transforming the construction sector is key to reaching net-zero, and many stakeholders expect its decarbonization through digitalization. But no quantified evidence has been brought to date. We propose the first environmental quantification of the impact of Building Information Modeling (BIM) in the construction sector. Specifically, the direct and indirect greenhouse gas (GHG) emissions generated by a monofunctional BIM to plan road maintenance, a Pavement Management System (PMS), are evaluated using field data from France. The related carbon footprints are calculated following a life cycle approach, using different sources of data, including ecoinvent v3.6, and the IPCC 2013 GWP 100a characterization factors. Three design-build-maintain pavement alternatives are compared: scenario 1 relates to a massive design and surface maintenance, scenario 2 to a progressive design and pre-planned structural maintenance, and scenario 3 to a progressive design and tailored structural maintenance supported by the PMS. First, results show negligible direct emissions due to the PMS existence: 0.02% of the life cycle emissions of scenario 3. Second, complementary sensitivity analyses show that using a PMS is climate-positive over the life cycle when pavement subgrade bearing capacity improves over time, and climate-neutral otherwise. The GHG emissions savings using BIM can reach up to 30% of the life cycle emissions compared to other scenarios, and 65% when restraining the scope to maintenance and rehabilitation and excluding original pavement construction. Third, the neutral effect of BIM in case of a deterioration of the bearing capacity of the subgrade may be explained by design practices and safety margins, that could be enhanced using BIM. Fourth, the decarbonization potential of a multifunctional BIM is discussed, and research perspectives are presented.         _ Less","","arXiv","https://arxiv.org/abs/2210.12307","1","0","origin_of_life"
"Solar Ring Mission: Building a Panorama of the Sun and Inner-heliosphere","Abstract:                _the whole view of solar transients and space weather in the inner heliosphere. With these capabilities, Solar Ring mission aims to address outstanding questions about the origin of solar cycle, the_         _ More           Solar Ring (SOR) is a proposed space science mission to monitor and study the Sun and inner heliosphere from a full 360_ perspective in the ecliptic plane. It will deploy three 120_-separated spacecraft on the 1-AU orbit. The first spacecraft, S1, locates 30_ upstream of the Earth, the second, S2, 90_ downstream, and the third, S3, completes the configuration. This design with necessary science instruments, e.g., the Doppler-velocity and vector magnetic field imager, wide-angle coronagraph, and in-situ instruments, will allow us to establish many unprecedented capabilities: (1) provide simultaneous Doppler-velocity observations of the whole solar surface to understand the deep interior, (2) provide vector magnetograms of the whole photosphere - the inner boundary of the solar atmosphere and heliosphere, (3) provide the information of the whole lifetime evolution of solar featured structures, and (4) provide the whole view of solar transients and space weather in the inner heliosphere. With these capabilities, Solar Ring mission aims to address outstanding questions about the origin of solar cycle, the origin of solar eruptions and the origin of extreme space weather events. The successful accomplishment of the mission will construct a panorama of the Sun and inner-heliosphere, and therefore advance our understanding of the star and the space environment that holds our life.         _ Less","","arXiv","https://arxiv.org/abs/2210.10402","1","1","multiple"
"Provenance of Lyfe: Chemical Autonomous Agents Surviving through Associative Learning","Abstract:                _that exhibit self-replication and homeostasis. With the novel ability of associative learning, we demonstrate that simple chemical patterns can exhibit a broad repertoire of life-like behaviour, paving the way for in vitro studies of autonomous chemical learning systems, with potential relevance to artificial_         _ More           We present a benchmark study of autonomous, chemical agents exhibiting associative learning of an environmental feature. Associative learning has been widely studied in cognitive science and artificial intelligence, but are most commonly implemented in highly complex or carefully engineered systems such as animal brains, artificial neural networks, DNA computing systems and gene regulatory networks. The ability to encode environmental correlations and use them to make predictions is a benchmark of biological resilience, and underpins a plethora of adaptive responses in the living hierarchy, spanning prey animal species anticipating the arrival of predators, to epigenetic systems in microorganisms learning environmental correlations. Given the ubiquitous and essential presence of learning behaviours in the biosphere, we aimed to explore whether simple, non-living dissipative structures could also exhibit associative learning. Inspired by previous modeling of associative learning in chemical networks, we simulated simple systems composed of long and short term memory chemical species that could encode the presence or absence of temporal correlations between two external species. The ability to learn this association was implemented in Gray-Scott reaction-diffusion spots, emergent chemical patterns that exhibit self-replication and homeostasis. With the novel ability of associative learning, we demonstrate that simple chemical patterns can exhibit a broad repertoire of life-like behaviour, paving the way for in vitro studies of autonomous chemical learning systems, with potential relevance to artificial life, origins of life, and systems chemistry. The experimental realisation of these learning behaviours in protocell systems could advance a novel research direction in astrobiology, since our system significantly reduces the lower bound on the required complexity for emergent learning.         _ Less","","arXiv","https://arxiv.org/abs/2210.05227","1","3","synthetic_biology"
"Self-move and Other-move: Quantum Categorical Foundations of Japanese","Abstract:                The purpose of this work is to contribute toward the larger goal of creating a Quantum Natural Language Processing (QNLP) translator program. This work contributes original diagrammatic representations of the Japanese language based on prior work that accomplished on the English language based on category theory. The germane differences between the English a_         _ More           The purpose of this work is to contribute toward the larger goal of creating a Quantum Natural Language Processing (QNLP) translator program. This work contributes original diagrammatic representations of the Japanese language based on prior work that accomplished on the English language based on category theory. The germane differences between the English and Japanese languages are emphasized to help address English language bias in the current body of research. Additionally, topological principles of these diagrams and many potential avenues for further research are proposed. Why is this endeavor important? Hundreds of languages have developed over the course of millennia coinciding with the evolution of human interaction across time and geographic location. These languages are foundational to human survival, experience, flourishing, and living the good life. They are also, however, the strongest barrier between people groups. Over the last several decades, advancements in Natural Language Processing (NLP) have made it easier to bridge the gap between individuals who do not share a common language or culture. Tools like Google Translate and DeepL make it easier than ever before to share our experiences with people globally. Nevertheless, these tools are still inadequate as they fail to convey our ideas across the language barrier fluently, leaving people feeling anxious and embarrassed. This is particularly true of languages born out of substantially different cultures, such as English and Japanese. Quantum computers offer the best chance to achieve translation fluency in that they are better suited to simulating the natural world and natural phenomenon such as natural speech.   Keywords: category theory, DisCoCat, DisCoCirc, Japanese grammar, English grammar, translation, topology, Quantum Natural Language Processing, Natural Language Processing         _ Less","","arXiv","https://arxiv.org/abs/2210.04451","0","1","synthetic_biology"
"ALT: A software for readability analysis of Portuguese-language texts","Abstract:                In the initial stage of human life, communication, seen as a process of social interaction, was always the best way to reach consensus between the parties. Understanding and credibility in this process are essential for the mutual agreement to be validated. But, how to do it so that this communication reaches the great mass? This is the main challenge when w_         _ More           In the initial stage of human life, communication, seen as a process of social interaction, was always the best way to reach consensus between the parties. Understanding and credibility in this process are essential for the mutual agreement to be validated. But, how to do it so that this communication reaches the great mass? This is the main challenge when what is sought is the dissemination of information and its approval. In this context, this study presents the ALT software, developed from original readability metrics adapted to the Portuguese language, available on the web, to reduce communication difficulties. The development of the software was motivated by the theory of communicative action of Habermas, which uses a multidisciplinary style to measure the credibility of the discourse in the communication channels used to build and maintain a safe and healthy relationship with the public.         _ Less","","arXiv","https://arxiv.org/abs/2210.00553","1","1","multiple"
"An astrophysical perspective of life. The growth of complexity","Abstract:                The existence of life is one of the most fundamental problems of astrophysics. The intriguing existence of progressively complex and apparently improbable living beings should be a general tendency of_         _ More           The existence of life is one of the most fundamental problems of astrophysics. The intriguing existence of progressively complex and apparently improbable living beings should be a general tendency of life in the Universe. We are looking for general physical laws governing the growth of complexity in any astrophysical environment. We posit the existence of a vital scalar field. This scalar is sensitive to the gradient of the inverse of specific entropy, such that its distribution tends to very high values in the interior of living beings. Besides the classical mutations, vital field driven mutations only produce decrements of entropy. The field equations give rise to the existence of vital waves. This theory is able to deal with both the origin of life and the evolution of life. We show that the growth of complexity is accelerated by the vital field.         _ Less","","arXiv","https://arxiv.org/abs/2209.12607","1","2","synthetic_biology"
"Opportunities for Technosignature Science in the Planetary Science and Astrobiology Decadal Survey","Abstract:                Solar system exploration provides numerous possibilities for advancing technosignature science. The search for life in the solar system includes missions designed to search for evidence of biosignatures on other planetary bodies, but many missions could also attempt to search for and constrain the presence of technology within the solar system. Technosignatu_         _ More           Solar system exploration provides numerous possibilities for advancing technosignature science. The search for life in the solar system includes missions designed to search for evidence of biosignatures on other planetary bodies, but many missions could also attempt to search for and constrain the presence of technology within the solar system. Technosignatures and biosignatures represent complementary approaches toward searching for evidence of life in our solar neighborhood, and beyond. This report summarizes the potential technosignature opportunities within ongoing solar system exploration and the recommendations of the 'Origins, Worlds, and Life' Planetary Science and Astrobiology Decadal Survey. We discuss opportunities for constraining the prevalence of technosignatures within the solar system using current or future missions at negligible additional cost, and we present a preliminary assessment of gaps that may exist in the search for technosignatures within the solar system.         _ Less","","arXiv","https://arxiv.org/abs/2209.11685","1","1","multiple"
"Peptide Bonds in the Interstellar Medium: Facile Autocatalytic Formation from Nitriles on Water-Ice Grains","Abstract:                _namely nitriles and water, reacting on a water-ice cluster containing catalytic amounts of hydrons in the interstellar medium with consequential implications towards the origins of life.         _ More           A recent suggestion that acetamide, \\ce{CH3C(O)NH2}, could be readily formed on water-ice grains by the acid induced addition of water across the \\ce{CN} bond is now shown to be valid. Computational modelling of the reaction between \\ce{R-CN} (R = H, \\ce{CH3}) and a cluster of 32 molecules of water and one \\ce{H3O+} proceeds auto-catalytically to form firstly a hydroxy imine \\ce{R-C(OH)=NH} and secondly an amide \\ce{R-C(O)NH2}. Quantum mechanical tunnelling, computed from small-curvature estimates, plays a key role in the rates of these reactions. This work represents the first credible effort to show how amides can be formed from abundant substrates, namely nitriles and water, reacting on a water-ice cluster containing catalytic amounts of hydrons in the interstellar medium with consequential implications towards the origins of life.         _ Less","","arXiv","https://arxiv.org/abs/2209.10929","1","0","origin_of_life"
"The Bayesian Origins of Growth Rates in Stochastic Environments","Abstract:                _of diversity dynamics and of the emergence of wealth inequality over long time scales. However, we still lack a general statistical framework that systematically explains the origins of these heterogeneities from the adaptation of agents to their environment. In this paper, we derive population growth parameters resulting from the interaction between agents_         _ More           Stochastic multiplicative dynamics characterize many complex natural phenomena such as selection and mutation in evolving populations, and the generation and distribution of wealth within social systems. Population heterogeneity in stochastic growth rates has been shown to be the critical driver of diversity dynamics and of the emergence of wealth inequality over long time scales. However, we still lack a general statistical framework that systematically explains the origins of these heterogeneities from the adaptation of agents to their environment. In this paper, we derive population growth parameters resulting from the interaction between agents and their knowable environment, conditional on subjective signals each agent receives. We show that average growth rates converge, under specific conditions, to their maximal value as the mutual information between the agent's signal and the environment, and that sequential Bayesian learning is the optimal strategy for reaching this maximum. It follows that when all agents access the same environment using the same inference model, the learning process dynamically attenuates growth rate disparities, reversing the long-term effects of heterogeneity on inequality. Our approach lays the foundation for a unified general quantitative modeling of social and biological phenomena such as the dynamical effects of cooperation, and the effects of education on life history choices.         _ Less","","arXiv","https://arxiv.org/abs/2209.09492","2","2","multiple"
"An experimental and theoretical investigation of HCN production in the Hadean Earth atmosphere","Abstract:                A critical early stage for the origin of life on Earth may have involved the production of hydrogen cyanide (HCN) in a reducing, predominantly H$_2$ atmosphere. HCN is crucial for the origin of life as it is a possible precursor to several_         _ More           A critical early stage for the origin of life on Earth may have involved the production of hydrogen cyanide (HCN) in a reducing, predominantly H$_2$ atmosphere. HCN is crucial for the origin of life as it is a possible precursor to several biomolecules that make up RNA and proteins including nucleobases, nucleotides, amino acids, and ribose. In this work, we perform an in depth experimental and theoretical investigation of HCN production in reducing atmospheric conditions (89-95% H$_2$) possibly representing the earliest stages of the Hadean eon, ~4.5-4.3 billion years ago. We make use of cold plasma discharges - a laboratory analog to shortwave UV radiation - to simulate HCN production in the upper layers of the atmosphere for CH$_4$ abundances ranging from 0.1-6.5%. We then combine experimental mass spectrum measurements with our theoretical plasma models to estimate the HCN concentrations produced in our experiments. We find that upper atmospheric HCN production scales linearly with CH$_4$ abundance with the relation [HCN] = 0.13 $\\pm$ 0.01[CH$_4$]. Concentrations of HCN near the surface of the Hadean Earth are expected to be about 2-3 orders of magnitude lower. The addition of 1% water to our experiments results in a ~50% reduction in HCN production. We find that four reactions are primarily responsible for HCN production in our experiments: (i) $^4$N + CH$_3$ -> H$_2$CN + H -> HCN + H$_2$, (ii) $^4$N + CH -> CN + H followed by CN + CH$_4$ -> HCN + CH$_3$, (iii) C$_2$H$_4$ + $^4$N -> HCN + CH$_3$, and (iv) $^4$N + $^3$CH$_2$ -> HCN + H. The most prebiotically favorable Hadean atmosphere would have been very rich in CH$_4$ (> 5%), and as a result of greenhouse effects the surface would be likely very hot. In such a prebiotic scenario, it may have been important to incorporate HCN into organic hazes that could later release biomolecules and precursors into the first ponds.         _ Less","","arXiv","https://arxiv.org/abs/2209.09257","2","0","origin_of_life"
"Some Long-Standing Quality Practices in Software Development","Abstract:                _has been the focus of most software developers and researchers for decades. This has culminated in the design of practices that promote quality in the designed software. Originating from the inception of the traditional software development life cycle (SDLC), through to the object-oriented methods, Iterative developmen_         _ More           The desire to build quality software systems has been the focus of most software developers and researchers for decades. This has culminated in the design of practices that promote quality in the designed software. Originating from the inception of the traditional software development life cycle (SDLC), through to the object-oriented methods, Iterative development, and now the agile methods, these practices have persisted through different periods. Such practices play the same quality role regardless of the perspective of the software development process they are part of. In this paper we review three software development methods representative of the software development history, with the aim of i) identifying key quality practices, ii) identifying the quality role played by the practice in the method, and iii) noting those quality practices that have persisted through the software development history. The identified quality practices that have persisted throughout the history of the software development processes include prototyping, iterative development, incremental development, risk-driven development, phase planning, and phase retrospection. These results would be useful to method engineers who seek to design high-quality software development methods as these practices serve as candidates for inclusion in their development processes. Software development practitioners seeking to design quality software would also benefit from adopting these practices in developing their software.         _ Less","","arXiv","https://arxiv.org/abs/2209.08348","1","1","multiple"
"Life on Exoplanets In the Habitable Zone of M-Dwarfs?","Abstract:                Exoplanets orbiting in the habitable zone around M-dwarf stars have been prime targets in the search for life due to the long lifetimes of the host star, the prominence of such stars in the galaxy, and the apparent excess of terrestrial planets found around M-dwarfs. However, the heightened stellar activity of M-dwarfs and the often tidally locked planets in_         _ More           Exoplanets orbiting in the habitable zone around M-dwarf stars have been prime targets in the search for life due to the long lifetimes of the host star, the prominence of such stars in the galaxy, and the apparent excess of terrestrial planets found around M-dwarfs. However, the heightened stellar activity of M-dwarfs and the often tidally locked planets in these systems have raised questions about the habitability of these planets. In this letter we examine another significant challenge that may exist: these systems seem to lack the architecture necessary to deliver asteroids to the habitable terrestrial planets, and asteroid impacts may play a crucial role in the origin of life. The most widely accepted mechanism for producing a stable asteroid belt and the late stage delivery of asteroids after gas disk dissipation requires a giant planet exterior to the snow line radius. We show that none of the observed systems with planets in the habitable zone of their star also contain a giant planet and therefore are unlikely to have stable asteroid belts. We consider the locations of observed giant planets relative to the snow line radius as a function of stellar mass and find that there is a population of giant planets outside of the snow line radius around M-dwarfs. Therefore, asteroid belt formation around M-dwarfs is generally possible. However, we find that multi-planetary system architectures around M-dwarfs can be quite different from those around more massive stars.         _ Less","","arXiv","https://arxiv.org/abs/2209.02860","2","0","origin_of_life"
"Evolutionary Dynamics Within and Among Competing Groups","Abstract:                _from the collective incentive of the group as a whole. Mechanisms to resolve this tension are responsible for profound transitions in evolutionary history, including the origin of cellular life, multi-cellular life, and even societies. Here we synthesize a growing literature that_         _ More           Biological and social systems are structured at multiple scales, and the incentives of individuals who interact in a group may diverge from the collective incentive of the group as a whole. Mechanisms to resolve this tension are responsible for profound transitions in evolutionary history, including the origin of cellular life, multi-cellular life, and even societies. Here we synthesize a growing literature that extends evolutionary game theory to describe multilevel evolutionary dynamics, using nested birth-death processes and partial differential equations to model natural selection acting on competition within and among groups of individuals. We apply this theory to analyze how mechanisms known to promote cooperation within a single group -- including assortment, reciprocity, and population structure -- alter evolutionary outcomes in the presence of competition among groups. We find that population structures most conducive to cooperation in multi-scale systems may differ from those most conducive within a single group. Likewise, for competitive interactions with a continuous range of strategies we find that among-group selection may fail to produce socially optimal outcomes, but it can nonetheless produce second-best solutions that balance individual incentives to defect with the collective incentives for cooperation. We conclude by describing the broad applicability of multi-scale evolutionary models to problems ranging from the production of diffusible metabolites in microbes to the management of common-pool resources in human societies.         _ Less","","arXiv","https://arxiv.org/abs/2209.02063","0","1","synthetic_biology"
"The Athena X-ray Integral Field Unit: a consolidated design for the system requirement review of the preliminary definition phase","Abstract:                _and the activities foreseen in the X-IFU Instrument Science Center, and touch on communication and outreach activities, the consortium organisation, and finally on the life cycle assessment of X-IFU aiming at minimising the environmental footprint, associated with the development of the instrument. Thanks to the studies conducted so far on X-IFU, it is expec_         _ More           The Athena X-ray Integral Unit (X-IFU) is the high resolution X-ray spectrometer, studied since 2015 for flying in the mid-30s on the Athena space X-ray Observatory, a versatile observatory designed to address the Hot and Energetic Universe science theme, selected in November 2013 by the Survey Science Committee. Based on a large format array of Transition Edge Sensors (TES), it aims to provide spatially resolved X-ray spectroscopy, with a spectral resolution of 2.5 eV (up to 7 keV) over an hexagonal field of view of 5 arc minutes (equivalent diameter). The X-IFU entered its System Requirement Review (SRR) in June 2022, at about the same time when ESA called for an overall X-IFU redesign (including the X-IFU cryostat and the cooling chain), due to an unanticipated cost overrun of Athena. In this paper, after illustrating the breakthrough capabilities of the X-IFU, we describe the instrument as presented at its SRR, browsing through all the subsystems and associated requirements. We then show the instrument budgets, with a particular emphasis on the anticipated budgets of some of its key performance parameters. Finally we briefly discuss on the ongoing key technology demonstration activities, the calibration and the activities foreseen in the X-IFU Instrument Science Center, and touch on communication and outreach activities, the consortium organisation, and finally on the life cycle assessment of X-IFU aiming at minimising the environmental footprint, associated with the development of the instrument. Thanks to the studies conducted so far on X-IFU, it is expected that along the design-to-cost exercise requested by ESA, the X-IFU will maintain flagship capabilities in spatially resolved high resolution X-ray spectroscopy, enabling most of the original X-IFU related scientific objectives of the Athena mission to be retained. (abridged).         _ Less","","arXiv","https://arxiv.org/abs/2208.14562","2","2","multiple"
"Growth and Evolution of Secondary Volcanic Atmospheres: II. The Importance of Kinetics","Abstract:                _in an atmosphere in the absence of CO. This supports the use of both biosignatures for detecting life. Quenched at the high temperature of their degassing, volcanic gases also have speciations characteristic of those produced from a more oxidized mantle, if interpreted as being at thermochemical equilibrium. This therefore complicates linking atmospheres to_         _ More           Volcanism is a major and long-term source of volatile elements such as C and H to Earth's atmosphere, likely has been to Venus's atmosphere, and may be for exoplanets. Models simulating volcanic growth of atmospheres often make one of two assumptions: either that atmospheric speciation is set by the high-temperature equilibrium of volcanism; or, that volcanic gases thermochemically re-equilibrate to the new, lower, temperature of the surface environment. In the latter case it has been suggested that volcanic atmospheres may create biosignature false positives. Here, we test the assumptions underlying such inferences by performing chemical kinetic calculations to estimate the relaxation timescale of volcanically-derived atmospheres to thermochemical equilibrium, in a simple 0D atmosphere neglecting photochemistry and reaction catalysis. We demonstrate that for planets with volcanic atmospheres, thermochemical equilibrium over geological timescales can only be assumed if the atmospheric temperature is above ~700K. Slow chemical kinetics at lower temperatures inhibit the relaxation of redox-sensitive species to low-temperature thermochemical equilibrium, precluding the production of two independent biosignatures through thermochemistry alone: 1. ammonia, and 2. the co-occurrence of CO$_2$ and CH$_4$ in an atmosphere in the absence of CO. This supports the use of both biosignatures for detecting life. Quenched at the high temperature of their degassing, volcanic gases also have speciations characteristic of those produced from a more oxidized mantle, if interpreted as being at thermochemical equilibrium. This therefore complicates linking atmospheres to the interiors of rocky exoplanets, even when their atmospheres are purely volcanic in origin.         _ Less","","arXiv","https://arxiv.org/abs/2208.05338","0","2","synthetic_biology"
"Origin of Plutonium-244 in the Early Solar System","Abstract:                We investigate the origin in the early Solar System of the short-lived radionuclide 244Pu (with a half_         _ More           We investigate the origin in the early Solar System of the short-lived radionuclide 244Pu (with a half life of 80 Myr) produced by the rapid (r) neutron-capture process. We consider two large sets of r-process nucleosynthesis models and analyse if the origin of 244Pu in the ESS is consistent with that of the other r and slow (s) neutron-capture process radioactive nuclei. Uncertainties on the r-process models come from both the nuclear physics input and the astrophysical site. The former strongly affects the ratios of isotopes of close mass (129I/127I, 244Pu/238U, and 247Pu/235U). The 129I/247Cm ratio, instead, which involves isotopes of a very different mass, is much more variable than those listed above and is more affected by the physics of the astrophysical site. We consider possible scenarios for the evolution of the abundances of these radioactive nuclei in the galactic interstellar medium and verify under which scenarios and conditions solutions can be found for the origin of 244Pu that are consistent with the origin of the other isotopes. Solutions are generally found for all the possible different regimes controlled by the interval ($_$) between additions from the source to the parcel of interstellar medium gas that ended up in the Solar System, relative to decay timescales. If r-process ejecta in interstellar medium are mixed within a relatively small area (leading to a long $_$), we derive that the last event that explains the 129I and 247Cm abundances in the early Solar System can also account for the abundance of 244Pu. Due to its longer half life, however, 244Pu may have originated from a few events instead of one only. If r-process ejecta in interstellar medium are mixed within a relatively large area (leading to a short $_$), we derive that the time elapsed from the formation of the molecular cloud to the formation of the Sun was 9-16 Myr.         _ Less","","arXiv","https://arxiv.org/abs/2208.02074","1","1","multiple"
"Mixed Anhydrides at the Intersection Between Peptide and RNA Autocatalytic Sets: Evolution of Biological Coding","Abstract:                We present a scenario for the origin of biological coding. In this context, coding is a semiotic relationship between chemical information stored in one location that links to chemical information stored in a separate location. Coding_         _ More           We present a scenario for the origin of biological coding. In this context, coding is a semiotic relationship between chemical information stored in one location that links to chemical information stored in a separate location. Coding originated by the cooperative interaction of two, originally separate collectively autocatalytic sets, one for nucleic acids and one for peptides. When these two sets interacted, a series of RNA-folding-directed processes led to their joint cooperativity. The amino acyl adenylate, today amino acid-AMP, was the first covalent association made by these two collectively autocatalytic sets and solidified their interdependence. This molecule is a palimpsest of this era, and is a relic of the original semiotic, and thus coding, relationship between RNA and proteins. More defined coding was driven by selection pressure to eliminate waste in the collective autocatalytic sets. Eventually a 1:1 relationship between single amino acids and short RNA pieces (e.g., three nucleotides) was established, leading to what is today known as the genetic code. Transfer RNA aminoacylating enzymes, or aaRSs, arose concomitantly with the advent of specific coding. The two classes of aaRS enzymes are remnants of the duality of complementary information in two nucleic acid strands, as originally postulated by Rodin and Ohno. Every stage in the evolution of coding was driven by the downward selection on the components of a system to satisfy the Kantian whole. Coding was ultimately forced because there were at least two chemically distinct classes of polymers needed for open-ended evolution; systems with only one polymer cannot exhibit this characteristic. Coding is thus synonymous with life as we know it, and can be thought of as a phase transition in the history of the universe.         _ Less","","arXiv","https://arxiv.org/abs/2208.01491","1","2","synthetic_biology"
"Many-to-One Knowledge Distillation of Real-Time Epileptic Seizure Detection for Low-Power Wearable Internet of Things Systems","Abstract:                _bring significant discomfort to the patients. Consequently, reducing power consumption and discomfort is necessary for patients to use IoT devices continuously during everyday life. To overcome these challenges, in the context of epileptic seizure detection, we propose a many-to-one signals knowledge distillation approach targeting single-biosignal processin_         _ More           Integrating low-power wearable Internet of Things (IoT) systems into routine health monitoring is an ongoing challenge. Recent advances in the computation capabilities of wearables make it possible to target complex scenarios by exploiting multiple biosignals and using high-performance algorithms, such as Deep Neural Networks (DNNs). There is, however, a trade-off between performance of the algorithms and the low-power requirements of IoT platforms with limited resources. Besides, physically larger and multi-biosignal-based wearables bring significant discomfort to the patients. Consequently, reducing power consumption and discomfort is necessary for patients to use IoT devices continuously during everyday life. To overcome these challenges, in the context of epileptic seizure detection, we propose a many-to-one signals knowledge distillation approach targeting single-biosignal processing in IoT wearable systems. The starting point is to get a highly-accurate multi-biosignal DNN, then apply our approach to develop a single-biosignal DNN solution for IoT systems that achieves an accuracy comparable to the original multi-biosignal DNN. To assess the practicality of our approach to real-life scenarios, we perform a comprehensive simulation experiment analysis on several state-of-the-art edge computing platforms, such as Kendryte K210 and Raspberry Pi Zero.         _ Less","","arXiv","https://arxiv.org/abs/2208.00885","1","1","multiple"
"The emergence of interstellar molecular complexity explained by interacting networks","Abstract:                _years have witnessed the detection of an increasing number of complex organic molecules in interstellar space, some of them being of prebiotic interest. Disentangling the origin of interstellar prebiotic chemistry and its connection to biochemistry and ultimately to biology is an enormously challenging scientific goal where the application of complexity theo_         _ More           Recent years have witnessed the detection of an increasing number of complex organic molecules in interstellar space, some of them being of prebiotic interest. Disentangling the origin of interstellar prebiotic chemistry and its connection to biochemistry and ultimately to biology is an enormously challenging scientific goal where the application of complexity theory and network science has not been fully exploited. Encouraged by this idea, we present a theoretical and computational framework to model the evolution of simple networked structures toward complexity. In our environment, complex networks represent simplified chemical compounds, and interact optimizing the dynamical importance of their nodes. We describe the emergence of a transition from simple networks toward complexity when the parameter representing the environment reaches a critical value. Notably, although our system does not attempt to model the rules of real chemistry, nor is dependent on external input data, the results describe the emergence of complexity in the evolution of chemical diversity in the interstellar medium. Furthermore, they reveal an as yet unknown relationship between the abundances of molecules in dark clouds and the potential number of chemical reactions that yield them as products, supporting the ability of the conceptual framework presented here to shed light on real scenarios. Our work reinforces the notion that some of the properties that condition the extremely complex journey from the chemistry in space to prebiotic chemistry and finally to life could show relatively simple and universal patterns.         _ Less","","arXiv","https://arxiv.org/abs/2207.14176","2","1","origin_of_life"
"Aries: Efficient Testing of Deep Neural Networks via Labeling-Free Accuracy Estimation","Abstract:                Deep learning (DL) plays a more and more important role in our daily life due to its competitive performance in industrial application domains. As the core of DL-enabled systems, deep neural networks (DNNs) need to be carefully evaluated to ensure the produced models match the expected requirements. In practice, the \\emph{de facto standard} to assess the qua_         _ More           Deep learning (DL) plays a more and more important role in our daily life due to its competitive performance in industrial application domains. As the core of DL-enabled systems, deep neural networks (DNNs) need to be carefully evaluated to ensure the produced models match the expected requirements. In practice, the \\emph{de facto standard} to assess the quality of DNNs in the industry is to check their performance (accuracy) on a collected set of labeled test data. However, preparing such labeled data is often not easy partly because of the huge labeling effort, i.e., data labeling is labor-intensive, especially with the massive new incoming unlabeled data every day. Recent studies show that test selection for DNN is a promising direction that tackles this issue by selecting minimal representative data to label and using these data to assess the model. However, it still requires human effort and cannot be automatic. In this paper, we propose a novel technique, named \\textit{Aries}, that can estimate the performance of DNNs on new unlabeled data using only the information obtained from the original test data. The key insight behind our technique is that the model should have similar prediction accuracy on the data which have similar distances to the decision boundary. We performed a large-scale evaluation of our technique on two famous datasets, CIFAR-10 and Tiny-ImageNet, four widely studied DNN models including ResNet101 and DenseNet121, and 13 types of data transformation methods. Results show that the estimated accuracy by \\textit{Aries} is only 0.03\\% -- 2.60\\% off the true accuracy. Besides, \\textit{Aries} also outperforms the state-of-the-art labeling-free methods in 50 out of 52 cases and selection-labeling-based methods in 96 out of 128 cases.         _ Less","","arXiv","https://arxiv.org/abs/2207.10942","1","0","origin_of_life"
"Origin of life from a maker's perspective -- focus on protocellular compartments in bottom-up synthetic biology","Abstract:                The origin of_         _ More           The origin of life is shrouded in mystery, with few surviving clues, obscured by evolutionary competition. Previous reviews have touched on the complementary approaches of top-down and bottom-up synthetic biology to augment our understanding of living systems. Here we point out the synergies between these fields, especially between bottom-up synthetic biology and origin of life research. We explore recent progress made in artificial cell compartmentation in line with the crowded cell, its metabolism, as well as cycles of growth and division, and how those efforts are starting to be combined. Though the complexity of current life is among its most striking characteristics, none of life's essential features require it, and they are unlikely to have emerged thus complex from the beginning. Rather than recovering the one true origin lost in time, current research converges towards reproducing the emergence of minimal life, by teasing out how complexity and evolution may arise from a set of essential components.         _ Less","","arXiv","https://arxiv.org/abs/2207.07225","4","8","synthetic_biology"
"Nitrogen fractionation towards a pre-stellar core traces isotope-selective photodissociation","Abstract:                Isotopologue abundance ratios are important to understand the evolution of astrophysical objects and ultimately the origins of a planetary system like our own. Being nitrogen a fundamental ingredient of pre-biotic material, understanding its chemistry and inheritance is of fundamental importance to understand the formation of the building blocks of_         _ More           Isotopologue abundance ratios are important to understand the evolution of astrophysical objects and ultimately the origins of a planetary system like our own. Being nitrogen a fundamental ingredient of pre-biotic material, understanding its chemistry and inheritance is of fundamental importance to understand the formation of the building blocks of life. We present here single-dish observations of the ground state rotational transitions of the $^{13}$C and $^{15}$N isotopologues of HCN, HNC and CN with the IRAM 30m telescope. We analyse their column densities and compute the $^{14}$N/$^{15}$N ratio map for HCN. The $^{15}$N-fractionation of CN and HNC is computed towards different offsets across L1544. The $^{15}$N-fractionation map of HCN shows a clear decrease of the $^{14}$N/$^{15}$N ratio towards the southern edge of L1544, where carbon chain molecules present a peak, strongly suggesting that isotope-selective photodissociation has a strong effect on the fractionation of nitrogen across pre-stellar cores. The $^{14}$N/$^{15}$N ratio in CN measured towards four positions across the core also shows a decrease towards the South-East of the core, while HNC shows opposite behaviour. The uneven illumination of the pre-stellar core L1544 provides clear evidence that $^{15}$N-fractionation of HCN and CN is enhanced toward the region more exposed to the interstellar radiation field. Isotope-selective photodissociation of N$_2$ is then a crucial process to understand $^{15}$N fractionation, as already found in protoplanetary disks. Therefore, the $^{15}$N-fractionation in pre-stellar material is expected to change depending on the environment within which pre-stellar cores are embedded. The $^{12}$CN/$^{13}$CN ratio also varies across the core, but its variation does not affect our conclusions on the effect of the environment on the fractionation of nitrogen.         _ Less","","arXiv","https://arxiv.org/abs/2207.06121","2","1","origin_of_life"
"An algebraic characterization of self-generating chemical reaction networks using semigroup models","Abstract:                The ability of a chemical reaction network to generate itself by catalyzed reactions from constantly present environmental food sources is considered a fundamental property in origin-of-life research. Based on Kaufmann's autocatalytic sets, Hordijk and Steel have constructed the versatile formalism of catalytic rea_         _ More           The ability of a chemical reaction network to generate itself by catalyzed reactions from constantly present environmental food sources is considered a fundamental property in origin-of-life research. Based on Kaufmann's autocatalytic sets, Hordijk and Steel have constructed the versatile formalism of catalytic reaction systems (CRS) to model and to analyze such self-generating networks, which they named reflexively autocatalytic and food generated (RAF). Previously, it was established that the subsequent and simultaenous catalytic functions of the chemicals of a CRS give rise to an algebraic structure, termed a semigroup model. The semigroup model allows to naturally consider the function of any subset of chemicals on the whole CRS. This gives rise to a generative dynamics by iteratively applying the function of a subset to the externally supplied food set. The fixed point of this dynamics yields the maximal self-generating set of chemicals. Moreover, the lattice of all functionally closed self-generating sets of chemicals is discussed and a structure theorem for this lattice is proven. It is also shown that a CRS which contains self-generating sets of chemicals cannot be nilpotent and thus a useful link to the combinatorial theory of finite semigroups is established. The main technical tool introduced and utilized in this work is the representation of the semigroup elements as decorated rooted trees, allowing to translate the generation of chemicals from a given set of resources into the semigroup language.         _ Less","","arXiv","https://arxiv.org/abs/2207.05335","0","1","synthetic_biology"
"Spin-down induced quark-hadron phase transition in cold isolated neutron stars","Abstract:                _mass stars are more likely to have a quark seeding in their lifetime at birth. Smaller neutron stars do not have a quark core and remain neutron stars throughout their life, whereas in massive stars, a quark core exists at their center from birth. In intermediate and massive stars, the quark core grows further as the star slows down. The appearance of a quar_         _ More           We have studied the spin-down induced phase transition in cold, isolated neutron stars in this work. After birth, as the star slows down, its central density rises and crosses the critical density of phase transition, and a quark core is seeded inside the star. Intermediate mass stars are more likely to have a quark seeding in their lifetime at birth. Smaller neutron stars do not have a quark core and remain neutron stars throughout their life, whereas in massive stars, a quark core exists at their center from birth. In intermediate and massive stars, the quark core grows further as the star slows down. The appearance of a quark core leads to a sudden change in the moment of inertia of the star in its evolutionary history, and it is also reflected in a sudden discontinuity in the braking index of the star (at the frequency where the quark core first seeds). The energy released during the phase transition process as the quark core is seeded can excite the f-mode oscillation in the star and is emitted in the form of the gravitational wave, which is in the range of detection with present operating detectors; however, future detectors will enable a more clean extraction of this signals. Also, neutrinos and bursts of gamma-rays can originate from phase transition events. The spin-down induced phase transition could be gradual or in the form of subsequent leaps producing persistent or multiple transient emissions.         _ Less","","arXiv","https://arxiv.org/abs/2207.03234","0","1","synthetic_biology"
"Exploring refractory organics in extraterrestrial particles","Abstract:                The origin of organic compounds detected in meteorites and comets, some of which could serve as precursors of_         _ More           The origin of organic compounds detected in meteorites and comets, some of which could serve as precursors of life on Earth, still remains an open question. The aim of the present study is to make one more step in revealing the nature and composition of organic materials of extraterrestrial particles by comparing infrared spectra of laboratory-made refractory organic residues to the spectra of cometary particles returned by the Stardust mission, interplanetary dust particles, and meteorites. Our results reinforce the idea of a pathway for the formation of refractory organics through energetic and thermal processing of molecular ices in the solar nebula. There is also the possibility that some of the organic material formed already in the parental molecular cloud before it entered the solar nebula. The majority of the IR 'organic' bands of the studied extraterrestrial particles can be reproduced in the spectra of the laboratory organic residues. We confirm the detection of water, nitriles, hydrocarbons, and carbonates in extraterrestrial particles and link it to the formation location of the particles in the outer regions of the solar nebula. To clarify the genesis of the species, high-sensitivity observations in combination with laboratory measurements like those presented in this paper are needed. Thus, this study presents one more piece of the puzzle of the origin of water and organic compounds on Earth and motivation for future collaborative laboratory and observational projects.         _ Less","","arXiv","https://arxiv.org/abs/2207.02537","1","0","origin_of_life"
"False positives and the challenge of testing the alien hypothesis","Abstract:                The origin of_         _ More           The origin of life and the detection of alien life have historically been treated as separate scientific research problems. However, they are not strictly independent. Here, we discuss the need for a better integration of the sciences of life detection and origins of life. Framing these dual problems within the formalism of Bayesian hypothesis testing, we show via simple examples how high confidence in life detection claims require either (1) a strong prior hypothesis about the existence of life in a particular alien environment, or conversely, (2) signatures of life that are not susceptible to false positives. As a case study, we discuss the role of priors and hypothesis testing in recent results reporting potential detection of life in the Venusian atmosphere and in the icy plumes of Enceladus. While many current leading biosignature candidates are subject to false positives because they are not definitive of life, our analyses demonstrate why it is necessary to shift focus to candidate signatures that are definitive. This indicates a necessity to develop methods that lack false positives, by using observables for life that rely on prior hypotheses with strong theoretical and empirical support in identifying defining features of life. Abstract theories developed in pursuit of understanding universal features of life are more likely to be definitive and to apply to life-as-we-don't-know-it. In the absence of alien examples these are best validated in origin of life experiments, substantiating the need for better integration between origins of life and biosignature science research communities.         _ Less","","arXiv","https://arxiv.org/abs/2207.00634","1","0","origin_of_life"
"Cosmic ray-driven bioenergetics for Life in Molecular Clouds and the Origin of Chemiosmosis","Abstract:                Some models such as the Nebula-Relay hypothesis, predict that the ancestors of Earth's life once lived in molecular clouds. Where does the energy come from for creatures in molecular clouds? In this draft, we proposed a new bioenergetic mechanism that is driven by the cosmic ray ionization of hydrogen molecules. Protons are naturally produced in this sce_         _ More           Some models such as the Nebula-Relay hypothesis, predict that the ancestors of Earth's life once lived in molecular clouds. Where does the energy come from for creatures in molecular clouds? In this draft, we proposed a new bioenergetic mechanism that is driven by the cosmic ray ionization of hydrogen molecules. Protons are naturally produced in this scenario, which may be the origin of chemiosmosis. Based on this bioenergetics mechanism, we speculate that LUCA is one type of biological hydrogen microbe.         _ Less","","arXiv","https://arxiv.org/abs/2206.12816","1","1","multiple"
"RendNet: Unified 2D/3D Recognizer With Latent Space Rendering","Abstract:                Vector graphics (VG) have been ubiquitous in our daily life with vast applications in engineering, architecture, designs, etc. The VG recognition process of most existing methods is to first render the VG into raster graphics (RG) and then conduct recognition based on RG formats. However, this procedure discards the structure of geometries and loses the high_         _ More           Vector graphics (VG) have been ubiquitous in our daily life with vast applications in engineering, architecture, designs, etc. The VG recognition process of most existing methods is to first render the VG into raster graphics (RG) and then conduct recognition based on RG formats. However, this procedure discards the structure of geometries and loses the high resolution of VG. Recently, another category of algorithms is proposed to recognize directly from the original VG format. But it is affected by the topological errors that can be filtered out by RG rendering. Instead of looking at one format, it is a good solution to utilize the formats of VG and RG together to avoid these shortcomings. Besides, we argue that the VG-to-RG rendering process is essential to effectively combine VG and RG information. By specifying the rules on how to transfer VG primitives to RG pixels, the rendering process depicts the interaction and correlation between VG and RG. As a result, we propose RendNet, a unified architecture for recognition on both 2D and 3D scenarios, which considers both VG/RG representations and exploits their interaction by incorporating the VG-to-RG rasterization process. Experiments show that RendNet can achieve state-of-the-art performance on 2D and 3D object recognition tasks on various VG datasets.         _ Less","","arXiv","https://arxiv.org/abs/2206.10066","1","0","origin_of_life"
"Event-related data conditioning for acoustic event classification","Abstract:                _events. Self-attention relies on the similarity between time frames, and uses global information from the whole segment to highlight specific features within a frame. In real life, information related to acoustic events will attenuate over time, which means the information within some frames around the event deserves more attention than distant time global i_         _ More           Models based on diverse attention mechanisms have recently shined in tasks related to acoustic event classification (AEC). Among them, self-attention is often used in audio-only tasks to help the model recognize different acoustic events. Self-attention relies on the similarity between time frames, and uses global information from the whole segment to highlight specific features within a frame. In real life, information related to acoustic events will attenuate over time, which means the information within some frames around the event deserves more attention than distant time global information that may be unrelated to the event. This paper shows that self-attention may over-enhance certain segments of audio representations, and smooth out the boundaries between events representations and background noises. Hence, this paper proposes an event-related data conditioning (EDC) for AEC. EDC directly works on spectrograms. The idea of EDC is to adaptively select the frame-related attention range based on acoustic features, and gather the event-related local information to represent the frame. Experiments show that: 1) compared with spectrogram-based data augmentation methods and trainable feature weighting and self-attention, EDC outperforms them in both the original-size mode and the augmented mode; 2) EDC effectively gathers event-related local information and enhances boundaries between events and backgrounds, improving the performance of AEC.         _ Less","","arXiv","https://arxiv.org/abs/2206.08233","1","0","origin_of_life"
"The Origin of Deformation Induced Topological Anisotropy in Silica Glass","Abstract:                Oxide glasses with a network structure are omnipresent in daily life. Often, they are regarded as isotropic materials; however, structural anisotropy can be induced through processing in mechanical fields and leads to unique materials properties. Unfortunately, due to the lack of local, atomic-scale analysis methods, the microscopic mechanisms leading to ani_         _ More           Oxide glasses with a network structure are omnipresent in daily life. Often, they are regarded as isotropic materials; however, structural anisotropy can be induced through processing in mechanical fields and leads to unique materials properties. Unfortunately, due to the lack of local, atomic-scale analysis methods, the microscopic mechanisms leading to anisotropy remained elusive. Using novel analysis methods on glasses generated by molecular dynamics simulations, this paper provides a microscopic understanding of topological anisotropy in silica (SiO$_2$) glass under mechanical loads. The anisotropy observed in silica glass originates from a preferred orientation of SiO$_4$ tetrahedra at both short- and medium-range levels that can be controlled via the mode of mechanical loading. The findings elucidate the relation between the deformation protocol and the resulting anisotropic structure of the silica network (involving both persistent and transient effects), and thus provide important insight for the design of oxide glasses with tailored materials properties.         _ Less","","arXiv","https://arxiv.org/abs/2206.03039","1","0","origin_of_life"
"Assembly Theory Explains and Quantifies the Emergence of Selection and Evolution","Abstract:                Since the time of Darwin, scientists have struggled to reconcile the evolution of biological forms in a universe determined by fixed laws. These laws underpin the origin of_         _ More           Since the time of Darwin, scientists have struggled to reconcile the evolution of biological forms in a universe determined by fixed laws. These laws underpin the origin of life, evolution, human culture and technology, as set by the boundary conditions of the universe, however these laws cannot predict the emergence of these things. By contrast evolutionary theory works in the opposite direction, indicating how selection can explain why some things exist and not others. To understand how open-ended forms can emerge in a forward-process from physics that does not include their design, a new approach to understand the non-biological to biological transition is necessary. Herein, we present a new theory, Assembly Theory (AT), which explains and quantifies the emergence of selection and evolution. In AT, the complexity of an individual observable object is measured by its Assembly Index (a), defined as the minimal number of steps needed to construct the object from basic building blocks. Combining a with the copy number defines a new quantity called Assembly which quantifies the amount of selection required to produce a given ensemble of objects. We investigate the internal structure and properties of assembly space and quantify the dynamics of undirected exploratory processes as compared to the directed processes that emerge from selection. The implementation of assembly theory allows the emergence of selection in physical systems to be quantified at any scale as the transition from undirected-discovery dynamics to a selected process within the assembly space. This yields a mechanism for the onset of selection and evolution and a formal approach to defining life. Because the assembly of an object is easily calculable and measurable it is possible to quantify a lower limit on the amount of selection and memory required to produce complexity uniquely linked to biology in the universe.         _ Less","","arXiv","https://arxiv.org/abs/2206.02279","2","1","origin_of_life"
"Molecular precursors of the RNA-world in space: new nitriles in the G+0.693-0.027 molecular cloud","Abstract:                Nitriles play a key role as molecular precursors in prebiotic experiments based on the RNA-world scenario for the origin of life. These chemical compounds could have been partially delivered to the young Earth from extraterrestrial objects, stressing the importance of establishing the reservoir of nitriles in the inter_         _ More           Nitriles play a key role as molecular precursors in prebiotic experiments based on the RNA-world scenario for the origin of life. These chemical compounds could have been partially delivered to the young Earth from extraterrestrial objects, stressing the importance of establishing the reservoir of nitriles in the interstellar medium. We report here the detection towards the molecular cloud G+0.693-0.027 of several nitriles, including cyanic acid (HOCN), and three C$_4$H$_3$N isomers (cyanoallene, CH$_2$CCHCN; propargyl cyanide, HCCCH$_2$CN; and cyanopropyne (CH$_3$CCCN), and the tentative detections of cyanoformaldehyde (HCOCN), and glycolonitrile (HOCH$_2$CN). We have also performed the first interstellar search of cyanoacetaldehyde (HCOCH$_2$CN), which was not detected. Based on the derived molecular abundances of the different nitriles in G+0.693-0.027 and other interstellar sources, we have discussed their formation mechanisms in the ISM. We propose that the observed HOCN abundance in G+0.693-0.027 is mainly due to surface chemistry and subsequent shock-induced desorption, while HCOCN might be mainly formed through gas-phase chemistry. In the case of HOCH$_2$CN, several grain-surface routes from abundant precursors could produce it. The derived abundances of the three C$_4$H$_3$N isomers in G+0.693-0.027 are very similar, and also similar to those previously reported in the dark cold cloud TMC-1. This suggests that the three isomers are likely formed through gas-phase chemistry from common precursors, possibly unsaturated hydrocarbons (CH$_3$CCH and CH$_2$CCH$_2$) that react with the cyanide radical (CN). The rich nitrile feedstock found towards G+0.693-0.027 confirms that interstellar chemistry is able to synthesize in space molecular species that could drive the prebiotic chemistry of the RNA-world.         _ Less","","arXiv","https://arxiv.org/abs/2206.01053","3","0","origin_of_life"
"The Role of Atmospheric Exchange in False-Positive Biosignature Detection","Abstract:                _sourced from TRAPPIST-1 d, could be introduced into the upper atmosphere of TRAPPIST-1 e and might be interpreted as biosignatures. We simulate this potential false-positive for life on TRAPPIST-1 e, by applying an external influx of water and oxygen into the top of the atmosphere using a coupled 1-D photochemical-climate model (Atmos), to predict atmospheri_         _ More           Saturn's Moon Titan receives volatiles into the top of its atmosphere-including atomic oxygen-sourced from cryovolcanoes on Enceladus. Similar types of atmosphere exchange from one body to another, such as O2 and O3 sourced from TRAPPIST-1 d, could be introduced into the upper atmosphere of TRAPPIST-1 e and might be interpreted as biosignatures. We simulate this potential false-positive for life on TRAPPIST-1 e, by applying an external influx of water and oxygen into the top of the atmosphere using a coupled 1-D photochemical-climate model (Atmos), to predict atmospheric composition. In addition, synthetic spectral observations are produced using the Planetary Spectrum Generator for the James Webb Space Telescope, Origins Space Telescope, Habitable Exoplanet Observatory and Large Ultra-violet/Optical/Infrared Surveyor to test the detectability of abiotic-generated O2 and O3 in the presence of abiotic and biotic surface fluxes of CH4. We determine that the incoming flux of material needed to trigger detection of abiotic O2/O3 by any of these observatories is more than two orders of magnitude (1E12 molecules/cm2/s) above what is physically plausible.         _ Less","","arXiv","https://arxiv.org/abs/2206.00028","1","1","multiple"
"Ca II Triplet Spectroscopy of Small Magellanic Cloud Red Giants. VI. Analysis of chemical properties of the Main Body","Abstract:                _in the clusters studied in that region. Metal-rich clusters present a clear age-metallicity relation, while metal-poor clusters present no chemical enrichment throughout the life of the galaxy. We present observational evidence that the chemical enrichment is complex in the SMC Main Body. Two cluster groups with potential different_         _ More           We derived radial velocities and CaT metallicity of more than 150 red giants stars in six SMC star clusters and their surrounding fields, with the instrument GMOS on GEMINI-S. The mean cluster radial velocity and metallicity were obtained with mean errors of 2.2 km\\,s$^{-1}$ and 0.03 dex, while the mean field metallicities have a mean error of 0.13 dex. We add this information to that available for another 51 clusters and 30 fields with CaT metallicities on the same scale. Using this expanded sample we analize the chemical properties of the SMC Main Body, defined as the inner 3.4 degrees in semimajor axis. We found a high probability that the metallicity distribution of the Main Body clusters is bimodal with a metal-rich and a metal-poor cluster group, having mean metallicities with a dispersion of $_= -0.80$, $_= 0.06$ and $_= -1.15$, $_= 0.10$ dex, respectively. On the other hand, Main Body field stars show a unimodal metallicity distribution peaking at $[Fe/H] \\sim -1$ and dispersion of $0.3$. Neither metal-rich nor metal-poor clusters present a metallicity gradient. However the full Main Body cluster sample and field stars have a negative metallicity gradient consistent with each other, but the one corresponding to clusters has a large error due to the large metallicity dispersion present in the clusters studied in that region. Metal-rich clusters present a clear age-metallicity relation, while metal-poor clusters present no chemical enrichment throughout the life of the galaxy. We present observational evidence that the chemical enrichment is complex in the SMC Main Body. Two cluster groups with potential different origins could be coexisting in the Main Body. More data with precise and homogeneous metallicities and distances are needed and dynamical simulations are required to understand possible different origins for the two possible cluster groups.         _ Less","","arXiv","https://arxiv.org/abs/2205.15134","1","0","origin_of_life"
"Modeling the Dynamics of the Coronavirus SARS-CoV-2 Pandemic using Modified SIR Model with the 'Damped-Oscillator' Dynamics of the Effective Reproduction Number","Abstract:                _and decision-makers unprepared. Even though epidemiological models have been known for almost a century (since the 'Spanish Influenza' pandemic of 1918-20), the real-life spread of the SARS-CoV-2 virus often confounded the modelers. While the general framework of epidemiological models like SEIR (susceptible-exposed-infected-recovered) or SIR (suscep_         _ More           The COVID-19 pandemic has been a great catastrophe that upended human lives and caused millions of deaths all over the world. The rapid spread of the virus, with its early-stage exponential growth and subsequent 'waves', caught many medical professionals and decision-makers unprepared. Even though epidemiological models have been known for almost a century (since the 'Spanish Influenza' pandemic of 1918-20), the real-life spread of the SARS-CoV-2 virus often confounded the modelers. While the general framework of epidemiological models like SEIR (susceptible-exposed-infected-recovered) or SIR (susceptible-exposed-infected) was not in question, the behavior of model parameters turned out to be unpredictable and complicated. In particular, while the 'basic' reproduction number, R0, can be considered a constant (for the original SARS-CoV-2 virus, prior to the emergence of variants, R0 is between 2.5 and 3.0), the 'effective' reproduction number, R(t), was a complex function of time, influenced by human behavior in response to the pandemic (e.g., masking, lockdowns, transition to remote work, etc.) To better understand these phenomena, we model the first year of the pandemic (between February 2020 and February 2021) for a number of localities (fifty US states, as well as several countries) using a simple SIR model. We show that the evolution of the pandemic can be described quite successfully by assuming that R(t) behaves in a 'viscoelastic' manner, as a sum of two or three 'damped oscillators' with different natural frequencies and damping coefficients. These oscillators likely correspond to different sub-populations having different reactions to proposed mitigation measures. The proposed approach can offer future data modelers new ways to fit the reproduction number evolution with time (as compared to the purely data-driven approaches most prevalent today).         _ Less","","arXiv","https://arxiv.org/abs/2205.14747","1","3","synthetic_biology"
"Large-Scale Privacy-Preserving Network Embedding against Private Link Inference Attacks","Abstract:                _private links. In this work, we address a novel problem of privacy-preserving network embedding against private link inference attacks. Basically, we propose to perturb the original network by adding or removing links, and expect the embedding generated on the perturbed network can leak little information about private links but hold high utility for various_         _ More           Network embedding represents network nodes by a low-dimensional informative vector. While it is generally effective for various downstream tasks, it may leak some private information of networks, such as hidden private links. In this work, we address a novel problem of privacy-preserving network embedding against private link inference attacks. Basically, we propose to perturb the original network by adding or removing links, and expect the embedding generated on the perturbed network can leak little information about private links but hold high utility for various downstream tasks. Towards this goal, we first propose general measurements to quantify privacy gain and utility loss incurred by candidate network perturbations; we then design a PPNE framework to identify the optimal perturbation solution with the best privacy-utility trade-off in an iterative way. Furthermore, we propose many techniques to accelerate PPNE and ensure its scalability. For instance, as the skip-gram embedding methods including DeepWalk and LINE can be seen as matrix factorization with closed form embedding results, we devise efficient privacy gain and utility loss approximation methods to avoid the repetitive time-consuming embedding training for every candidate network perturbation in each iteration. Experiments on real-life network datasets (with up to millions of nodes) verify that PPNE outperforms baselines by sacrificing less utility and obtaining higher privacy protection.         _ Less","","arXiv","https://arxiv.org/abs/2205.14440","1","0","origin_of_life"
"From the origin of life to pandemics: Emergent phenomena in complex systems","Abstract:                _where we provide a synthesis of the contents tackled in the Issue and outline how they relate to these challenges, spanning from current advances in our understanding on the origin of life to the large-scale propagation of infectious diseases.         _ More           When a large number of similar entities interact among each other and with their environment at a low scale, unexpected outcomes at higher spatio-temporal scales might spontaneously arise. This nontrivial phenomenon, known as emergence, characterizes a broad range of distinct complex systems -- from physical to biological and social ones -- and is often related to collective behavior. It is ubiquitous, from non-living entities such as oscillators that under specific conditions synchronize, to living ones, such as birds flocking or fish schooling. Despite the ample phenomenological evidence of the existence of systems' emergent properties, central theoretical questions to the study of emergence remain still unanswered, such as the lack of a widely accepted, rigorous definition of the phenomenon or the identification of the essential physical conditions that favour emergence. We offer here a general overview of the phenomenon of emergence and sketch current and future challenges on the topic. Our short review also serves as an introduction to the Theme Issue 'Emergent phenomena in complex physical and socio-technical systems: from cells to societies', where we provide a synthesis of the contents tackled in the Issue and outline how they relate to these challenges, spanning from current advances in our understanding on the origin of life to the large-scale propagation of infectious diseases.         _ Less","","arXiv","https://arxiv.org/abs/2205.11595","4","2","origin_of_life"
"Micro-video recommendation model based on graph neural network and attention mechanism","Abstract:                _development of Internet technology and the comprehensive popularity of Internet applications, online activities have gradually become an indispensable part of people's daily life. The original recommendation learning algorithm is mainly based on user-microvideo interaction for learning, modeling the user-micro-vide_         _ More           With the rapid development of Internet technology and the comprehensive popularity of Internet applications, online activities have gradually become an indispensable part of people's daily life. The original recommendation learning algorithm is mainly based on user-microvideo interaction for learning, modeling the user-micro-video connection relationship, which is difficult to capture the more complex relationships between nodes. To address the above problems, we propose a personalized recommendation model based on graph neural network, which utilizes the feature that graph neural network can tap deep information of graph data more effectively, and transforms the input user rating information and item side information into graph structure, for effective feature extraction, based on the importance sampling strategy. The importance-based sampling strategy measures the importance of neighbor nodes to the central node by calculating the relationship tightness between the neighbor nodes and the central node, and selects the neighbor nodes for recommendation tasks based on the importance level, which can be more targeted to select the sampling neighbors with more influence on the target micro-video nodes. The pooling aggregation strategy, on the other hand, trains the aggregation weights by inputting the neighborhood node features into the fully connected layer before aggregating the neighborhood features, and then introduces the pooling layer for feature aggregation, and finally aggregates the obtained neighborhood aggregation features with the target node itself, which directly introduces a symmetric trainable function to fuse the neighborhood weight training into the model to better capture the different neighborhood nodes' differential features in a learnable manner to allow for a more accurate representation of the current node features.         _ Less","","arXiv","https://arxiv.org/abs/2205.10588","2","1","origin_of_life"
"Relating Information and Proof","Abstract:                In mathematics information is a number that measures uncertainty (entropy) based on a probabilistic distribution, often of an obscure origin. In real life language information is a datum, a statement, more precisely, a formula. But such a formula should be justified by a proof. I try to formalize this perception of inf_         _ More           In mathematics information is a number that measures uncertainty (entropy) based on a probabilistic distribution, often of an obscure origin. In real life language information is a datum, a statement, more precisely, a formula. But such a formula should be justified by a proof. I try to formalize this perception of information. The measure of informativeness of a proof is based on the set of proofs related to the formulas under consideration. This set of possible proofs (`a knowledge base') defines a probabilistic measure, and entropic weight is defined using this measure. The paper is mainly conceptual, it is not clear where and how this approach can be applied.         _ Less","","arXiv","https://arxiv.org/abs/2205.07635","1","0","origin_of_life"
"Biological Homochirality and the Search for Extraterrestrial Biosignatures","Abstract:                Most amino acids and sugars molecules occur in mirror, or chiral, images of each other, knowns as enantiomers. However, life on Earth is mostly homochiral: proteins contain almost exclusively L-amino acids, while only D-sugars appear in RNA and DNA. The mechanism behind this fundamental asymmetry of_         _ More           Most amino acids and sugars molecules occur in mirror, or chiral, images of each other, knowns as enantiomers. However, life on Earth is mostly homochiral: proteins contain almost exclusively L-amino acids, while only D-sugars appear in RNA and DNA. The mechanism behind this fundamental asymmetry of life remains unknown, despite much progress in the theoretical and experimental understanding of homochirality in the past decades. We review three potential mechanisms for the emergence of biological homochirality on primal Earth and explore their implications for astrobiology: the first, that biological homochirality is a stochastic process driven by local environmental fluctuations; the second, that it is driven by circularly-polarized ultraviolet radiation in star-forming regions; and the third, that it is driven by parity violation at the elementary particle level. We argue that each of these mechanisms leads to different observational consequences for the existence of enantiomeric excesses in our solar system and in exoplanets, pointing to the possibility that the search for life elsewhere will help elucidate the origins of homochirality on Earth.         _ Less","","arXiv","https://arxiv.org/abs/2205.01193","2","1","origin_of_life"
"Studying Retrievability of Publications and Datasets in an Integrated Retrieval System","Abstract:                In this paper, we investigate the retrievability of datasets and publications in a real-life Digital Library (DL). The measure of retrievability was originally developed to quantify the influence that a retrieval system has on the access to information. Retrievability can also enable DL engineers to evaluate their sear_         _ More           In this paper, we investigate the retrievability of datasets and publications in a real-life Digital Library (DL). The measure of retrievability was originally developed to quantify the influence that a retrieval system has on the access to information. Retrievability can also enable DL engineers to evaluate their search engine to determine the ease with which the content in the collection can be accessed. Following this methodology, in our study, we propose a system-oriented approach for studying dataset and publication retrieval. A speciality of this paper is the focus on measuring the accessibility biases of various types of DL items and including a metric of usefulness. Among other metrics, we use Lorenz curves and Gini coefficients to visualize the differences of the two retrievable document types (specifically datasets and publications). Empirical results reported in the paper show a distinguishable diversity in the retrievability scores among the documents of different types.         _ Less","","arXiv","https://arxiv.org/abs/2205.00937","1","0","origin_of_life"
"Local mathematics and scaling field: effects on local physics and on cosmology","Abstract:                The origin of this paper starts with the observation by Yang Mills that what state represents a proton in isospin space at one location does not determine what state represents a proton in isospin space at another location. This is accounted for by the presence of a unitary gauge transformation operator, $U(y,x)$, between vector spaces at different locations_         _ More           The origin of this paper starts with the observation by Yang Mills that what state represents a proton in isospin space at one location does not determine what state represents a proton in isospin space at another location. This is accounted for by the presence of a unitary gauge transformation operator, $U(y,x)$, between vector spaces at different locations. This operator defines the notion of same states for vector spaces at different locations. If $_$ is a state in a vector space at $x$ then $U(y,x)_$ is the same state in the vector space at $y$. Vector spaces include scalar fields in their axiomatic description. These appear as norms, closure under vector scalar multiplication, etc. This leads to a conflict: local vector spaces and global scalar fields. Here this conflict is removed by replacing global scalar fields with local scalar fields. These are represented by $\\bar{S}_{x}$ where $x$ is any location in Euclidean space or space time. Here $S$ represents the different type of numbers, (natural, integers, rational, real, and complex). The association of scalar fields with vector spaces and the Yang Mills observation raises the question, What corresponds to the Yang Mills observation for numbers? The answer is that two different concepts, number and number meaning or value, are conflated in the usual use of mathematics. These two concepts are distinct.         _ Less","","arXiv","https://arxiv.org/abs/2204.10369","1","0","origin_of_life"
"On Xing Tian and the Perseverance of Anti-China Sentiment Online","Abstract:                _of Sinophobia, between 2016 and 2021, on two mainstream and fringe Web communities. By analyzing 8B posts from Reddit and 206M posts from 4chan's /pol/, we investigate the origins, evolution, and content of Sinophobia. We find that, anti-Chinese content may be evoked by political events not directly related to China, e.g., the U.S. withdrawal from the Pa_         _ More           Sinophobia, anti-Chinese sentiment, has existed on the Web for a long time. The outbreak of COVID-19 and the extended quarantine has further amplified it. However, we lack a quantitative understanding of the cause of Sinophobia as well as how it evolves over time. In this paper, we conduct a large-scale longitudinal measurement of Sinophobia, between 2016 and 2021, on two mainstream and fringe Web communities. By analyzing 8B posts from Reddit and 206M posts from 4chan's /pol/, we investigate the origins, evolution, and content of Sinophobia. We find that, anti-Chinese content may be evoked by political events not directly related to China, e.g., the U.S. withdrawal from the Paris Agreement. And during the COVID-19 pandemic, daily usage of Sinophobic slurs has significantly increased even with the hate-speech ban policy. We also show that the semantic meaning of the words 'China' and 'Chinese' are shifting towards Sinophobic slurs with the rise of COVID-19 and remain the same in the pandemic period. We further use topic modeling to show the topics of Sinophobic discussion are pretty diverse and broad. We find that both Web communities share some common Sinophobic topics like ethnics, economics and commerce, weapons and military, foreign relations, etc. However, compared to 4chan's /pol/, more daily life-related topics including food, game, and stock are found in Reddit. Our finding also reveals that the topics related to COVID-19 and blaming the Chinese government are more prevalent in the pandemic period. To the best of our knowledge, this paper is the longest quantitative measurement of Sinophobia.         _ Less","","arXiv","https://arxiv.org/abs/2204.08935","0","1","synthetic_biology"
"Precursors of fatty alcohols in the ISM: Discovery of n-propanol","Abstract:                Theories on the origins of_         _ More           Theories on the origins of life propose that early cell membranes were synthesized from amphiphilic molecules simpler than phospholipids such as fatty alcohols. The discovery in the interstellar medium (ISM) of ethanolamine, the simplest phospholipid head group, raises the question whether simple amphiphilic molecules are also synthesized in space. We investigate whether precursors of fatty alcohols are present in the ISM. For this, we have carried out a spectral survey at 7, 3, 2 and 1 mm toward the Giant Molecular Cloud G+0.693-0.027 located in the Galactic Center using the IRAM 30m and Yebes 40m telescopes. Here, we report the detection in the ISM of the primary alcohol n-propanol (in both conformers Ga-n-C3H7OH and Aa-n-C3H7OH), a precursor of fatty alcohols. The derived column densities of n-propanol are (5.5+-0.4)x10^13 cm^-2 for the Ga conformer and (3.4+-0.3)x10^13 cm^-2 for the Aa conformer, which imply molecular abundances of (4.1+-0.3)x10^-10 for Ga-n-C3H7OH and of (2.5+-0.2)x10^-10 for Aa-n-C3H7OH. We also searched for the AGa conformer of n-butanol (AGa-n-C4H9OH) without success yielding an upper limit to its abundance of <4.1x10^-11. The inferred CH3OH:C2H5OH:C3H7OH:C4H9OH abundance ratios go as 1:0.04:0.006:<0.0004 toward G+0.693-0.027, i.e. they decrease roughly by one order of magnitude for increasing complexity. We also report the detection of both syn and anti conformers of vinyl alcohol, with column densities of (1.11+-0.08)x10^14 cm^-2 and (1.3+-0.4)x10^13 cm^-2, and abundances of (8.2+-0.6)x10^-10 and (9.6+-3.0)x10^-11, respectively. The detection of n-propanol, together with the recent discovery of ethanolamine in the ISM, opens the possibility that precursors of lipids according to theories of the origin of life, could have been brought to Earth from outer space.         _ Less","","arXiv","https://arxiv.org/abs/2204.08267","2","1","origin_of_life"
"Possible Ribose Synthesis in Carbonaceous Planetesimals","Abstract:                The origin of_         _ More           The origin of life might be sparked by the polymerization of the first RNA molecules in Darwinian ponds during wet-dry cycles. The key life-building block ribose was found in carbonaceous chondrites. Its exogenous delivery onto the Hadean Earth could be a crucial step toward the emergence of the RNA world. Here, we investigate the formation of ribose through a simplified version of the formose reaction inside carbonaceous chondrite parent bodies. Following up on our previous studies regarding nucleobases with the same coupled physico-chemical model, we calculate the abundance of ribose within planetesimals of different sizes and heating histories. We perform laboratory experiments using catalysts present in carbonaceous chondrites to infer the yield of ribose among all pentoses (5Cs) forming during the formose reaction. These laboratory yields are used to tune our theoretical model that can only predict the total abundance of 5Cs. We found that the calculated abundances of ribose were similar to the ones measured in carbonaceous chondrites. We discuss the possibilities of chemical decomposition and preservation of ribose and derived constraints on time and location in planetesimals. In conclusion, the aqueous formose reaction might produce most of the ribose in carbonaceous chondrites. Together with our previous studies on nucleobases, we found that life-building blocks of the RNA world could be synthesized inside parent bodies and later delivered onto the early Earth.         _ Less","","arXiv","https://arxiv.org/abs/2204.06523","4","0","origin_of_life"
"Open Wilson chain numerical renormalization group approach to Green's functions","Abstract:                _functions required by the standard numerical renormalization group algorithm. Our approach is based on the exact reproduction of the continuous coupling function in the original quantum impurity model. It augments each chain site of the Wilson chain by a coupling to an additional reservoir. This open Wilson chain is constructed by a continuous fraction expan_         _ More           By combining Wilson's numerical renormalization group with a modified Bloch-Redfield approach we are able to eliminate the artificial broadening of the Lehmann representation of quantum impurity spectral functions required by the standard numerical renormalization group algorithm. Our approach is based on the exact reproduction of the continuous coupling function in the original quantum impurity model. It augments each chain site of the Wilson chain by a coupling to an additional reservoir. This open Wilson chain is constructed by a continuous fraction expansion and the coupling function is treated in second order in the context of the Bloch-Redfield approach. The eigenvalues of the resulting Bloch-Redfield tensor generate a finite life time of the numerical renormalization group excitations that leads to a natural broadening of the spectral functions. We combine this approach with z-averaging and an analytical exact expression for the correlation part of the self-energy to obtain an accurate representation of the spectral function of the original continuum model in the absence and presence of an external magnetic field.         _ Less","","arXiv","https://arxiv.org/abs/2204.03453","0","1","synthetic_biology"
"Thermodynamics and the Origin of Life","Abstract:                Modern developments in nonequilibrium thermodynamics have significant implications for the origins of life. The reasons for this are closely related to a generalized version of the second law of thermodynamics recently found for entropy production during irreversible evolution of a given system such as self-replicating_         _ More           Modern developments in nonequilibrium thermodynamics have significant implications for the origins of life. The reasons for this are closely related to a generalized version of the second law of thermodynamics recently found for entropy production during irreversible evolution of a given system such as self-replicating RNA. This paper is intended to serve as an introduction to these developments.         _ Less","","arXiv","https://arxiv.org/abs/2204.00416","1","2","synthetic_biology"
"Mapping Topics in 100,000 Real-life Moral Dilemmas","Abstract:                _in theorizing both about ethical norms and moral psychology. Yet thought experiments borrowed from the philosophical literature often lack the nuances and complexity of real life. We leverage 100,000 threads -- the largest collection to date -- from Reddit's r/AmItheAsshole to examine the features of everyday moral dilemmas. Combining topic modeling with_         _ More           Moral dilemmas play an important role in theorizing both about ethical norms and moral psychology. Yet thought experiments borrowed from the philosophical literature often lack the nuances and complexity of real life. We leverage 100,000 threads -- the largest collection to date -- from Reddit's r/AmItheAsshole to examine the features of everyday moral dilemmas. Combining topic modeling with evaluation from both expert and crowd-sourced workers, we discover 47 finer-grained, meaningful topics and group them into five meta-categories. We show that most dilemmas combine at least two topics, such as family and money. We also observe that the pattern of topic co-occurrence carries interesting information about the structure of everyday moral concerns: for example, the generation of moral dilemmas from nominally neutral topics, and interaction effects in which final verdicts do not line up with the moral concerns in the original stories in any simple way. Our analysis demonstrates the utility of a fine-grained data-driven approach to online moral dilemmas, and provides a valuable resource for researchers aiming to explore the intersection of practical and theoretical ethics.         _ Less","","arXiv","https://arxiv.org/abs/2203.16762","1","0","origin_of_life"
"On the Origins of Life's Homochirality: Inducing Enantiomeric Excess with Spin-Polarized Electrons","Abstract:        Life as we know it is homochiral, but the_         _ More   Life as we know it is homochiral, but the origins of biological homochirality on early Earth remain elusive. Shallow closed-basin lakes are a plausible prebiotic environment on early Earth, and most are expected to have significant sedimentary magnetite deposits. We hypothesize that UV (200-300nm) irradiation of magnetite deposits could generate hydrated spin-polarized electrons sufficient to induce chirally selective prebiotic chemistry. Such electrons are potent reducing agents that drive reduction reactions where the spin polarization direction can alter enantioselectively the reaction kinetics. Our estimate of this chiral bias is based on the strong effective spin-orbit coupling observed in the chiral-induced spin selectivity (CISS) effect, as applied to energy differences in reduction reactions for different isomers. In the original CISS experiments, spin selective electron transmission through a monolayer of dsDNA molecules is observed at room temperature - indicating a strong coupling between molecular chirality and electron spin. We propose that the chiral symmetry breaking due to the CISS effect, when applied to reduction chemistry, can induce enantioselective synthesis on the prebiotic Earth and thus facilitate the homochiral assembly of life's building blocks.         _ Less","","arXiv","https://arxiv.org/abs/2203.16011","1","0","origin_of_life"
"Revisiting Digital Twins: Origins, Fundamentals and Practices","Abstract:                _environment that combines the most modern Information Communication Technology (ICTs) and engineering mechanisms digitization, and characterized by system/product/service life cycle management, physically geometric visualization, real-time sensing and measurement of system operating conditions, predictability of system performance/safety/lifespan, complete e_         _ More           The Digital Twins (DT) has quickly become a hot topic since it was proposed. It not only appears in all kinds of commercial propaganda, but also is widely quoted by academic circles. However, there are misstatements and misuse of the term DT in business and academy. This paper revisits Digital Twins and defines it to be a more advanced system/product/service modelling and simulation environment that combines the most modern Information Communication Technology (ICTs) and engineering mechanisms digitization, and characterized by system/product/service life cycle management, physically geometric visualization, real-time sensing and measurement of system operating conditions, predictability of system performance/safety/lifespan, complete engineering mechanisms-based simulations. The idea of Digital Twins originates from modelling and simulation practices of engineering informatization, including Virtual Manufacturing (VM), Model Predictive Control (MPC), and Building Information Model (BIM). Based on the two-element VM model, we propose a three-element model to represent Digital Twins. Digital Twins does not have its own unique technical characteristics; the existing practices of Digital Twins are extensions of the engineering informatization embracing modern ICTs. These insights clarify the origin of Digital Twins and its technical essentials.         _ Less","","arXiv","https://arxiv.org/abs/2203.12867","1","0","origin_of_life"
"Ly_ irradiation of solid-state formamide","Abstract:                _CHO), a potential prebiotic precursor, has been proposed to play an important role in the context of origin of life on our planet. It has been observed in different environments in space including the protostellar regions and comets. The abundance and stability of NH$_2$CHO in the early stages of star formation can be_         _ More           Formamide (NH$_2$CHO), a potential prebiotic precursor, has been proposed to play an important role in the context of origin of life on our planet. It has been observed in different environments in space including the protostellar regions and comets. The abundance and stability of NH$_2$CHO in the early stages of star formation can be better understood by incorporating the formation and destruction data in the astrochemical models. We carried out an experimental investigation to study the destruction of pure NH$_2$CHO ice at 12 K by the interaction of Ly$_$ (121.6 nm) photons. The UV photo destruction of NH$_2$CHO was studied using Fourier-transform infrared spectroscopy. After UV processing, the intensity of NH$_2$CHO IR bands decreases and new bands corresponding to HCN, CO, NH$_4^+$ OCN$^-$, HNCO, and CO$_2$ appeared in the spectrum. Destruction and cumulative product formation cross-sections were derived. The comparison of destruction rate derived from the cross-section in cold and dense molecular cloud for different energetic processing agents, reveals that UV photons induces an order of magnitude higher NH$_2$CHO destruction than cosmic rays, but three orders of magnitude lower than for H atoms.         _ Less","","arXiv","https://arxiv.org/abs/2203.12390","3","0","origin_of_life"
"ALT: um software para an_lise de legibilidade de textos em L_ngua Portuguesa","Abstract:                In the initial stage of human life, communication, seen as a process of social interaction, was always the best way to reach consensus between the parties. Understanding and credibility in this process are essential for the mutual agreement to be validated. But, how to do it so that this communication reaches the great mass? This is the main challenge when w_         _ More           In the initial stage of human life, communication, seen as a process of social interaction, was always the best way to reach consensus between the parties. Understanding and credibility in this process are essential for the mutual agreement to be validated. But, how to do it so that this communication reaches the great mass? This is the main challenge when what is sought is the dissemination of information and its approval. In this context, this study presents the ALT software, developed from original readability metrics adapted to the Portuguese language, available on the web, to reduce communication difficulties. The development of the software was motivated by the theory of communicative action of Habermas, which uses a multidisciplinary style to measure the credibility of the discourse in the communication channels used to build and maintain a safe and healthy relationship with the public.   --   No est_gio inicial da vida humana a comunica_o, vista como um processo de intera_o social, foi sempre o melhor caminho para o consenso entre as partes. O entendimento e a credibilidade nesse processo s_o fundamentais para que o acordo m_tuo seja validado. Mas, como faz_-lo de forma que essa comunica_o alcance a grande massa? Esse _ o principal desafio quando o que se busca _ a difus_o da informa_o e a sua aprova_o. Nesse contexto, este estudo apresenta o software ALT, desenvolvido a partir de m_tricas de legibilidade originais adaptadas para a L_ngua Portuguesa, dispon_vel na web, para reduzir as dificuldades na comunica_o. O desenvolvimento do software foi motivado pela teoria do agir comunicativo de Habermas, que faz uso de um estilo multidisciplinar para medir a credibilidade do discurso nos canais de comunica_o utilizados para construir e manter uma rela_o segura e saud_vel com o p_blico.         _ Less","","arXiv","https://arxiv.org/abs/2203.12135","1","1","multiple"
"Transfer Dynamics in Emergent Evolutionary Curricula","Abstract:                PINSKY is a system for open-ended learning through neuroevolution in game-based domains. It builds on the Paired Open-Ended Trailblazer (POET) system, which originally explored learning and environment generation for bipedal walkers, and adapts it to games in the General Video Game AI (GVGAI) system. Previous work showed that by co-evolving levels and neural_         _ More           PINSKY is a system for open-ended learning through neuroevolution in game-based domains. It builds on the Paired Open-Ended Trailblazer (POET) system, which originally explored learning and environment generation for bipedal walkers, and adapts it to games in the General Video Game AI (GVGAI) system. Previous work showed that by co-evolving levels and neural network policies, levels could be found for which successful policies could not be created via optimization alone. Studied in the realm of Artificial Life as a potentially open-ended alternative to gradient-based fitness, minimal criteria (MC)-based selection helps foster diversity in evolutionary populations. The main question addressed by this paper is how the open-ended learning actually works, focusing in particular on the role of transfer of policies from one evolutionary branch ('species') to another. We analyze the dynamics of the system through creating phylogenetic trees, analyzing evolutionary trajectories of policies, and temporally breaking down transfers according to species type. Furthermore, we analyze the impact of the minimal criterion on generated level diversity and inter-species transfer. The most insightful finding is that inter-species transfer, while rare, is crucial to the system's success.         _ Less","","arXiv","https://arxiv.org/abs/2203.10941","0","1","synthetic_biology"
"Chemical Habitability: Supply and Retention of Life's Essential Elements During Planet Formation","Abstract:                Carbon, Hydrogen, Nitrogen, Oxygen, Phosphorus and Sulfur (CHNOPS) play key roles in the origin and proliferation of_         _ More           Carbon, Hydrogen, Nitrogen, Oxygen, Phosphorus and Sulfur (CHNOPS) play key roles in the origin and proliferation of life on Earth. Given the universality of physics and chemistry, not least the ubiquity of water as a solvent and carbon as a backbone of complex molecules, CHNOPS are likely crucial to most habitable worlds. To help guide and inform the search for potentially habitable and ultimately inhabited environments, we begin by summarizing the CHNOPS budget of various reservoirs on Earth, their role in shaping our biosphere, and their origins in the Solar Nebula. We then synthesize our current understanding of how these elements behave and are distributed in diverse astrophysical settings, tracing their journeys from synthesis in dying stars to molecular clouds, protoplanetary settings, and ultimately temperate rocky planets around main sequence stars. We end by identifying key branching points during this journey, highlighting instances where a forming planets' distribution of CHNOPS can be altered dramatically, and speculating about the consequences for the chemical habitability of these worlds.         _ Less","","arXiv","https://arxiv.org/abs/2203.10056","1","0","origin_of_life"
"Geophysical Evolution During Rocky Planet Formation","Abstract:                Progressive astronomical characterization of planet-forming disks and rocky exoplanets highlight the need for increasing interdisciplinary efforts to understand the birth and life cycle of terrestrial worlds in a unified picture. Here, we review major geophysical and geochemical processes that shape the evolution of rocky planets and their precursor planetes_         _ More           Progressive astronomical characterization of planet-forming disks and rocky exoplanets highlight the need for increasing interdisciplinary efforts to understand the birth and life cycle of terrestrial worlds in a unified picture. Here, we review major geophysical and geochemical processes that shape the evolution of rocky planets and their precursor planetesimals during planetary formation and early evolution, and how these map onto the astrophysical timeline and varying accretion environments of planetary growth. The evolution of the coupled core-mantle-atmosphere system of growing protoplanets diverges in thermal, compositional, and structural states to first order, and ultimately shapes key planetary characteristics that can discern planets harboring clement surface conditions from those that do not. Astronomical campaigns seeking to investigate rocky exoplanets will require significant advances in laboratory characterization of planetary materials and time- and spatially-resolved theoretical models of planetary evolution, to extend planetary science beyond the Solar System and constrain the origins and frequency of habitable worlds like our own.         _ Less","","arXiv","https://arxiv.org/abs/2203.10023","2","3","synthetic_biology"
"A major asymmetric ice trap in a planet-forming disk: III. First detection of dimethyl ether","Abstract:                The complex organic molecules (COMs) detected in star-forming regions are the precursors of the prebiotic molecules that can lead to the emergence of life. By studying COMs in more evolved protoplanetary disks we can gain a better understanding of how they are incorporated into planets. This paper presents ALMA band 7 observations of the dust and ice trap in_         _ More           The complex organic molecules (COMs) detected in star-forming regions are the precursors of the prebiotic molecules that can lead to the emergence of life. By studying COMs in more evolved protoplanetary disks we can gain a better understanding of how they are incorporated into planets. This paper presents ALMA band 7 observations of the dust and ice trap in the protoplanetary disk around Oph IRS 48. We report the first detection of dimethyl ether (CH3OCH3) in a planet-forming disk and a tentative detection of methyl formate (CH3OCHO). We determined column densities for the detected molecules and upper limits on non-detected species using the CASSIS spectral analysis tool. The inferred column densities of CH3OCH3 and CH3OCHO with respect to methanol (CH3OH) are of order unity, indicating unusually high abundances of these species compared to other environments. Alternatively, the 12CH3OH emission is optically thick and beam diluted, implying a higher CH3OH column density and a smaller emitting area than originally thought. The presence of these complex molecules can be explained by thermal ice sublimation, where the dust cavity edge is heated by irradiation and the full volatile ice content is observable in the gas phase. This work confirms the presence of oxygen-bearing molecules more complex than CH3OH in protoplanetary disks for the first time. It also shows that it is indeed possible to trace the full interstellar journey of COMs across the different evolutionary stages of star, disk, and planet formation.         _ Less","","arXiv","https://arxiv.org/abs/2203.02936","3","1","origin_of_life"
"The SKA as a prebiotic molecule detector","Abstract:                One of the theories for the origin of life proposes that a significant fraction of prebiotic material could have arrived to Earth from outer space between 4.1 and 3.8 billion years ago. This suggests that those prebiotic compounds could have originated in interstellar space, to b_         _ More           One of the theories for the origin of life proposes that a significant fraction of prebiotic material could have arrived to Earth from outer space between 4.1 and 3.8 billion years ago. This suggests that those prebiotic compounds could have originated in interstellar space, to be later on incorporated to small Solar-system bodies and planetesimals. The recent discovery of prebiotic molecules such as hydroxylamine and ethanolamine in the interstellar medium, strongly supports this hypothesis. However, some species such as sugars, key for the synthesis of ribonucleotides and for metabolic processes, remain to be discovered in space. The unmatched sensitivity of the Square Kilometer Array (SKA) at centimeter wavelengths will be able to detect even more complex and heavier prebiotic molecules than existing instrumentation. In this contribution, we illustrate the potential of the SKA to detect simple sugars with three and four carbon atoms, using a moderate investment of observing time.         _ Less","","arXiv","https://arxiv.org/abs/2203.00534","2","0","origin_of_life"
"Time-resolved chiral X-Ray photoelectron spectroscopy with transiently enhanced atomic site-selectivity: a Free Electron Laser investigation of electronically excited fenchone enantiomers","Abstract:                Chiral molecules are widespread in nature, playing a fundamental role in bio-chemical processes and in the origin of life itself. The observation of dynamics in chiral molecules is crucial for the understanding and control of the chiral activity of photo-excited states. One of the most promising techniques for the stud_         _ More           Chiral molecules are widespread in nature, playing a fundamental role in bio-chemical processes and in the origin of life itself. The observation of dynamics in chiral molecules is crucial for the understanding and control of the chiral activity of photo-excited states. One of the most promising techniques for the study of photo-excited chiral systems is time-resolved photoelectron circular dichroism (TR-PECD), which offers an intense and sensitive probe for vibronic and geometric molecular structure as well as electronic structures, and their evolution on a femtosecond timescale. However, the non-local character of the PECD effect, which is imprinted during the electron scattering off the molecule, makes the interpretation of TR-PECD experiments challenging. In this respect, core-photoionization is known to allow site- and chemical-sensitivity to photelectron spectroscopy. Here we demonstrate that TR-PECD utilising core-level photoemission enables probing the chiral electronic structure and its relaxation dynamics with atomic site sensitivity. Following UV pumped excitation to a 3s Rydberg state, fenchone enantiomers (C 10 H 16 O) were probed on a femtosecond scale using circularly polarized soft X-ray light pulses provided by the free-electron laser FERMI. C 1s binding energy shifts caused by the redistribution of valence electron density in this 3s-valence-Rydberg excitation allowed us to measure transient PECD chiral responses with an enhanced C-atom site-selectivity compared to that achievable in the ground state molecule. These results represent the first chemical-specific and site-specific, enantio-sensitive observations on the electronic structure of a photo-excited chiral molecule and pave the way towards chiral femtochemistry probed by core-level photoemission.         _ Less","","arXiv","https://arxiv.org/abs/2202.13704","1","1","multiple"
"Collaborative Training of Heterogeneous Reinforcement Learning Agents in Environments with Sparse Rewards: What and When to Share?","Abstract:                In the early stages of human life, babies develop their skills by exploring different scenarios motivated by their inherent satisfaction rather than by extrinsic rewards from the environment. This behavior, referred to as intrinsic motivation, has emerged as one solution to address the exploration challenge derived from reinforcement learning environments wi_         _ More           In the early stages of human life, babies develop their skills by exploring different scenarios motivated by their inherent satisfaction rather than by extrinsic rewards from the environment. This behavior, referred to as intrinsic motivation, has emerged as one solution to address the exploration challenge derived from reinforcement learning environments with sparse rewards. Diverse exploration approaches have been proposed to accelerate the learning process over single- and multi-agent problems with homogeneous agents. However, scarce studies have elaborated on collaborative learning frameworks between heterogeneous agents deployed into the same environment, but interacting with different instances of the latter without any prior knowledge. Beyond the heterogeneity, each agent's characteristics grant access only to a subset of the full state space, which may hide different exploration strategies and optimal solutions. In this work we combine ideas from intrinsic motivation and transfer learning. Specifically, we focus on sharing parameters in actor-critic model architectures and on combining information obtained through intrinsic motivation with the aim of having a more efficient exploration and faster learning. We test our strategies through experiments performed over a modified ViZDooM's My Way Home scenario, which is more challenging than its original version and allows evaluating the heterogeneity between agents. Our results reveal different ways in which a collaborative framework with little additional computational cost can outperform an independent learning process without knowledge sharing. Additionally, we depict the need for modulating correctly the importance between the extrinsic and intrinsic rewards to avoid undesired agent behaviors.         _ Less","","arXiv","https://arxiv.org/abs/2202.12174","1","0","origin_of_life"
"A pathway to peptides in space through the condensation of atomic carbon","Abstract:                _without irradiation or the presence of water. The delivery of biopolymers formed by this chemistry to rocky planets in the habitable zone might be an important element in the origins of life.         _ More           Organic molecules are widely present in the dense interstellar medium, and many have been synthesized in the laboratory on Earth under the conditions typical for an interstellar environment. Until now, however, only relatively small molecules of biological interest have been demonstrated to form experimentally under typical space conditions. Here we prove experimentally that the condensation of carbon atoms on the surface of cold solid particles (cosmic dust) leads to the formation of isomeric polyglycine monomers (aminoketene molecules). Following encounters between aminoketene molecules, they polymerize to produce peptides of different lengths. The chemistry involves three of the most abundant species (CO, C and NH$_3$) present in star-forming molecular clouds, and proceeds via a novel pathway that skips the stage of amino acid formation in protein synthesis. The process is efficient, even at low temperatures, without irradiation or the presence of water. The delivery of biopolymers formed by this chemistry to rocky planets in the habitable zone might be an important element in the origins of life.         _ Less","","arXiv","https://arxiv.org/abs/2202.12170","1","1","multiple"
"Data-Driven Decision Making in COVID-19 Response: A Survey","Abstract:                COVID-19 has spread all over the world, having an enormous effect on our daily life and work. In response to the epidemic, a lot of important decisions need to be taken to save communities and economies worldwide. Data clearly plays a vital role in effective decision making. Data-driven decision making uses data related evidence and insights to guide the dec_         _ More           COVID-19 has spread all over the world, having an enormous effect on our daily life and work. In response to the epidemic, a lot of important decisions need to be taken to save communities and economies worldwide. Data clearly plays a vital role in effective decision making. Data-driven decision making uses data related evidence and insights to guide the decision making process and to verify the plan of action before it is committed. To better handle the epidemic, governments and policy making institutes have investigated abundant data originating from COVID-19. These data include those related to medicine, knowledge, media, etc. Based on these data, many prevention and control policies are made. In this survey paper, we summarize the progress of data-driven decision making in the response to COVID-19, including COVID-19 prevention and control, psychological counselling, financial aid, work resumption, and school re-opening. We also propose some current challenges and open issues in data-driven decision making, including data collection and quality, complex data analysis, and fairness in decision making. This survey paper sheds light on current policy making driven by data, which also provides a feasible direction for further scientific research.         _ Less","","arXiv","https://arxiv.org/abs/2202.11435","1","1","multiple"
"Certified Verification of Relational Properties","Abstract:                _non-interference, continuity, or monotonicity. They can also relate calls to different functions, for instance, to show that an optimized implementation is equivalent to its original counterpart. However, relational properties cannot be expressed and verified directly in the traditional setting of modular deductive verification. Self-composition has been pro_         _ More           The use of function contracts to specify the behavior of functions often remains limited to the scope of a single function call. Relational properties link several function calls together within a single specification. They can express more advanced properties of a given function, such as non-interference, continuity, or monotonicity. They can also relate calls to different functions, for instance, to show that an optimized implementation is equivalent to its original counterpart. However, relational properties cannot be expressed and verified directly in the traditional setting of modular deductive verification. Self-composition has been proposed to overcome this limitation, but it requires complex transformations and additional separation hypotheses for real-life languages with pointers. We propose a novel approach that is not based on code transformation and avoids those drawbacks. It directly applies a verification condition generator to produce logical formulas that must be verified to ensure a given relational property. The approach has been fully formalized and proved sound in the Coq proof assistant.         _ Less","","arXiv","https://arxiv.org/abs/2202.10349","1","0","origin_of_life"
"On the ideas of the origin of eukaryotes: a critical review","Abstract:                The origin and early evolution of eukaryotes are one of the major transitions in the evolution of_         _ More           The origin and early evolution of eukaryotes are one of the major transitions in the evolution of life on earth. One of its most interesting aspects is the emergence of cellular organelles, their dynamics, their functions, and their divergence. Cell compartmentalization and architecture in prokaryotes is a less understood complex property. In eukaryotes it is related to cell size, specific genomic architecture, evolution of cell cycles, biogenesis of membranes and endosymbiotic processes. Explaining cell evolution through form and function demands an interdisciplinary approach focused on microbial diversity, phylogenetic and functional cell biology. Two centuries of views on eukaryotic origin have completed the disciplinary tools necessarily to answer these questions. We have moved from Haeckel SCALA NATURAE to the un-rooted tree of life. However, the major relations among cell domains are still elusive and keep the nature of eukaryotic ancestor enigmatic. Here we present a review on state of art views of eukaryogenesis; the background and perspectives of different disciplines involved in this topic         _ Less","","arXiv","https://arxiv.org/abs/2202.08825","2","4","synthetic_biology"
"A Mutation Threshold for Cooperative Takeover","Abstract:                One of the leading theories for the origin of life includes the hypothesis according to which life would have evolved as cooperative networks of molecules. Explaining cooperation$-$and particularly, its emergence in favoring the evolution of_         _ More           One of the leading theories for the origin of life includes the hypothesis according to which life would have evolved as cooperative networks of molecules. Explaining cooperation$-$and particularly, its emergence in favoring the evolution of life-bearing molecules$-$is thus a key element in describing the transition from nonlife to life. Using agent-based modeling of the iterated prisoner's dilemma, we investigate the emergence of cooperative behavior in a stochastic and spatially extended setting and characterize the effects of inheritance and variability. We demonstrate that there is a mutation threshold above which cooperation is$-$counterintuitively$-$selected, which drives a dramatic and robust cooperative takeover of the whole system sustained consistently up to the error catastrophe, in a manner reminiscent of typical phase transition phenomena in statistical physics. Moreover, our results also imply that one of the simplest conditional cooperative strategies, 'Tit-for-Tat', plays a key role in the emergence of cooperative behavior required for the origin of life.         _ Less","","arXiv","https://arxiv.org/abs/2202.06732","2","1","origin_of_life"
"Did bio-homochirality arise from spin-polarized electron?","Abstract:                The origin of bio-homochirality is a subject of much debate. The emergence of chirality and_         _ More           The origin of bio-homochirality is a subject of much debate. The emergence of chirality and life on earth is a break of symmetry to be compared with the breaks of symmetry in the evolution of the universe. Based on a perspective of asymmetry transfer, the chirality at molecular level might stem from electron spin at subatomic level. Accordingly, in this paper a spin-induced chiral selectivity (SICS) mechanism and its outreach are introduced and discussed. The stress force or spin torque derived from quantum electrodynamics (QED) might be the driving force for the transfer of asymmetry and the formation of molecular chirality. Some recent experimental results seem to support the SICS conjecture. If spin-polarized electrons (SPEs) did cause life to become chirally selective, a magnetic half-metal material such as greigite (Fe3S4), a mineral present in a primordial site where life could have emerged, might act as a spin filter to produce SPEs, which then induced the asymmetric synthesis of chiral molecules via the SICS mechanism. All these tentative thoughts may help explain how homochirality and life could have arisen on the early Earth.         _ Less","","arXiv","https://arxiv.org/abs/2202.04808","2","1","origin_of_life"
"Flow and aerosol dispersion from wind musical instruments","Abstract:                _through aerosol dispersion. This study, made possible by the participation of members of the Philadelphia Orchestra, brings insight on the modes of production and early life of aerosols of human origin emitted by wind instruments. We find that these instruments produce aerosol levels that are comparable to normal speec_         _ More           In the midst of the COVID-19 pandemic, many live musical activities had to be postponed and even canceled to protect musicians and audience. Orchestral ensembles face a particular challenge of contamination because they are personnel heavy and instrumentally diverse. A chief concern is whether wind instruments are vectors of contamination through aerosol dispersion. This study, made possible by the participation of members of the Philadelphia Orchestra, brings insight on the modes of production and early life of aerosols of human origin emitted by wind instruments. We find that these instruments produce aerosol levels that are comparable to normal speech in quantity and size distribution. However, the exit jet flow speeds are much lower than violent expiratory events (coughing, sneezing). For most wind instruments, the flow decays to background indoor-air levels at approximately 2 meters away from the instrument's opening. Long range aerosol dispersion is thus via ambient air currents.         _ Less","","arXiv","https://arxiv.org/abs/2201.10386","1","0","origin_of_life"
"The DRAKE mission: finding the frequency of life in the Cosmos","Abstract:                In the search for life in the Universe, exoplanets represent numerous natural experiments in planet formation, evolution, and the emergence of_         _ More           In the search for life in the Universe, exoplanets represent numerous natural experiments in planet formation, evolution, and the emergence of life. This raises the fascinating prospect of evaluating cosmic life on a statistical basis. One key statistic is the occurrence rate of life-bearing worlds, $f_{\\rm L}$, the 'frequency of life' term in the famous Drake Equation. Measuring $f_{\\rm L}$ would give profound insight into how common life is and may help to constrain origin-of-life theories. I propose $f_{\\rm L}$ as the goal for the DRAKE mission (Dedicated Research for Advancing Knowledge of Exobiology): a transit spectroscopy survey of M-dwarf habitable zone terrestrial planets. I investigate how the uncertainty on the observed value of $f_{\\rm L}$ scales with sample size. I determine that sampling error dominates over observational error and that the uncertainty is a function of the observed $f_{\\rm L}$ value. I show that even small sample sizes can provide significant constraints on $f_{\\rm L}$, boding well for the transit spectroscopy approach. I perform a feasibility study of the DRAKE mission using a nominal instrument design and mission plan. Due to low observing efficiencies, DRAKE may need to be incorporated into a wider-ranging deep-space or lunar observatory. A 50-planet survey could constrain $f_{\\rm L}$ to $\\leq$ 0.06 (at 95% confidence) if the sample $f_{\\rm L}$ = 0, or 0.03-0.2 if the sample $f_{\\rm L}$ = 0.1. This can be achieved (on average) in 10 years using a 17-m telescope with an unrestricted field-of-regard. DRAKE is a viable approach to attempting the first experimental measurement of $f_{\\rm L}$.         _ Less","","arXiv","https://arxiv.org/abs/2201.10226","3","2","origin_of_life"
"Large Impacts onto the Early Earth: Planetary Sterilization and Iron Delivery","Abstract:                Late accretion onto the Hadean Earth included large impacts that could have influenced early habitability, either by sterilizing the planet or alternatively catalyzing the origin of_         _ More           Late accretion onto the Hadean Earth included large impacts that could have influenced early habitability, either by sterilizing the planet or alternatively catalyzing the origin of life by delivering iron required to create a reducing environment/atmosphere. We present 3D numerical simulations of 1500-3400 km diameter impacts on the early Earth in order to quantify their effects on planetary habitability. We find sterilizing impact events require larger projectiles than previously assumed, with a 2000-2700 km diameter impactor required to completely melt Earth's surface and an extrapolated >700 km diameter impactor required for ocean-vaporization. We also find that reducing environments are less likely to arise following large impacts than previously suggested, because >70% of the projectile iron is deposited in the crust and upper mantle where it is not immediately available to reduce surface water and contribute to forming a reducing atmosphere. Although the largest expected late accretion impacts (~1 lunar mass) delivered sufficient iron to the atmosphere to have reduced an entire ocean mass of water, such impacts would also have melted the entire surface, potentially sequestering condensing iron that is not oxidized quickly. The hypothesis that life emerged in the aftermath of large impacts requires an efficient mechanism of harnessing the reducing power of iron sequestered in the crust/mantle, or an origin of life pathway that operates in more weakly-reducing post-impact environments that require smaller quantities of impact-delivered iron.         _ Less","","arXiv","https://arxiv.org/abs/2201.09349","1","0","origin_of_life"
"Resolving conceptual issues in Modern Coexistence Theory","Abstract:                _new models; but also addresses misconceptions about coexistence mechanisms. For example, the storage effect has little to do with bet-hedging or 'storage' via a robust life-history stage; relative nonlinearity is more likely to promote coexistence than originally thought; and fitness-density covariance is an am_         _ More           In this paper, we discuss the conceptual underpinnings of Modern Coexistence Theory (MCT), a quantitative framework for understanding ecological coexistence. In order to use MCT to infer how species are coexisting, one must relate a complex model (which simulates coexistence in the real world) to simple models in which previously proposed explanations for coexistence have been codified. This can be accomplished in three steps: 1) relating the construct of coexistence to invasion growth rates, 2) mathematically partitioning the invasion growth rates into coexistence mechanisms (i.e., classes of explanations for coexistence), and 3) relating coexistence mechanisms to simple explanations for coexistence. Previous research has primarily focused on step 2. Here, we discuss the other crucial steps and their implications for inferring the mechanisms of coexistence in real communities.   Our discussion of step 3 -- relating coexistence mechanisms to simple explanations for coexistence -- serves a heuristic guide for hypothesizing about the causes of coexistence in new models; but also addresses misconceptions about coexistence mechanisms. For example, the storage effect has little to do with bet-hedging or 'storage' via a robust life-history stage; relative nonlinearity is more likely to promote coexistence than originally thought; and fitness-density covariance is an amalgam of a large number of previously proposed explanations for coexistence (e.g., the competition-colonization trade-off, heteromyopia, spatially-varying resource supply ratios). Additionally, we review a number of topics in MCT, including the role of 'scaling factors'; whether coexistence mechanisms are approximations; whether the magnitude or sign of invasion growth rates matters more; whether Hutchinson solved the paradox of the plankton; the scale-dependence of coexistence mechanisms; and much more.         _ Less","","arXiv","https://arxiv.org/abs/2201.07926","1","2","synthetic_biology"
"A Material-based Panspermia Hypothesis: The Potential of Polymer Gels and Membraneless Droplets","Abstract:                The Panspermia hypothesis posits that either life's building blocks (molecular Panspermia) or life itself (organism-based Panspermia) may have been interplanetary transferred to facilitate the Origins of Life (OoL) on a given planet, co_         _ More           The Panspermia hypothesis posits that either life's building blocks (molecular Panspermia) or life itself (organism-based Panspermia) may have been interplanetary transferred to facilitate the Origins of Life (OoL) on a given planet, complementing several current OoL frameworks. Although many spaceflight experiments were performed in the past to test for potential terrestrial organisms as Panspermia seeds, it is uncertain whether such organisms will likely 'seed' a new planet even if they are able to survive spaceflight. Therefore, rather than using organisms, using abiotic chemicals as seeds has been proposed as part of the molecular Panspermia hypothesis. Here, as an extension of this hypothesis, we introduce and review the plausibility of a polymeric material-based Panspermia seed (M-BPS) theoretical concept, where the type of polymeric material that can function as a M-BPS must be able to: 1) survive spaceflight, and 2) 'function', i.e., contingently drive chemical evolution towards some form of abiogenesis once arriving on a foreign planet.   We use polymeric gels as a model example of a potential M-BPS. Polymeric gels that can be prebiotically synthesized on one planet (such as polyester gels) could be transferred to another planet via meteoritic transfer, where upon landing on a liquid bearing planet, can assemble into structures containing cellular-like characteristics and functionalities. Such features presupposed that these gels can assemble into compartments through phase separation to accomplish relevant functions such as encapsulation of primitive metabolic, genetic and catalytic materials, exchange of these materials, motion, coalescence, and evolution. All of these functions can result in the gels' capability to alter local geochemical niches on other planets, thereby allowing chemical evolution to lead to OoL events.         _ Less","","arXiv","https://arxiv.org/abs/2201.06732","4","2","origin_of_life"
"Self-organized lasers of reconfigurable colloidal assemblies","Abstract:                Biological cells self-organize into living materials that uniquely blend structure with functionality and responsiveness to the environment. The integration of similar life-like features in man-made materials remains challenging, yet desirable to manufacture active, adaptive and autonomous systems. Here we show the self-organization of programmable random la_         _ More           Biological cells self-organize into living materials that uniquely blend structure with functionality and responsiveness to the environment. The integration of similar life-like features in man-made materials remains challenging, yet desirable to manufacture active, adaptive and autonomous systems. Here we show the self-organization of programmable random lasers from the reversible out-of-equilibrium self-assembly of colloids. Random lasing originates from the optical amplification of light undergoing multiple scattering within the dissipative colloidal assemblies and therefore is crucially dependent on their self-organization behavior. Under external light stimuli, these dynamic random lasers are responsive and present a continuously tunable laser threshold. They can thus reconfigure and cooperate by emulating the ever-evolving spatiotemporal relationship between structure and functionality typical of living matter.         _ Less","","arXiv","https://arxiv.org/abs/2201.05427","0","2","synthetic_biology"
"Novel Symmetry-preserving Neural Network Model for Phylogenetic Inference","Abstract:                Scientists world-wide are putting together massive efforts to understand how the biodiversity that we see on Earth evolved from single-cell organisms at the origin of life and this diversification process is represented through the Tree of Life. Low sampling rates and high hetero_         _ More           Scientists world-wide are putting together massive efforts to understand how the biodiversity that we see on Earth evolved from single-cell organisms at the origin of life and this diversification process is represented through the Tree of Life. Low sampling rates and high heterogeneity in the rate of evolution across sites and lineages produce a phenomenon denoted 'long branch attraction' (LBA) in which long non-sister lineages are estimated to be sisters regardless of their true evolutionary relationship. LBA has been a pervasive problem in phylogenetic inference affecting different types of methodologies from distance-based to likelihood-based. Here, we present a novel neural network model that outperforms standard phylogenetic methods and other neural network implementations under LBA settings. Furthermore, unlike existing neural network models, our model naturally accounts for the tree isomorphisms via permutation invariant functions which ultimately result in lower memory and allows the seamless extension to larger trees.         _ Less","","arXiv","https://arxiv.org/abs/2201.04663","1","1","multiple"
"A train of shocks at 3000 au scale? Exploring the clash of an expanding bubble into the NGC 1333 IRAS 4 region. SOLIS XIV","Abstract:                _0 IRAS4 protostars lie. We use new IRAM-NOEMA observations of SiO and CH3OH, both known to trace violent events as shocks, toward IRAS 4A as part of the Large Program Seeds Of Life in Space (SOLIS). We detected three parallel elongated ($>$6000 au) structures, called fingers, with narrow line profiles (~1.5 $km s^{-1}$) peaked at the cloud systemic veloci_         _ More           There is evidence that the star formation process is linked to the intricate net of filaments in molecular clouds, which may be also due to gas compression from external triggers. We studied the southern region of the Perseus NGC 1333 molecular cloud, known to be heavily shaped by similar external triggers, to shed light on the process that perturbed the filament where the Class 0 IRAS4 protostars lie. We use new IRAM-NOEMA observations of SiO and CH3OH, both known to trace violent events as shocks, toward IRAS 4A as part of the Large Program Seeds Of Life in Space (SOLIS). We detected three parallel elongated ($>$6000 au) structures, called fingers, with narrow line profiles (~1.5 $km s^{-1}$) peaked at the cloud systemic velocity, tracing gas with high density (5-20 $10^5 cm^{-3}$) and high temperature (80-160 K). They are chemically different, with the northern finger traced by both SiO and CH3OH ([CH3OH]/[SiO]~160-300), while the other two only by SiO ([CH3OH]/[SiO]$<$ 40). Among various possibilities, a train of three shocks, distanced by $>$5000 yr, would be consistent with the observations if a substantial fraction of silicon, frozen onto the grain mantles, is released by the shocks.We suggest that the shock train is due to an expanding gas bubble, coming behind NGC 1333 from the southwest and clashing against the filament, where IRAS 4A lies. Finally, we propose a solution to the two-decades long debate on the nature and origin of the widespread narrow SiO emission observed in the south part of NGC 1333, namely that it is due to unresolved trains of shocks.         _ Less","","arXiv","https://arxiv.org/abs/2201.03434","1","0","origin_of_life"
"Differentially Private Release of Event Logs for Process Mining","Abstract:                _of anonymizing an event log in order to guarantee that, upon release of the anonymized log, the probability that an attacker may single out any individual represented in the original log does not increase by more than a threshold. The article proposes a differentially private release mechanism, which samples the cases in the log and adds noise to the timesta_         _ More           The applicability of process mining techniques hinges on the availability of event logs capturing the execution of a business process. In some use cases, particularly those involving customer-facing processes, these event logs may contain private information. Data protection regulations restrict the use of such event logs for analysis purposes. One way of circumventing these restrictions is to anonymize the event log to the extent that no individual can be singled out using the anonymized log. This article addresses the problem of anonymizing an event log in order to guarantee that, upon release of the anonymized log, the probability that an attacker may single out any individual represented in the original log does not increase by more than a threshold. The article proposes a differentially private release mechanism, which samples the cases in the log and adds noise to the timestamps to the extent required to achieve the above privacy guarantee. The article reports on an empirical comparison of the proposed approach against the state-of-the-art approaches using 14 real-life event logs in terms of data utility loss and computational efficiency.         _ Less","","arXiv","https://arxiv.org/abs/2201.03010","1","0","origin_of_life"
"ALMA Survey of Orion Planck Galactic Cold Clumps (ALMASOP): A Hot Corino Survey toward Protostellar Cores in the Orion Cloud","Abstract:                The presence of complex organic molecules (COMs) in the interstellar medium (ISM) is of great interest since it may link to the origin and prevalence of life in the universe. Aiming to investigate the occurrence of COMs and their possible origins, we conducted a chemical census t_         _ More           The presence of complex organic molecules (COMs) in the interstellar medium (ISM) is of great interest since it may link to the origin and prevalence of life in the universe. Aiming to investigate the occurrence of COMs and their possible origins, we conducted a chemical census toward a sample of protostellar cores as part of the ALMA Survey of Orion Planck Galactic Cold Clumps (ALMASOP) project. We report the detection of 11 hot corino sources, which exhibit compact emissions from warm and abundant COMs, among 56 Class 0/I protostellar cores. All the hot corino sources discovered are likely Class 0 and their sizes of the warm region ($>$ 100 K) are comparable to 100 au. The luminosity of the hot corino sources exhibits positive correlations with the total number of methanol and the extent of its emissions. Such correlations are consistent with the thermal desorption picture for the presence of hot corino and suggest that the lower luminosity (Class 0) sources likely have a smaller region with COMs emissions. With the same sample selection method and detection criteria being applied, the detection rates of the warm methanol in the Orion cloud (15/37) and the Perseus cloud (28/50) are statistically similar when the cloud distances and the limited sample size are considered. Observing the same set of COM transitions will bring a more informative comparison between the cloud properties.         _ Less","","arXiv","https://arxiv.org/abs/2201.02497","1","1","multiple"
"Quantum thermodynamic devices: from theoretical proposals to experimental reality","Abstract:                Thermodynamics originated in the need to understand novel technologies developed by the Industrial Revolution. However, over the centuries the description of engines, refrigerators, thermal accelerators, and heaters has become so abstract that a direct application of the universal statements to real-life devices is eve_         _ More           Thermodynamics originated in the need to understand novel technologies developed by the Industrial Revolution. However, over the centuries the description of engines, refrigerators, thermal accelerators, and heaters has become so abstract that a direct application of the universal statements to real-life devices is everything but straight forward. The recent, rapid development of quantum thermodynamics has taken a similar trajectory, and, e.g., 'quantum engines' have become a widely studied concept in theoretical research. However, if the newly unveiled laws of nature are to be useful, we need to write the dictionary that allows us to translate abstract statements of theoretical quantum thermodynamics to physical platforms and working mediums of experimentally realistic scenarios. To assist in this endeavor, this review is dedicated to providing an overview over the proposed and realized quantum thermodynamic devices, and to highlight the commonalities and differences of the various physical situations.         _ Less","","arXiv","https://arxiv.org/abs/2201.01740","2","3","synthetic_biology"
"Towards RNA life on Early Earth: From atmospheric HCN to biomolecule production in warm little ponds","Abstract:                The origin of life on Earth involves the early appearance of an information-containing molecule such as RNA. The basic building blocks of RNA could have been delivered by carbon-rich meteorites, or produced in situ by processes beginning with the synthesis of hydrogen cyanide (HCN) in the early Earth's atmosphere._         _ More           The origin of life on Earth involves the early appearance of an information-containing molecule such as RNA. The basic building blocks of RNA could have been delivered by carbon-rich meteorites, or produced in situ by processes beginning with the synthesis of hydrogen cyanide (HCN) in the early Earth's atmosphere. Here, we construct a robust physical and non-equilibrium chemical model of the early Earth atmosphere. The atmosphere is supplied with hydrogen from impact degassing of meteorites, sourced with water evaporated from the oceans, carbon dioxide from volcanoes, and methane from undersea hydrothermal vents, and in which lightning and external UV-driven chemistry produce HCN. This allows us to calculate the rain-out of HCN into warm little ponds (WLPs). We then use a comprehensive sources and sinks numerical model to compute the resulting abundances of nucleobases, ribose, and nucleotide precursors such as 2-aminooxazole resulting from aqueous and UV-driven chemistry within them. We find that at 4.4 bya (billion years ago) the limits of adenine concentrations in ponds for habitable surfaces is 0.05$_$M in the absence of seepage. These concentrations can be maintained for over 100 Myr. Meteorite delivery of adenine to WLPs can provide boosts in concentration by 2-3 orders of magnitude, but these boosts deplete within months by UV photodissociation, seepage, and hydrolysis. The early evolution of the atmosphere is dominated by the decrease of hydrogen due to falling impact rates and atmospheric escape, and the rise of oxygenated species such as OH from H2O photolysis. Our work points to an early origin of RNA on Earth within ~200 Myr of the Moon-forming impact.         _ Less","","arXiv","https://arxiv.org/abs/2201.00829","3","2","origin_of_life"
"A Multiscale Investigation of the Physical Origins of Tension--Compression Asymmetry in Crystals and their Implications for Cyclic Behavior","Abstract:                _the materials damage and ultimately their failure. In the present work, we associate mesoscale Dislocation Dynamics simulations and Finite Element simulations to identify two original dislocation mechanisms at the_         _ More           Most of crystalline materials develop an hysteresis on their deformation curve when a mechanical loading is applied in alternating directions. This effect, also known as the Bauschinger effect, is intimately related to the reversibile part of the plastic deformation and controls the materials damage and ultimately their failure. In the present work, we associate mesoscale Dislocation Dynamics simulations and Finite Element simulations to identify two original dislocation mechanisms at the origin of the traction/compression asymmetry and quantify their impacts on the cyclic behaviour of FCC single-crystals. After demonstrating that no long-range internal stresses can be measured in the simulations, careful analysis of the dislocation network show that the Bauschinger effect is caused by an asymmetry in the stability of junctions formed from segments whose curvature is determined by the applied stress, and a significant portion of the stored dislocation segments is easily recovered during the backward motion of dislocations in previously explored regions of the crystal. These mechanisms are incorporated into a modified crystal plasticity framework with few parameters quantified from statistical analysis of Dislocation Dynamics simulations or from the literature. This strategy has a real predictive capability and the macroscale results are in good agreement with most of the experimental literature existing on the Bauschinger and cyclic deformation of FCC single-crystals. This work provides valuable mechanistic insight to assist in the interpretation of experiments and the design of structural components to consolidate their life under cyclic loading.         _ Less","","arXiv","https://arxiv.org/abs/2112.15481","1","0","origin_of_life"
"Human Niche Evolution: pathways, choices and outcomes","Abstract:                _human niche evolution depends on a new human beings relationship with the biosphere. Human lifestyles nowadays are very Antropocentric and in many ways deleterious to the other life forms. Here we try to identify future scenarios, where the less deleterious is the Natural-Technological Model that points the urgent need to change the evolutionary direction of_         _ More           Humankind has spread worldwide supported by cultural and technological knowledge, but the environmental sustainability on the human niche evolution depends on a new human beings relationship with the biosphere. Human lifestyles nowadays are very Antropocentric and in many ways deleterious to the other life forms. Here we try to identify future scenarios, where the less deleterious is the Natural-Technological Model that points the urgent need to change the evolutionary direction of the human niche seeking the resumption of original ecological relations. New cultural habits and novel technologies, thereby, would reverse the current anthropogenic impacts. The middle way is the Bio-Anthropogenic Model that predicts the success of the emerging ecosystems and the symbiotic relationship of humans and anthropogenic-favored species, hybrids, aliens and genetically modified organisms. For such, we must also change our way of life and adopt new conscious ways of consumption aiming at the socio-environmental good. Lastly, the Wear Out Model, which depends only on maintaining current patterns of human expansion. The lack of investments on new technologies and new cultural habits, added to the current patterns of human niche evolution that are based on the massive exploitation of world resources, will lead to a fearsome scenario with a precarious global health, biodiversity losses and food scarcity. This theoretical models indicates some pathways and can help us to choose a better future.         _ Less","","arXiv","https://arxiv.org/abs/2112.14852","0","1","synthetic_biology"
"A rich population of free-floating planets in the Upper Scorpius young stellar association","Abstract:                The nature and origin of free-floating planets (FFPs) are still largely unconstrained because of a lack of large homogeneous samples to enable a statistical analysis of their properties. So far, most FFPs have been discovered using indirect methods; microlensing surveys have proved particularly successful to detect these objects down to a few Earth masses. H_         _ More           The nature and origin of free-floating planets (FFPs) are still largely unconstrained because of a lack of large homogeneous samples to enable a statistical analysis of their properties. So far, most FFPs have been discovered using indirect methods; microlensing surveys have proved particularly successful to detect these objects down to a few Earth masses. However, the ephemeral nature of microlensing events prevents any follow-up observations and individual characterization. Several studies have identified FFPs in young stellar clusters and the Galactic field but their samples are small or heterogeneous in age and origin. Here we report the discovery of between 70 and 170 FFPs (depending on the assumed age) in the region encompassing Upper Scorpius and Ophiuchus, the closest young OB association to the Sun. We found an excess of FFPs by a factor of up to seven compared with core-collapse model predictions, demonstrating that other formation mechanisms may be at work. We estimate that ejection from planetary systems might have a contribution comparable to that of core-collapse in the formation of FFPs. Therefore, ejections due to dynamical instabilities in giant exoplanet systems must be frequent within the first 10 Myr of a system's life.         _ Less","","arXiv","https://arxiv.org/abs/2112.11999","2","1","origin_of_life"
"Topic-Aware Encoding for Extractive Summarization","Abstract:                Document summarization provides an instrument for faster understanding the collection of text documents and has several real-life applications. With the growth of online text data, numerous summarization models have been proposed recently. The Sequence-to-Sequence (Seq2Seq) based neural summarization model is the most widely used in the summarization field d_         _ More           Document summarization provides an instrument for faster understanding the collection of text documents and has several real-life applications. With the growth of online text data, numerous summarization models have been proposed recently. The Sequence-to-Sequence (Seq2Seq) based neural summarization model is the most widely used in the summarization field due to its high performance. This is because semantic information and structure information in the text is adequately considered when encoding. However, the existing extractive summarization models pay little attention to and use the central topic information to assist the generation of summaries, which leads to models not ensuring the generated summary under the primary topic. A lengthy document can span several topics, and a single summary cannot do justice to all the topics. Therefore, the key to generating a high-quality summary is determining the central topic and building a summary based on it, especially for a long document. We propose a topic-aware encoding for document summarization to deal with this issue. This model effectively combines syntactic-level and topic-level information to build a comprehensive sentence representation. Specifically, a neural topic model is added in the neural-based sentence-level representation learning to adequately consider the central topic information for capturing the critical content in the original document. The experimental results on three public datasets show that our model outperforms the state-of-the-art models.         _ Less","","arXiv","https://arxiv.org/abs/2112.09572","2","2","multiple"
"Towards fuzzification of adaptation rules in self-adaptive architectures","Abstract:                _rule-based system and a system based on a generic neural network. We show how to navigate in this continuum and create a neural network architecture that naturally embeds the original logical rules and how to gradually scale the learning potential of the network, thus controlling the uncertainty inherent to all soft computing models. We showcase and evaluate_         _ More           In this paper, we focus on exploiting neural networks for the analysis and planning stage in self-adaptive architectures. The studied motivating cases in the paper involve existing (legacy) self-adaptive architectures and their adaptation logic, which has been specified by logical rules. We further assume that there is a need to endow these systems with the ability to learn based on examples of inputs and expected outputs. One simple option to address such a need is to replace the reasoning based on logical rules with a neural network. However, this step brings several problems that often create at least a temporary regress. The reason is the logical rules typically represent a large and tested body of domain knowledge, which may be lost if the logical rules are replaced by a neural network. Further, the black-box nature of generic neural networks obfuscates how the systems work inside and consequently introduces more uncertainty. In this paper, we present a method that makes it possible to endow an existing self-adaptive architectures with the ability to learn using neural networks, while preserving domain knowledge existing in the logical rules. We introduce a continuum between the existing rule-based system and a system based on a generic neural network. We show how to navigate in this continuum and create a neural network architecture that naturally embeds the original logical rules and how to gradually scale the learning potential of the network, thus controlling the uncertainty inherent to all soft computing models. We showcase and evaluate the approach on representative excerpts from two larger real-life use cases.         _ Less","","arXiv","https://arxiv.org/abs/2112.09468","0","1","synthetic_biology"
"Meteorites and the RNA World: Synthesis of Nucleobases in Carbonaceous Planetesimals and the Role of Initial Volatile Content","Abstract:                Prebiotic molecules, fundamental building blocks for the origin of life, have been found in carbonaceous chondrites. The exogenous delivery of these organic molecules onto the Hadean Earth could have sparked the polymerization of the first RNA molecules in Darwinian ponds during wet-dry cycles. Here, we investigate the_         _ More           Prebiotic molecules, fundamental building blocks for the origin of life, have been found in carbonaceous chondrites. The exogenous delivery of these organic molecules onto the Hadean Earth could have sparked the polymerization of the first RNA molecules in Darwinian ponds during wet-dry cycles. Here, we investigate the formation of the RNA and DNA nucleobases adenine, uracil, cytosine, guanine, and thymine inside parent body planetesimals of carbonaceous chondrites. An up-to-date thermochemical equilibrium model coupled with a 1D thermodynamic planetesimal model is used to calculate the nucleobase concentrations. Different from the previous study (Pearce & Pudritz 2016), we assume initial volatile concentrations more appropriate for the formation zone of carbonaceous chondrite parent bodies. This represents more accurately cosmochemical findings that these bodies have formed inside the inner, $\\sim 2\\mathrm{-}5\\,\\mathrm{au}$, warm region of the solar system. Due to these improvements, our model represents the concentrations of adenine and guanine measured in carbonaceous chondrites. Our model did not reproduce per se the measurements of uracil, cytosine, and thymine in these meteorites. This can be explained by transformation reactions between nucleobases and potential decomposition of thymine. The synthesis of prebiotic organic matter in carbonaceous asteroids could be well explained by a combination of i) radiogenic heating, ii) aqueous chemistry involving a few key processes at a specific range of radii inside planetesimals where water can exist in the liquid phase, and iii) a reduced initial volatile content (H$_2$, CO, HCN, CH$_2$O) of the protoplanetary disk material in the parent body region compared to the outer region of comets.         _ Less","","arXiv","https://arxiv.org/abs/2112.09160","4","0","origin_of_life"
"Spatial population genetics with fluid flow","Abstract:                _by fluid flows in spatially extended environments, with immediate consequences for questions of spatial population genetics in marine ecology, planktonic diversity and origin of life scenarios. Here, we review recent progress made in understanding this rich problem in the simplified setting of two competing genetic mic_         _ More           The growth and evolution of microbial populations is often subjected to advection by fluid flows in spatially extended environments, with immediate consequences for questions of spatial population genetics in marine ecology, planktonic diversity and origin of life scenarios. Here, we review recent progress made in understanding this rich problem in the simplified setting of two competing genetic microbial strains subjected to fluid flows. As a pedagogical example we focus on antagonsim, i.e., two killer microorganism strains, each secreting toxins that impede the growth of their competitors (competitive exclusion), in the presence of stationary fluid flows. By solving two coupled reaction-diffusion equations that include advection by simple steady cellular flows composed of characteristic flow motifs in two dimensions (2d), we show how local flow shear and compressibility effects can interact with selective advantage to have a dramatic influence on genetic competition and fixation in spatially distributed populations. We analyze several 1d and 2d flow geometries including sources, sinks, vortices and saddles, and show how simple analytical models of the dynamics of the genetic interface can be used to shed light on the nucleation, coexistence and flow-driven instabilities of genetic drops. By exploiting an analogy with phase separation with nonconserved order parameters, we uncover how these genetic drops harness fluid flows for novel evolutionary strategies, even in the presence of number fluctuations, as confirmed by agent-based simulations as well.         _ Less","","arXiv","https://arxiv.org/abs/2112.09079","2","3","synthetic_biology"
"Geoastronomy: Rocky planets as the Lavosier-Lomonosov Bridge from the non-living to the living world","Abstract:        Life on Earth emerged at the interface of the geosphere, hydrosphere and atmosphere. This setting serves as our basis for how biological systems_         _ More   Life on Earth emerged at the interface of the geosphere, hydrosphere and atmosphere. This setting serves as our basis for how biological systems originate on rocky planets. Often overlooked, however, is the fact that the chemical nature of a rocky planet is ultimately a product of galactic chemical evolution. Elemental abundances of the major rock-forming elements can be different for different stars and planets formed at different times in galactic history. These differences mean that we cannot expect small rocky exoplanets to be just like Earth. Furthermore, age of the system dictates starting nuclide inventory from galactic chemical evolution, and past, present and future mantle and crust thermal regimes. The bulk silicate mantle composition of a rocky planet modulates the kind of atmosphere and hydrosphere it possesses. Hence, the ingredients of a rocky planet are as important for its potential to host life as proximity to the so-called habitable zone around a star where liquid water is stable at the surface. To make sense of these variables, a new trans-disciplinary approach is warranted that fuses the disciplines of Geology and Astronomy into what is here termed, Geoastronomy.         _ Less","","arXiv","https://arxiv.org/abs/2112.04309","1","1","multiple"
"Thermodynamics of Darwinian evolution in molecular replicators","Abstract:                _bounds that arise from finite population sizes and error thresholds. These bounds may be relevant for understanding thermodynamic constraints faced by early replicators at the origin of life. We illustrate our approach on several examples, including a classic model of replicators in a chemostat.         _ More           We consider the relationship between thermodynamics, fitness, and Darwinian evolution in autocatalytic molecular replicators. We uncover a thermodynamic bound that relates fitness, replication rate, and the Gibbs free energy dissipated per copy. This bound applies to a broad range of systems, including elementary and non-elementary autocatalytic reactions, polymer-based replicators, and certain kinds of autocatalytic sets. In addition, we show that the critical selection coefficient (the minimal fitness difference visible to selection) is bounded by the Gibbs free energy dissipated per replication. Our results imply fundamental thermodynamic bounds on the strength of selection in molecular evolution, complementary to other bounds that arise from finite population sizes and error thresholds. These bounds may be relevant for understanding thermodynamic constraints faced by early replicators at the origin of life. We illustrate our approach on several examples, including a classic model of replicators in a chemostat.         _ Less","","arXiv","https://arxiv.org/abs/2112.02809","1","1","multiple"
"GECCO: Constraint-driven Abstraction of Low-level Event Logs","Abstract:                _that enables users to impose requirements on the resulting log in terms of constraints. GECCO then groups events so that the constraints are satisfied and the distance to the original log is minimized. Since exhaustive log abstraction suffers from an exponential runtime complexity, GECCO also offers a heuristic approach guided by behavioral dependencies foun_         _ More           Process mining enables the analysis of complex systems using event data recorded during the execution of processes. Specifically, models of these processes can be discovered from event logs, i.e., sequences of events. However, the recorded events are often too fine-granular and result in unstructured models that are not meaningful for analysis. Log abstraction therefore aims to group together events to obtain a higher-level representation of the event sequences. While such a transformation shall be driven by the analysis goal, existing techniques force users to define how the abstraction is done, rather than what the result shall be. In this paper, we propose GECCO, an approach for log abstraction that enables users to impose requirements on the resulting log in terms of constraints. GECCO then groups events so that the constraints are satisfied and the distance to the original log is minimized. Since exhaustive log abstraction suffers from an exponential runtime complexity, GECCO also offers a heuristic approach guided by behavioral dependencies found in the log. We show that the abstraction quality of GECCO is superior to baseline solutions and demonstrate the relevance of considering constraints during log abstraction in real-life settings.         _ Less","","arXiv","https://arxiv.org/abs/2112.01897","1","0","origin_of_life"
"An Intelligent Vice Cluster Head Election Protocol in WSN","Abstract:                _network operates. Many obstacles prevent wireless sensor networks from being used in a wide range of fields. This includes maintaining network stability and extending network life. In a wireless network, sensors are the most essential component. Sensors are powered by a battery that has a finite amount of power. The battery is prone to power loss, and the se_         _ More           Wireless sensor networks (WSNs) has a practical ability to link a set of sensors to build a wireless network that can be accessed remotely; this technology has become increasingly popular in recent years. Wi-Fi-enabled sensor networks (WSNs) are used to gather information from the environment in which the network operates. Many obstacles prevent wireless sensor networks from being used in a wide range of fields. This includes maintaining network stability and extending network life. In a wireless network, sensors are the most essential component. Sensors are powered by a battery that has a finite amount of power. The battery is prone to power loss, and the sensor is therefore rendered inoperative as a result. In addition, the growing number of sensor nodes off-site affects the network's stability. The transmission and reception of information between the sensors and the base consumes the most energy in the sensor. An Intelligent Vice Cluster Head Selection Protocol is proposed in this study (IVC LEACH). In order to achieve the best performance with the least amount of energy consumption, the proposed hierarchical protocol relies on a fuzzy logic algorithm using four parameters to calculate the value of each node in the network and divides them into three hierarchical levels based on their value. This improves network efficiency and reliability while extending network life by 50 percent more than the original Low Energy Adaptive Clustering Hierarchy protocol         _ Less","","arXiv","https://arxiv.org/abs/2112.01310","1","0","origin_of_life"
"Mars: new insights and unresolved questions","Abstract:                Mars exploration motivates the search for extraterrestrial life, the development of space technologies, and the design of human missions and habitations. Here we seek new insights and pose unresolved questions relating to the natural history of Mars, habitability, robotic and human exploration, planetary protection, and the impacts on human society. Key obse_         _ More           Mars exploration motivates the search for extraterrestrial life, the development of space technologies, and the design of human missions and habitations. Here we seek new insights and pose unresolved questions relating to the natural history of Mars, habitability, robotic and human exploration, planetary protection, and the impacts on human society. Key observations and findings include:(1)high escape rates of early Mars' atmosphere, including loss of water, impact present-day habitability;(2)putative fossils on Mars will likely be ambiguous biomarkers for life;(3)microbial contamination resulting from human habitation is unavoidable;(4)based on Mars' current planetary protection category, robotic payload(s) should characterize the local martian environment for any life-forms prior to human habitation. Some of the outstanding questions are:(1)which interpretation of the hemispheric dichotomy of the planet is correct;(2)to what degree did deep-penetrating faults transport subsurface liquids to Mars' surface;(3)in what abundance are carbonates formed by atmospheric processes;(4)what properties of martian meteorites could be used to constrain their source locations;(5)the origin(s) of organic macromolecules;(6)was/is Mars inhabited;(7)how can missions designed to uncover microbial activity in the subsurface eliminate potential false positives caused by microbial contaminants from Earth;(8)how can we ensure that humans and microbes form a stable and benign biosphere;(9)should humans relate to putative extraterrestrial life from a biocentric viewpoint (preservation of all biology), or anthropocentric viewpoint of expanding habitation of space? Studies of Mars' evolution can shed light on the habitability of extrasolar planets. In addition, Mars exploration can drive future policy developments and confirm (or put into question) the feasibility and/or extent of human habitability of space.         _ Less","","arXiv","https://arxiv.org/abs/2112.00596","0","1","synthetic_biology"
"Drewnowski's index to measure lifespan variation: Revisiting the Gini coefficient of the life table","Abstract:                The Gini coefficient of the life table is a concentration index that provides information on lifespan variation._         _ More           The Gini coefficient of the life table is a concentration index that provides information on lifespan variation. Originally proposed by economists to measure income and wealth inequalities, it has been widely used in population studies to investigate variation in ages at death. We focus on a complementary indicator, Drewnowski's index, which is as a measure of equality. We study its mathematical properties and analyze how changes over time relate to changes in life expectancy. Further, we identify the threshold age below which mortality improvements are translated into decreasing lifespan variation and above which these improvements translate into increasing lifespan inequality. We illustrate our theoretical findings simulating scenarios of mortality improvement in the Gompertz model. Our experiments demonstrate how Drewnowski's index can serve as an indicator of the shape of mortality patterns. These properties, along with our analytical findings, support studying lifespan variation alongside life expectancy trends in multiple species.         _ Less","","arXiv","https://arxiv.org/abs/2111.11256","1","0","origin_of_life"
"Abiogenesis","51 Pegasi b is the first Jupiter-type planet, with a minimum mass slightly smaller than half of  that of Jupiter, discovered around a sunlike star. It was detected by_ radial-velocity _","Springer","Google Scholar","https://link.springer.com/content/pdf/10.1007/978-3-662-65093-6_2.pdf","1","0","origin_of_life"
"Nucleic acids: function and potential for abiogenesis","The emergence of functional cooperation between the three main classes of biomolecules _  nucleic acids, peptides and lipids _ defines life at the molecular level. However, how such _","cambridge.org","Google Scholar","https://www.cambridge.org/core/journals/quarterly-reviews-of-biophysics/article/nucleic-acids-function-and-potential-for-abiogenesis/842529B9BDAD6E86F7919827725C1931","2","0","origin_of_life"
"Some Mathematical Aspects of Abiogenesis","In this paper, we try to modestly, but strictly, using a mathematical approach, show that life was  createdwith a certain goal and that the possibility of accidental origin of life is equal to zero_","ceeol.com","Google Scholar","https://www.ceeol.com/search/article-detail?id=936460","2","0","origin_of_life"
"[PDF][PDF] Dialogue concerning life: Abiogenesis, biogenesis or creationism: Religious response","_ using the far-reaching implications of abiogenesis discourse for religious beliefs as a case  study. Here, the implications and rationality of abiogenesis for some religious traditions and _","academia.edu","Google Scholar","https://www.academia.edu/download/79372705/10225.pdf","1","0","origin_of_life"
"[LIVRE][B] Abiogenesis: The Physical Basis for Living Systems","This textbook serves to teach readers about the origins of life, the probabilistic process of  self-assembly underpinning all living systems, from a biophysics perspective. The author _","books.google.com","Google Scholar","https://books.google.com/books?hl=fr&lr=&id=zuINEQAAQBAJ&oi=fnd&pg=PR5&dq=abiogenesis&ots=9jnYd3n6Nr&sig=pkvcrxemyVOzgRFxnPrlaudw99M","1","1","multiple"
"A review on the spontaneous formation of the building blocks of life and the generation of a set of hypotheses governing universal abiogenesis","_ which govern universal abiogenesis. The _ on abiogenesis can be formulated. The hypotheses  proposed by this paper are incorporated in many of the current theories of abiogenesis, _","cambridge.org","Google Scholar","https://www.cambridge.org/core/journals/international-journal-of-astrobiology/article/review-on-the-spontaneous-formation-of-the-building-blocks-of-life-and-the-generation-of-a-set-of-hypotheses-governing-universal-abiogenesis/DAE5465EC3DC2FFF1612B31C0F5B6E94","3","1","origin_of_life"
"The Abiogenesis Cataloque: Plausibility and Utility in Astrobiology","_ abiogenesis, either by locating extraterrestrial life or by a second terrestrial abiogenesis, has  _ work and its implications for the search for a second abiogenesis in the galaxy and beyond. _","hal.science","Google Scholar","https://hal.science/hal-04590531/","1","0","origin_of_life"
"Abiogenesis: The Emergence of Life from Non-living Matter","_ Further pursuit of this and related questions in the field of abiogenesis is beyond the scope  of this book, but a deeper exploration of abiogenesis is provided by Nick Lane_s Book, _The _","Springer","Google Scholar","https://link.springer.com/chapter/10.1007/978-3-030-01869-6_5","2","0","origin_of_life"
"[HTML][HTML] The requirement of cellularity for abiogenesis","_ Current theories on the abiogenesis of life must account for a moment in evolution (_ By  surveying our current understanding of the involvement of compartments in abiogenesis and _","Elsevier","Google Scholar","https://www.sciencedirect.com/science/article/pii/S2001037021001422","2","2","multiple"
"Why is Abiogenesis Such a Tough Nut to Crack?","The latest life-origin literature is reviewed, along with grouping and classification of the most  enduring models of abiogenesis. New trends are identified in origin-of-life thought. _","preprints.org","Google Scholar","https://www.preprints.org/manuscript/202312.0231","2","1","origin_of_life"
"Abiogenesis-Biogenesis Transition in Evolutionary Cybernetic System","_ Biogenesis and abiogenesis stages of natural evolution are _ It is accustomed to think  that an abiogenesis as the early _ In this report, we discuss possible nature of abiogenesis-_","Taylor & Francis","Google Scholar","https://www.tandfonline.com/doi/abs/10.1080/01969722.2021.1991662","1","1","multiple"
"[PDF][PDF] Ideology in Biology: Theism Meets Atheism in the Case of Abiogenesis.","_ Abiogenesis is the proposed process through which inanimate _ abiogenesis as an atheistic  endeavor and many do. However, atheism is not a requirement to believe that abiogenesis _","cdr.creighton.edu","Google Scholar","https://cdr.creighton.edu/bitstream/handle/10504/129191/2021-15.pdf","1","0","origin_of_life"
"Simplicity out of complexity? On physical eschatology and abiogenesis","Standard reductionist narrative about the necessity of complex systems arising from simple  subsystems can be undermined from multiple directions. Here, I shall suggest an unexpected _","doiserbia.nb.rs","Google Scholar","https://doiserbia.nb.rs/Article.aspx?id=0351-22742103005C","1","0","origin_of_life"
"Abiogenesis: the Carter argument reconsidered","_ abiogenesis occurred, thus nothing can be inferred about the probability of abiogenesis _  Though we definitely had to find ourselves on a planet where abiogenesis occurred, I argue _","cambridge.org","Google Scholar","https://www.cambridge.org/core/journals/international-journal-of-astrobiology/article/abiogenesis-the-carter-argument-reconsidered/BBA3D5F057C5212D76E01F1A0570AB0D","1","0","origin_of_life"
"From spontaneous generation to cosmic abiogenesis. An attempt at systematization of biogenesis theories","The question of the origin of life interested people for centuries. All existing views on this  subject can be classified into different areas of our knowledge of the world: natural sciences, _","ceeol.com","Google Scholar","https://www.ceeol.com/search/article-detail?id=1018654","2","0","origin_of_life"
"[PDF][PDF] Life might be rare despite its early emergence on Earth: a Bayesian analysis of the probability of abiogenesis","_ model of the probability of abiogenesis, we calculate a _ of Bayesian prior for the abiogenesis  probability parameter has a _ intrinsic probability of abiogenesis for plausible uninformative _","researchgate.net","Google Scholar","https://www.researchgate.net/profile/Dave-Spiegel/publication/51924468_Bayesian_analysis_of_the_astrobiological_implications_of_life's_early_emergence_on_Earth/links/00b7d520312842b7d6000000/Bayesian-analysis-of-the-astrobiological-implications-of-lifes-early-emergence-on-Earth.pdf","2","0","origin_of_life"
"Self-Organization Meets Evolution: Ernst Haeckel and Abiogenesis","_ contributed to the growth of experimental studies of abiogenesis in the early 1920s_for _ of  abiogenesis in some detail. In this chapter, we reconstruct Haeckel_s theory of abiogenesis as _","Springer","Google Scholar","https://link.springer.com/chapter/10.1007/978-3-031-04783-1_2","1","3","synthetic_biology"
"Rethinking Abiogenesis: Part 1, Continuity of Life through Time.","_ More broadly, a widespread assertion is that _abiogenesis,_ as the _ and abiogenesis, we  believe that one of the chief impediments to closing this gap emerges from treating abiogenesis _","search.ebscohost.com","Google Scholar","https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=08922675&AN=141766274&h=vjd2ikEcHaO1pL3UfQQKFDfIEakdSCcqLLNjzvSWTqZ2Wv7fazoyqGdcv9XHjRP87kWaDXHhLrHLqMNw%2F3bcfQ%3D%3D&crl=c","1","0","origin_of_life"
"Cumulative, Adaptive, Open-ended Change through Self-Other Reorganization: Reply to comment on 'An evolutionary process without variation and selection'","Abstract:                _model the process whereby, through their interactions, a set of elements become a 'collective self.' SOR shows how the RAF setting provides a means of encompassing abiogenesis and cultural evolution under the same explanatory framework and provides a plausible explanation for the origins of both evolutionary processes. Although SOR allows for detrime_         _ More           Self-Other Reorganization (SOR) is a theory of how interacting entities or individuals, each of which can be described as an autocatalytic network, collectively exhibit cumulative, adaptive, open-ended change, or evolution. Zachar et al.'s critique of SOR stems from misunderstandings; it does not weaken the arguments in (Gabora & Steel, 2021). The formal framework of Reflexively Autocatalytic and foodset-derived sets (RAFs) enables us to model the process whereby, through their interactions, a set of elements become a 'collective self.' SOR shows how the RAF setting provides a means of encompassing abiogenesis and cultural evolution under the same explanatory framework and provides a plausible explanation for the origins of both evolutionary processes. Although SOR allows for detrimental stimuli (and products), there is (naturally) limited opportunity for elements that do not contribute to or reinforce a RAF to become part of it. Replication and cumulative, adaptive change in RAFs is well-established in the literature. Contrary to Zachar et al., SOR is not a pure percolation model (such as SIR); it encompasses not only learning (modeled as assimilation of foodset elements) but also creative restructuring (modeled as generation of foodset-derived elements), as well as the emergence of new structures made possible by new foodset- and foodset-derived elements. Cultural SOR is robust to degradation, and imperfect replication. Zachar et al.'s simulation contains no RAFs, and does not model SOR.         _ Less","","arXiv","https://arxiv.org/abs/2410.05294","2","1","origin_of_life"
"A Multiwavelength Survey of Nearby M dwarfs: Optical and Near-Ultraviolet Flares and Activity with Contemporaneous TESS, Kepler/K2, \\textit{Swift}, and HST Observations","Abstract:                _overall potential to sustain life on any exoplanets they host. We find that early and mid-M dwarfs (M0-M5) have the potential to generate NUV flares capable of initiating abiogenesis.         _ More           We present a comprehensive multiwavelength investigation into flares and activity in nearby M~dwarf stars. We leverage the most extensive contemporaneous dataset obtained through the Transiting Exoplanet Sky Survey (TESS), Kepler/K2, the Neil Gehrels Swift Observatory (\\textit{Swift}), and the Hubble Space Telescope (HST), spanning the optical and near-ultraviolet (NUV) regimes. In total, we observed 213 NUV flares on 24 nearby M dwarfs, with $\\sim$27\\% of them having detected optical counterparts, and found that all optical flares had NUV counterparts. We explore NUV/optical energy fractionation in M dwarf flares. Our findings reveal a slight decrease in the ratio of optical to NUV energies with increasing NUV energies, a trend in agreement with prior investigations on G-K stars' flares at higher energies. Our analysis yields an average NUV fraction of flaring time for M0-M3 dwarfs of 2.1\\%, while for M4-M6 dwarfs, it is 5\\%. We present an empirical relationship between NUV and optical flare energies and compare to predictions from radiative-hydrodynamic and blackbody models. We conducted a comparison of the flare frequency distribution (FFDs) of NUV and optical flares, revealing the FFDs of both NUV and optical flares exhibit comparable slopes across all spectral subtypes. NUV flares on stars affect the atmospheric chemistry, the radiation environment, and the overall potential to sustain life on any exoplanets they host. We find that early and mid-M dwarfs (M0-M5) have the potential to generate NUV flares capable of initiating abiogenesis.         _ Less","","arXiv","https://arxiv.org/abs/2404.12310","3","2","origin_of_life"
"Beyond the Drake Equation: A Time-Dependent Inventory of Habitable Planets and Life-Bearing Worlds in the Solar Neighborhood","Abstract:                _Earth-like planet would be < 20 pc away if microbial life arose as soon as it did on Earth in > 1 % of the TTPs around K stars. If simple life is abundant (fast abiogenesis), it is also old, as it would have emerged more than 8 Gyr ago in about one third of all life-bearing planets today. Older Earth analogs are more likely to have developed sufficient_         _ More           We introduce a mathematical framework for statistical exoplanet population and astrobiology studies that may help directing future observational efforts and experiments. The approach is based on a set of differential equations and provides a time-dependent mapping between star formation, metal enrichment, and the occurrence of exoplanets and potentially life-harboring worlds over the chemo-population history of the solar neighborhood. Our results are summarized as follows: 1) the formation of exoplanets in the solar vicinity was episodic, starting with the emergence of the thick disk about 11 Gyr ago; 2) within 100 pc from the Sun, there are as many as 11,000 (eta/0.24) Earth-size planets in the habitable zone ('temperate terrestrial planets' or TTPs) of K-type stars. The solar system is younger than the median TTP, and was created in a star formation surge that peaked 5.5 Gyr ago and was triggered by an external agent; 3) the metallicity modulation of the giant planet occurrence rate results in a later typical formation time, with TTPs outnumbering giant planets at early times; 4) the closest, life-harboring Earth-like planet would be < 20 pc away if microbial life arose as soon as it did on Earth in > 1 % of the TTPs around K stars. If simple life is abundant (fast abiogenesis), it is also old, as it would have emerged more than 8 Gyr ago in about one third of all life-bearing planets today. Older Earth analogs are more likely to have developed sufficiently complex life capable of altering the environment and producing detectable oxygenic biosignatures.         _ Less","","arXiv","https://arxiv.org/abs/2309.11927","3","0","origin_of_life"
"A Census of NUV M-Dwarf Flares Using Archival GALEX Data and the gPhoton2 Pipeline","Abstract:                _orders of magnitude above any previous study in the UV. We estimate the combined effect of NUV luminosities and flare rates of stars later than M2 to be sufficient for abiogenesis on habitable zone exoplanets orbiting them. As a counterpoint, we speculate the high frequencies of energetic UV flares and associated coronal mass ejections would inhibit the for_         _ More           M-dwarfs are common stellar hosts of habitable-zone exoplanets. NUV radiation can severely impact the atmospheric and surface conditions of such planets, making characterization of NUV flaring activity a key aspect in determining habitability. We use archival data from the GALEX and XMM-Newton telescopes to study the flaring activity of M-dwarfs in the NUV. The GALEX observations form the most extensive dataset of M-dwarfs in the NUV to date, with exploitation of this data possible due to the new gPhoton2 pipeline. We run a dedicated algorithm to detect flares in the pipeline produced lightcurves and find some of the most energetic flares observed to date within the NUV bandpass, with energies of $\\sim 10^{34}$ ergs. Using GALEX data, we constrain flare frequency distributions for stars from M0 to M6 in the NUV up to $10^5$ s in equivalent duration and $10^{34}$ ergs in energy, orders of magnitude above any previous study in the UV. We estimate the combined effect of NUV luminosities and flare rates of stars later than M2 to be sufficient for abiogenesis on habitable zone exoplanets orbiting them. As a counterpoint, we speculate the high frequencies of energetic UV flares and associated coronal mass ejections would inhibit the formation of an ozone layer, possibly preventing genesis of complex Earth-like lifeforms due to sterilizing levels of surface UV radiation. We also provide a framework for future observations of M-dwarfs with ULTRASAT, a wide FoV NUV telescope to be launched in 2026.         _ Less","","arXiv","https://arxiv.org/abs/2306.17045","2","0","origin_of_life"
"A Birth-Death-Migration Model for Life in Astrophysical Environments","Abstract:                To assess the number of life-bearing worlds in astrophysical environments, it is necessary to take the intertwined processes of abiogenesis (birth), extinction (death), and transfer of life (migration) into account. We construct a mathematical model that incorporates this trio of mechanisms and accordingly derive the probability distribution function and oth_         _ More           To assess the number of life-bearing worlds in astrophysical environments, it is necessary to take the intertwined processes of abiogenesis (birth), extinction (death), and transfer of life (migration) into account. We construct a mathematical model that incorporates this trio of mechanisms and accordingly derive the probability distribution function and other statistical properties (e.g., mean) for the number of worlds with biospheres. We show that a given astrophysical setting may become eventually saturated with life if the rate of successful transfers of organisms is higher than the extinction rate of biospheres. Based on the available data, we suggest that this criterion might be fulfilled for star-forming clusters (and perhaps the Galactic bulge under optimal circumstances), thereby indicating that such regions could constitute promising abodes for hosting and detecting life.         _ Less","","arXiv","https://arxiv.org/abs/2306.10899","1","0","origin_of_life"
"Prevalence of multistability and nonstationarity in driven chemical networks","Abstract:                _of bifurcations. Our results suggest that coupling a minimal number of chemical signatures with external driving can lead to features present in biochemical processes and abiogenesis.         _ More           External flows of energy, entropy, and matter can cause sudden transitions in the stability of biological and industrial systems, fundamentally altering their dynamical function. How might we control and design these transitions in chemical reaction networks? Here, we analyze transitions giving rise to complex behavior in random reaction networks subject to external driving forces. In the absence of driving, we characterize the uniqueness of the steady state and identify the percolation of a giant connected component in these networks as the number of reactions increases. When subject to chemical driving (influx and outflux of chemical species), the steady state can undergo bifurcations, leading to multistability or oscillatory dynamics. By quantifying the prevalence of these bifurcations, we show how chemical driving and network sparsity tend to promote the emergence of these complex dynamics and increased rates of entropy production. We show that catalysis also plays an important role in the emergence of complexity, strongly correlating with the prevalence of bifurcations. Our results suggest that coupling a minimal number of chemical signatures with external driving can lead to features present in biochemical processes and abiogenesis.         _ Less","","arXiv","https://arxiv.org/abs/2306.09408","2","1","origin_of_life"
"The ultraviolet habitable zone of exoplanets","Abstract:                _temperature. We find that eighteen of the CHZ exoplanets actually orbit outside the UHZ, i.e., the NUV luminosity of their M-dwarf hosts is decisively too low to trigger abiogenesis - through cyanosulfidic chemistry - on them. Only stars with effective temperature >3900 K illuminate their CHZ planets with enough NUV radiation to trigger_         _ More           The dozens of rocky exoplanets discovered in the Circumstellar Habitable Zone (CHZ) currently represent the most suitable places to host life as we know it outside the Solar System. However, the presumed presence of liquid water on the CHZ planets does not guarantee suitable environments for the emergence of life. According to experimental studies, the building blocks of life are most likely produced photochemically in presence of a minimum ultraviolet (UV) flux. On the other hand, high UV flux can be life-threatening, leading to atmospheric erosion and damaging biomolecules essential to life. These arguments raise questions about the actual habitability of CHZ planets around stars other than Solar-type ones, with different UV to bolometric luminosity ratios. By combining the 'principle of mediocricy' and recent experimental studies, we define UV boundary conditions (UV-habitable Zone, UHZ) within which life can possibly emerge and evolve. We investigate whether exoplanets discovered in CHZs do indeed experience such conditions. By analysing Swift-UV/Optical Telescope data, we measure the near ultraviolet (NUV) luminosities of 17 stars harbouring 23 planets in their CHZ. We derive an empirical relation between NUV luminosity and stellar effective temperature. We find that eighteen of the CHZ exoplanets actually orbit outside the UHZ, i.e., the NUV luminosity of their M-dwarf hosts is decisively too low to trigger abiogenesis - through cyanosulfidic chemistry - on them. Only stars with effective temperature >3900 K illuminate their CHZ planets with enough NUV radiation to trigger abiogenesis. Alternatively, colder stars would require a high-energy flaring activity.         _ Less","","arXiv","https://arxiv.org/abs/2303.16229","2","0","origin_of_life"
"Observing M Dwarfs UV and optical flares from a CubeSat and their implications for exoplanets habitability","Abstract:                _of flares have shown that the flaring flux can be x100 times stronger in UV than in the optical. UV is also preferable to constrain more accurately both the prebiotic abiogenesis and the atmospheric erosion. For these reasons, we are developing a CubeSat payload concept to complement current flare surveys operating in the optical. This CubeSat will observe a_         _ More           M dwarfs show the highest rocky planet occurrence among all spectral types, in some instances within the Habitable Zone. Because some of them are very active stars, they are often subject to frequent and powerful flaring, which can be a double-edged sword in regard of exoplanet habitability. On one hand, the increased flux during flare events can trigger the chemical reactions that are necessary to build the basis of prebiotic chemistry. On the other hand, sufficiently strong flares may erode exoplanets' atmospheres and reduce their UV protection. Recent observations of flares have shown that the flaring flux can be x100 times stronger in UV than in the optical. UV is also preferable to constrain more accurately both the prebiotic abiogenesis and the atmospheric erosion. For these reasons, we are developing a CubeSat payload concept to complement current flare surveys operating in the optical. This CubeSat will observe a high number of flaring M dwarfs, following an all-sky scanning law coverage, both in the UV and the optical to better understand the different effective temperatures as wavelengths and flaring status go. This will complement the bright optical flares data acquired from the current ground-based, high-cadence, wide FoV surveys. Another scientific planned goal is to conduct few-minute after-the-flare follow-up optical ground-based time-resolved spectroscopy, that will be triggered by the detection of UV flares in space on board of the proposed CubeSat. Finally, the study of M dwarfs stellar activity in the UV band will provide useful data for larger forthcoming missions that will survey exoplanets, such as PLATO, ARIEL, HabEx and LUVOIR.         _ Less","","arXiv","https://arxiv.org/abs/2302.12566","3","1","origin_of_life"
"Extending Optical Flare Models to the UV: Results from Comparing of TESS and GALEX Flare Observations For M Dwarfs","Abstract:                _M stars after accounting for the contribution from UV line emission. We also applied our correction factors to the results of previous studies of the role of flares in abiogenesis. Our results show that M stars do not need to be as active as previously thought in order to provide the NUV flux required for prebiotic chemistry, however we note that flares will_         _ More           The ultraviolet (UV) emission of stellar flares may have a pivotal role in the habitability of rocky exoplanets around low-mass stars. Previous studies have used white-light observations to calibrate empirical models which describe the optical and UV flare emission. However, the accuracy of the UV predictions of models have previously not been tested. We combined TESS optical and GALEX UV observations to test the UV predictions of empirical flare models calibrated using optical flare rates of M stars. We find that the canonical 9000 K blackbody model used by flare studies underestimates the GALEX NUV energies of field age M stars by up to a factor of 6.5$\\pm$0.7 and the GALEX FUV energies of fully convective field age M stars by 30.6$\\pm$10.0. We calculated energy correction factors that can be used to bring the UV predictions of flare models closer in line with observations. We calculated pseudo-continuum flare temperatures that describe both the white-light and GALEX NUV emission. We measured a temperature of 10,700 K for flares from fully convective M stars after accounting for the contribution from UV line emission. We also applied our correction factors to the results of previous studies of the role of flares in abiogenesis. Our results show that M stars do not need to be as active as previously thought in order to provide the NUV flux required for prebiotic chemistry, however we note that flares will also provide more FUV flux than previously modelled.         _ Less","","arXiv","https://arxiv.org/abs/2210.15688","2","0","origin_of_life"
"A Unified Spectroscopic and Photometric Model to Infer Surface Inhomogeneity: Application to Luhman 16B","Abstract:                _can be caused by star spots, clouds, and vortices. Star spots and associated stellar flares play a significant role in habitability, either stifling life or catalyzing abiogenesis depending on the emission frequency, magnitude, and orientation. Clouds and vortices may be the source of spectral and photometric variability observed at the L/T transition of BDs_         _ More           Extremely large telescopes (ELTs) provide an opportunity to observe surface inhomogeneities for ultracool objects including M dwarfs, brown dwarfs (BDs), and gas giant planets via Doppler imaging and spectro-photometry techniques. These inhomogeneities can be caused by star spots, clouds, and vortices. Star spots and associated stellar flares play a significant role in habitability, either stifling life or catalyzing abiogenesis depending on the emission frequency, magnitude, and orientation. Clouds and vortices may be the source of spectral and photometric variability observed at the L/T transition of BDs and are expected in gas giant exoplanets. We develop a versatile analytical framework to model and infer surface inhomogeneities which can be applied to both spectroscopic and photometric data. This model is validated against a slew of numerical simulations. Using archival spectroscopic and photometric data, we infer star spot parameters (location, size, and contrast) and generate global surface maps for Luhman 16B (an early T dwarf and one of our solar system's nearest neighbors at a distance of approximately 2 pc). We confirm previous findings that Luhman 16B's atmosphere is inhomogeneous with time-varying features. In addition, we provide tentative evidence of longer timescale atmospheric structures such as dark equatorial and bright mid-latitude to polar spots. These findings are discussed in the context of atmospheric circulation and dynamics for ultracool dwarfs. Our analytical model will be valuable in assessing the feasibility of using ELTs to study surface inhomogeneities of gas giant exoplanets and other ultracool objects.         _ Less","","arXiv","https://arxiv.org/abs/2206.01770","1","0","origin_of_life"
"A Study of Flares in the Ultra-Cool Regime from SPECULOOS-South","Abstract:                _planets orbiting ultra-cool stars. As stars become cooler, they flare less frequently; therefore, it is unlikely that planets around the very reddest dwarfs would enter the `abiogenesis' zone or drive visible-light photosynthesis through flares alone.         _ More           We present a study of photometric flares on 154 low-mass ($\\leq 0.2 \\textrm{M}_{\\odot}$) objects observed by the SPECULOOS-South Observatory from 1st June 2018 to 23rd March 2020. In this sample we identify 85 flaring objects, ranging in spectral type from M4 to L0. We detect 234 flares in this sample, with energies between $10^{29.2}$ and $10^{32.7}$ erg, using both automated and manual methods. With this work, we present the largest photometric sample of flares on late-M and ultra-cool dwarfs to date. By extending previous M dwarf flare studies into the ultra-cool regime, we find M5-M7 stars are more likely to flare than both earlier, and later, M dwarfs. By performing artificial flare injection-recovery tests we demonstrate that we can detect a significant proportion of flares down to an amplitude of 1 per cent, and we are most sensitive to flares on the coolest stars. Our results reveal an absence of high-energy flares on the reddest dwarfs. To probe the relations between rotation and activity for fully convective stars, we extract rotation periods for fast rotators and lower-bound period estimates of slow rotators. These rotation periods span from 2.2 hours to 65 days, and we find that the proportion of flaring stars increases for the very fastest rotators. Finally, we discuss the impact of our flare sample on planets orbiting ultra-cool stars. As stars become cooler, they flare less frequently; therefore, it is unlikely that planets around the very reddest dwarfs would enter the `abiogenesis' zone or drive visible-light photosynthesis through flares alone.         _ Less","","arXiv","https://arxiv.org/abs/2204.10417","1","0","origin_of_life"
"Selecting Continuous Life-Like Cellular Automata for Halting Unpredictability: Evolving for Abiogenesis","Abstract:                Substantial efforts have been applied to engineer CA with desired emergent properties, such as supporting gliders. Recent work in continuous CA has generated a wide variety of compelling bioreminiscent patterns, and the expansion of CA research into continuously-valued domains, multiple channels, and higher dimensions complicates their study. In this work we devise a strategy for evolving CA and C_         _ More           Substantial efforts have been applied to engineer CA with desired emergent properties, such as supporting gliders. Recent work in continuous CA has generated a wide variety of compelling bioreminiscent patterns, and the expansion of CA research into continuously-valued domains, multiple channels, and higher dimensions complicates their study. In this work we devise a strategy for evolving CA and CA patterns in two steps, based on the simple idea that CA are likely to be complex and computationally capable if they support patterns that grow indefinitely as well as patterns that vanish completely, and are difficult to predict the difference in advance. The second part of our strategy evolves patterns by selecting for mobility and conservation of mean cell value. We validate our pattern evolution method by re-discovering gliders in 17 of 17 Lenia CA, and also report 4 new evolved CA and 1 randomly evolved CA that support novel evolved glider patterns. The CA reported here share neighborhood kernels with previously described Lenia CA, but exhibit a wider range of typical dynamics than their Lenia counterparts. Code for evolving continuous CA is made available under an MIT License (https://github.com/rivesunder/yuca).         _ Less","","arXiv","https://arxiv.org/abs/2204.07541","1","1","multiple"
"TESS observations of flares and quasi-periodic pulsations from low mass stars and potential impact on exoplanets","Abstract:                _2. We also discuss the flare frequency of the seven stars determining whether this could result in ozone depletion or abiogenesis. Three of our stars have a sufficiently high rate of energetic flares which are likely to cause abiogenesis. However, two of them are also in the range where ozone depletion is likely to occ_         _ More           We have performed a search for flares and Quasi-Periodic Pulsations (QPPs) from low mass M dwarf stars using TESS 2 min cadence data. We find seven stars which show evidence of QPPs. Using Fourier and Empirical Mode Decomposition techniques, we confirm the presence of 11 QPPs in these seven stars with a period between 10.2 and 71.9 min, including an oscillation with strong drift in the period and a double-mode oscillation. The fraction of flares we examined which showed QPPs (7 percent) is higher than other studies of stellar flares, but is very similar to the fraction of Solar C-class flares. Based on the stellar parameters taken from the TESS Input Catalog, we determine the lengths and magnetic field strengths of the flare coronal loops using the period of the QPPs and various assumptions about the origin of the QPPs. We also use a scaling relationship based on flares from Solar and Solar-type stars and the observed energy, plus the duration of the flares, finding that the different approaches predict loop lengths which are consistent to a factor of $\\sim$2. We also discuss the flare frequency of the seven stars determining whether this could result in ozone depletion or abiogenesis. Three of our stars have a sufficiently high rate of energetic flares which are likely to cause abiogenesis. However, two of them are also in the range where ozone depletion is likely to occur. We speculate on the implications for surface life on these stars and the effects of the loop lengths and QPPs on potential exoplanets in the habitable zone.         _ Less","","arXiv","https://arxiv.org/abs/2108.10670","1","0","origin_of_life"
"Of Aliens and Exoplanets: Why the search for life, probably, requires the search for water","Abstract:                _systems. In fact, the origin of life mechanism, this being how biological organisms form from non-living matter, is unknown. In an attempt to better understand how abiogenesis can occur, some researchers have taken water out of their models and instead opted for more exotic approaches. These assumptions will have strong implications for astronomical observat_         _ More           It is not currently possible to create a living organism ab initio due to the overwhelming complexity of biological systems. In fact, the origin of life mechanism, this being how biological organisms form from non-living matter, is unknown. In an attempt to better understand how abiogenesis can occur, some researchers have taken water out of their models and instead opted for more exotic approaches. These assumptions will have strong implications for astronomical observations and potential future space exploration. By breaking down water's properties to the physical, chemical and biological level, herewith it is demonstrated to be the most adequate medium for the formation of life.         _ Less","","arXiv","https://arxiv.org/abs/2104.01683","3","0","origin_of_life"
"A Statistical Estimation of the Occurrence of Extraterrestrial Intelligence in the Milky Way Galaxy","Abstract:                _for ETI (SETI) with a set of criteria, including well-established astrophysical properties of the Milky Way. Further, typically overlooked factors such as the process of abiogenesis, different evolutionary timescales and potential self-annihilation are incorporated to explore the growth propensity of ETI. We examine three major parameters: 1) the likelihood_         _ More           In the field of Astrobiology, the precise location, prevalence and age of potential extraterrestrial intelligence (ETI) have not been explicitly explored. Here, we address these inquiries using an empirical galactic simulation model to analyze the spatial-temporal variations and the prevalence of potential ETI within the Galaxy. This model estimates the occurrence of ETI, providing guidance on where to look for intelligent life in the Search for ETI (SETI) with a set of criteria, including well-established astrophysical properties of the Milky Way. Further, typically overlooked factors such as the process of abiogenesis, different evolutionary timescales and potential self-annihilation are incorporated to explore the growth propensity of ETI. We examine three major parameters: 1) the likelihood rate of abiogenesis (_A); 2) evolutionary timescales (Tevo); and 3) probability of self-annihilation of complex life (Pann). We found Pann to be the most influential parameter determining the quantity and age of galactic intelligent life. Our model simulation also identified a peak location for ETI at an annular region approximately 4 kpc from the Galactic center around 8 billion years (Gyrs), with complex life decreasing temporally and spatially from the peak point, asserting a high likelihood of intelligent life in the galactic inner disk. The simulated age distributions also suggest that most of the intelligent life in our galaxy are young, thus making observation or detection difficult.         _ Less","","arXiv","https://arxiv.org/abs/2012.07902","1","2","synthetic_biology"
"Superconductivity mystery turns 25","Abstract:                _at high temperatures.   'The great tragedy of Science [is] the slaying of a beautiful hypothesis by an [experimental] fact.'   - T.H. Huxley, Biogenesis and abiogenesis, (1884)         _ More           In 1994, an unconventional form of superconductivity was detected in strontium ruthenate. The discovery has shed light on the mechanism of unconventional superconductivity at high temperatures.   'The great tragedy of Science [is] the slaying of a beautiful hypothesis by an [experimental] fact.'   - T.H. Huxley, Biogenesis and abiogenesis, (1884)         _ Less","","arXiv","https://arxiv.org/abs/2006.06916","1","0","origin_of_life"
"Autocatalytic Networks: An Intimate Relation between Network Topology and Dynamics","Abstract:                _Hyperchains, and the associated dynamical system called replicator equations, are a possible mechanism for macromolecular evolution and proposed to play a role in abiogenesis, the origin of life from prebiotic chemistry. The same dynamical system also occurs in evolutionary game dynamics, genetic selection, and as Lotka-Volterra equations of ecology. An arr_         _ More           We study a family of networks of autocatalytic reactions, which we call hyperchains, that are a generalization of hypercycles. Hyperchains, and the associated dynamical system called replicator equations, are a possible mechanism for macromolecular evolution and proposed to play a role in abiogenesis, the origin of life from prebiotic chemistry. The same dynamical system also occurs in evolutionary game dynamics, genetic selection, and as Lotka-Volterra equations of ecology. An arrow in a hyperchain encapsulates the enzymatic influence of one species on the autocatalytic replication of another. We show that the network topology of a hyperchain, which captures all such enzymatic influences, is intimately related to the dynamical properties of the mass action system it generates. Dynamical properties such as existence, uniqueness and stability of a positive equilibrium as well as permanence, are determined by graph-theoretic properties such as existence of a spanning linear subgraph, being unrooted, being cyclic, and Hamiltonicity.         _ Less","","arXiv","https://arxiv.org/abs/2006.01384","3","1","origin_of_life"
"An Objective Bayesian Analysis of Life's Early Start and Our Late Arrival","Abstract:                Life emerged on the Earth within the first quintile of its habitable window, but a technological civilization did not blossom until its last. Efforts to infer the rate of abiogenesis, based on its early emergence, are frustrated by the selection effect that if the evolution of intelligence is a slow process, then life's early start may simply be a prereq_         _ More           Life emerged on the Earth within the first quintile of its habitable window, but a technological civilization did not blossom until its last. Efforts to infer the rate of abiogenesis, based on its early emergence, are frustrated by the selection effect that if the evolution of intelligence is a slow process, then life's early start may simply be a prerequisite to our existence, rather than useful evidence for optimism. In this work, we interpret the chronology of these two events in a Bayesian framework, extending upon previous work by considering that the evolutionary timescale is itself an unknown that needs to be jointly inferred, rather than fiducially set. We further adopt an objective Bayesian approach, such that our results would be agreed upon even by those using wildly different priors for the rates of abiogenesis and evolution - common points of contention for this problem. It is then shown that the earliest microfossil evidence for life indicates that the rate of abiogenesis is at least 2.8 times more likely to be a typically rapid process, rather than a slow one. This modest limiting Bayes factor rises to 8.7 if we accept the more disputed evidence of C13 depleted zircon deposits (Bell et al. 2015). For intelligence evolution, it is found that a rare-intelligence scenario is slightly favored at 3:2 betting odds. Thus, if we re-ran Earth's clock, one should statistically favor life to frequently re-emerge, but intelligence may not be as inevitable.         _ Less","","arXiv","https://arxiv.org/abs/2005.09008","2","1","origin_of_life"
"Emergence of life in an inflationary universe","Abstract:                _Sun-like stars. If life can emerge at least once in such a large volume, it is not in contradiction with our observations of life on Earth, even if the expected number of abiogenesis events is negligibly small within the observable universe that contains only $10^{22}$ stars. Here, a quantitative relation is derived between the minimum RNA length_         _ More           Abiotic emergence of ordered information stored in the form of RNA is an important unresolved problem concerning the origin of life. A polymer longer than 40--100 nucleotides is necessary to expect a self-replicating activity, but the formation of such a long polymer having a correct nucleotide sequence by random reactions seems statistically unlikely. However, our universe, created by a single inflation event, likely includes more than $10^{100}$ Sun-like stars. If life can emerge at least once in such a large volume, it is not in contradiction with our observations of life on Earth, even if the expected number of abiogenesis events is negligibly small within the observable universe that contains only $10^{22}$ stars. Here, a quantitative relation is derived between the minimum RNA length $l_{\\min}$ required to be the first biological polymer, and the universe size necessary to expect the formation of such a long and active RNA by randomly adding monomers. It is then shown that an active RNA can indeed be produced somewhere in an inflationary universe, giving a solution to the abiotic polymerization problem. On the other hand, $l_{\\min}$ must be shorter than $\\sim$20 nucleotides for the abiogenesis probability close to unity on a terrestrial planet, but a self-replicating activity is not expected for such a short RNA. Therefore, if extraterrestrial organisms of a different origin from those on Earth are discovered in the future, it would imply an unknown mechanism at work to polymerize nucleotides much faster than random statistical processes.         _ Less","","arXiv","https://arxiv.org/abs/1911.08092","4","1","origin_of_life"
"The high-energy radiation environment of the habitable-zone super-Earth LHS 1140b","Abstract:                _but the X-ray/UV activity of cool stars is very different from that of our Sun. The high-energy radiation environment influences the habitability, plays a crucial role for abiogenesis, and impacts planetary atmospheres. LHS 1140b is a super-Earth-size planet orbiting in the HZ of LHS 1140, an M4.5 dwarf at ~15 parsecs. We present the results of a Swift X-ra_         _ More           In the last few years many exoplanets in the habitable zone (HZ) of M-dwarfs have been discovered, but the X-ray/UV activity of cool stars is very different from that of our Sun. The high-energy radiation environment influences the habitability, plays a crucial role for abiogenesis, and impacts planetary atmospheres. LHS 1140b is a super-Earth-size planet orbiting in the HZ of LHS 1140, an M4.5 dwarf at ~15 parsecs. We present the results of a Swift X-ray/UV observing campaign. We characterize for the first time the X-ray/UV radiation environment of LHS 1140b. We measure the variability of the near ultraviolet (NUV) flux and estimate the far ultraviolet (FUV) flux with a correlation between FUV and NUV flux of a sample of low-mass stars in the GALEX archive. We highlight the presence of a dominating X-ray source close to the J2000 coordinates of LHS 1140, characterize its spectrum, and derive an X-ray flux upper limit for LHS 1140. We find that this contaminant source could have influenced the previously estimated spectral energy distribution. No significant variation of the NUV flux of LHS 1140 is found over 3 months, and we do not observe any flare during the 38 ks on the target. LHS 1140 is in the 25th percentile of least variable M4-M5 dwarfs of the GALEX sample. Analyzing the UV flux experienced by the HZ planet LHS 1140b, we find that outside the atmosphere it receives a NUV flux <2% with respect to that of the present-day Earth, while the FUV/NUV ratio is ~100-200 times higher. This represents a lower limit to the true FUV/NUV ratio since the GALEX FUV band does not include Lyman-alpha, which dominates the FUV output of low-mass stars. This is a warning for future searches for biomarkers, which must take into account this high ratio. The relatively low level and stability of UV flux experienced by LHS 1140b should be favorable for its present-day habitability.         _ Less","","arXiv","https://arxiv.org/abs/1906.08783","1","0","origin_of_life"
"A Prerequisite for Life","Abstract:                _unstable in the cytosol. (3) And living organism are mortal. These three common features together give a prerequisite for the prebiotic self-assembly at the start of the Abiogenesis. Here we argue , that it all together indicates, that the prebiotic self-assembly of structures and reactions took place in a more saline environment, whereby the homochirality o_         _ More           The complex physicochemical structures and chemical reactions in living organism have some common features: (1) The life processes take place in the cytosol in the cells, which, from a physicochemical point of view is an emulsion of biomolecules in a dilute aqueous suspension. (2) All living systems are homochiral with respect to the units of amino acids and carbohydrates, but (some) proteins are chiral unstable in the cytosol. (3) And living organism are mortal. These three common features together give a prerequisite for the prebiotic self-assembly at the start of the Abiogenesis. Here we argue , that it all together indicates, that the prebiotic self-assembly of structures and reactions took place in a more saline environment, whereby the homochirality of proteins not only could be obtained, but also preserved. A more saline environment for the prebiotic self-assembly of organic molecules and establishment of biochemical reactions could have been the hydrothermal vents.         _ Less","","arXiv","https://arxiv.org/abs/1905.09104","2","1","origin_of_life"
"The Origin of RNA Precursors on Exoplanets","Abstract:                _. By balancing the rates for the light and dark chemistry, we delineate the 'abiogenesis zones' around stars of different stellar types based on whether their UV fluxes are sufficient for building up this macromolecular prebiotic inventory. We find that the SO$_3^{2-}$ 'light chemistry' is rapid enough to build up the prebiotic inventory for_         _ More           Given that the macromolecular building blocks of life were likely produced photochemically in the presence of ultraviolet (UV) light, we identify some general constraints on which stars produce sufficient UV for this photochemistry. We estimate how much light is needed for the UV photochemistry by experimentally measuring the rate constant for the UV chemistry (`light chemistry', needed for prebiotic synthesis) versus the rate constants for the bimolecular reactions that happen in the absence of the UV light (`dark chemistry'). We make these measurements for representative photochemical reactions involving SO$_3^{2-}$ and HS$^-$. By balancing the rates for the light and dark chemistry, we delineate the 'abiogenesis zones' around stars of different stellar types based on whether their UV fluxes are sufficient for building up this macromolecular prebiotic inventory. We find that the SO$_3^{2-}$ 'light chemistry' is rapid enough to build up the prebiotic inventory for stars hotter than K5 (4400 K). We show how the abiogenesis zone overlaps with the liquid water habitable zone. Stars cooler than K5 may also drive the formation of these building blocks if they are very active. The HS$^-$ 'light chemistry' is too slow to work even for the Early Earth.         _ Less","","arXiv","https://arxiv.org/abs/1808.02718","3","0","origin_of_life"
"Molecular Imprinting: The missing piece in the puzzle of abiogenesis?","Abstract:                _Nobel Laureate Paul Lauterbur proposed that molecular imprinting in amorphous materials -- a phenomenon with an extensive experimental literature -- played a key role in abiogenesis. The present paper builds on Lauterbur's idea to propose imprint-mediated templating (IMT), a mechanism for prebiotic peptide replication that could potentially avoid a rang_         _ More           In a neglected 2005 paper, Nobel Laureate Paul Lauterbur proposed that molecular imprinting in amorphous materials -- a phenomenon with an extensive experimental literature -- played a key role in abiogenesis. The present paper builds on Lauterbur's idea to propose imprint-mediated templating (IMT), a mechanism for prebiotic peptide replication that could potentially avoid a range of difficulties arising in classic gene-first and metabolism-first models of abiogenesis. Unlike models that propose prebiotic RNA synthesis, activation, and polymerization based on unknown chemistries, peptide/IMT models are compatible with demonstrably realistic prebiotic chemistries: synthesis of dilute mixtures of racemic amino acids from atmospheric gases, and polymerization of unactivated amino acids on hot, intermittently-wetted surfaces. Starting from a peptide/IMT-based genetics, plausible processes could support the elaboration of genetic and metabolic complexity in an early-Earth environment, both explaining the emergence of homochirality and providing a potential bridge to nucleic acid metabolism. Peptide/IMT models suggest directions for both theoretical and experimental inquiry.         _ Less","","arXiv","https://arxiv.org/abs/1807.07065","4","1","origin_of_life"
"On the Rate of Abiogenesis from a Bayesian Informatics Perspective","Abstract:                Life appears to have emerged relatively quickly on the Earth, a fact sometimes used to justify a high rate of spontaneous abiogenesis ($_$) among Earth-like worlds. Conditioned upon a single datum - the time of earliest evidence for life ($t_{\\mathrm{obs}}$) - previous Bayesian formalisms for the posterior distribution of $_$ have demonstrated how inferences_         _ More           Life appears to have emerged relatively quickly on the Earth, a fact sometimes used to justify a high rate of spontaneous abiogenesis ($_$) among Earth-like worlds. Conditioned upon a single datum - the time of earliest evidence for life ($t_{\\mathrm{obs}}$) - previous Bayesian formalisms for the posterior distribution of $_$ have demonstrated how inferences are highly sensitive to the priors. Rather than attempt to infer the true $_$ posterior, we here compute the relative change to $_$ when new experimental/observational evidence is introduced. By simulating posterior distributions and resulting entropic information gains, we compare three experimental pressures on $_$: 1) evidence for an earlier start to life; $t_{\\mathrm{obs}}$; 2) constraints on spontaneous abiogenesis from the lab; and 3) an exoplanet survey for biosignatures. First, we find that experiments 1 and 2 can only yield lower limits on $_$, unlike 3. Second, evidence for an earlier start to life can yield negligible information on $_$ if $t_{\\mathrm{obs}} \\ll __{\\mathrm{max}}^{-1}$. Vice versa, experiment 2 is uninformative when $__{\\mathrm{max}} \\gg t_{\\mathrm{obs}}^{-1}$. Whilst experiment 3 appears the most direct means of measuring $_$, we highlight that early starts inform us of the conditions of abiogenesis, and that lab experiments could succeed in building new life. Together then, the three experiments are complimentary and we encourage activity in all to solve this grand challenge.         _ Less","","arXiv","https://arxiv.org/abs/1806.08033","3","1","origin_of_life"
"The start of the Abiogenesis: Preservation of homochirality in proteins as a necessary and sufficient condition for the establishment of the metabolism","Abstract:                _their life. There are, however, some common structures and reactions in the systems: the homochirality of carbohydrates and proteins, the metabolism and the genetics. The Abiogenesis, or the origin of life, is probably not a result of a series of single events, but rather the result of a gradual process with increasing complexity of molecules and chemical re_         _ More           Biosystems contain an almost infinite amount of vital important details, which together ensure their life. There are, however, some common structures and reactions in the systems: the homochirality of carbohydrates and proteins, the metabolism and the genetics. The Abiogenesis, or the origin of life, is probably not a result of a series of single events, but rather the result of a gradual process with increasing complexity of molecules and chemical reactions, and the prebiotic synthesis of molecules might not have left a trace of the establishment of structures and reactions at the beginning of the evolution. But alternatively, one might be able to determine some order in the formation of the chemical denominators in the Abiogenesis. Here we review experimental results and present a model of the start of the Abionenesis, where the spontaneous formation of homochirality in proteins is the precondition for the establishment of homochirality of carbohydrates and for the metabolism at the start of the Abiogenesis.         _ Less","","arXiv","https://arxiv.org/abs/1803.01560","5","3","origin_of_life"
"Sulfidic Anion Concentrations on Early Earth for Surficial Origins-of-Life Chemistry","Abstract:                A key challenge in origin-of-life studies is understanding the environmental conditions on early Earth under which abiogenesis occurred. While some constraints do exist (e.g., zircon evidence for surface liquid water), relatively few constraints exist on the abundances of trace chemical species, which are relevant to assessing the plausibility and guiding th_         _ More           A key challenge in origin-of-life studies is understanding the environmental conditions on early Earth under which abiogenesis occurred. While some constraints do exist (e.g., zircon evidence for surface liquid water), relatively few constraints exist on the abundances of trace chemical species, which are relevant to assessing the plausibility and guiding the development of postulated prebiotic chemical pathways which depend on these species. In this work, we combine literature photochemistry models with simple equilibrium chemistry calculations to place constraints on the plausible range of concentrations of sulfidic anions (HS$^-$, HSO$_3^{-}$, SO$_3^{2-}$) available in surficial aquatic reservoirs on early Earth due to outgassing of SO$_2$ and H$_2$S and their dissolution into small shallow surface water reservoirs like lakes. We find that this mechanism could have supplied prebiotically relevant levels of SO$_2$-derived anions, but not H$_2$S-derived anions. Radiative transfer modelling suggests UV light would have remained abundant on the planet surface for all but the largest volcanic explosions. We apply our results to the case study of the proposed prebiotic reaction network of Patel et al. (2015), and discuss the implications for improving its prebiotic plausibility. In general, epochs of moderately high volcanism could have been especially conducive to cyanosulfidic prebiotic chemistry. Our work can be similarly applied to assess and improve the prebiotic plausibility of other postulated surficial prebiotic chemistries that are sensitive to sulfidic anions, and our methods adapted to study other atmospherically-derived trace species.         _ Less","","arXiv","https://arxiv.org/abs/1801.07725","2","1","origin_of_life"
"Percolation clusters of organics in interstellar ice grains as the incubators of life","Abstract:                _formed. The interior regions of such superclusters provided for chemical micro-environments that are filtered versions of the outside environment. I argue that models for abiogenesis are more likely to work when considered inside such micro-environments. As the supercluster breaks up, biochemical systems in such micro-environments gradually become subject to_         _ More           Biomolecules can be synthesized in interstellar ice grains subject to UV radiation and cosmic rays. I show that on time scales of $\\gtrsim 10^{6}$ years, these processes lead to the formation of large percolation clusters of organic molecules. Some of these clusters would have ended up on proto-planets where large, loosely bound aggregates of clusters (superclusters) would have formed. The interior regions of such superclusters provided for chemical micro-environments that are filtered versions of the outside environment. I argue that models for abiogenesis are more likely to work when considered inside such micro-environments. As the supercluster breaks up, biochemical systems in such micro-environments gradually become subject to a less filtered environment, allowing them to get adapted to the more complex outside environment. A particular system originating from a particular location on some supercluster would have been the first to get adapted to the raw outside environment and survive there, thereby becoming the first microbe. A collision of a microbe-containing proto-planet with the Moon could have led to fragments veering off back into space, microbes in small fragments would have been able to survive a subsequent impact with the Earth.         _ Less","","arXiv","https://arxiv.org/abs/1711.01945","2","0","origin_of_life"
"Implications of tides for life on exoplanets","Abstract:                _could be more prominent due to stronger tidal forces. We identify the conditions under which tides may exert a significant positive influence on biotic processes including abiogenesis, biological rhythms, nutrient upwelling and stimulating photosynthesis. We conclude our analysis with the identification of large-scale algal blooms as potential temporal biosi_         _ More           As evident from the nearby examples of Proxima Centauri and TRAPPIST-1, Earth-sized planets in the habitable zone of low-mass stars are common. Here, we focus on such planetary systems and argue that their (oceanic) tides could be more prominent due to stronger tidal forces. We identify the conditions under which tides may exert a significant positive influence on biotic processes including abiogenesis, biological rhythms, nutrient upwelling and stimulating photosynthesis. We conclude our analysis with the identification of large-scale algal blooms as potential temporal biosignatures in reflectance light curves that can arise indirectly as a consequence of strong tidal forces.         _ Less","","arXiv","https://arxiv.org/abs/1707.04594","1","0","origin_of_life"
"Atmospheric escape from the TRAPPIST-1 planets and implications for habitability","Abstract:                _the TRAPPIST-1 system are capable of retaining their atmospheres over billion-year timescales. The consequences arising from our results are also explored in the context of abiogenesis, biodiversity, and searches for future exoplanets. In light of the many unknowns and assumptions involved, we recommend that these conclusions must be interpreted with due cau_         _ More           The presence of an atmosphere over sufficiently long timescales is widely perceived as one of the most prominent criteria associated with planetary surface habitability. We address the crucial question as to whether the seven Earth-sized planets transiting the recently discovered ultracool dwarf star TRAPPIST-1 are capable of retaining their atmospheres. To this effect, we carry out numerical simulations to characterize the stellar wind of TRAPPIST-1 and the atmospheric ion escape rates for all the seven planets. We also estimate the escape rates analytically and demonstrate that they are in good agreement with the numerical results. We conclude that the outer planets of the TRAPPIST-1 system are capable of retaining their atmospheres over billion-year timescales. The consequences arising from our results are also explored in the context of abiogenesis, biodiversity, and searches for future exoplanets. In light of the many unknowns and assumptions involved, we recommend that these conclusions must be interpreted with due caution.         _ Less","","arXiv","https://arxiv.org/abs/1705.05535","1","0","origin_of_life"
"The Surface UV Environment on Planets Orbiting M-Dwarfs: Implications for Prebiotic Chemistry & Need for Experimental Follow-Up","Abstract:                _planets have access to 100-1000 times less bioactive UV fluence than the young Earth. It is unclear whether UV-sensitive prebiotic chemistry that may have been important to abiogenesis, such as the only known prebiotically plausible pathways for pyrimidine ribonucleotide synthesis, could function on M-dwarf planets. This uncertainty affects objects like the_         _ More           Potentially-habitable planets orbiting M-dwarfs are of intense astrobiological interest because they are the only rocky worlds accessible to biosignature search over the next 10+ years due to a confluence of observational effects. Simultaneously, recent experimental and theoretical work suggests that UV light may have played a key role in the origin of life on Earth, and especially the origin of RNA. Characterizing the UV environment on M-dwarfs planets is important to understanding whether life as we know it could emerge on such worlds. In this work, we couple radiative transfer models to observed M-dwarf spectra to determine the UV environment on prebiotic Earth-analog planets orbiting M-dwarfs. We calculate dose rates to quantify the impact of different host stars on prebiotically-important photoprocesses. We find that M-dwarf planets have access to 100-1000 times less bioactive UV fluence than the young Earth. It is unclear whether UV-sensitive prebiotic chemistry that may have been important to abiogenesis, such as the only known prebiotically plausible pathways for pyrimidine ribonucleotide synthesis, could function on M-dwarf planets. This uncertainty affects objects like the recently-discovered habitable-zone planets orbiting Proxima Centauri, TRAPPIST-1, and LHS 1140. Laboratory studies of the sensitivity of putative prebiotic pathways to irradiation level are required to resolve this uncertainty. If steady-state M-dwarf UV output is insufficient to power these pathways, transient elevated UV irradiation due to flares may suffice; laboratory studies can constrain this possibility as well.         _ Less","","arXiv","https://arxiv.org/abs/1705.02350","3","0","origin_of_life"
"Enhanced interplanetary panspermia in the TRAPPIST-1 system","Abstract:                _is potentially orders of magnitude more likely to occur in the TRAPPIST-1 system compared to the Earth-to-Mars case. As a consequence, we argue that the probability of abiogenesis is enhanced on the TRAPPIST-1 planets compared to the Solar system. By adopting models from theoretical ecology, we show that the number of species transferred and the number of li_         _ More           We present a simple model for estimating the probability of interplanetary panspermia in the recently discovered system of seven planets orbiting the ultracool dwarf star TRAPPIST-1, and find that panspermia is potentially orders of magnitude more likely to occur in the TRAPPIST-1 system compared to the Earth-to-Mars case. As a consequence, we argue that the probability of abiogenesis is enhanced on the TRAPPIST-1 planets compared to the Solar system. By adopting models from theoretical ecology, we show that the number of species transferred and the number of life-bearing planets is also likely to be higher, because of the increased rates of immigration. We propose observational metrics for evaluating whether life was initiated by panspermia on multiple planets in the TRAPPIST-1 system. These results are also applicable to habitable exoplanets and exomoons in other planetary systems.         _ Less","","arXiv","https://arxiv.org/abs/1703.00878","1","0","origin_of_life"
"Habitability properties of circumbinary planets","Abstract:                _concentrated on particular classes of CBP-MS, and life on Earth is an outlier, in this sense. In this scenario, Lathe's mechanism for the tidal 'chain reaction' abiogenesis on Earth is favored as generic for CBP-MS, due to photo-tidal synchronization inherent to them. Problems with this scenario are discussed in detail.         _ More           It is shown that several habitability conditions (in fact, at least seven such conditions) appear to be fulfilled automatically by circumbinary planets of main-sequence stars (CBP-MS), whereas on Earth these conditions are fulfilled only by chance. Therefore, it looks natural that most of the production of replicating biopolymers in the Galaxy is concentrated on particular classes of CBP-MS, and life on Earth is an outlier, in this sense. In this scenario, Lathe's mechanism for the tidal 'chain reaction' abiogenesis on Earth is favored as generic for CBP-MS, due to photo-tidal synchronization inherent to them. Problems with this scenario are discussed in detail.         _ Less","","arXiv","https://arxiv.org/abs/1701.03475","1","0","origin_of_life"
"Atmospheric Constraints on the Surface UV Environment of Mars at 3.9 Ga Relevant to Prebiotic Chemistry","Abstract:                _meaning that their presence affects prebiotic pathways in different ways. In particular, high SO2 environments may admit UV fluence that favors pathways conducive to abiogenesis over pathways unfavorable to it. However, better measurements of the spectral quantum yields of these pathways are required to evaluate this hypothesis definitively.         _ More           Recent findings suggest Mars may have been a clement environment for the emergence of life, and may even have compared favorably to Earth in this regard. These findings have revived interest in the hypothesis that prebiotically important molecules or even nascent life may have formed on Mars and been transferred to Earth. UV light plays a key role in prebiotic chemistry. Characterizing the early Martian surface UV environment is key to understanding how Mars compares to Earth as a venue for prebiotic chemistry.   Here, we present two-stream multi-layer calculations of the UV surface radiance on Mars at 3.9 Ga, to constrain the surface UV environment as a function of atmospheric state. We explore a wide range of atmospheric pressures, temperatures and compositions, corresponding to the diversity of Martian atmospheric states consistent with available constraints. We include the effects of clouds and dust. We calculate dose rates to quantify the effect of different atmospheric states on UV-sensitive prebiotic chemistry.   We find that for normative clear-sky CO2-H2O atmospheres, the UV environment on young Mars is comparable to young Earth. This similarity is robust to moderate cloud cover: thick clouds ($_$>100) are required to significantly affect the Martian UV environment, because cloud absorption is degenerate with atmospheric CO2. On the other hand, absorption from SO2, H2S, and dust is nondegenerate with CO2, meaning if they can build up to high levels, surface UV fluence will be suppressed. These absorbers have spectrally variable absorption, meaning that their presence affects prebiotic pathways in different ways. In particular, high SO2 environments may admit UV fluence that favors pathways conducive to abiogenesis over pathways unfavorable to it. However, better measurements of the spectral quantum yields of these pathways are required to evaluate this hypothesis definitively.         _ Less","","arXiv","https://arxiv.org/abs/1701.01373","3","0","origin_of_life"
"Galactic Distribution of Chirality Sources of Organic Molecules","Abstract:                Conceptualizing planetary habitability depends on understanding how living organisms originated and what features of environments are essential to foster abiogenesis. Estimates of the abundance of life's building blocks are confounded by incomplete knowledge of the role of chirality and racemization in organic compounds in the origination of living organ_         _ More           Conceptualizing planetary habitability depends on understanding how living organisms originated and what features of environments are essential to foster abiogenesis. Estimates of the abundance of life's building blocks are confounded by incomplete knowledge of the role of chirality and racemization in organic compounds in the origination of living organisms. Chirality is an essential feature of enzymes as well as many lock-and-key type structures. There are four known processes that can act on complex organic molecules to promote racemization for abiogenesis: quantum-tunneling effects; selection via interaction with circularly polarized light (CPL); templating processes; and interactions with electrical and magnetic (EM) fields. These occur in different places, respectively: cold interstellar space; regions of space with energetic photons, dust and/or magnetic fields; and mineral surfaces (for both templating and EM fields). Chirality as a feature of terrestrial life suggests neither a special place for local development of homochirality nor for extra-terrestrial enrichment and delivery. The presence of these molecules in three competing scenarios for life's origin - chemical gardens, geothermal fields, and ice substrates - relies on a framework of hypothesis and estimation. An easily-modified worksheet is included in the supplemental material that allows a user to generate different scenarios and data related to the distribution of chiral organic molecules as building blocks for living organisms within the galaxy. A simple hypothetical mechanism for planetary magnetic field reversals, based on a high-density plasma inner core, is also presented as a means to aid in estimating field polarity and hence the orientation of racemization processes based on planetary magnetic fields.         _ Less","","arXiv","https://arxiv.org/abs/1612.06720","1","1","multiple"
"Constraints on the Early Terrestrial Surface UV Environment Relevant to Prebiotic Chemistry","Abstract:                The UV environment is a key boundary condition for the origin of life. However, considerable uncertainty exists as to planetary conditions and hence surface UV at abiogenesis. Here, we present two-stream multi-layer clear-sky calculations of the UV surface radiance on Earth at 3.9 Ga to constrain the UV surface fluence as a function of albedo, solar zenith a_         _ More           The UV environment is a key boundary condition for the origin of life. However, considerable uncertainty exists as to planetary conditions and hence surface UV at abiogenesis. Here, we present two-stream multi-layer clear-sky calculations of the UV surface radiance on Earth at 3.9 Ga to constrain the UV surface fluence as a function of albedo, solar zenith angle (SZA), and atmospheric composition. Variation in albedo and latitude (through SZA) can affect maximum photoreaction rates by a factor of >10.4; for the same atmosphere, photoreactions can proceed an order of magnitude faster at the equator of a snowball Earth than at the poles of a warmer world. Surface conditions are important considerations when computing prebiotic UV fluences. For climatically reasonable levels of CO2, fluence shortward of 189 nm is screened out, meaning that prebiotic chemistry is robustly shielded from variations in UV fluence due to solar flares or variability. Strong shielding from CO2 also means that the UV surface fluence is insensitive to plausible levels of CH4, O2, and O3. At scattering wavelengths, UV fluence drops off comparatively slowly with increasing CO2 levels. However, if SO2 and/or H2S can build up to the 1-100 ppm level as hypothesized by some workers, then they can dramatically suppress surface fluence and hence prebiotic photoprocesses. H2O is a robust UV shield for <198 nm. This means that regardless of the levels of other atmospheric gases, fluence <198 nm is only available for cold, dry atmospheres, meaning sources with emission <198 nm (e.g. ArF eximer lasers) can only be used in simulations of cold environments with low abundance of volcanogenic gases. On the other hand, fluence at 254 nm is unshielded by H2O and is available across a broad range of CO2 columns, meaning that mercury lamps are suitable for initial studies regardless of the uncertainty in primordial H2O and CO2 levels.         _ Less","","arXiv","https://arxiv.org/abs/1610.06223","3","0","origin_of_life"
"Early onset of structural inequality in the formation of collaborative knowledge, Wikipedia","Abstract:                _In particular, the rapid increase in the Gini coefficient suggests that this entrenched inequality stems from the nature of such open-editing communal data sets, namely the abiogenesis of the supereditors' oligopoly. We show that these supereditor groups were created at the early stages of these open-editing media and are still active. Furthermore, our_         _ More           We perform an in-depth analysis on the inequality in 863 Wikimedia projects. We take the complete editing history of 267,304,095 Wikimedia items until 2016, which not only covers every language edition of Wikipedia, but also embraces the complete versions of Wiktionary, Wikisource, Wikivoyage, etc. Our findings of common growth pattern described by the interrelations between four characteristic growth yardsticks suggest a universal law of communal data formation. In this encyclopaedic data set, we observe the interplay between the number of edits and the degree of inequality. In particular, the rapid increase in the Gini coefficient suggests that this entrenched inequality stems from the nature of such open-editing communal data sets, namely the abiogenesis of the supereditors' oligopoly. We show that these supereditor groups were created at the early stages of these open-editing media and are still active. Furthermore, our model considers both short-term and long-term memories to successfully elucidate the underlying mechanism of the establishment of oligarchy in Wikipedia. Our results anticipate a noticeable prospect of such communal databases in the future: the disparity will not be resolved spontaneously.         _ Less","","arXiv","https://arxiv.org/abs/1610.06006","2","1","origin_of_life"
"Influence of the UV Environment on the Synthesis of Prebiotic Molecules","Abstract:                Ultraviolet (UV) radiation is common to most planetary environments, and could play a key role in the chemistry of molecules relevant to abiogenesis (prebiotic chemistry). In this work, we explore the impact of UV light on prebiotic chemistry that might occur in liquid water on the surface of a planet with an atmosphere. We consider effects including atmosph_         _ More           Ultraviolet (UV) radiation is common to most planetary environments, and could play a key role in the chemistry of molecules relevant to abiogenesis (prebiotic chemistry). In this work, we explore the impact of UV light on prebiotic chemistry that might occur in liquid water on the surface of a planet with an atmosphere. We consider effects including atmospheric absorption, attenuation by water, and stellar variability to constrain the UV input as a function of wavelength. We conclude that the UV environment would be characterized by broadband input, and wavelengths below 204 nm and 168 nm would be shielded out by atmospheric CO2 and water, respectively. We compare this broadband prebiotic UV input to the narrowband UV sources (e.g. mercury lamps) often used in laboratory studies of prebiotic chemistry, and explore the implications for the conclusions drawn from these experiments. We consider as case studies the ribonucleotide synthesis pathway of Powner et al (2009) and the sugar synthesis pathway of Ritson et al (2012). Irradiation by narrowband UV light from a mercury lamp formed an integral component of these studies: we quantitatively explore the impact of more realistic UV input on the conclusions that can be drawn from these experiments. Finally, we explore the constraints solar UV input places on the buildup of prebiotically important feedstock gasses like CH4 and HCN. Our results demonstrate the importance of characterizing the wavelength dependence (action spectra) of prebiotic synthesis pathways to determine how pathways derived under laboratory irradiation conditions will function under planetary prebiotic conditions.   Keywords: Laboratory Investigations; Origin of Life; Planetary Environments; UV Radiation; RNA World         _ Less","","arXiv","https://arxiv.org/abs/1511.00698","4","0","origin_of_life"
"Sustainability of Transient Kinetic Regimes and Origins of Death","Abstract:                _recognized that a distinguishing feature of life is its peculiar capability to avoid equilibration. The origin of this capability and its evolution along the timeline of abiogenesis is not yet understood. We propose to study an analog of this phenomenon that could emerge in non-biological systems. To this end, we introduce the concept of sustainability of tr_         _ More           It is generally recognized that a distinguishing feature of life is its peculiar capability to avoid equilibration. The origin of this capability and its evolution along the timeline of abiogenesis is not yet understood. We propose to study an analog of this phenomenon that could emerge in non-biological systems. To this end, we introduce the concept of sustainability of transient kinetic regimes. This concept is illustrated via investigation of cooperative effects in an extended system of compartmentalized chemical oscillators under batch and semi-batch conditions. The computational study of a model system shows robust enhancement of lifetimes of the decaying oscillations which translates into the evolution of the survival function of the transient non-equilibrium regime. This model does not rely on any form of replication. Rather, it explores the role of a structured effective environment as a contributor to the system-bath interactions that define non-equilibrium regimes. We implicate the noise produced by the effective environment of a compartmentalized oscillator as the cause of the lifetime extension.         _ Less","","arXiv","https://arxiv.org/abs/1507.06160","1","1","multiple"
"The Lipid-RNA World","Abstract:                The simplest possible beginning of abiogenesis has been a riddle from the last century, which is most successfully solved by the Lipid World hypothesis. However, origin of the next stages of evolution starting form lipids is still in dark. We propose a 'Lipid-RNA World Scenario' based on the assumption that modern stable lipid-RNA interactions are mo_         _ More           The simplest possible beginning of abiogenesis has been a riddle from the last century, which is most successfully solved by the Lipid World hypothesis. However, origin of the next stages of evolution starting form lipids is still in dark. We propose a 'Lipid-RNA World Scenario' based on the assumption that modern stable lipid-RNA interactions are molecular fossils of an ancient stage of evolution when RNA World originated from Lipid World. In accordance to the faint young sun conditions, we present an 'ice-covered hydrothermal vent' model of Hadean Ocean. Our hypothetical model suggests that faint young sun condition probably provided susceptible physical conditions for an evolutionary route from Lipid-World to Protein-RNA World, through an intermediate Lipid-RNA World. Ancient ribozymes were 'protected' by lipids assuring their survival in prebiotic ocean. The origin of natural selection ensures transition of Lipid-RNA World to Protein-RNA World after the origin of ribosome. Assuming the modern peptidyltransferase as the proto-ribosome structure, we have presented a hypothetical translation mechanism: proto-ribosome randomly polymerized amino acids being attached to the inner layer of a lipid-vesicle, using only physical energies available from our Hadean Ocean model. In accordance to the strategy of chemical evolution, we also have described the possible evolutionary behavior of this proto-ribosome, which explains the contemporary three-dimensional structure of 50S subunit and supports the predictions regarding the ancient regions of it. It also explains the origin of membrane-free 'minimal ribosome' in the time of LUCA.         _ Less","","arXiv","https://arxiv.org/abs/1211.0413","6","2","origin_of_life"
"Three-stage Origin of Life as a Result of Directional Darwinian Evolution","Abstract:                _origin of life (TOL) on the Earth is developed and discussed. The role of the temperature factor in life origin is considered. It is supposed, that three stages of abiogenesis (DNA world, RNA world and the Protein world) consistently followed each other during Darwinian evolution. At the same time, the natural directional selection of the most stable macromo_         _ More           The original hypothesis about Three-stage origin of life (TOL) on the Earth is developed and discussed. The role of the temperature factor in life origin is considered. It is supposed, that three stages of abiogenesis (DNA world, RNA world and the Protein world) consistently followed each other during Darwinian evolution. At the same time, the natural directional selection of the most stable macromolecules and effective catalytic reactions took place. The direction of this selection is related to action of the principle of _Increasing Independence from the Environment_ (IIE) and is caused by temperature evolution of the atmosphere of the Earth. The direction of Anagenesis and inevitability of occurrence of genetic mechanisms is discussed.         _ Less","","arXiv","https://arxiv.org/abs/1201.0384","3","1","origin_of_life"
"The Biological Big Bang: The First Oceans of Primordial Planets at 2-8 Million Years Explain Hoyle/Wickramasinghe Cometary Panspermia","Abstract:                _froze. HGD cosmology explains, very naturally, the Hoyle/Wickramasinghe concept of cometary panspermia by giving a vast, hot, nourishing, cosmological primordial soup for abiogenesis, and the means for transmitting the resulting life forms and their evolving chemical mechanisms widely throughout the universe. A primordial astrophysical basis is provided for_         _ More           Hydrogravitional-dynamics (HGD) cosmology of Gibson/Schild 1996 predicts that the primordial H-He^4 gas of big bang nucleosynthesis became proto-globular-star-cluster clumps of Earth-mass planets at 300 Kyr. The first stars formed from mergers of these 3000 K gas planets. Chemicals C, N, O, Fe etc. created by stars and supernovae then seeded many of the reducing hydrogen gas planets with oxides to give them hot water oceans with metallic iron-nickel cores. Water oceans at critical temperature 647 K then hosted the first organic chemistry and the first life, distributed to the 10^80 planets of the cosmological big bang by comets produced by the new (HGD) planet-merger star formation mechanism. The biological big bang scenario occurs between 2 Myr when liquid oceans condensed and 8 Myr when they froze. HGD cosmology explains, very naturally, the Hoyle/Wickramasinghe concept of cometary panspermia by giving a vast, hot, nourishing, cosmological primordial soup for abiogenesis, and the means for transmitting the resulting life forms and their evolving chemical mechanisms widely throughout the universe. A primordial astrophysical basis is provided for astrobiology by HGD cosmology. Concordance _CDMHC cosmology is rendered obsolete by the observation of complex life on Earth.         _ Less","","arXiv","https://arxiv.org/abs/1109.1262","2","0","origin_of_life"
"Bayesian analysis of the astrobiological implications of life's early emergence on Earth","Abstract:                _had cooled to the point that it could support water-based organisms on its surface. The early emergence of life on Earth has been taken as evidence that the probability of abiogenesis is high, if starting from young-Earth-like conditions. We revisit this argument quantitatively in a Bayesian statistical framework. By constructing a simple model of the probab_         _ More           Life arose on Earth sometime in the first few hundred million years after the young planet had cooled to the point that it could support water-based organisms on its surface. The early emergence of life on Earth has been taken as evidence that the probability of abiogenesis is high, if starting from young-Earth-like conditions. We revisit this argument quantitatively in a Bayesian statistical framework. By constructing a simple model of the probability of abiogenesis, we calculate a Bayesian estimate of its posterior probability, given the data that life emerged fairly early in Earth's history and that, billions of years later, curious creatures noted this fact and considered its implications. We find that, given only this very limited empirical information, the choice of Bayesian prior for the abiogenesis probability parameter has a dominant influence on the computed posterior probability. Although terrestrial life's early emergence provides evidence that life might be common in the Universe if early-Earth-like conditions are, the evidence is inconclusive and indeed is consistent with an arbitrarily low intrinsic probability of abiogenesis for plausible uninformative priors. Finding a single case of life arising independently of our lineage (on Earth, elsewhere in the Solar System, or on an extrasolar planet) would provide much stronger evidence that abiogenesis is not extremely rare in the Universe.         _ Less","","arXiv","https://arxiv.org/abs/1107.3835","3","0","origin_of_life"
"Origin of Life","Abstract:                _the Earth and elsewhere in the Universe, the issue remains far from a tangible solution. This paper examines the various prevailing hypotheses regarding origin of life like abiogenesis, RNA World, Iron-sulphur World, and panspermia; and concludes that delivery of life-bearing organic molecules by the comets in the early epoch of the Earth alone possibly was_         _ More           The evolution of life has been a big enigma despite rapid advancements in the fields of biochemistry, astrobiology, and astrophysics in recent years. The answer to this puzzle has been as mind-boggling as the riddle relating to evolution of Universe itself. Despite the fact that panspermia has gained considerable support as a viable explanation for origin of life on the Earth and elsewhere in the Universe, the issue remains far from a tangible solution. This paper examines the various prevailing hypotheses regarding origin of life like abiogenesis, RNA World, Iron-sulphur World, and panspermia; and concludes that delivery of life-bearing organic molecules by the comets in the early epoch of the Earth alone possibly was not responsible for kick-starting the process of evolution of life on our planet.         _ Less","","arXiv","https://arxiv.org/abs/0907.3552","3","1","origin_of_life"
"The Chirality Of Life: From Phase Transitions To Astrobiology","Abstract:                _life elsewhere in the universe is a pivotal question in modern science. However, to address whether life is common in the universe we must first understand the likelihood of abiogenesis by studying the origin of life on Earth. A key missing piece is the origin of biomolecular homochirality: permeating almost every life-form on Earth is the presence of exclus_         _ More           The search for life elsewhere in the universe is a pivotal question in modern science. However, to address whether life is common in the universe we must first understand the likelihood of abiogenesis by studying the origin of life on Earth. A key missing piece is the origin of biomolecular homochirality: permeating almost every life-form on Earth is the presence of exclusively levorotary amino acids and dextrorotary sugars. In this work we discuss recent results suggesting that life's homochirality resulted from sequential chiral symmetry breaking triggered by environmental events in a mechanism referred to as punctuated chirality. Applying these arguments to other potentially life-bearing platforms has significant implications for the search for extraterrestrial life: we predict that a statistically representative sampling of extraterrestrial stereochemistry will be racemic on average.         _ Less","","arXiv","https://arxiv.org/abs/0811.1291","2","0","origin_of_life"
"The Implications of the Early Formation of Life on Earth","Abstract:                _surprisingly short length of time it took for life to arise on Earth. Previous authors have analysed this information, concluding that it is evidence that the probability of abiogenesis is moderate ($>$ 13% with 95% probability) and cannot be extremely small. In this paper I use simple probabilistic model to show that this conclusion was based more on an_         _ More           One of the most interesting unsolved questions in science today is the question of life on other planets. At the present time it is safe to say that we do not have much of an idea as to whether life is common or exceedingly rare in the universe, and this will probably not be solved for certain unless definitive evidence of extraterrestrial life is found in the future. Our presence on Earth is just as consistent with the hypothesis that life is extremely rare as it is with the hypothesis that it is common, since if there was only one planet with intelligent life, we would find ourselves on it. However, we have more information than this, such as the the surprisingly short length of time it took for life to arise on Earth. Previous authors have analysed this information, concluding that it is evidence that the probability of abiogenesis is moderate ($>$ 13% with 95% probability) and cannot be extremely small. In this paper I use simple probabilistic model to show that this conclusion was based more on an unintentional assumption than on the data. While the early formation of life on Earth provides some evidence in the direction of life being common, it is far from conclusive, and in particular does not rule out the possibility that abiogenesis has only occurred once in the history of the universe.         _ Less","","arXiv","https://arxiv.org/abs/0807.4969","2","0","origin_of_life"
"Thermodynamic properties of an ideal Quark-Gluon plasma under quantum gravitational effects","Abstract:                In this study, we investigate the thermodynamic properties of an ideal Quark-Gluon Plasma (QGP) at a vanishing chemical potential, under the influence of quantum gravitational effects, specifically incorporating the Linear-Quadratic Generalized Uncertainty Principle (LQGUP). We analyze the impact of LQGUP on key thermodynamic quantities, including the grand_         _ More           In this study, we investigate the thermodynamic properties of an ideal Quark-Gluon Plasma (QGP) at a vanishing chemical potential, under the influence of quantum gravitational effects, specifically incorporating the Linear-Quadratic Generalized Uncertainty Principle (LQGUP). We analyze the impact of LQGUP on key thermodynamic quantities, including the grand canonical potential, pressure, energy density, entropy, speed of sound, and the bulk viscosity's response to changes in the speed of sound. Furthermore, we extend our analysis to examine the time evolution of the universe's temperature in the presence of LQGUP effects.         _ Less","","arXiv","https://arxiv.org/abs/2501.01159","0","1","synthetic_biology"
"AI and Quantum Computing in Binary Photocatalytic Hydrogen Production","Abstract:                Photocatalytic water splitting has emerged as a sustainable pathway for hydrogen production, leveraging sunlight to drive chemical reactions. This review explores the integration of density functional theory (DFT) with machine learning (ML) to accelerate the discovery, optimization, and design of photocatalysts. DFT provides quantum-mechanical insights into_         _ More           Photocatalytic water splitting has emerged as a sustainable pathway for hydrogen production, leveraging sunlight to drive chemical reactions. This review explores the integration of density functional theory (DFT) with machine learning (ML) to accelerate the discovery, optimization, and design of photocatalysts. DFT provides quantum-mechanical insights into electronic structures and reaction mechanisms, while ML algorithms enable high-throughput analysis of material properties, prediction of catalytic performance, and inverse design. This paper emphasizes advancements in binary photocatalytic systems, highlighting materials like $TiO_2$, $BiVO_4$, and $g-C_3N_4$, as well as novel heterojunctions and co-catalysts that improve light absorption and charge separation efficiency. Key breakthroughs include the use of ML architectures such as random forests, support vector regression, and neural networks, trained on experimental and computational datasets to optimize band gaps, surface reactions, and hydrogen evolution rates. Emerging techniques like quantum machine learning (QML) and generative models (GANs, VAEs) demonstrate the potential to explore hypothetical materials and enhance computational efficiency. The review also highlights advanced light sources, such as tunable LEDs and solar simulators, for experimental validation of photocatalytic systems. Challenges related to data standardization, scalability, and interpretability are addressed, proposing collaborative frameworks and open-access repositories to democratize DFT-AI tools. By bridging experimental and computational methodologies, this synergistic approach offers transformative potential for achieving scalable, cost-effective hydrogen production, paving the way for sustainable energy solutions.         _ Less","","arXiv","https://arxiv.org/abs/2501.00575","1","2","synthetic_biology"
"Mathematical modelling of flow and adsorption in a gas chromatograph","Abstract:                In this paper, a mathematical model is developed to describe the evolution of the concentration of compounds through a gas chromatography column. The model couples mass balances and kinetic equations for all components. Both single and multiple-component cases are considered with constant or variable velocity. Non-dimensionalisation indicates the small effec_         _ More           In this paper, a mathematical model is developed to describe the evolution of the concentration of compounds through a gas chromatography column. The model couples mass balances and kinetic equations for all components. Both single and multiple-component cases are considered with constant or variable velocity. Non-dimensionalisation indicates the small effect of diffusion. The system where diffusion is neglected is analysed using Laplace transforms. In the multiple-component case, it is demonstrated that the competition between the compounds is negligible and the equations may be decoupled. This reduces the problem to solving a single integral equation to determine the concentration profile for all components (since they are scaled versions of each other). For a given analyte, we then only two parameters need to be fitted to the data. To verify this approach, the full governing equations are also solved numerically using the finite difference method and a global adaptive quadrature method to integrate the Laplace transformation. Comparison with the Laplace solution verifies the high degree of accuracy of the simpler Laplace form. The Laplace solution is then verified against experimental data from BTEX chromatography. This novel method, which involves solving a single equation and fitting parameters in pairs for individual components, is highly efficient. It is significantly faster and simpler than the full numerical solution and avoids the computationally expensive methods that would normally be used to fit all curves at the same time.         _ Less","","arXiv","https://arxiv.org/abs/2501.00001","1","1","multiple"
"Co-diffusion of hydrogen and oxygen for dense oxyhydride synthesis","Abstract:                _their mechanism remains challenging due to the difficulty in oxyhydride synthesis involving the trade-off between achieving density sintering and preventing hydrogen evolution. High-temperature treatments, often required to reduce intergranular resistance, typically cause hydrogen_         _ More           Oxyhydrides are gaining attention for their diverse functionality. However, evaluating electron, ion, and phonon transport properties and comprehending their mechanism remains challenging due to the difficulty in oxyhydride synthesis involving the trade-off between achieving density sintering and preventing hydrogen evolution. High-temperature treatments, often required to reduce intergranular resistance, typically cause hydrogen evolution before sufficient sintering. Instead of a post-annealing process aiming for strong chemical connections between oxyhydride particles, this research demonstrates a novel synthesis technique that converts pre-sintered bulk oxides into oxyhydrides while preserving the dense state. The process employs a high-pressure diffusion control method, facilitating the co-diffusion of hydride and oxide ions.         _ Less","","arXiv","https://arxiv.org/abs/2412.21086","0","1","synthetic_biology"
"Investigating chemical variations between interstellar gas clouds in the Solar neighbourhood","Abstract:                The interstellar medium (ISM) is a fundamental component of the Milky Way. Studying its chemical composition and the level of its_         _ More           The interstellar medium (ISM) is a fundamental component of the Milky Way. Studying its chemical composition and the level of its chemical diversity gives us insight into the evolution of the Milky Way and the role of gas in the Galactic environment. In this paper, we use a novel simulation technique to model the distribution of total hydrogen between gas components, and therefore derive new constraints on the dust depletion and metallicity. We study individual gas components along the lines of sight towards eight bright O/B stars within 1.1 kpc of the Sun using high-resolution HST/STIS absorption spectra (R sim 114 000). We measure the level of dust depletion for these individual components and find components with higher levels of dust depletion compared to Milky Way sightlines in the literature. We find large ranges in the level of dust depletion among components along lines of sight, up to 1.19 dex. Although it is not possible to directly measure the metallicity of individual components due to the saturated and damped Ly-alpha line, we investigate possible metallicity ranges for individual gas components by exploring many different distributions of the total hydrogen gas between components. We select possible combinations of these gas fractions which produce the minimum metallicity difference between components, and for these cases we determine individual metallicities to accuracies that range between sim 0.1 to 0.4 dex. This work shows that full line-of-sight analyses wash out the level of diversity along lines of sight, and that component-by-component studies give a more in-depth understanding of the chemical intricacies of the interstellar medium.         _ Less","","arXiv","https://arxiv.org/abs/2412.18986","0","1","synthetic_biology"
"Inferring intermediate states by leveraging the many-body Arrhenius law","Abstract:                _states appear as long-lived intermediate states in various natural transport phenomena which are governed by energy landscapes. Moreover, they dominate a system's evolution in deciding the selective outcome or shedding light on the preferred mechanism on how a system explores the energy landscape. It is thus crucial to develop techniques to quantify thes_         _ More           Metastable states appear as long-lived intermediate states in various natural transport phenomena which are governed by energy landscapes. Moreover, they dominate a system's evolution in deciding the selective outcome or shedding light on the preferred mechanism on how a system explores the energy landscape. It is thus crucial to develop techniques to quantify these metastabilities hence uncovering key details of the energy landscape. Here, we propose a powerful method by leveraging a many-body Arrhenius law that detects the metastabilites in an escape problem, involving interacting particles with excluded volume confined to a complex energy landscape. Observing transport in colloidal systems or translocation of macromolecules through biological pores can be an ideal test bed to verify our results.         _ Less","","arXiv","https://arxiv.org/abs/2412.18574","0","1","synthetic_biology"
"Spectro-temporal symmetry in action-detected optical spectroscopy: highlighting excited-state dynamics in large systems","Abstract:                Multidimensional optical spectroscopy observes transient excitation dynamics through the time evolution of spectral correlations. Its action-detected variants offer several advantages over the coherent detection and are thus becoming increasingly widespread. Nevertheless, a drawback of action-detected spectra is the presence of a large stationary background_         _ More           Multidimensional optical spectroscopy observes transient excitation dynamics through the time evolution of spectral correlations. Its action-detected variants offer several advantages over the coherent detection and are thus becoming increasingly widespread. Nevertheless, a drawback of action-detected spectra is the presence of a large stationary background of so-called incoherent mixing of excitations from independent states that resembles a product of ground-state absorption spectra and obscures the excited-state signal. This issue is especially problematic in fluorescence-detected two-dimensional electronic spectroscopy (F-2DES) and fluorescence-detected pump--probe spectroscopy (F-PP) of extended systems, where large incoherent mixing arises from efficient exciton--exciton annihilation. In this work, we demonstrate on the example of F-2DES and F-PP an inherent spectro-temporal symmetry of action-detected spectra, which allows general, system-independent subtraction of any stationary signals including incoherent mixing. We derive the expressions for spectra with normal and reversed time ordering of the pulses, relating these to the symmetry of the system response. As we demonstrate both analytically and numerically, the difference signal constructed from spectra with normal and reversed pulse ordering is free of incoherent mixing and highlights the excitation dynamics. We further verify the approach on the experimental F-PP spectra of a molecular squaraine heterodimer and the F-2DES spectra of the photosynthetic antenna LH2 of purple bacteria. The approach is generally applicable to action-detected 2DES and pump--probe spectroscopy without experimental modifications and independent of the studied system, enabling their application to large systems such as molecular complexes.         _ Less","","arXiv","https://arxiv.org/abs/2412.17788","0","1","synthetic_biology"
"A diffuse-interface model for predicting the evolution of metallic negative electrodes and interfacial voids in solid-state batteries with homogeneous and polycrystalline solid electrolyte separators","Abstract:                This paper presents a novel diffuse-interface electrochemical model that simultaneously simulates the evolution of the metallic negative electrode and interfacial voids during the stripping and plating processes in solid-state batteries. The utility and validity of this model are demonstrated for the first time on a cell with a sodium (Na) negative electrode_         _ More           This paper presents a novel diffuse-interface electrochemical model that simultaneously simulates the evolution of the metallic negative electrode and interfacial voids during the stripping and plating processes in solid-state batteries. The utility and validity of this model are demonstrated for the first time on a cell with a sodium (Na) negative electrode and a Na-$_^{\\prime\\prime}$-alumina ceramic solid electrolyte (SE) separator. Three examples are simulated. First, stripping and plating with a perfect electrode/electrolyte interface; second, stripping and plating with a single interfacial void at the electrode/electrolyte interface; third, stripping with multiple interfacial voids. Both homogeneous SE properties and polycrystalline SEs with either low or high conductivity grain boundaries (GBs) are considered for all three examples. Heterogeneous GB conductivity has no significant impact on the behavior with a perfect electrode/electrolyte interface. However, it does result in local changes to void growth due to interactions between the void edge and the GBs. The void growth rate is a linear function of the flux of Na atoms at the void edge, which in turn depends on the applied current density. We also show that the void coalescence rate increases with applied current density and can be marginally influenced by GB conductivity.         _ Less","","arXiv","https://arxiv.org/abs/2412.17147","0","2","synthetic_biology"
"On the Spectral Shape of the Structural Relaxation in Deeply Supercooled Liquids","Abstract:                _behavior and the evolution of the spectral shape towards higher temperatures.         _ More           Structural relaxation in deeply supercooled liquids is non-exponential. In susceptibility representation, $_^{\\prime\\prime}(_)$, the spectral shape of the structural relaxation is observed as an asymmetrically broadened peak with a $_^{1}$ low- and $_^{-_}$ high-frequency behavior. In this perspective article we discuss common notions, recent results and open questions regarding the spectral shape of the structural relaxation. In particular, we focus on the observation that a high-frequency behavior of $_^{-1/2}$ appears to be a generic feature in a broad range of different deeply supercooled liquids. Moreover, we review extensive evidence that contributions from orientational cross-correlations can lead to deviations from the generic spectral shape in certain substances, in particular in dielectric loss spectra. Additionally, intramolecular dynamics can contribute significantly to the spectral shape in substances containing more complex and flexible molecules. Finally, we discuss the open questions regarding potential physical origins of the generic $_^{-1/2}$ behavior and the evolution of the spectral shape towards higher temperatures.         _ Less","","arXiv","https://arxiv.org/abs/2412.17014","1","2","synthetic_biology"
"A multiscale radiation biophysical stochastic model describing the cell survival response at ultra-high dose rate","Abstract:                _we developed the MultiScale Generalized Stochastic Microdosimetric Model (MS-GSM2), a multi-stage extension of the GSM2, which is a probabilistic model describing the time evolution of the DNA damage in an irradiated cell nucleus. The MS-GSM2 can investigate several_         _ More           Ultra-high dose-rate (UHDR) radiotherapy, characterized by an extremely high radiation delivery rate, represents one of the most recent and promising frontier in radiotherapy. UHDR radiotherapy, addressed in the field as FLASH radiotherapy, is a disruptive treatment modality with several benefits, including significantly shorter treatment times, unchanged effectiveness in treating tumors, and clear reductions in side effects on normal tissues. While the benefits of UHDR irradiation have been well highlighted experimentally, the biological mechanism underlying the FLASH effect is still unclear and highly debated. Nonetheless, to effectively use UHDR radiotherapy in clinics, understanding the driving biological mechanism is paramount. Since the concurrent involvement of multiple scales of radiation damage has been suggested, we developed the MultiScale Generalized Stochastic Microdosimetric Model (MS-GSM2), a multi-stage extension of the GSM2, which is a probabilistic model describing the time evolution of the DNA damage in an irradiated cell nucleus. The MS-GSM2 can investigate several chemical species combined effects, DNA damage formation, and time evolution. We demonstrate that the MS-GSM2 can predict various in-vitro UHDR experimental results across various oxygenation levels, radiation types, and energies. The MS-GSM2 can accurately describe the empirical trend of dose and dose rate-dependent cell sensitivity over a wide range, consistently describing multiple aspects of the FLASH effect and reproducing the main evidence from the in-vitro experimental data. Our model also proposes a consistent explanation for the differential outcomes observed in normal tissues and tumors, in-vivo and in-vitro.         _ Less","","arXiv","https://arxiv.org/abs/2412.16322","1","1","multiple"
"A Probabilistic Model to Estimate Number Densities from Column Densities in Molecular Clouds","Abstract:                Constraining the physical and chemical evolution of molecular clouds is essential to our understanding of star formation. These investigations often necessitate knowledge of some local representative number density of the gas along the line of sight. However, constraining the number density is a difficult endeavor. Rob_         _ More           Constraining the physical and chemical evolution of molecular clouds is essential to our understanding of star formation. These investigations often necessitate knowledge of some local representative number density of the gas along the line of sight. However, constraining the number density is a difficult endeavor. Robust constraints of the number density often require line observations of specific molecules along with radiation transfer modeling, which provides densities traced by that specific molecule. Column density maps of molecular clouds are more readily available, with many high-fidelity maps calculated from dust emission and extinction, in particular from surveys conducted with the Herschel Space Observatory. We introduce a new probabilistic model which is based on the assumption that the total hydrogen nuclei column density along a line of sight can be decomposed into a turbulent component and a gravitationally-dominated component. Therefore, for each pixel in a column density map, the line of sight is decomposed into characteristic diffuse (dubbed ``turbulent'') and dense (dubbed ``gravitational'') gas number densities from column density maps. The method thus exploits a physical model of turbulence to decouple the random turbulent column from gas in dense bound structures empirically using the observed column density maps. We find the model produces reasonable turbulent and gravitational densities in the Taurus L1495/B213 and Polaris Flare clouds. The model can also be used to infer an effective attenuating column density into the cloud, which is useful for astrochemical models of the clouds. We conclude by demonstrating an application of this method by predicting the emission of the [C II], [C I], and CO (J = 1-0) lines across the Taurus L1495/B213 region at the native resolution of the column density map utilizing a grid of photodissociation-region models.         _ Less","","arXiv","https://arxiv.org/abs/2412.16290","3","2","origin_of_life"
"Cloud-scale elemental abundance variations and the CO-to-dust-mass conversion factor in M31","Abstract:                _relatively flat, while the Nitrogen gradient is significantly steeper, indicating a higher N/O ratio in M31's inner regions, consistent with recent simulations of galaxy chemical evolution. No strong evidence was found of systematic galaxy-scale trends beyond the radial gradient. After subtracting the radial gradie_         _ More           From a spectroscopic survey of candidate H II regions in the Andromeda galaxy (M31) with MMT/Hectospec, we have identified 294 H II regions using emission line ratios and calculated elemental abundances from strong-line diagnostics (values ranging from sub-solar to super-solar) producing both Oxygen and Nitrogen radial abundance gradients. The Oxygen gradient is relatively flat, while the Nitrogen gradient is significantly steeper, indicating a higher N/O ratio in M31's inner regions, consistent with recent simulations of galaxy chemical evolution. No strong evidence was found of systematic galaxy-scale trends beyond the radial gradient. After subtracting the radial gradient from abundance values, we find an apparently stochastic and statistically significant scatter of standard deviation 0.06 dex, which exceeds measurement uncertainties. One explanation includes a possible collision with M32 200 - 800 Myrs ago. Using the two-point correlation function of the Oxygen abundance, we find that, similar to other spiral galaxies, M31 is well-mixed on sub-kpc scales but less so on larger (kpc) scales, which could be a result of an exponential decrease in mixing speed with spatial scale, and the aforementioned recent merger. Finally, the MMT spectroscopy is complemented by a dust continuum and CO survey of individual Giant Molecular Clouds, conducted with the Submillimeter Array. By combining the MMT and SMA observations, we obtain a unique direct test of the Oxygen abundance dependence of the $_^{\\prime}(^{12}\\mathrm{CO})$ factor which is crucial to convert CO emission to dust mass. Our results suggest that within our sample there is no trend of the $_^{\\prime}(^{12}\\mathrm{CO})$ with Oxygen abundance.         _ Less","","arXiv","https://arxiv.org/abs/2412.16069","2","2","multiple"
"Recovering the properties of the interstellar medium through integrated spectroscopy: application to the z~0 ECO volume-limited star-forming galaxy sample","Abstract:                Deriving physical parameters from integrated galaxy spectra is paramount to interpret the cosmic evolution of star formation, chemical enrichment, and energetic sources. We develop modeling techniques to characterize the ionized gas properties in the subset of 2052 star-forming galaxies from the volume-limited, dwarf-d_         _ More           Deriving physical parameters from integrated galaxy spectra is paramount to interpret the cosmic evolution of star formation, chemical enrichment, and energetic sources. We develop modeling techniques to characterize the ionized gas properties in the subset of 2052 star-forming galaxies from the volume-limited, dwarf-dominated, z~0 ECO catalog. The MULTIGRIS statistical framework is used to evaluate the performance of various models using strong lines as constraints. The reference model involves physical parameters distributed as power-laws with free parameter boundaries. Specifically, we use combinations of 1D photoionization models (i.e., considering the propagation of radiation toward a single cloud) to match optical HII region lines, in order to provide probability density functions of the inferred parameters. The inference predicts non-uniform physical conditions within galaxies. The integrated spectra of most galaxies are dominated by relatively low-excitation gas with a metallicity around 0.3 solar. Using the average metallicity in galaxies, we provide a new fit to the mass-metallicity relationship which is in line with direct abundance method determinations from the calibrated range at low metallicity to stacks at high metallicity. The average metallicity shows a weakly bimodal distribution which may be due related to external (e.g., refueling of non-cluster early-type galaxies above ~10^9.5 solar masses) or internal processes (more efficient star-formation in metal-rich regions). The specific line set used for inference affects the results and we identify potential issues with the use of the [SII] line doublet. Complex modelling approaches are limited by the inherent 1D model database as well as caveats regarding the gas geometry. Our results highlight, however, the possibility to extract useful and significant information from integrated spectra.         _ Less","","arXiv","https://arxiv.org/abs/2412.15860","1","1","multiple"
"Second-law-allowed temporal cooling of the coldest reservoir without external refrigeration","Abstract:                Non-equilibrium quantum thermodynamics is an intensively developing field with many existing applications. We study the dynamics of temperatures and chemical potentials of fermionic reservoirs coupled to an open quantum system. We show that heat transfer from the coldest reservoir to the hottest one is allowed by the Clausius inequality and results in transi_         _ More           Non-equilibrium quantum thermodynamics is an intensively developing field with many existing applications. We study the dynamics of temperatures and chemical potentials of fermionic reservoirs coupled to an open quantum system. We show that heat transfer from the coldest reservoir to the hottest one is allowed by the Clausius inequality and results in transient cooling of the coldest reservoir without additional external refrigeration. We show that during the establishment of thermal and chemical equilibrium, non-monotone evolution of reservoirs' temperatures and chemical potentials is possible, including changes in reservoirs' temperatures and chemical potentials orderliness. Achieved results can be used in the design of quantum thermal machines and nanoelectronic devices.         _ Less","","arXiv","https://arxiv.org/abs/2412.15355","0","1","synthetic_biology"
"Quantum-selected configuration interaction with time-evolved state","Abstract:                _device. Here we propose using a time-evolved state by the target Hamiltonian (for some initial state) as an input of QSCI. Our proposal is based on the intuition that the time evolution by the Hamiltonian creates electron excitations of various orders when applied to the initial state. We numerically investigate the accuracy of the energy obtained by the pro_         _ More           Quantum-selected configuration interaction (QSCI) utilizes an input quantum state on a quantum device to select important bases (electron configurations in quantum chemistry) which define a subspace where we diagonalize a target Hamiltonian, i.e., perform selected configuration interaction, on classical computers. Previous proposals for preparing a good input state, which is crucial for the quality of QSCI, based on optimization of quantum circuits may suffer from optimization difficulty and require many runs of the quantum device. Here we propose using a time-evolved state by the target Hamiltonian (for some initial state) as an input of QSCI. Our proposal is based on the intuition that the time evolution by the Hamiltonian creates electron excitations of various orders when applied to the initial state. We numerically investigate the accuracy of the energy obtained by the proposed method for quantum chemistry Hamiltonians describing electronic states of small molecules. Numerical results reveal that our method can yield sufficiently accurate ground-state energies for the investigated molecules. Our proposal provides a systematic and optimization-free method to prepare the input state of QSCI and could contribute to practical applications of quantum computers to quantum chemistry calculations.         _ Less","","arXiv","https://arxiv.org/abs/2412.13839","0","1","synthetic_biology"
"Hunting pre-stellar cores with APEX: IRAS16293E (Oph464)","Abstract:                Pre-stellar cores are the first steps in the process of star and planet formation. However, the dynamical and chemical evolution of pre-stellar cores is still not well understood. We aim at estimating the central density of the pre-stellar core IRAS16293E and at carrying out an inventory of molecular species towards th_         _ More           Pre-stellar cores are the first steps in the process of star and planet formation. However, the dynamical and chemical evolution of pre-stellar cores is still not well understood. We aim at estimating the central density of the pre-stellar core IRAS16293E and at carrying out an inventory of molecular species towards the density peak of the core. We observed high-$J$ rotational transitions of N$_2$H$^+$ and N$_2$D$^+$, and several other molecular lines towards the dust emission peak using the Atacama Pathfinder EXperiment (APEX) telescope, and derived the density and temperature profiles of the core using far-infrared surface brightness maps from $Herschel$. The N$_2$H$^+$ and N$_2$D$^+$ lines were analysed by non-LTE radiative transfer modelling. Our best-fit core model consists in a static inner region, embedded in an infalling envelope with an inner radius of approximately 3000 au (21' at 141 pc). The observed high-J lines of N$_2$H$^+$ and N$_2$D$^+$ (with critical densities greater than 10$^6$ cm$^{-3}$) turn out to be very sensitive to depletion; the present single-dish observations are best explained with no depletion of N$_2$H$^+$ and N$_2$D$^+$ in the inner core. The N$_2$D$^+$/N$_2$H$^+$ ratio that best reproduces our observations is 0.44, one of the largest observed to date in pre-stellar cores. Additionally, half of the molecules that we observed are deuterated isotopologues, confirming the high-level of deuteration towards this source. Non-LTE radiative transfer modelling of N$_2$H$^+$ and N$_2$D$^+$ lines proved to be an excellent diagnostic of the chemical structure and dynamics of a pre-stellar core. Probing the physical conditions immediately before the protostellar collapse is a necessary reference for theoretical studies and simulations with the aim of understanding the earliest stages of star and planet formation and the time scale of this process.         _ Less","","arXiv","https://arxiv.org/abs/2412.13760","2","1","origin_of_life"
"Unveiling the formation channels of stellar halos through their chemical fingerprints","Abstract:                _their formation and assembly history. Using simulations, we can trace the origins of different stellar populations in these halos, contributing to our understanding of galaxy evolution. We aim to investigate the assembly of stellar halos and their_         _ More           Stellar halos around galaxies contain key information about their formation and assembly history. Using simulations, we can trace the origins of different stellar populations in these halos, contributing to our understanding of galaxy evolution. We aim to investigate the assembly of stellar halos and their chemical abundances in 28 galaxies from CIELO project with logMgal[9 and 11]Msun. Stellar halos were identified using the AM E method, focusing on the outer regions between the 1.5 optical radius and the virial radius. We divided the stellar populations based on their formation channel: exsitu, endodebris, and insitu, and analyzed their chemical abundances, ages, and spatial distributions. Additionally, we explored correlations between halo mass, metallicity, and alpha element enrichment. CIELO simulations reveal that stellar halos are predominantly composed of accreted material (exsitu and endodebris stars), in agreement with previous works. The mass fraction of these populations is independent of stellar halo mass, though their metallicities scale linearly with it. Exsitu stars tend to dominate the outskirts and be more alpha rich and older, while endodebris stars are more prevalent at lower radii and tend to be less alpha rich and slightly younger. Massive stellar halos require a median of five additional satellites to build 90 percent of their mass, compared to lower mass halos, which typically need fewer (median of 2.5) and lower-mass satellites and are assembled earlier. The diversity of accreted satellite histories results in well defined stellar halo mass metallicity and [alpha/Fe] [Fe/H] relations, offering a detailed view of the chemical evolution and assembly history of stellar halos. We find that the [alpha/Fe] [Fe/H] is more sensitive to the characteristics and star formation history of the contributing satellites than the stellar halo mass metallicity relationship         _ Less","","arXiv","https://arxiv.org/abs/2412.13483","2","2","multiple"
"Explorando el impacto de los gradientes qu_micos en los procesos de mezcla del interior estelar","Abstract:                During the various steps of stellar evolution are formed convectives zones that alter the_         _ More           During the various steps of stellar evolution are formed convectives zones that alter the chemical stratification in stars. Usually, in astrophysics is used the Mixing Length Theory (MLT) for modeling the convective movement and, in general, it is used with the Schwarzschild instability criterion, which neglects the impact of chemical composition gradients in the development of convection. However, towards the end of central helium burning and during the thermal pulses in the Asymptotic Giant Branch (AGB) are produced stratification processes with inversions in the chemical gradient that would produce instabilities beyond the ones predicted by the Schwarzschild criterion. These instabilities would alter the chemical profile in the white dwarfs, with respect to the one predicted by MLT, having observable consequences in the pulsational modes of such objects. In the present work we will explore an extension of MLT in which we will consider the chemical instabilities as generators of convectives and non-convectives instabilities. This theory will be applied in stellar evolution models in comparison with standard MLT and a double diffusive mixing theory, discussing the benefits and shortcomings of each one.         _ Less","","arXiv","https://arxiv.org/abs/2412.13087","0","1","synthetic_biology"
"Control of open quantum systems: Manipulation of a qubit coupled to a thermal bath by an external driving field","Abstract:                _that even in the parameter regime suitable for the application of the Redfield/Lindblad approach, the two methods yield drastically different results when addressing evolution involving mixed states. In particular, we find that, in addition to predicting different optimal driving profiles, a more accurate description of system_         _ More           Fast and reliable manipulation with qubits is fundamental for any quantum technology. The implementation of these manipulations in physical systems is the focus of studies involving optimal control theory. Realistic physical devices are open quantum systems. So far, studies in optimal control theory have primarily utilized the Redfield/Lindblad quantum master equation to simulate the dynamics of such systems. However, this Markov description is not always sufficient. Here, we present a study of qubit control utilizing the nonequilibrium Green's function method. We compare the traditional master equation with more general Green's function results and demonstrate that even in the parameter regime suitable for the application of the Redfield/Lindblad approach, the two methods yield drastically different results when addressing evolution involving mixed states. In particular, we find that, in addition to predicting different optimal driving profiles, a more accurate description of system evolution enables the system to reach the desired final state much more quickly. We argue that the primary reason for this is the significance of the non-Markov description of driven system dynamics due to the effect of time-dependent driving on dissipation.         _ Less","","arXiv","https://arxiv.org/abs/2412.12624","0","1","synthetic_biology"
"Modelling chemical clocks -- Theoretical evidences of the space and time evolution of [s/alpha] in the Galactic disc with Gaia-ESO survey","Abstract:        Chemical clocks based on [s-process elements/alpha-elements] ratios are widely used to estimate ages of Galactic stellar populations. However, the [s/alpha] vs. age relations are not universal, varying with metallicity, location in the Galactic disc, and specific s-process elements. Current Galactic_         _ More   Chemical clocks based on [s-process elements/alpha-elements] ratios are widely used to estimate ages of Galactic stellar populations. However, the [s/alpha] vs. age relations are not universal, varying with metallicity, location in the Galactic disc, and specific s-process elements. Current Galactic chemical evolution models struggle to reproduce the observed [s/alpha] increase at young ages. We provide chemical evolution models for the Milky Way disc to identify the conditions required to reproduce the observed [s/H], [s/Fe], and [s/alpha] vs. age relations. We adopt a multi-zone chemical evolution model including state-of-the-art nucleosynthesis prescriptions for neutron-capture elements (AGB stars, rotating massive stars, neutron star mergers, magneto-driven supernovae). We explore variations in gas infall, AGB yield dependencies on progenitor stars, and rotational velocity distributions for massive stars. Results are compared with open cluster data from the Gaia-ESO survey. A three-infall scenario for disc formation captures the rise of [s/alpha] with age in the outer regions but fails in the inner ones, especially for second s-process peak elements. Ba production in the last 3 Gyr of chemical evolution would need to increase by half to match observations. S-process contributions from low-mass AGB stars improve predictions but require increases not supported by nucleosynthesis calculations, even with potential i-process contribution. Variations in the metallicity dependence of AGB yields show inconsistent effects across elements. Distributions of massive star rotational velocities fail to improve results due to balanced effects on elements. We confirm that there is no single relationship [s/alpha] vs. age, but that it varies along the MW disc. Current prescriptions for neutron-capture element yields cannot fully capture the complexity of evolution, particularly in the inner disc.         _ Less","","arXiv","https://arxiv.org/abs/2412.11844","3","2","origin_of_life"
"Differentiating Confined from Adsorbed Water in Single-Walled Carbon Nanotubes via Electronic Transport","Abstract:                _(CNTFET) constructed with an isolated single carbon nanotube subjected to controlled environments. More precisely, this distinction is made possible by observing the evolution of the transfer characteristic as a function of the electric field imposed by the gate voltage. It appears that the presence of water results in a displacement of the electrical neutra_         _ More           In this article, we show that it is possible to differentiate between water adsorbed on the outside of a single-walled carbon nanotube and that confined inside. To this aim, we measured the electronic transport of a carbon nanotube based field effect transistor (CNTFET) constructed with an isolated single carbon nanotube subjected to controlled environments. More precisely, this distinction is made possible by observing the evolution of the transfer characteristic as a function of the electric field imposed by the gate voltage. It appears that the presence of water results in a displacement of the electrical neutrality point, corresponding to a charge transfer between the nanotube and its environment. Using this approach, we demonstrate the existence of 3 types of water molecules: (i) chemically adsorbed on the SiO\\textsubscript{2} surface of the substrate, i.e., forming silanol groups; (ii) physically adsorbed outside next to the nanotube; and (iii) confined inside the nanotube. The first one can only be eliminated by high temperature treatment under vacuum, the second one desorbs in a moderate vacuum at room temperature, while the confined water can be removed at room temperature at higher vacuum, i.e. $10^{-3}$ mbar. We also observe that both water adsorption outside and water confinement inside the nanotube are spontaneous and rather fast, i.e. less than 1 minute in our experimental conditions, while removing the water adsorbed outside and confined inside takes much longer, i.e. 40-60 minutes, thus indicating that water confinement is thermodynamically favorable. It is also shown that the metallicity of the nanotube has no qualitative influence on its interaction with water. Our results experimentally prove the stronger affinity of water for the inner surface of CNT than for the outer one.         _ Less","","arXiv","https://arxiv.org/abs/2412.11703","0","1","synthetic_biology"
"Structure and Dynamic Evolution of Interfaces between Polymer Solutions and Gels and Polymer Interdiffusion: A Molecular Dynamics Study","Abstract:                _time regimes are observed: An initial compression of the gel caused by the osmotic pressure of the solution, followed by an expansion due to swelling. We characterize the time evolution of density profiles, the penetration of free polymers into the gel and the connection between the gel and solution phase. The interfacial structure locally equilibrates after_         _ More           Letting free polymers diffuse from solution into a crosslinked polymer gel is often a crucial processing step in the synthesis of multiphase polymer-based gels, e.g., core-shell microgels. Here we use coarse-grained molecular dynamics simulations to obtain molecular insights into this process. We consider idealized situations where the gel is modeled as a regular polymer network with the topology of a diamond lattice, and all free polymers and strands have the same length and consist of the same type of monomer. After bringing the gel and the polymer solution into contact, two time regimes are observed: An initial compression of the gel caused by the osmotic pressure of the solution, followed by an expansion due to swelling. We characterize the time evolution of density profiles, the penetration of free polymers into the gel and the connection between the gel and solution phase. The interfacial structure locally equilibrates after roughly 100 chain relaxation times. At late times, the free chains inside the gel undergo a percolation transition if the polymer concentration in the gel exceeds a critical value, which is of the same order as the overlap concentration. The fluctuations of the interface can be described by a capillary wave model that accounts for the elasticity of the gel. Based on this, we extract the interfacial tension of the gel-solution interface. Interestingly, both the interfacial tension and the local interfacial width increase with increasing free polymer concentration - in contrast to liquid-liquid interfaces, where these two quantities are typically anticorrelated.         _ Less","","arXiv","https://arxiv.org/abs/2412.11346","0","1","synthetic_biology"
"The Circumgalactic Medium","Abstract:                _processes. The circumgalactic medium (CGM) contains multiphase gas spanning a broad dynamic range in spatial scale, density, and temperature, with its thermodynamic and chemical properties deeply linked to the star formation histories of galaxies. As a rich laboratory for studying gas physics, the CGM offers unique insights into the processes governing gas c_         _ More           Galaxies are part of a vast cosmic ecosystem, embedded in an extensive gaseous reservoir that regulates their growth by providing the necessary fuel for star formation while preserving a fossil record of past interactions, outflows, and feedback processes. The circumgalactic medium (CGM) contains multiphase gas spanning a broad dynamic range in spatial scale, density, and temperature, with its thermodynamic and chemical properties deeply linked to the star formation histories of galaxies. As a rich laboratory for studying gas physics, the CGM offers unique insights into the processes governing gas cooling, heating, and material transfer between galaxies and their surroundings. Chemical tagging, based on the relative abundances of multiple elements, serves as a powerful timing tool to trace the origin of the gas and connect the stars in the interstellar medium (ISM) to the diffuse CGM. Developing a complete understanding of the CGM and its cosmic evolution requires multi-wavelength observational tools, ranging from X-ray, UV/optical, and sub-mm to radio, to probe this diffuse gas in both absorption and emission.         _ Less","","arXiv","https://arxiv.org/abs/2412.10579","1","2","synthetic_biology"
"The JWST EXCELS survey: direct estimates of C, N, and O abundances in two relatively metal-rich galaxies at $\\mathbf{z\\simeq5}$","Abstract:                _to the majority of local galaxies. In contrast to the top-heavy IMF invoked in some studies to explain low C/N ratios in metal-poor galaxies, we find, via comparison to chemical evolution models, that a standard or bottom-heavy IMF better explains the observed abundance ratios in more enriched systems due to an increas_         _ More           We present a spectroscopic analysis of two star-forming galaxies at z~5 observed with JWST/NIRSpec as part of the Early eXtragalactic Continuum and Emission Line Science (EXCELS) survey. The detection of the C III]$_$1906,09, [O II]$_$3726,29, [O III]$_$4363,5007, and [N II]$_$6584 nebular emission lines enables investigation of the C/O, N/O, and C/N abundance ratios using the temperature-sensitive method. The two galaxies have stellar masses of log($M_{\\star}$/M$_{\\odot}$ ) = 8.13$\\pm$0.09 and log($M_{\\star}$/M$_{\\odot}$ )=8.52$\\pm$0.13 and corresponding metallicities of Z~0.2Z$_{\\odot}$ and Z~0.3Z$_{\\odot}$. These metallicities are somewhat higher than is typical for other z>5 galaxies with similar stellar mass and are in fact comparable to high-redshift analogue galaxies at z~0. Both galaxies display evidence for N/O enhancement with respect to the z~0 sample, with log(N/O)=-1.07$\\pm$0.17 and log(N/O)=-0.86$\\pm$0.15 respectively. In contrast, we find low C abundances, with log(C/O)=-0.82$\\pm$0.22 and log(C/O)=-1.02$\\pm$0.22, consistent with the predicted yields of core-collapse supernovae. Following the trend observed in other high-redshift sources, we find that the C/N ratios are lower at fixed O/H compared to the majority of local galaxies. In contrast to the top-heavy IMF invoked in some studies to explain low C/N ratios in metal-poor galaxies, we find, via comparison to chemical evolution models, that a standard or bottom-heavy IMF better explains the observed abundance ratios in more enriched systems due to an increase in N-enrichment from intermediate mass (4-7M$_{\\odot}$) stars. Our results demonstrate that robust measurements of CNO abundances with JWST can reveal unique enrichment pathways in galaxies as a function of both metallicity and redshift.         _ Less","","arXiv","https://arxiv.org/abs/2412.10557","2","2","multiple"
"3 mm Spectroscopic Observations of Massive Star-Forming Regions with IRAM 30-m","Abstract:                _molecules. The related parameters, such as peak temperature, integrated intensity, and line width of the identified molecular lines were obtained. The line widths of the chemically related molecules show strong positive correlations, suggesting they likely originate from similar gases within star-forming regions. This work highlights the fundamental properti_         _ More           Broadband spectroscopic observations with high sensitivity provide an unbiased way to detect emissions of molecules in space. We present deep observations from ~ 105.8 GHz to 113.6 GHz toward 50 Galactic massive star-forming regions using IRAM 30-m millimeter telescope, with noise levels ranging from 6 to 29 at frequency channel spacing of 195 kHz, which corresponds to ~ 0.54 km/s at 110 GHz. Totally, 27 molecular species have been identified, of which 16 are complex organic molecules. The related parameters, such as peak temperature, integrated intensity, and line width of the identified molecular lines were obtained. The line widths of the chemically related molecules show strong positive correlations, suggesting they likely originate from similar gases within star-forming regions. This work highlights the fundamental properties of the detected molecular lines and offers a valuable dataset for further studies on the astrochemical evolution of molecules in massive star-forming cores.         _ Less","","arXiv","https://arxiv.org/abs/2412.09823","1","1","multiple"
"On the evolutionary nature of massive B-type supergiants: a modern empirical reappraisal using data from IACOB, Gaia and TESS","Abstract:                Massive stars are key contributors to the chemodynamical evolution of galaxies and the Universe. Despite their significance, discrepancies between observational data and theoretical models of massive stars challenge our understanding of these objects. A major uncertainty is the overdensity of B-type supergiants (BSGs) in the Hertzsprung-Russell diagram, wher_         _ More           Massive stars are key contributors to the chemodynamical evolution of galaxies and the Universe. Despite their significance, discrepancies between observational data and theoretical models of massive stars challenge our understanding of these objects. A major uncertainty is the overdensity of B-type supergiants (BSGs) in the Hertzsprung-Russell diagram, where models predict the end of the main sequence phase (or TAMS). Is uncertain whether the TAMS needs to be redefined or if the overdensity results from overlapping populations following different evolutionary paths. Conceived as direct descendants of O-type stars, BSGs may include stars not only evolving in the main sequence but also returning from a post-red supergiant phase. A representative fraction of massive stars are predicted to be products of binary interaction, creating additional evolutionary channels. In addition, some fundamental properties of BSGs such as the spin- and mass-loss rates are not as well constrained as in O-type stars, having a significant impact on massive star evolution. To overcome this situation, statistically significant spectroscopic samples offer a unique opportunity to study the physical and chemical properties of BSGs. Moreover, the advent of space astrometry and photometry missions such as Gaia and TESS has brought a new era for studying additional properties in detail. This thesis comprises the study of 1000 Galactic blue supergiants (O- and B-type) combining multi-epoch high-resolution spectroscopic data from the IACOB project and the ESO archive with Gaia distances and TESS photometry, becoming the largest holistic empirical study of the physical, chemical, and pulsational properties of these objects performed to date. All these properties gathered into a unique volume-limited sample allowed to provide an empirical reassessment of the main properties of BSGs and investigate their intricate nature.         _ Less","","arXiv","https://arxiv.org/abs/2412.09454","0","1","synthetic_biology"
"Chemical Evolution of R-process Elements in Stars (CERES). III. Chemical abundances of neutron capture elements from Ba to Eu","Abstract:                The chemical abundances of elements such as barium and the lanthanides are essential to understand the nucleosynthesis of heavy elements in the early Universe as well as the contribution of different neutron capture processes (for example slow versus rapid) at different epochs. The_         _ More           The chemical abundances of elements such as barium and the lanthanides are essential to understand the nucleosynthesis of heavy elements in the early Universe as well as the contribution of different neutron capture processes (for example slow versus rapid) at different epochs. The Chemical Evolution of R-process Elements in Stars (CERES) project aims to provide a homogeneous analysis of a sample of metal-poor stars ( [Fe/H]\\<-1.5) to improve our understanding of the nucleosynthesis of neutron capture elements, in particular the r-process elements, in the early Galaxy. Our data consist of a sample of high resolution and high signal-to-noise ratio UVES spectra. The chemical abundances were derived through spectrum synthesis, using the same model atmospheres and stellar parameters as derived in the first paper of the CERES series. We measured chemical abundances or upper limits of seven heavy neutron capture elements (Ba, La, Ce, Pr, Nd, Sm, and Eu) for a sample of 52 metal-poor giant stars. We estimated through the mean shift clustering algorithm that at Ba/H =-2.4 and Fe/H =-2.4 a variation in the trend of X/Ba with X=La,Nd,Sm,Eu, versus Ba/H occurs. This result suggests that, for Ba/H $\\<$$-2.4$, Ba nucleosynthesis in the Milky Way halo is primarily due to the $r$-process, while for Ba/H \\<-2.4 the effect of the s-process contribution begins to be visible. In our sample, stars with Ba/Eu compatible with a Solar System pure r-process value (hereafter, r-pure) do not show any particular trend compared to other stars, suggesting r-pure stars may form in similar environments to stars with less pure r-process enrichments. Homogeneous investigations of high resolution and signal-to-noise ratio spectra are crucial for studying the heavy elements formation, as they provide abundances that can be used to test nucleosynthesis models as well as Galactic chemical evolution models.         _ Less","","arXiv","https://arxiv.org/abs/2412.09141","2","1","origin_of_life"
"Chemodynamic evolution of Sun-like stars in nearby moving groups","Abstract:                Sun-like stars are well represented in the solar neighbourhood but are currently under-utilised, with many studies of chemical and kinematic evolution focusing on red giants (which can be observed further away) or turn-off stars (which have well measured ages). Recent surveys (e.g. GALAH) provide spectra for large numb_         _ More           Sun-like stars are well represented in the solar neighbourhood but are currently under-utilised, with many studies of chemical and kinematic evolution focusing on red giants (which can be observed further away) or turn-off stars (which have well measured ages). Recent surveys (e.g. GALAH) provide spectra for large numbers of nearby Sun-like stars, which provides an opportunity to apply our newly developed method for measuring metallicities, temperatures, and surface gravities - the EPIC algorithm - which yields improved ages via isochrone fitting. We test this on moving groups, by applying it to the large GALAH DR3 sample. This defines a sample of 72,288 solar analogue targets for which the stellar parameter measurements are most precise and reliable. These stars are used to estimate, and test the accuracy and precision of, age measurements derived with the SAMD isochrone fitting algorithm. Using these ages, we recover the age-metallicity relationships for nearby (<= 1 kpc) moving groups, traced by solar analogues, and analyse them with respect to the stellar kinematics. In particular, we found that the age-metallicity relationships of all moving groups follows a particular trend of young (age < 6 Gyr) stars having constant metallicity and older (age >= 6 Gyr) stars decreasing in metallicity with increasing age. The Hercules stream carries the highest fraction of metal-rich young stars (~ 0.1 dex) in our sample, which is consistent with a migrating population of stars from the inner Galaxy, and we discuss the possible causes of this migration in the context of our results.         _ Less","","arXiv","https://arxiv.org/abs/2412.09128","1","2","synthetic_biology"
"Towards Galactic Archaeology with Inferred Ages of Giant Stars From Gaia Spectra","Abstract:                _Gyr. Since SIDRA-XP outperforms SIDRA-RVS, we apply SIDRA-XP to analyse the ages for 2,218,154 stars. This allowed us to map the chronological and chemical properties of Galactic disc stars, revealing distinct features such as the Gaia-Sausage-Enceladus merger and a potential gas-rich interaction event linked to the first infall of the Sagittarius dwarf gal_         _ More           In the era of Gaia, the accurate determination of stellar ages is transforming Galactic archaeology. We demonstrate the feasibility of inferring stellar ages from Gaia's RVS spectra and the BP/RP (XP) spectrophotometric data, specifically for red giant branch and high-mass red clump stars. We successfully train two machine learning models, dubbed SIDRA: Stellar age Inference Derived from Gaia spectRA to predict the age. The SIDRA-RVS model uses the RVS spectra and SIDRA-XP the stellar parameters obtained from the XP spectra by Fallows and Sanders 2024. Both models use BINGO, an APOGEE-derived stellar age from Ciuca et al. 2021 as the training data. SIDRA-RVS estimates ages of stars whose age is around $__\\mathrm{BINGO}=10$ Gyr with a standard deviation of residuals of $\\sim$ 0.12 dex in the unseen test dataset, while SIDRA-XP achieves higher precision with residuals $\\sim$ 0.064 dex for stars around $__\\mathrm{BINGO}=10$ Gyr. Since SIDRA-XP outperforms SIDRA-RVS, we apply SIDRA-XP to analyse the ages for 2,218,154 stars. This allowed us to map the chronological and chemical properties of Galactic disc stars, revealing distinct features such as the Gaia-Sausage-Enceladus merger and a potential gas-rich interaction event linked to the first infall of the Sagittarius dwarf galaxy. This study demonstrates that machine learning techniques applied to Gaia's spectra can provide valuable age information, particularly for giant stars, thereby enhancing our understanding of the Milky Way's formation and evolution.         _ Less","","arXiv","https://arxiv.org/abs/2412.09040","1","1","multiple"
"Mountain pine beetle struggles with jack pine: A mechanistic explanation for slowed range expansion in Alberta","Abstract:                _jack pine's phenotype itself is the primary impediment. We propose that jack pine's smaller size, thinner phloem, and lower monoterpene concentrations result in weaker chemical cues during the host-finding and mass-attack stages of MPB's life cycle, ultimately leading to fewer successful attacks. These findings suggest a reduced risk of further e_         _ More           Following widespread outbreaks across western North America, mountain pine beetle recently expanded its range from British Columbia into Alberta. However, mountain pine beetle's eastward expansion across Canada has stalled unexpectedly, defying predictions of rapid spread through jack pine, a novel host tree. This study investigates the underlying causes of this deceleration using an integrative approach combining statistical modeling, simulations, and experimental data. We find that the slow spread is primarily due to mountain pine beetle's difficulty in finding and successfully attacking jack pine trees, rather than issues with reproduction or larval development. The underlying mechanism impeding beetle range expansion has been hypothesized to be lower pine volumes in eastern forests, which are primarily a consequence of lower stem density. However, our analysis suggests that jack pine's phenotype itself is the primary impediment. We propose that jack pine's smaller size, thinner phloem, and lower monoterpene concentrations result in weaker chemical cues during the host-finding and mass-attack stages of MPB's life cycle, ultimately leading to fewer successful attacks. These findings suggest a reduced risk of further eastward spread, but should be interpreted cautiously due to enormous policy implications and the inherent limitations of ecological forecasting.         _ Less","","arXiv","https://arxiv.org/abs/2412.08778","0","1","synthetic_biology"
"Yields from massive stars in binaries. Chemical evolution of the Milky Way disk","Abstract:                A large fraction of massive stars in the Galaxy reside in binary systems and their evolution is different from that of single stars. The yields of massive stars, which are the main responsible for the production of metals, can be therefore affected by the binary nature of the systems. Recently, Farmer et al. (2023) computed new grids of yields for single and_         _ More           A large fraction of massive stars in the Galaxy reside in binary systems and their evolution is different from that of single stars. The yields of massive stars, which are the main responsible for the production of metals, can be therefore affected by the binary nature of the systems. Recently, Farmer et al. (2023) computed new grids of yields for single and binary-stripped massive stars with solar chemical composition. The main purpose of this paper is to test these yields on the chemical evolution of Galactic stars. To do that, we adopt well-tested chemical evolution models for the Milky Way disk, implementing both yields for single and binary-stripped massive stars. In particular, we assume different percentages of massive binary systems within the initial mass function. We compute the evolution of 22 chemical species starting from $^{4}$He to $^{64}$Zn. Our main results can be summarized as follows: i) when adopting the yields of Farmer et al. (2023), large differences are found relative to the predicted solar abundances by chemical evolution models adopting 'standard' massive star yields from the literature for $^{12}$C, $^{14}$N, $^{24}$Mg, $^{39}$K, $^{40}$Ca, $^{55}$Mn and $^{59}$Co. Generally, the yields for single stars reproduce slightly better the observed solar abundances, although for several elements a large fraction of binaries helps in reproducing the observations; ii) different fractions of massive binaries (from 50% to 100%) produce negligible differences in the predicted solar abundances, whereas the differences are more marked between models with and without binary-stripped stellar yields; iii) for the [X/Fe] vs. [Fe/H] relations, the yields including massive stars in binaries produce the best results for $^{52}$Cr, while for $^{12}$C, $^{39}$K, $^{40}$Ca and $^{24}$Mg the best results are obtained with Farmer's yields with no binaries.         _ Less","","arXiv","https://arxiv.org/abs/2412.07845","1","1","multiple"
"Hamiltonian simulation-based quantum-selected configuration interaction for large-scale electronic structure calculations with a quantum computer","Abstract:                Quantum-selected configuration interaction (QSCI) is one of the most promising approaches for quantum chemical calculations with the current pre-fault tolerant quantum computers. In the conventional QSCI, the Slater determinants used for the wave function expansion are sampled by iteratively performing approximate wave function preparation and subsequent mea_         _ More           Quantum-selected configuration interaction (QSCI) is one of the most promising approaches for quantum chemical calculations with the current pre-fault tolerant quantum computers. In the conventional QSCI, the Slater determinants used for the wave function expansion are sampled by iteratively performing approximate wave function preparation and subsequent measurement in the computational basis, and then the subspace Hamiltonian matrix is diagonalized on a classical computer. In this approach, the preparation of a high-quality approximate wave function is necessary to compute total energies accurately. In this work, we propose a Hamiltonian simulation-based QSCI (HSB-QSCI) to avoid this difficulty. In the HSB-QSCI, the Slater determinants are sampled from quantum states generated by the real-time evolution of approximate wave functions. We provide numerical simulations for the spin-singlet ground state and the first excited spin-triplet state of oligoacenes (benzene, naphthalene, and anthracene), phenylene-1,4-dinitrene, and hexa-1,2,3,4,5-pentaene molecules; these results reveal that the HSB-QSCI is applicable not only to molecules where the Hartree--Fock provides a good approximation of the ground state, but also to strongly correlated systems with multiconfigurational characteristics (i.e., the case where preparing a high-quality approximate wave function is hard). We have also numerically confirmed that the HSB-QSCI is robust to approximation errors of the Hamiltonian simulation, such as Trotter errors and the truncation errors of Hamiltonian term by maximum locality in the localized molecular orbital basis. Hardware demonstrations of the HSB-QSCI are also reported for the hexa-1,2,3,4,5-pentaene molecule using 20 qubits IBM superconducting device. The differences between the HSB-QSCI energy and the CAS-CI value are at most 0.15 kcal mol$^{-1}$, achieving chemical precision.         _ Less","","arXiv","https://arxiv.org/abs/2412.07218","0","1","synthetic_biology"
"The Pristine Inner Galaxy Survey (PIGS) XI: Revealing the chemical evolution of the interacting Sagittarius dwarf galaxy","Abstract:                _tidal interactions with our Galaxy. Its accretion history has led to a distinct stellar overdensity, which is the remnant of the core of the progenitor. We present a complete chemical analysis of 111 giant stars in the core of Sgr dSph to investigate the chemical evolution and en_         _ More           The Sagittarius dwarf spheroidal galaxy (Sgr dSph) is a satellite orbiting the Milky Way that has experienced multiple stripping events due to tidal interactions with our Galaxy. Its accretion history has led to a distinct stellar overdensity, which is the remnant of the core of the progenitor. We present a complete chemical analysis of 111 giant stars in the core of Sgr dSph to investigate the chemical evolution and enrichment history of this satellite. Employing the metallicity-sensitive Ca H&K photometry from the Pristine Inner Galaxy Survey, we selected stars spanning a wide metallicity range and obtained high-resolution spectra with the ESO FLAMES/GIRAFFE multi-object spectrograph. For the stellar sample covering $-2.13 < \\rm{[Fe/H] < -0.35}$, we derived abundances for up to 14 chemical elements with average uncertainties of $\\sim 0.09$ dex and a set of stellar ages which allowed us to build an age-metallicity relation (AMR) for the entire sample. With the most comprehensive set of chemical species measured for the core of Sgr, we studied several [X/Fe] ratios. Most trends align closely with Galactic chemical trends, but notable differences emerge in the heavy $n$-capture elements, which offer independent insights into the star formation history of a stellar population. The deficiency in the $_$-elements with respect the Milky Way suggests a slower, less efficient early star formation history, similar to other massive satellites. $S$-process element patterns indicate significant enrichment from AGB stars over time. The AMR and chemical ratios point to an extended star formation history, with a rapid early phase in the first Gyr, followed by declining activity and later star-forming episodes. These findings are consistent with Sgr hosting multiple stellar populations, from young ($\\sim 4$ Gyr) to old, metal-poor stars ($\\sim 10$ Gyr)         _ Less","","arXiv","https://arxiv.org/abs/2412.06896","4","3","origin_of_life"
"New Ionization Models and the Shocking Nitrogen Excess at z > 5","Abstract:                The new era of galaxy evolution studies hearkened in by JWST has led to the discovery of z > 5 galaxies exhibiting excess nitrogen with log(N/O)~1 dex or more than expected from log(N/O) vs 12+log(O/H) trends in the local Universe. A variety of novel enrichment pathways have been presented to explain the apparent nitrogen excess, invoking a wide range of_         _ More           The new era of galaxy evolution studies hearkened in by JWST has led to the discovery of z > 5 galaxies exhibiting excess nitrogen with log(N/O)~1 dex or more than expected from log(N/O) vs 12+log(O/H) trends in the local Universe. A variety of novel enrichment pathways have been presented to explain the apparent nitrogen excess, invoking a wide range of processes from very massive stars to stripped binaries to fine-tuned star-formation histories. However, understanding the excitation mechanism responsible for the observed nebular emission is necessary to accurately infer chemical abundances. As of yet, the ionization sources of these galaxies have not been thoroughly explored, with radiative shocks left out of the picture. We present a suite of homogeneous excitation models for star-forming galaxies, active galactic nuclei, and radiative shocks, with which we explore possible explanations for the apparent nitrogen excess. We propose new BPT-style diagnostics to classify galaxies at z > 5, finding that, when combined with O iii] 1660,66 and He ii 1640, N iii] 1747-54 / C iii] 1907,09 best selects shock-dominated galaxies while N iv] 1483,86 / C iii] 1907,09 best distinguishes between active black holes and star forming galaxies. From our diagnostics, we find that slow/intermediate radiative shocks (v = 75-150 km/s) are most consistent with observed UV emission line flux ratios in nitrogen-bright galaxies. Accounting for the effects of shocks can bring nitrogen estimates into better agreement with abundance patterns observed in the local Universe and may be attributable to Wolf Rayet populations actively enriching these galaxies with nitrogen and possibly driving winds responsible for these shocks.         _ Less","","arXiv","https://arxiv.org/abs/2412.06763","1","1","multiple"
"White Dwarf Stars in the Big Data Era","Abstract:                White dwarf stars are the most common endpoint of stellar evolution. Therefore, these old, numerous and compact objects provide valuable information on the late stages of stellar_         _ More           White dwarf stars are the most common endpoint of stellar evolution. Therefore, these old, numerous and compact objects provide valuable information on the late stages of stellar evolution, the physics of dense plasma and the structure and evolution of our Galaxy. The ESA Gaia space mission has revolutionized this research field, providing parallaxes and multi-band photometry for nearly 360,000 white dwarfs. Furthermore, this data, combined with spectroscopical and spectropolarimetric observations, have provided new information on their chemical abundances and magnetic fields. This large data set has raised new questions on the nature of white dwarfs, boosting our theoretical efforts for understanding the physics that governs their evolution and for improving the statistical analysis of their collective properties. In this article, I summarize the current state of our understanding of the collective properties of white dwarfs, based of detailed theoretical models and population synthesis studies.         _ Less","","arXiv","https://arxiv.org/abs/2412.06516","1","1","multiple"
"NLTE abundances of Eu for a sample of metal-poor stars in the Galactic Halo and Metal-poor Disk with 1D and <3D> models","Abstract:                _dex, using non-local thermodynamic equilibrium (NLTE) line formation. We compare these measurements with Galactic Chemical_         _ More           Accurate measurements of europium abundances in cool stars are essential for an enhanced understanding of the r-process mechanisms. We measure the abundance of Eu in solar spectra and a sample of metal-poor stars in the Galactic halo and metal-poor disk, with the metallicities ranging from \\GG{$-2.4$} to $-0.5$ dex, using non-local thermodynamic equilibrium (NLTE) line formation. We compare these measurements with Galactic Chemical Evolution (GCE) models to \\GG{explore the impact of the NLTE corrections on the contribution of r-process site in Galactic chemical evolution. In this work, we use NLTE line formation, as well as one-dimensional (1D) hydrostatic and spatial averages of 3D hydrodynamical ($<$3D$>$) model atmospheres to measure the abundance of Eu based on both the Eu II 4129 _ and Eu II 6645 _ lines for solar spectra and metal-poor stars. We find that \\GG{for Eu II 4129 _ line the NLTE modelling leads to higher (0.04 dex) solar Eu abundance in 1D and higher (0.07 dex) in \\GG{$<$3D$>$} NLTE while} NLTE modelling leads to higher (0.01 dex) solar Eu abundance in 1D and lower (0.03 dex) in \\GG{$<$3D$>$} NLTE for Eu II 6645 _ line. Although the NLTE corrections for the Eu II $_$ 4129 _ and Eu II $_$ 6645 _ lines are opposite, the discrepancy between the abundances derived from these individual lines reduces after applying NLTE corrections, highlighting the critical role of NLTE abundance determinations. By comparing these measurements with Galactic chemical evolution (GCE) models, we find that the \\G{amount of NLTE correction does not require significant change of the parameters for Eu production} in the GCE models.         _ Less","","arXiv","https://arxiv.org/abs/2412.06277","2","1","origin_of_life"
"Quasiparticle second-order dissipative hydrodynamics at finite chemical potential","Abstract:                We extend the derivation of second-order relativistic viscous hydrodynamics to incorporate the effects of baryon current, a non-vanishing chemical potential, and a realistic equation of state. Starting from a microscopic quantum theory, we employ a quasiparticle approximation to describe the evolution of hydrodynamic d_         _ More           We extend the derivation of second-order relativistic viscous hydrodynamics to incorporate the effects of baryon current, a non-vanishing chemical potential, and a realistic equation of state. Starting from a microscopic quantum theory, we employ a quasiparticle approximation to describe the evolution of hydrodynamic degrees of freedom and establish its connection to the Wigner formalism. Using methods from relativistic kinetic theory, we perform a second-order expansion to derive a closed set of equations for the components of the stress-energy tensor and the baryon current. The resulting transport coefficients, which depend on the equation of state, are obtained through a unified prescription that ensures thermodynamic consistency.         _ Less","","arXiv","https://arxiv.org/abs/2412.06024","0","1","synthetic_biology"
"Enhancing Fenton-like Photo-degradation and Electrocatalytic Oxygen Evolution Reaction (OER) in Fe-doped Copper Oxide (CuO) Catalysts","Abstract:                _splitting still occurs with sluggish kinetics. It is a challenging barrier for H2 production on a large scale. Moreover, research is still underway to understand the oxygen evolution reaction (OER) and design the catalysts with improved OER performance. Herein, we report the synthesis, characterization, and OER performance of iron-doped copper oxide (CuO) as_         _ More           Although hydrogen generation by water electrolysis is the cheapest of all other available sources, water splitting still occurs with sluggish kinetics. It is a challenging barrier for H2 production on a large scale. Moreover, research is still underway to understand the oxygen evolution reaction (OER) and design the catalysts with improved OER performance. Herein, we report the synthesis, characterization, and OER performance of iron-doped copper oxide (CuO) as low-cost catalysts for water oxidation. The OER occurs at about 1.49 V versus the RHE with a Tafel slope of 69 mV/dec in a 1 M KOH solution. The overpotential of 338 mV at 10 mA/cm2 is among the lowest compared with other copper-based materials. The catalyst can deliver a stable current density of >10 mA/cm2 for more than 10 hours. Additionally, wastewater treatment, particularly synthetic dye wastewater, is vital for preventing water scarcity and adverse effects on human health and ecotoxicology. The as-synthesized catalysts are also utilized for Fenton-like photo-degradation under low-power visible household LED lights toward the most commonly industrially used simulated Methylene blue dye wastewater. Almost complete degradation of the MB dye has been achieved within 50 minutes of visible light irradiation with a first-order rate constant of 0.0973/min. This dual functionality feature can open new pathways as a non-noble, highly efficient, and robust catalyst for OER and wastewater treatments.         _ Less","","arXiv","https://arxiv.org/abs/2412.05637","0","1","synthetic_biology"
"Local fermion-to-qudit mappings","Abstract:                _complexity. We validate our approach by simulating prototypical models such as the spinless t-V model and the Fermi-Hubbard model in two dimensions, using Trotterized time evolution. Our results highlight the potential of qudit-based quantum simulations in achieving scalability and efficiency for fermionic systems on near-term quantum devices.         _ More           In this paper, we present a new set of local fermion-to-qudit mappings for simulating fermionic lattice systems. We focus on the use of multi-level qudits, specifically ququarts. Traditional mappings, such as the Jordan-Wigner transformation (JWT), while useful, often result in non-local operators that scale unfavorably with system size. To address these challenges, we introduce mappings that efficiently localize fermionic operators on qudits, reducing the non-locality and operator weights associated with JWT. We propose one mapping for spinless fermions and two mappings for spinful fermions, comparing their performance in terms of qudit-weight, circuit depth, and gate complexity. By leveraging the extended local Hilbert space of qudits, we show that these mappings enable more efficient quantum simulations in terms of two-qudit gates, reducing hardware requirements without increasing computational complexity. We validate our approach by simulating prototypical models such as the spinless t-V model and the Fermi-Hubbard model in two dimensions, using Trotterized time evolution. Our results highlight the potential of qudit-based quantum simulations in achieving scalability and efficiency for fermionic systems on near-term quantum devices.         _ Less","","arXiv","https://arxiv.org/abs/2412.05616","1","1","multiple"
"High N/O ratio at high redshift as a result of a strong burst of star formation and differential galactic winds","Abstract:                _in galaxies at very high redshift. On the other hand, these galaxies show subsolar metallicity. The observed N/O ratios are difficult to reproduce in the framework of chemical_         _ More           Recent observations by JWST have revealed supersolar $^{14}$N abundances in galaxies at very high redshift. On the other hand, these galaxies show subsolar metallicity. The observed N/O ratios are difficult to reproduce in the framework of chemical evolution models for the Milky Way. Our aim is to reproduce these high N/O ratios with chemical evolution models assuming different histories of star formation triggering galactic winds coupled with detailed nucleosynthesis prescriptions for $^{14}$N, $^{12}$C, $^{16}$O and $^{56}$Fe. We compute several models for small galaxies ($10^{9}\\text{ - }10^{10}\\text{ M}_{\\odot}$) with high star formation efficiency and strong galactic winds. These winds are assumed to be differential, carrying out mainly the products of the explosion of core-collapse supernovae. We find that only models with high star formation rates, normal initial mass function, and differential galactic winds can reproduce the observed chemical abundances. We also find that with the same assumptions about star formation and galactic winds, but with a very rapid formation resulting from fast gas infall, we can also reproduce the estimated ages of these objects. We find no necessity to invoke peculiar nucleosynthesis from Population III stars, very massive stars and supermassive stars.         _ Less","","arXiv","https://arxiv.org/abs/2412.05363","2","1","origin_of_life"
"C/O ratios in self-gravitating protoplanetary discs with dust evolution","Abstract:                Elemental abundances, particularly the C/O ratio, are seen as a way to connect the composition of planetary atmospheres with planet formation scenario and the disc chemical environment. We model the_         _ More           Elemental abundances, particularly the C/O ratio, are seen as a way to connect the composition of planetary atmospheres with planet formation scenario and the disc chemical environment. We model the chemical composition of gas and ices in a self-gravitating disc on timescales of 0.5\\,Myr since its formation to study the evolution of C/O ratio due to dust dynamics and growth, and phase transitions of the volatile species. We use the thin-disc hydrodynamic code FEOSAD, which includes disc self-gravity, thermal balance, dust evolution and turbulent diffusion, and treats dust as a dynamically different and evolving component interacting with the gas. It also describes freeze-out, sublimation and advection of four volatile species: H$_2$O, CO$_2$, CH$_4$ and CO. We demonstrate the effect of gas and dust substructures on the distribution of volatiles and C/O ratios, including the formation of multiple snowlines of one species, and point out the anticorrelation between dust-to-gas ratio and total C/O ratio emerging due to the contribution of oxygen-rich ice mantles. We identify time and spatial locations where two distinct trigger mechanisms for planet formation are operating and differentiate them by C/O ratio range: wide range of the C/O ratios of $0-1.4$ for streaming instability, and a much narrower range $0.3-0.6$ for gravitational instability (with the initial value of 0.34). This conclusion is corroborated by observations, showing that transiting exoplanets, which possibly experienced migration through a variety of disc conditions, have significantly larger spread of C/O in comparison with directly imaged exoplanets likely formed in gravitationally unstable outer disk regions. We show that the ice-phase C/O$\\approx0.2-0.3$ between the CO, CO$_2$ and CH$_4$ snowlines corresponds to the composition of the Solar system comets, that represent primordial planetesimals.         _ Less","","arXiv","https://arxiv.org/abs/2412.05099","1","2","synthetic_biology"
"Chemical Abundances in the Nuclear Star Cluster of the Milky Way: alpha-Element Trends and Their Similarities with the Inner Bulge","Abstract:                A chemical characterization of the Galactic Center is essential for understanding its formation and structural_         _ More           A chemical characterization of the Galactic Center is essential for understanding its formation and structural evolution. Trends of alpha-elements, such as Mg, Si, and Ca, serve as powerful diagnostic tools, offering insights into star-formation rates and gas-infall history. However, high extinction has previously hindered such studies. In this study, we present a detailed chemical abundance analysis of M giants in the Milky Way's Nuclear Star Cluster (NSC), focusing on alpha-element trends with metallicity. High-resolution, near-infrared spectra were obtained using the IGRINS spectrograph on the Gemini South telescope for nine M giants. Careful selection of spectral lines, based on a solar-neighborhood control sample of 50 M giants, was implemented to minimize systematic uncertainties. Our findings show enhanced alpha-element abundances in the predominantly metal-rich NSC stars, consistent with trends in the inner bulge. The NSC stars follow the high-[alpha/Fe] envelope seen in the solar vicinity's metal-rich population, indicating a high star-formation rate. The alpha-element trends decrease with increasing metallicity, also at the highest metallicities. Our results suggest the NSC population likely shares a similar evolutionary history with the inner bulge, challenging the idea of a recent dominant star formation burst. This connection between the NSC and the inner-disk sequence suggests that the chemical properties of extragalactic NSCs of Milky Way type galaxies could serve as a proxy for understanding the host galaxies' evolutionary processes.         _ Less","","arXiv","https://arxiv.org/abs/2412.04528","1","1","multiple"
"In-situ Investigation of the Phase Formation and Superconductivity in V$_3$Si Thin Films at High Temperatures","Abstract:                _formation when a thin layer of vanadium undergoes reactive diffusion with a silicon dioxide film on silicon at temperatures from 650-800 _C. To further investigate the time evolution of different phases under various annealing temperatures, a chemical model was developed and subsequent simulations were performed. The r_         _ More           Vanadium silicide (V$_3$Si) is a promising superconductor for integration with silicon-based electronics, however the interfacial growth kinetics have a strong influence on the resulting superconducting properties and are not yet fully understood. In this study, we have used neutron reflectometry to reveal the phase transformation during thin film growth driven by different annealing strategies. We examined the silicide formation when a thin layer of vanadium undergoes reactive diffusion with a silicon dioxide film on silicon at temperatures from 650-800 _C. To further investigate the time evolution of different phases under various annealing temperatures, a chemical model was developed and subsequent simulations were performed. The results of this model were validated using X-ray diffraction and cross-sectional TEM analysis. Correlations were observed between the structure and superconducting properties. Over-annealing films leads to complete depletion of the SiO$_2$ barrier layer, forming diffuse interfaces and driving the formation of undesirable silicon-rich silicides. Avoiding this by controlling time and temperature, allows higher quality superconducting films to be achieved. The $T_c$ of the films was found to be 13 K, and the annealing conditions influenced the critical fields and the paramagnetic Meissner effect near $T_c$. For optimally-annealed films, superconducting order parameters were calculated. Ginzberg-Landau theory was applied to explain flux penetration.         _ Less","","arXiv","https://arxiv.org/abs/2412.04159","1","2","synthetic_biology"
"The ALPINE-ALMA [CII] Survey: Unveiling the baryon evolution in the ISM of $z\\sim5$ star-forming galaxies","Abstract:                _of dust production and destruction in the interstellar medium (ISM) is advancing, probing baryonic processes in the early Universe remains a complex task. We characterize the evolution of 98 z~5 star-forming galaxies observed as part of the ALPINE survey by constraining the physical processes underpinning the gas and dust production, consumption, and destruc_         _ More           Recent observations reveal a rapid dust build-up in high-redshift galaxies (z > 4), challenging current models of galaxy formation. While our understanding of dust production and destruction in the interstellar medium (ISM) is advancing, probing baryonic processes in the early Universe remains a complex task. We characterize the evolution of 98 z~5 star-forming galaxies observed as part of the ALPINE survey by constraining the physical processes underpinning the gas and dust production, consumption, and destruction in their ISM. We make use of chemical evolution models to simultaneously reproduce the observed dust and gas content. For each galaxy, we estimate initial gas mass, inflows and outflows, and efficiencies of dust growth and destruction. We test the models with the canonical Chabrier and top-heavy initial mass functions (IMFs), with the latter enabling rapid dust production on shorter timescales. Our models successfully reproduce gas and dust content in older galaxies (> 600 Myr) regardless of the IMF, with Type II SNe as the primary dust source and no dust growth in ISM with moderate inflow of primordial gas. In case of intermediate-age galaxies (300 - 600 Myr), we reproduce the gas and dust content through Type II SNe and dust growth in ISM, though we observe an over-prediction of dust mass in older galaxies, potentially indicating an unaccounted dust destruction mechanism and/or an overestimation of the observed dust masses. The number of young galaxies (< 300 Myr) reproduced, increases for models assuming top-heavy IMF but with maximal prescriptions of dust production. Galactic outflows are necessary to reproduce observed gas and dust masses. The Chabrier IMF models reproduce 65% of galaxies, while top-heavy IMF models improve this to 93%, easing tensions with observations. Upcoming JWST data will refine these models by resolving degeneracies in intrinsic galaxy properties.         _ Less","","arXiv","https://arxiv.org/abs/2412.02505","3","3","multiple"
"Signatures of Rapidly Rotating Stars with Chemically Homogeneous Evolution in the First Galaxies","Abstract:                _, challenging `standard' galaxy formation models. This study investigates the role of rapidly rotating (massive) stars undergoing chemically homogeneous evolution (CHE) in reconciling this potential tension. These stars are more compact, hotter, and exhibit enhanced UV emission. We find that the rest-frame UV lumin_         _ More           The James Webb Space Telescope (JWST) has revealed an unexpectedly high abundance of UV luminous galaxies at redshifts $z\\gtrsim 10$, challenging `standard' galaxy formation models. This study investigates the role of rapidly rotating (massive) stars undergoing chemically homogeneous evolution (CHE) in reconciling this potential tension. These stars are more compact, hotter, and exhibit enhanced UV emission. We find that the rest-frame UV luminosity of star-forming galaxies can be significantly enhanced by a factor of $\\sim 3-6$ when CHE stars above a minimum initial mass of $m_{\\star,\\min}^{\\rm CHE}\\sim 2-10\\ \\rm M_\\odot$ account for more than half of the total stellar mass following a Salpeter initial mass function. As a result, the UV luminosity functions observed at $z\\sim 12-16$ can be reproduced with less extreme values of star formation efficiency and UV luminosity stochastic variability. Our results highlight the potential of CHE in explaining the UV-bright galaxy populations detected by JWST and call for future work to explore the broader astrophysical implications of CHE and its associated phenomena in the early universe, such as gamma-ray bursts, compact object binaries, and metal enrichment.         _ Less","","arXiv","https://arxiv.org/abs/2412.02002","1","1","multiple"
"CO2-rich protoplanetary discs as a probe of dust radial drift & trapping","Abstract:                MIR spectra imply considerable chemical diversity in the inner regions of protoplanetary discs: some are H2O-dominated, others by CO2. Sublimating ices from radially drifting dust grains are often invoked to explain some of this diversity, particularly the H2O-rich discs. We use a 1D protoplanetary disc_         _ More           MIR spectra imply considerable chemical diversity in the inner regions of protoplanetary discs: some are H2O-dominated, others by CO2. Sublimating ices from radially drifting dust grains are often invoked to explain some of this diversity, particularly the H2O-rich discs. We use a 1D protoplanetary disc evolution code to model how radially drifting dust grains that transport ices inwards to snowlines impact the chemistry of the inner regions of protoplanetary discs. We explore differences between smooth discs and those where radial drift is impeded by dust trapping outside gas gaps and quantify the effects of gap location and formation time. Discs evolve through an initial H2O-rich phase due to sublimating ices, followed by a CO2-rich phase as H2O vapour advects onto the star and CO2 advects into the inner disc from its snowline. The inclusion of traps hastens the transition between the phases, raising the CO2/H2O ratio; gaps opened early or close-in produce lower increases by blocking more CO2 ice from reaching the inner disc. This leads to a potential correlation between CO2/H2O and gap location that occurs on Myr timescales for fiducial parameters. We produce synthetic spectra from the models which we analyse with 0D LTE slab models to understand how this evolution may be expressed observationally. Whether the evolution can be retrieved depends on the contribution of dust grains to the optical depth: dust that couples to the gas after crossing the H2O snowline can add to the continuum optical depth and obscure the delivered H2O, largely hiding the evolution in its visible column density. However, the CO2/H2O visible column density ratio is only weakly sensitive to dust continuum obscuration. This suggests it may be a clearer tracer of the impact of transport on chemistry than individual column densities for spectra that show weak features probing deep enough in the disc. (Abridged)         _ Less","","arXiv","https://arxiv.org/abs/2412.01895","1","1","multiple"
"Influence of light, temperature and iron oxidation state on the dissolution rate of combusted iron particles in oxalic acid","Abstract:                _Unlike previous studies, real combusted iron particles with varying fuel-to-air equivalence ratios were used instead of model oxides. In-situ video recordings reveal the evolution of particle size and morphology. Increasing temperature and short-wavelength light exposure enhance the reaction rate, with light-induced effects only becoming significant above_         _ More           In this study, the influence of temperature $(40-80 ^\\circ\\mathrm{C})$ and light exposure on the dissolution of combusted iron particles in aqueous oxalic acid $(0.45~\\mathrm{mol/L})$ is experimentally investigated. Unlike previous studies, real combusted iron particles with varying fuel-to-air equivalence ratios were used instead of model oxides. In-situ video recordings reveal the evolution of particle size and morphology. Increasing temperature and short-wavelength light exposure enhance the reaction rate, with light-induced effects only becoming significant above $40 ^\\circ$C for the duration of the experiments. This behavior differs significantly from hematite/maghemite oxides, attributed to the internal Fe phase structure of the combusted iron particles. At $80^\\circ$C with additional light irradiation, a sudden decrease in reaction rate is observed due to solid ferrous oxide formation. While the fuel-to-air ratio induces differences in iron oxide phase composition, it does not affect the dissolution combusted iron particles significantly.         _ Less","","arXiv","https://arxiv.org/abs/2412.01689","1","1","multiple"
"Detectability of biosignatures in warm, water-rich atmospheres","Abstract:                _climate-chemistry column model 1D-TERRA to simulate the composition of planetary atmospheres at different distances from the Sun, assuming Earth's planetary parameters and evolution. We increased the incoming instellation by up to 50 percent in steps of 10 percent, corresponding to orbits of 1.00 to 0.82 AU. Simulations were performed with and without mo_         _ More           Warm rocky exoplanets within the habitable zone of Sun-like stars are favoured targets for current and future missions. Theory indicates these planets could be wet at formation and remain habitable long enough for life to develop. In this work we test the climate-chemistry response, maintenance, and detectability of biosignatures in warm, water-rich atmospheres with Earth biomass fluxes within the framework of the planned LIFE mission. We used the coupled climate-chemistry column model 1D-TERRA to simulate the composition of planetary atmospheres at different distances from the Sun, assuming Earth's planetary parameters and evolution. We increased the incoming instellation by up to 50 percent in steps of 10 percent, corresponding to orbits of 1.00 to 0.82 AU. Simulations were performed with and without modern Earth's biomass fluxes. Emission spectra of all simulations were produced using the GARLIC radiative transfer model. LIFEsim was then used to add noise to and simulate observations of these spectra to assess how biotic and abiotic atmospheres of Earth-like planets can be distinguished. Increasing instellation leads to surface water vapour pressures rising from 0.01 bar (1.13%) to 0.61 bar (34.72%). In the biotic scenarios, the ozone layer survives because hydrogen oxide reactions with nitrogen oxides prevent the net ozone chemical sink from increasing. Synthetic observations with LIFEsim, assuming a 2.0 m aperture and resolving power of R = 50, show that O3 signatures at 9.6 micron reliably point to Earth-like biosphere surface fluxes of O2 only for systems within 10 parsecs. Increasing the aperture to 3.5 m increases this range to 22.5 pc. The differences in atmospheric temperature due to differing H2O profiles also enables observations at 15.0 micron to reliably identify planets with a CH4 surface flux equal to that of Earth's biosphere.         _ Less","","arXiv","https://arxiv.org/abs/2412.01266","1","1","multiple"
"Local variations of the radial metallicity gradient in a simulated NIHAO-UHD Milky Way analogue and their implications for (extra-)galactic studies","Abstract:                Radial metallicity gradients are fundamental to understanding galaxy formation and evolution. In our high-resolution simulation of a NIHAO-UHD Milky Way analogue, we analyze the linearity, scatter, spatial coherence, and age-related variations of metallicity gradients using young stars and gas. While a global linear model generally captures the gradient, it_         _ More           Radial metallicity gradients are fundamental to understanding galaxy formation and evolution. In our high-resolution simulation of a NIHAO-UHD Milky Way analogue, we analyze the linearity, scatter, spatial coherence, and age-related variations of metallicity gradients using young stars and gas. While a global linear model generally captures the gradient, it ever so slightly overestimates metallicity in the inner galaxy and underestimates it in the outer regions of our simulated galaxy. Both a quadratic model, showing an initially steeper gradient that smoothly flattens outward, and a piecewise linear model with a break radius at 10~kpc (2.5 effective radii) fit the data equally better. The spread of [Fe/H] of young stars in the simulation increases by tenfold from the innermost to the outer galaxy at a radius of 20~kpc. We find that stars born at similar times along radial spirals drive this spread in the outer galaxy, with a chemical under- and over-enhancement of up to 0.1 dex at leading and trailing regions of such spirals, respectively. This localised chemical variance highlights the need to examine radial and azimuthal selection effects for both Galactic and extragalactic observational studies. The arguably idealised but volume-complete simulations suggest that future studies should not only test linear and piecewise linear gradients, but also non-linear functions such as quadratic ones to test for a smooth gradient rather than one with a break radius. Either finding would help to determine the importance of different enrichment or mixing pathways and thus our understanding of galaxy formation and evolution scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2412.01157","1","1","multiple"
"The Structure, Populations and Kinematics of the Milky Way central and inner Bulge with OGLE, APOGEE and Gaia data","Abstract:                _were identified as halo interlopers. Then, orbital analysis of 28,188 APOGEE Red Clump and Red Giant Branch stars revealed kinematic properties consistent with RRabs, and chemical abundance distribution displayed a bimodal stellar density pattern, suggesting complex star evolution histories and also slightly different_         _ More           We present an analysis of the structure, kinematics, and chemo-dynamical properties of the Milky Way bulge using data from OGLE, APOGEE, and Gaia. Firstly, we identified 2,156 ab-type RR Lyrae stars (RRabs) from OGLE-IV, then through their apocenters derived from orbital integration, we distinguished three populations: the central bulge RRabs, the inner bulge RRabs and halo interlopers. Inner bulge RRabs kinematically align with the Galactic bar, while central bulge RRabs show slower rotation with lower velocity dispersion, which do not trace the bar. Higher velocity dispersion stars were identified as halo interlopers. Then, orbital analysis of 28,188 APOGEE Red Clump and Red Giant Branch stars revealed kinematic properties consistent with RRabs, and chemical abundance distribution displayed a bimodal stellar density pattern, suggesting complex star evolution histories and also slightly different star formation histories for the inner bulge and central bulge. The differences in the density distribution on the $|\\mathrm{Z}|_{\\text{max}}$-eccentricity plane for the central bulge, inner bulge, and halo regions are clearly detected. Finally, the chemodynamical analysis of 301,485 Gaia DR3 red giants without orbital integration indicated that metal-rich bulge stars form a bar-like structure, while metal-poor bulge stars are dominated by velocity dispersion. It is found that the classification of bulge stars based on orbital parameters, rather than solely on metallicity, provides a more accurate population separation. Our results also support that secular evolution of the Galactic disk is the primary origin of the bulge, and boxy/peanut (B-P) bulge population might be more dominant than X-shape bulge population.         _ Less","","arXiv","https://arxiv.org/abs/2412.00752","1","1","multiple"
"Chemical Evolution of R-process Elements in Stars (CERES): IV. An observational run-up of the third r-process peak with Hf, Os, Ir, and Pt","Abstract:                _understanding of the r-process in a broader context. To understand how the abundances of the third r-process peak are synthesised and evolve in the Universe, a homogeneous chemical analysis of metal-poor stars using high quality data observed in the blue region of the electromagnetic spectrum (< 400 nm) is necessary. We provide a homogeneous set of abunda_         _ More           The third r-process peak (Os, Ir, Pt) is poorly understood due to observational challenges, with spectral lines located in the blue or near-ultraviolet region of stellar spectra. These challenges need to be overcome for a better understanding of the r-process in a broader context. To understand how the abundances of the third r-process peak are synthesised and evolve in the Universe, a homogeneous chemical analysis of metal-poor stars using high quality data observed in the blue region of the electromagnetic spectrum (< 400 nm) is necessary. We provide a homogeneous set of abundances for the third r-process peak (Os, Ir, Pt) and Hf, increasing by up to one order of magnitude their availability in the literature. A classical 1D, local thermodynamic equilibrium (LTE) analysis of four elements (Hf, Os, Ir, Pt) is performed, using ATLAS model atmospheres to fit synthetic spectra in high resolution (> 40,000), high signal-to-noise ratio, of 52 red giants observed with UVES/VLT. Due to the heavy line blending involved, a careful determination of upper limits and uncertainties is done. The observational results are compared with state-of-the-art nucleosynthesis models. Our sample displays larger abundances of Ir (Z=77) in comparison to Os (Z=76), which have been measured in a few stars in the past. The results also suggest decoupling between abundances of third r-process peak elements with respect to Eu (rare earth element) in Eu-poor stars. This seems to contradict a co-production scenario of Eu and the third r-process peak elements Os, Ir, and Pt in the progenitors of these objects. Our results are challenging to explain from the nucleosynthetic point of view: the observationally derived abundances indicate the need for an additional early, primary formation channel (or a non-robust r-process).         _ Less","","arXiv","https://arxiv.org/abs/2412.00195","2","2","multiple"
"Silicon Isotopic Composition of Mainstream Presolar SiC Grains Revisited: The Impact of Nuclear Reaction Rate Uncertainties","Abstract:                _influenced by nucleosynthesis within the parent star, but rather represents the pristine stellar composition. Silicon isotopes can thus be used as a proxy for galactic chemical evolution. However, the measured correlation of $^{29}$Si/$^{28}$Si versus $^{30}$Si/$^{28}$Si does not agree with any current_         _ More           Presolar grains are stardust particles that condensed in the ejecta or in the outflows of dying stars and can today be extracted from meteorites. They recorded the nucleosynthetic fingerprint of their parent stars and thus serve as valuable probes of these astrophysical sites. The most common types of presolar silicon carbide grains (called mainstream SiC grains) condensed in the outflows of asymptotic giant branch stars. Their measured silicon isotopic abundances are not significantly influenced by nucleosynthesis within the parent star, but rather represents the pristine stellar composition. Silicon isotopes can thus be used as a proxy for galactic chemical evolution. However, the measured correlation of $^{29}$Si/$^{28}$Si versus $^{30}$Si/$^{28}$Si does not agree with any current chemical evolution model. Here, we use a Monte Carlo model to vary nuclear reaction rates within their theoretical or experimental uncertainties and process them through stellar nucleosynthesis and galactic chemical evolution models to study the variation of silicon isotope abundances based on these nuclear reaction rate uncertainties. We find that these uncertainties can indeed be responsible for the discrepancy between measurements and models and that the slope of the silicon isotope correlation line measured in mainstream SiC grains agrees with chemical evolution models within the nuclear reaction rate uncertainties. Our result highlights the importance of future precision reaction rate measurements for resolving the apparent data-model discrepancy.         _ Less","","arXiv","https://arxiv.org/abs/2411.19935","1","1","multiple"
"Rediscovering the Milky Way with orbit superposition approach and APOGEE data III. Panoramic view of the bulge","Abstract:                _However, this region contains the most massive complex stellar component of the MW, the bulge, primarily composed of disc stars whose structure is (re-)shaped by the evolution of the bar. In this work, we extend the application of the orbit superposition method to explore the present-day 3D structure, orbital composition,_         _ More           The innermost parts of the Milky Way (MW) are very difficult to observe due to the high extinction along the line of sight, especially close to the disc mid-plane. However, this region contains the most massive complex stellar component of the MW, the bulge, primarily composed of disc stars whose structure is (re-)shaped by the evolution of the bar. In this work, we extend the application of the orbit superposition method to explore the present-day 3D structure, orbital composition, chemical abundance trends and kinematics of the MW bulge. Thanks to our approach, we are able to transfer astrometry from Gaia and stellar parameters from APOGEE DR 17 to map the inner MW without obscuration by the survey footprint and selection function. We demonstrate that the MW bulge is made of two main populations originating from a metal-poor, high-_ thick disc and a metal-rich, low-_ thin disc, with a mass ratio of 4:3, seen as two major components in the MDF. Finer MDF structures hint at multiple sub-populations associated with different orbital families of the bulge, which, however, have broad MDFs themselves. Decomposition using 2D GMMs in [Fe/H] -[Mg/Fe] identifies five components including a population with ex-situ origin. Two dominant ones correspond to the thin and thick discs and two in between trace the transition between them. We show that no universal metallicity gradient value can characterise the MW bulge. The radial gradients closely trace the X-shaped bulge density structure, while the vertical gradient variations follow the boxy component. While having, on average, subsolar metallicity, the MW bulge populations are more metal-rich compared to the surrounding disc, in agreement with extragalactic observations and state-of-the-art simulations reinforcing its secular origin.         _ Less","","arXiv","https://arxiv.org/abs/2411.18182","1","2","synthetic_biology"
"Exploring IMF Sampling Effects on Star Formation and Metallicity in Ultra-Faint Dwarf Galaxies","Abstract:                _reflected in stellar metallicity. These findings emphasize the essential role of choosing appropriate IMF sampling methods for accurately modeling the star formation and chemical evolution of UFD galaxies.         _ More           We examine the impact of various Initial Mass Function (IMF) sampling methods on the star formation and metal enrichment histories of Ultra-Faint Dwarf (UFD) galaxy analogs. These analogs are characterized by $M_{\\rm vir}\\sim10^8 M_\\odot$ and $M_{\\ast}\\lesssim10^5 M_\\odot$ at $z=0$, utilizing high-resolution cosmological hydrodynamic zoom-in simulations with a gas particle mass resolution of $\\sim63 M_\\odot$. Specifically, we evaluate three IMF sampling techniques: the burst model, stochastic IMF sampling, and individual IMF sampling. Our results demonstrate that the choice of IMF sampling method critically affects stellar feedback dynamics, particularly supernova (SN) feedback, thus impacting the star formation and metallicity characteristics of UFD analogs. We find that simulations with stochastic IMF sampling yield UFD analogs with 40\\% to 70\\% higher stellar masses than those using the burst model, due to a less immediate suppression of star formation by SNe. The individual IMF method results in even greater stellar masses, 8\\% to 58\\% more than stochastic runs, as stars form individually and continuously. Star formation is most continuous with individual sampling, followed by stochastic, and least with the burst model, which shows the longest quenching periods. Furthermore, the individual sampling approach achieves higher metallicity stars, aligning well with observed values, unlike the lower metallicities (about 1 dex less) found in the burst and stochastic methods. This difference is attributed to the continuous star formation in individual sampling, where gas metallicity shaped by previous SN events is immediately reflected in stellar metallicity. These findings emphasize the essential role of choosing appropriate IMF sampling methods for accurately modeling the star formation and chemical evolution of UFD galaxies.         _ Less","","arXiv","https://arxiv.org/abs/2411.17862","2","1","origin_of_life"
"Toward a Quantum Computing Formulation of the Electron Nuclear Dynamics Method via Fukutome Unitary Representation","Abstract:                _(END) method within the variational quantum simulator (VQS) scheme: END/QC/VQS. END is a time-dependent, variational, on-the-flight, and non-adiabatic method to simulate chemical reactions. END represents nuclei with frozen Gaussian wave packets and electrons with a single-determinantal state in the Thouless non-unitary representation. Within the hybrid quan_         _ More           We present the first installment of the quantum computing (QC) formulation of the electron nuclear dynamics (END) method within the variational quantum simulator (VQS) scheme: END/QC/VQS. END is a time-dependent, variational, on-the-flight, and non-adiabatic method to simulate chemical reactions. END represents nuclei with frozen Gaussian wave packets and electrons with a single-determinantal state in the Thouless non-unitary representation. Within the hybrid quantum/classical VQS, END/QC/VQS evaluates the metric matrix M and gradient vector V of the symplectic END/QC equations on a quantum computer, and calculates basis function integrals and time evolution on a classical computer. To adapt END to QC, we substitute the Thouless non-unitary representation with Fukutome unitary representation. We formulate the first END/QC/VQS version for pure electronic dynamics in chemical models consisting of two-electron units. Therein, Fukutome unitary matrices factorize into products of triads of one-qubit rotational matrices, which leads to a QC encoding of one electron per qubit. We design QC circuits to evaluate M and V in one-electron diatomic molecules. In log2-log2 plots, errors and deviations of those evaluations decrease linearly with the number of shots and with slopes = -1/2. We illustrate an END/QC/VQS simulation with the pure electronic dynamics of H2+. We discuss the present results and future END/QC/QVS extensions.         _ Less","","arXiv","https://arxiv.org/abs/2411.17657","0","1","synthetic_biology"
"Gas dynamics around a Jupiter mass planet: II. Chemical evolution of circumplanetary material","Abstract:                _the protoplanetary disk to the planet. In this work we post-process 3D numerical simulations of an embedded Jupiter-massed planet in its protoplanetary disk to explore the chemical_         _ More           In an ongoing effort to understand planet formation the link between the chemistry of the protoplanetary disk and the properties of resulting planets have long been a subject of interest. These connections have generally been made between mature planets and young protoplanetary disks through the carbon-to-oxygen (C/O) ratio. In a rare number of systems, young protoplanets have been found within their natal protoplanetary disks. These systems offer a unique opportunity to directly study the delivery of gas from the protoplanetary disk to the planet. In this work we post-process 3D numerical simulations of an embedded Jupiter-massed planet in its protoplanetary disk to explore the chemical evolution of gas as it flows from the disk to the planet. The relevant dust to this chemical evolution is assumed to be small, co-moving grains with a reduced dust-to-gas ratio indicative of the upper atmosphere of a protoplanetary disk. We find that as the gas enters deep into the planet's gravitational well, it warms significantly (up to $\\sim 800$ K), releasing all of the volatile content from the ice phase. This change in phase can influence our understanding of the delivery of volatile species to the atmospheres of giant planets. The primary carbon, oxygen, and sulfur carrying ices: CO$_2$, H$_2$O, and H$_2$S are released into the gas phase and along with the warm gas temperatures near the embedded planets lead to the production of unique species like CS, SO, and SO$_2$ compared to the protoplanetary disk. We compute the column densities of SO, SO$_2$, CS, and H$_2$CS in our model and find that their values are consistent with previous observational studies.         _ Less","","arXiv","https://arxiv.org/abs/2411.17408","2","1","origin_of_life"
"A link between rocky exoplanet composition and stellar age","Abstract:                _dynamo and the strength of gravity on the planetary surface, both of which heavily impact thermal and possible biological processes and thus the habitability for life and its evolution on the planet. However, detailed measurements of the planetary interiors are extremely challenging for small exoplanets, and existing data suggest a wide diversity in planet c_         _ More           Interior compositions are key for our understanding of Earth-like exoplanets. The composition of the core can influence the presence of a magnetic dynamo and the strength of gravity on the planetary surface, both of which heavily impact thermal and possible biological processes and thus the habitability for life and its evolution on the planet. However, detailed measurements of the planetary interiors are extremely challenging for small exoplanets, and existing data suggest a wide diversity in planet compositions. Hitherto, only certain photospheric chemical abundances of the host stars have been considered as tracers to explain the diversity of exoplanet compositions. Here we present a homogeneous analysis of stars hosting rocky exoplanets, with ages between 2 and 14 Gyr, revealing a correlation between rocky exoplanet compositions and the ages of the planetary systems. Denser rocky planets are found around younger stars. This suggests that the compositional diversity of rocky exoplanets can be linked to the ages of their host stars. We interpret this to be a result of chemical evolution of stars in the Milky Way, which modifies the material out of which stars and planets form. The results imply that rocky planets which form today, at similar galactocentric radii, may have different formation conditions, and thus different properties than planets which formed several billion years ago, such as the Earth.         _ Less","","arXiv","https://arxiv.org/abs/2411.17358","2","1","origin_of_life"
"On the Hidden Transient Interphase in Metal Anodes: Dynamic Precipitation Controls Electrochemical Interfaces in Batteries","Abstract:                _and resultant electrolyte salt deposition. The T-SEI fundamentally alters the dissolution kinetics at the electrochemical interface, leading to a self-limiting morphological evolution and eventually yielding a flat, clean surface. Unlike a classical SEI formed due to electrolyte decomposition, the T-SEI is fully relaxable upon removal of the enforced dissolu_         _ More           The Solid-Electrolyte Interphase, SEI, formed on a battery electrode has been a central area of research for decades. This thin, complex layer profoundly impacts the electrochemical deposition morphology and stability of the metal in battery anodes. Departing from conventional approaches, we investigate metal dissolution, the reverse reaction of deposition, in battery environments using a state-of-the-art electroanalytical system combining a rotating-disk electrode and in-operando visualization. Our key finding is the presence of a Transient Solid-Electrolyte Interphase, T-SEI, that forms during fast discharging at high dissolution rates. We attribute T-SEI formation to transient local supersaturation and resultant electrolyte salt deposition. The T-SEI fundamentally alters the dissolution kinetics at the electrochemical interface, leading to a self-limiting morphological evolution and eventually yielding a flat, clean surface. Unlike a classical SEI formed due to electrolyte decomposition, the T-SEI is fully relaxable upon removal of the enforced dissolution current. The formation of T-SEI, surprisingly, plays a critical role in the subsequent electrodeposition. When the metal is redeposited on a fully relaxed T-SEI surface, the morphology is remarkably different from that deposited on pristine or low-rate discharged metal electrodes. Electron backscatter diffraction analysis suggests a homoepitaxial relationship with the original grains in the electrode. This is in stark contrast to the isolated, particulate nuclei seen on standard metal electrodes without T-SEI formation. Our findings provide important insights into the electrochemical kinetics at the metal-electrolyte interface, particularly in concentrated or water-in-salt electrolytes that are close to the salt saturation limit. The results suggest a new dimension for electrochemical engineering in batteries.         _ Less","","arXiv","https://arxiv.org/abs/2411.16741","1","1","multiple"
"A constant potential reactor framework for electrochemical reaction simulations","Abstract:                Understanding the evolution of electrified solid-liquid interfaces during electrochemical reactions is crucial. However, capturing the dynamic behavior of the interfaces with high temporal resolution and accuracy over long timescales remains a major challenge for both experimental and computational techniques. Here, we present a constant potential reactor fr_         _ More           Understanding the evolution of electrified solid-liquid interfaces during electrochemical reactions is crucial. However, capturing the dynamic behavior of the interfaces with high temporal resolution and accuracy over long timescales remains a major challenge for both experimental and computational techniques. Here, we present a constant potential reactor framework that enables the simulation of electrochemical reactions with ab initio accuracy over extended timescales, allowing for real-time atomic scale observations for the electrified solid-liquid interface evolution. By implementing an enhanced sampling active learning protocol, we develop fast, accurate, and scalable neural network potentials that generalize across systems with varying electron counts, based on high-throughput density functional theory computations within an explicit-implicit hybrid solvent model. The simulation of reactions in realistic electrochemical environments uncovers the intrinsic mechanisms through which alkali metal cations promote CO2 adsorption and suppress the hydrogen evolution reaction. These findings align with previous experimental results and clarify previously elusive observations, offering valuable computational insights. Our framework lay the groundwork for future studies exploring the dynamic interplay between interfacial structure and reactivity in electrochemical environments.         _ Less","","arXiv","https://arxiv.org/abs/2411.16330","0","1","synthetic_biology"
"Material mixing in pulsar wind nebulae of massive runaway stars","Abstract:                _examine the manner pulsar wind, supernova ejecta and defunct stellar wind materials distribute and melt together into plerions. We performed 2.5D MHD simulations of the entire evolution of their stellar surroundings and different scenarios are explored, whether the star dies as a red supergiant and Wolf Rayet supernova progenitors, and whether it moved with_         _ More           In this study we quantitatively examine the manner pulsar wind, supernova ejecta and defunct stellar wind materials distribute and melt together into plerions. We performed 2.5D MHD simulations of the entire evolution of their stellar surroundings and different scenarios are explored, whether the star dies as a red supergiant and Wolf Rayet supernova progenitors, and whether it moved with velocity 20 km/s or 40 km/s through the ISM. Within the post explosion, early 10 kyr, the H burning products rich red supergiant wind only mixes by <= 20 per cent, due to its dense circumstellar medium filling the progenitor bow shock trail, still unaffected by the supernova blastwave. Wolf Rayet materials, enhanced in C, N, O elements, distribute circularly for the 35 Mo star moving at 20 km/s and oblongly at higher velocities, mixing efficiently up to 80 per cent. Supernova ejecta, filled with Mg, Si, Ca, Ti and Fe, remain spherical for longer times at 20 km/s but form complex patterns at higher progenitor speeds due to earlier interaction with the bow shock, in which they mix more efficiently. The pulsar wind mixing is more efficient for Wolf Rayet (25 per cent) than red supergiant progenitors (20 per cent). This work reveals that the past evolution of massive stars and their circumstellar environments critically shapes the internal distribution of chemical elements on plerionic supernova remnants, and, therefore, governs the origin of the various emission mechanisms at work therein. This is essential for interpreting multi-frequency observations of atomic and molecular spectral lines, such as in optical, infrared, and soft X rays.         _ Less","","arXiv","https://arxiv.org/abs/2411.16202","0","1","synthetic_biology"
"Enhancing Open Quantum Dynamics Simulations Using Neural Network-Based Non-Markovian Stochastic Schr_dinger Equation Method","Abstract:                _to its low scaling complexity and suitability for parallel computing. However, its application at low temperatures faces significant convergence challenges. While short-time evolution converges quickly, long-time evolution requires a much larger number of stochastic trajectories, leading to high computational costs. To_         _ More           The Non-Markovian Stochastic Schrodinger Equation (NMSSE) offers a promising approach for open quantum simulations, especially in large systems, owing to its low scaling complexity and suitability for parallel computing. However, its application at low temperatures faces significant convergence challenges. While short-time evolution converges quickly, long-time evolution requires a much larger number of stochastic trajectories, leading to high computational costs. To this end,we propose a scheme that combines neural network techniques with simulations of the non-Markovian stochastic Schrodinger equation. By integrating convolutional neural networks (CNNs) and long short-term memory recurrent neural networks (LSTMs),along with the iterative attentional feature fusion (iAFF) technique, this approach significantly reduces the number of trajectories required for long-time simulations, particularly at low temperatures, thereby substantially lowering computational costs and improving convergence. To demonstrate our approach, we investigated the dynamics of the spin-boson model and the Fenna-Matthews-Olson (FMO) complex across a range of parameter variations.         _ Less","","arXiv","https://arxiv.org/abs/2411.15914","0","1","synthetic_biology"
"Metal-Poor Stars in the Milky Way System","Abstract:                _stars remain present in all components of our home galaxy, the Milky Way. Born a few hundred million after the Big Bang and during a time that marked the very beginning of the chemical_         _ More           Ancient, long-lived stars remain present in all components of our home galaxy, the Milky Way. Born a few hundred million after the Big Bang and during a time that marked the very beginning of the chemical evolution, these stars display very low abundances of elements heavier and hydrogen and helium, making them 'metal-poor'. Studying the chemical composition of these stars reveals direct information about the conditions of the early universe because each of them has long preserved the local chemical signature of their individual birth gas clouds in their stellar atmosphere. There are many different types of metal-poor stars, each of them providing information on a different element production history that occurred prior to their own births. Large samples of metal-poor stars enable the reconstruction of nucleosynthesis and the chemical evolution of our Galaxy, early star formation processes, and various aspects of the assembly and evolution of the Milky Way.         _ Less","","arXiv","https://arxiv.org/abs/2411.15415","2","1","origin_of_life"
"Analysis of the Internal Radial Gradient of Chemical Abundances in Spiral Galaxies from CALIFA","Abstract:                The study of chemical_         _ More           The study of chemical evolution is of paramount importance for understanding the galaxies evolution. Models and observations propose an inside-out mechanism in the formation of spiral galaxy disks implying a negative radial gradient of elemental abundances when represented in logarithmic scale. However, observed chemical abundance gradients, in some instances, deviate from a single linear negative straight line, revealing inner drops or outer flattenings, particularly in more massive galaxies. This study analyzes oxygen abundance gradients in spiral galaxies based on observations from the Calar Alto Legacy Integral Field Area (CALIFA) survey. Our focus is specifically on examining oxygen abundance gradient profiles, as obtained with data from HII regions, with a special emphasis on the inner radial gradient. We employ an automated fitting procedure to establish correlations between the physical properties of galaxies and bulges and the presence of these inner drops, seeking for potential explanations for these gradient variations. We find that the different criteria used in the literature to distinguish HII regions from other ionization sources in the galaxy, such as Active Galactic Nuclei, significantly impact the results, potentially altering abundance gradient profiles and uncovering galaxies with distinct inner drops. Additionally, we analyze the abundance radial gradients to investigate the impact of diffuse ionized gas (DIG) decontamination on oxygen abundances over the featuring inner drops. We observe that DIG, concentrated mainly in the central regions of galaxies, can modify oxygen abundance gradient profiles if left unaddressed.         _ Less","","arXiv","https://arxiv.org/abs/2411.15327","3","2","origin_of_life"
"Balancing property optimization and constraint satisfaction for constrained multi-property molecular optimization","Abstract:                Molecular optimization, which aims to discover improved molecules from a vast chemical search space, is a critical step in_         _ More           Molecular optimization, which aims to discover improved molecules from a vast chemical search space, is a critical step in chemical development. Various artificial intelligence technologies have demonstrated high effectiveness and efficiency on molecular optimization tasks. However, few of these technologies focus on balancing property optimization with constraint satisfaction, making it difficult to obtain high-quality molecules that not only possess desirable properties but also meet various constraints. To address this issue, we propose a constrained multi-property molecular optimization framework (CMOMO), which is a flexible and efficient method to simultaneously optimize multiple molecular properties while satisfying several drug-like constraints. CMOMO improves multiple properties of molecules with constraints based on dynamic cooperative optimization, which dynamically handles the constraints across various scenarios. Besides, CMOMO evaluates multiple properties within discrete chemical spaces cooperatively with the evolution of molecules within an implicit molecular space to guide the evolutionary search. Experimental results show the superior performance of the proposed CMOMO over five state-of-the-art molecular optimization methods on two benchmark tasks of simultaneously optimizing multiple non-biological activity properties while satisfying two structural constraints. Furthermore, the practical applicability of CMOMO is verified on two practical tasks, where it identified a collection of candidate ligands of $_$2-adrenoceptor GPCR and candidate inhibitors of glycogen synthase kinase-3$_$ with high properties and under drug-like constraints.         _ Less","","arXiv","https://arxiv.org/abs/2411.15183","0","1","synthetic_biology"
"PDS 70b Shows Stellar-like Carbon-to-oxygen Ratio","Abstract:                _5 Myr PDS 70 is the only known system with protoplanets residing in the cavity of the circumstellar disk from which they formed, ideal for studying exoplanet formation and evolution within its natal environment. Here we report the first spin constraint and C/O measurement of PDS 70b from Keck/KPIC high-resolution spectroscopy. We detected CO (3.8 $_$) and H_         _ More           The $\\sim$5 Myr PDS 70 is the only known system with protoplanets residing in the cavity of the circumstellar disk from which they formed, ideal for studying exoplanet formation and evolution within its natal environment. Here we report the first spin constraint and C/O measurement of PDS 70b from Keck/KPIC high-resolution spectroscopy. We detected CO (3.8 $_$) and H$_2$O (3.5 $_$) molecules in the PDS 70b atmosphere via cross-correlation, with a combined CO and H$_2$O template detection significance of 4.2 $_$. Our forward model fits, using BT-Settl model grids, provide an upper limit for the spin-rate of PDS 70b ($<$29 km s$^{-1}$). The atmospheric retrievals constrain the PDS 70b C/O ratio to ${0.28}^{+0.20}_{-0.12}$ ($<$0.63 under 95$\\%$ confidence level) and a metallicity [C/H] of ${-0.2}^{+0.8}_{-0.5}$ dex, consistent with that of its host star. The following scenarios can explain our measured C/O of PDS 70b in contrast with that of the gas-rich outer disk (for which C/O $\\gtrsim$ 1). First, the bulk composition of PDS 70b might be dominated by dust+ice aggregates rather than disk gas. Another possible explanation is that the disk became carbon-enriched $\\textit{after}$ PDS 70b was formed, as predicted in models of disk chemical evolution and as observed in both very low mass star and older disk systems with $\\textit{JWST}$/MIRI. Because PDS 70b continues to accrete and its chemical evolution is not yet complete, more sophisticated modeling of the planet and the disk, and higher quality observations of PDS 70b (and possibly PDS 70c), are necessary to validate these scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2411.15117","2","1","origin_of_life"
"Unveiling the structural, chemical state, and optical band-gap evolution of Ta-doped epitaxial SrTiO3 thin films using first-principles calculations and spectroscopic ellipsometry","Abstract:                _achieve this theoretically, we vary the concentration of Ta from 0 - 12.5% in SrTi1-xTaxO3 system by substitutional doping and report its effect on the resulting structural, chemical, electronic, chemical, and optical properties. Additionally, we perform band unfolding to shed light on the true nature of optical transi_         _ More           In this report, the optical properties of Ta doped SrTiO3 (STO) due to its potential in transparent conducting oxides (TCOs) is explored by a combination of theoretical studies based on density functional theory and spectroscopic ellipsometry. To achieve this theoretically, we vary the concentration of Ta from 0 - 12.5% in SrTi1-xTaxO3 system by substitutional doping and report its effect on the resulting structural, chemical, electronic, chemical, and optical properties. Additionally, we perform band unfolding to shed light on the true nature of optical transitions due to Ta doping. We verify these results experimentally by fabricating epitaxial SrTi1-xTaxO3 thin films ( x = 0 - 5%) by pulsed laser deposition and obtain the optical dielectric properties of the system with the help of spectroscopic ellipsometry. By combining theoretical and experimental studies, we provide evidence that the band gap of STO increases due to Ta doping while also enhancing its electronic properties. The findings of our study offer an extensive understanding of the intricacies associated with elemental doping in perovskite oxides and propose strategies for addressing obstacles associated with TCOs.         _ Less","","arXiv","https://arxiv.org/abs/2411.15023","0","1","synthetic_biology"
"Protosolar D-to-H abundance and one part-per-billion PH$_{3}$ in the coldest brown dwarf","Abstract:                _testing our understanding of physics and chemistry for these complex, cool worlds. At these cold temperatures, their atmospheres are cold enough for water clouds to form, and chemical timescales increase, increasing the likelihood of disequilibrium chemistry compared to warmer classes of planets. JWST observations are revolutionizing the characterization of_         _ More           The coldest Y spectral type brown dwarfs are similar in mass and temperature to cool and warm ($\\sim$200 -- 400 K) giant exoplanets. We can therefore use their atmospheres as proxies for planetary atmospheres, testing our understanding of physics and chemistry for these complex, cool worlds. At these cold temperatures, their atmospheres are cold enough for water clouds to form, and chemical timescales increase, increasing the likelihood of disequilibrium chemistry compared to warmer classes of planets. JWST observations are revolutionizing the characterization of these worlds with high signal-to-noise, moderate resolution near- and mid-infrared spectra. The spectra have been used to measure the abundances of prominent species like water, methane, and ammonia; species that trace chemical reactions like carbon monoxide; and even isotopologues of carbon monoxide and ammonia. Here, we present atmospheric retrieval results using both published fixed-slit (GTO program 1230) and new averaged time series observations (GO program 2327) of the coldest known Y dwarf, WISE 0855-0714 (using NIRSpec G395M spectra), which has an effective temperature of $\\sim$ 264 K. We present a detection of deuterium in an atmosphere outside of the solar system via a relative measurement of deuterated methane (CH$_{3}$D) and standard methane. From this, we infer the D/H ratio of a substellar object outside the solar system for the first time. We also present a well-constrained part-per-billion abundance of phosphine (PH$_{3}$). We discuss our interpretation of these results and the implications for brown dwarf and giant exoplanet formation and evolution.         _ Less","","arXiv","https://arxiv.org/abs/2411.14541","1","1","multiple"
"Examining the evolution of the Supersoft X-ray Source RX J$0513.9-6951$","Abstract:                _spectra of hot WDs computed under the assumption of local thermodynamic equilibrium. Our aim is to test a contraction model of the source variability by tracking the evolution of the WD properties. The used grid of hot WD model atmospheres spans a wide range of effective temperatures ($T_{\\rm eff}=100-1000\\,\\rm kK$ in steps of $25\\,\\rm kK$) and eight values_         _ More           Supersoft X-ray sources (SSS) are thought to be accreting white dwarfs (WDs) in close binary systems, with thermonuclear burning on their surfaces. The SSS RX J$0513.9-6951$ in the Large Magellanic Cloud (LMC) exhibits cyclic variations between optical low and high states, which are anti-correlated with its X-ray flux. This behaviour is believed to result from the periodic expansion and contraction of the WD due to variations in the accretion rate in the system. We analyse eight high-resolution XMM and six grating Chandra spectra of RX J$0513.9-6951$ with our grid of model atmosphere spectra of hot WDs computed under the assumption of local thermodynamic equilibrium. Our aim is to test a contraction model of the source variability by tracking the evolution of the WD properties. The used grid of hot WD model atmospheres spans a wide range of effective temperatures ($T_{\\rm eff}=100-1000\\,\\rm kK$ in steps of $25\\,\\rm kK$) and eight values of surface gravity $\\log g$. The LMC chemical composition was assumed. The obtained fitting parameters ($T_{\\rm eff}$, $\\log g$, and bolometric luminosity $L$) evolve on the $T_{\\rm eff}- \\log g$ and $T_{\\rm eff}- L$ planes. This evolution follows the model tracks of WDs with masses of $1.05-1.15\\,M_{\\odot}$ and thermonuclear burning on the surface. The analysis has showed that the optical brightness of the system is lower when the WD is larger, more luminous, and more effectively illuminates the accretion disc. These results contradict the contraction model, which predicts the opposite behaviour of the source. We use a model, that assumes that the far UV/soft X-ray flux is reprocessed into the optical band due to multiple scattering in the cloud system above the accretion disc. More significant illumination can lead to rarefying of the cloud slab, thereby reducing the reprocessing efficiency and making the source fainter in the optical band.         _ Less","","arXiv","https://arxiv.org/abs/2411.14273","0","1","synthetic_biology"
"Determining the absolute chemical abundance of nitrogen and sulfur in the quasar outflow of 3C298","Abstract:                Context. Quasar outflows are key players in the feedback processes that influence the evolution of galaxies and the intergalactic medium. The_         _ More           Context. Quasar outflows are key players in the feedback processes that influence the evolution of galaxies and the intergalactic medium. The chemical abundance of these outflows provides crucial insights into their origin and impact. Aims. To determine the absolute abundances of nitrogen and sulfur and the physical conditions of the outflow seen in quasar 3C298. Methods. We analyze archival spectral data from the Hubble Space Telescope (HST) for 3C298. We measure Ionic column densities from the absorption troughs and compare the results to photoionization predictions made by the Cloudy code for three different spectral energy distributions (SED), including MF87, UVsoft, and HE0238 SEDs. We also calculate the ionic column densities of excited and ground states of N iii to estimate the electron number density and location of the outflow using the Chianti atomic database. Results. The MF87, UVsoft, and HE0238 SEDs yield nitrogen and sulfur abundances at super-solar, solar, and sub-solar values, respectively, with a spread of 0.4 to 3 times solar. Additionally, we determined an electron number density of log(ne) greater than 3.3 cm-3, with the outflow possibly extending up to a maximum distance of 2.8 kpc. Conclusions. Our results indicate solar metallicity within a 60 percent uncertainty range, driven by variations in the chosen SED and photoionization models. This study underscores the importance of SEDs impact on determining chemical abundances in quasars outflows. These findings highlight the necessity of considering a wider range of possible abundances, spanning from sub solar to super solar values.         _ Less","","arXiv","https://arxiv.org/abs/2411.14231","0","1","synthetic_biology"
"Aeos: Transport of metals from minihalos following Population III stellar feedback","Abstract:                _giant branch winds to the s-process elements, which are normally thought to only be important at late times. In this work, we establish important mechanisms for early chemical enrichment which allows us to apply Aeos in later epochs to trace the evolution of enrichment during the complete transition from Population III_         _ More           We investigate how stellar feedback from the first stars (Population III) distributes metals through the interstellar and intergalactic medium using the star-by-star cosmological hydrodynamics simulation, Aeos. We find that energy injected from the supernovae of the first stars is enough to expel a majority of gas and injected metals beyond the virial radius of halos with mass $M_* \\lesssim 10^7$ M$_\\odot$, regardless of the number of supernovae. This prevents self-enrichment and results in a non-monotonic increase in metallicity at early times. Most minihalos ($M \\gtrsim 10^5 \\, \\rm M_\\odot$) do not retain significant fractions of the yields produced within their virial radii until they have grown to halo masses of $M \\gtrsim 10^7 \\, \\rm M_\\odot$. The loss of metals to regions well beyond the virial radius delays the onset of enriched star formation and extends the period that Population III star formation can persist. We also explore the contributions of different nucleosynthetic channels to 10 individual elements. On the timescale of the simulation (lowest redshift $z=14.3$), enrichment is dominated by core-collapse supernovae for all elements, but with a significant contribution from asymptotic giant branch winds to the s-process elements, which are normally thought to only be important at late times. In this work, we establish important mechanisms for early chemical enrichment which allows us to apply Aeos in later epochs to trace the evolution of enrichment during the complete transition from Population III to Population II stars.         _ Less","","arXiv","https://arxiv.org/abs/2411.14209","1","1","multiple"
"Planets Around Solar Twins/Analogs (PASTA) I.: High precision stellar chemical abundance for 17 planet-hosting stars and the condensation temperature trend","Abstract:                _with Magellan II/MIKE, to investigate whether this depletion is related to planet formation. We derive stellar parameters, including stellar atmosphere, age, radius, mass, and chemical abundances for 22 elements from carbon to europium through line-by-line differential analysis. Our uncertainties range from 0.01 dex for Fe and Si to 0.08 dex for Sr, Y, and E_         _ More           The Sun is depleted in refractory elements compared to nearby solar twins, which may be linked to the formation of giant or terrestrial planets. Here we present high-resolution, high signal-to-noise spectroscopic data for 17 solar-like stars hosting planets, obtained with Magellan II/MIKE, to investigate whether this depletion is related to planet formation. We derive stellar parameters, including stellar atmosphere, age, radius, mass, and chemical abundances for 22 elements from carbon to europium through line-by-line differential analysis. Our uncertainties range from 0.01 dex for Fe and Si to 0.08 dex for Sr, Y, and Eu. By comparing the solar abundances to those of the 17 stars, we investigate the differential abundance ([X/Fe]$_{\\rm solar}$ - [X/Fe]$_{\\rm star}$) versus condensation temperature ($T_c$) trend. In particular, we apply Galactic chemical evolution corrections to five solar twins within the full sample. Our results conform to previous studies that the Sun is relatively depleted in refractory compared to volatile elements. For both five solar twins and the rest of solar-like stars, we find that all stars hosting known gas giant planets exhibit negative $T_c$ trend slopes, suggesting that the Sun is relatively depleted in refractory elements compared to similar giant-planet-host stars. Additionally, we find no correlation between $T_c$ trend slopes and the total mass of detected terrestrial planets in each system, suggesting that terrestrial planet formation may not be the cause of refractory element depletion in the Sun.         _ Less","","arXiv","https://arxiv.org/abs/2411.13825","2","1","origin_of_life"
"Chemical evolution of an evaporating lava pool","Abstract:                _them directly via emission spectroscopy or by observing the dust tails which trail the low mass `catastrophically evaporating planets'. In this work, we develop a simple chemical model of the lava pool--atmosphere system under mass loss, to study its evolution. Mass loss can occur both into space and from the day t_         _ More           Many known rocky exoplanets are so highly irradiated that their dayside surfaces are molten, and `silicate atmospheres', composed of rock-forming elements, are generated above these lava pools. The compositions of these `lava planet' atmospheres are of great interest because they must be linked to the composition of the underlying rocky interiors. It may be possible to investigate these atmospheres, either by detecting them directly via emission spectroscopy or by observing the dust tails which trail the low mass `catastrophically evaporating planets'. In this work, we develop a simple chemical model of the lava pool--atmosphere system under mass loss, to study its evolution. Mass loss can occur both into space and from the day to the nightside. We show that the system reaches a steady state, where the material in the escaping atmosphere has the same composition as that melted into the lava pool from the mantle. We show that the catastrophically evaporating planets are likely to be in this evolved state. This means that the composition of their dust tails is likely to be a direct trace of the composition of the mantle material that is melted into the lava pool. We further show that, due to the strength of day-to-nightside atmospheric transport, this evolved state may even apply to relatively high-mass planets (>1 Earth Mass). Moreover, the low pressure of evolved atmospheres implies that non-detections may not be due to the total lack of an atmosphere. Both conclusions are important for the interpretation of future observations.         _ Less","","arXiv","https://arxiv.org/abs/2411.13686","1","1","multiple"
"Atomistic investigation of irradiation-induced defect dynamics in FeNiCu medium-entropy alloy: effect of local chemical order","Abstract:                _for nuclear applications. In this study, we investigate the irradiation behavior of FeNiCu, a promising Co-free medium-entropy alloy (MEA) with a focus on the effect of local chemical order (LCO) using hybrid-molecular dynamics and Monte Carlo simulations. Considerable LCOs in Cu-Cu and Fe-Ni pairs were observed in the thermodynamically stable ordered system_         _ More           Medium and high-entropy alloys (M/HEAs) have garnered significant attention as potential nuclear structural materials due to their excellent stability at high temperatures and resistance to radiation. However, the common use of Co in M/HEAs, which exhibits high radioactivity under radiation has prompted the development of Co-free M/HEAs for nuclear applications. In this study, we investigate the irradiation behavior of FeNiCu, a promising Co-free medium-entropy alloy (MEA) with a focus on the effect of local chemical order (LCO) using hybrid-molecular dynamics and Monte Carlo simulations. Considerable LCOs in Cu-Cu and Fe-Ni pairs were observed in the thermodynamically stable ordered system. To conduct a comprehensive comparative study of irradiation-induced defect formation and dynamics, cumulative displacement cascades up to 500 were performed in random and ordered configurations of the MEA as well as in pure Ni for benchmark. Our study revealed LCO configuration as the most radiation resistant structure among the three. Complex potential energy landscape (PEL) in MEAs disrupts dislocation growth resulting in its dispersed distribution. The Cu-rich uniform regions in the ordered system act as defect traps enabling faster diffusion and high defect recombination resulting in formation of the dislocation networks in/near these regions. The lower stair-rod dislocation density in the ordered system revealed its high resistance to irradiation swelling signifying the effect of LCO even more, positioning FeNiCu MEA as a strong candidate for future nuclear application. Additionally, the theoretical insights into defect evolution covering formation and diffusion in both random and ordered structures enhance our understanding of LCO's impact, offering a solid foundation for the future development of radiation-resistant M/HEAs for nuclear applications.         _ Less","","arXiv","https://arxiv.org/abs/2411.13665","2","3","synthetic_biology"
"Radial Metallicity Gradients for the Chemically Selected Galactic Thin Disc Main-Sequence Stars","Abstract:                {We present the radial metallicity gradients within the Galactic thin disc population through main-sequence stars selected on the chemical plane using GALAH DR3 accompanied with Gaia DR3 astrometric data. The [Fe/H], [$_$/Fe] and [Mg/H] radial gradients are estimated for guiding radius as $-0.074\\pm 0.006$, $+0.004\\pm0.002$, $-0.074\\pm0.006$ dex kpc$^{-1}$ a_         _ More           {We present the radial metallicity gradients within the Galactic thin disc population through main-sequence stars selected on the chemical plane using GALAH DR3 accompanied with Gaia DR3 astrometric data. The [Fe/H], [$_$/Fe] and [Mg/H] radial gradients are estimated for guiding radius as $-0.074\\pm 0.006$, $+0.004\\pm0.002$, $-0.074\\pm0.006$ dex kpc$^{-1}$ and for the traceback early orbital radius as $-0.040\\pm0.002$, $+0.003\\pm 0.001$, $-0.039\\pm 0.002$ dex kpc$^{-1}$ for 66,545 thin-disc stars, respectively. Alteration of the chemical structure within the Galactic disc caused by the radial orbital variations complicates results for the radial metallicity gradient. The effect of radial orbital variations on the metallicity gradients as a function on time indicates the following results: (i) The presence of a gradient along the disc throughout the time for which the model provides similar prediction, (ii) the radial orbital variations becomes more pronounced with the age of the stellar population and (iii) the effect of radial orbital variations on the metallicity gradients is minimal. The effect of radial orbital variations is found to be at most 6\\% which does not statistically affect the radial gradient results. These findings contribute to a better understanding of the chemical evolution within the Galactic disc and provide an important basis for further research.         _ Less","","arXiv","https://arxiv.org/abs/2411.13660","1","1","multiple"
"Assessing the processes behind planet engulfment and its imprints","Abstract:                Throughout a planetary system's formation evolution, some of the planetary material may end up falling into the host star and be engulfed by it, leading to a potential variation of the stellar composition. The present study explores how planet engulfment may impact the_         _ More           Throughout a planetary system's formation evolution, some of the planetary material may end up falling into the host star and be engulfed by it, leading to a potential variation of the stellar composition. The present study explores how planet engulfment may impact the chemical composition of the stellar surface and discusses what would be the rate of events with an observable imprint, for Sun-like stars. We use data from the NGPPS calculations by the Generation III Bern model to analyse the conditions under which planet engulfment may occur. Additionally, we use stellar models computed with Cesam2k20 to account for how the stellar internal structure and its processes may affect the dilution of the signal caused by planet engulfment. Our results show that there are three different phases associated to different mechanisms under which engulfment events may happen. Moreover, systems that undergo planet engulfment are more likely to come from protoplanetary disks that are more massive and more metal-rich than non-engulfing systems. Engulfment events leading to an observable signal happen after the dissipation of the protoplanetary disk when the convective envelope of the stars becomes thinner. With the stellar convective layer shrinking as the star evolves in the main sequence, they display a higher variation of chemical composition, which also correlates with the amount of engulfed material. By accounting for the physical processes happening in the stellar interior and in the optimistic case of being able to detect variations above 0.02 dex in the stellar composition, we find an engulfment rate no higher than $20\\%$ for Sun-like stars that may reveal detectable traces of planet engulfment. Engulfment events that lead to an observable variation of the stellar composition are rare due to the specific conditions required to result in such signatures.         _ Less","","arXiv","https://arxiv.org/abs/2411.13455","1","1","multiple"
"Equation of state of isospin asymmetric QCD with small baryon chemical potentials","Abstract:                We extend our measurement of the equation of state of isospin asymmetric QCD to small baryon and strangeness chemical potentials, using the leading order Taylor expansion coefficients computed directly at non-zero isospin_         _ More           We extend our measurement of the equation of state of isospin asymmetric QCD to small baryon and strangeness chemical potentials, using the leading order Taylor expansion coefficients computed directly at non-zero isospin chemical potentials. Extrapolating the fully connected contributions to vanishing pion sources is particularly challenging, which we overcome by using information from isospin chemical potential derivatives evaluated numerically. Using the Taylor coefficients, we present, amongst others, first results for the equation of state along the electric charge chemical potential axis, which is potentially of relevance for the evolution of the early Universe at large lepton flavour asymmetries.         _ Less","","arXiv","https://arxiv.org/abs/2411.12918","1","1","multiple"
"On a modified Cahn-Hilliard-Brinkman model with chemotaxis and nonlinear sensitivity","Abstract:                _equation with singular potential, mass source and transport effects, to a Brinkman-type relation for the macroscopic velocity field and to a further equation describing the evolution of the concentration of a_         _ More           We consider an evolutionary PDE system coupling the Cahn-Hilliard equation with singular potential, mass source and transport effects, to a Brinkman-type relation for the macroscopic velocity field and to a further equation describing the evolution of the concentration of a chemical substance affecting the phase separation process. The main application we have in mind refers to tumor growth models: in particular, the equation for the chemical prescribes that such a substance tends to migrate towards the regions where the tumor cells are more dense and consume it more actively. The cross-diffusion effects characterizing the system are similar to those occurring in the Keller-Segel model for chemotaxis. There is, however, a profound difference between the two settings: actually, the Cahn-Hilliard system prescribes a fourth-order dynamics with respect to space variables, whereas most models for chemotaxis are of the second order in space. This fact has a number of specific consequences regarding regularity properties of solutions and conditions ensuring existence. Our main results are devoted to proving existence of weak solutions in the case when the chemotactic sensitivity function depends nonlinearly on the chemical species concentration, and, more precisely, has a slow growth at infinity so to avoid finite-time blowup. We also analyze the asymptotic problem obtained by letting the viscosity go to zero so to get a Darcy flow regime in the limit.         _ Less","","arXiv","https://arxiv.org/abs/2411.12505","0","2","synthetic_biology"
"Chemical Evolution during Molecular Cloud Formation Triggered by an Interstellar Shock Wave: Dependence on Shock Parameters and Comparison with Molecular Absorption Lines","Abstract:                _the interstellar magnetic field and the shock wave, pre-shock density, and shock velocity. Then we derive 1D mean-flow models, along which we calculate a detailed gas-grain chemical reaction network as a post process with various chemical parameters, i.e. cosmic-ray ionization rate, abundances of PAHs, and metals in th_         _ More           We investigate chemistry in the compression layer behind the interstellar shock waves, where molecular cloud formation starts. We perform three-dimensional magnetohydrodynamics simulations of converging flows of atomic gas with shock parameters of inclination between the interstellar magnetic field and the shock wave, pre-shock density, and shock velocity. Then we derive 1D mean-flow models, along which we calculate a detailed gas-grain chemical reaction network as a post process with various chemical parameters, i.e. cosmic-ray ionization rate, abundances of PAHs, and metals in the gas phase. While carbon chains reach their peak abundances when atomic carbon is dominant in the pseudo-time-dependent models of molecular clouds, such behavior is less significant in our models since the visual extinction of the compression layer is low ($\\lesssim 1$ mag) when atomic carbon is abundant. Carbon chains, CN, and HCN increase at $A_V \\gtrsim 1$ mag, where the gas-phase C/O ratio increases due to water ice formation. Shock parameters affect the physical structure and the evolutional timescale of the compression layer, and thus molecular evolution. Carbon chains are more abundant in models with higher post-shock density and slower gas accumulation. We calculate molecular column densities in the compression layer and compare them with the observations of diffuse and translucent clouds, which show reasonable agreement for water ice, carbon chains, and HCO$^+$. The observed variation of their column densities could be due to the difference in shock parameters and chemical parameters. The column density of CN is overestimated, for which we discuss possible reasons.         _ Less","","arXiv","https://arxiv.org/abs/2411.12394","2","2","multiple"
"The age of the Methuselah star in light of stellar evolution models with tailored abundances","Abstract:                Context. HD140283, or the Methuselah star, is a well-known reference object in stellar evolution. Its peculiar_         _ More           Context. HD140283, or the Methuselah star, is a well-known reference object in stellar evolution. Its peculiar chemical composition, proximity and absence of reddening makes it an interesting case-study of Pop II stars. Thanks to recent observational efforts, we now have precise interferometric and spectroscopic constraints, as well as revised astrometric parallaxes from the Gaia mission. Aims. We aim at determining the age of HD140283 with these lastest constraints, as well as quantifying the impact of systematics from physical inaccuracies in the stellar evolution models. Methods. Using recent spectroscopic abundances from the literature, including 3D non-LTE values for C, O, and Fe, we compute opacity tables specific to HD140283. We then use them in grids of stellar evolution models coupled to a Markov Chain Monte Carlo tool to determine the age of HD140283. Results. With our tailored models we find an age of 12.3Gy. Using a solar-scaled mixture instead results in an age value of 14Gy, in tension with the age of the universe ($13.77\\pm0.06$Gy). We also find that reducing the mixing length parameter from its solar calibrated value will lead to an even lower age, in agreement with other recent studies. However, we find no direct evidence to favour a lower mixing length parameter value from our modelling. Conclusions. Taking into account the specific elemental abundances is crucial for the modelling of HD140283, as it leads to significant differences in the inferred age. However, this effect is degenerate with a lowering of the mixing length parameter. In this respect, asteroseismic constraints might play a key role in accurately deriving the mass of HD140283, therefore strongly constraining its age.         _ Less","","arXiv","https://arxiv.org/abs/2411.12343","0","1","synthetic_biology"
"Clouds and Hazes in the Atmospheres of Triton and Pluto","Abstract:                _interactions between atmospheric gases and ultraviolet photons from the Sun and those scattered by the local interstellar medium. These interactions lead to a rich network of chemical reactions that produces higher order hydrocarbons and nitriles that condense out to form ice clouds, and ultimately complex haze particles that rain down onto the surface that_         _ More           Clouds and hazes are abundant in the thin and cold atmospheres of Triton and Pluto, where they are thought to be produced by interactions between atmospheric gases and ultraviolet photons from the Sun and those scattered by the local interstellar medium. These interactions lead to a rich network of chemical reactions that produces higher order hydrocarbons and nitriles that condense out to form ice clouds, and ultimately complex haze particles that rain down onto the surface that impact the atmospheric thermal structure, gas chemistry, and surface evolution. In this chapter, we will review the observational evidence for clouds and hazes in the atmospheres of Triton and Pluto and theoretical interpretations thereof, and the emerging set of experiments aiming to produce Triton and Pluto clouds and hazes in the lab to learn about them in detail.         _ Less","","arXiv","https://arxiv.org/abs/2411.12031","1","2","synthetic_biology"
"The JWST EXCELS survey: tracing the chemical enrichment pathways of high-redshift star-forming galaxies with O, Ar and Ne abundances","Abstract:                _from the JWST EXCELS survey for which we obtain robust chemical abundance estimates for the $_$-elements O, Ne and Ar. The $_$-elements are primarily produced via core-collapse supernovae (CCSNe) which should result in $_$-element abundance ratios that do not vary significantly across cosmic time. However, Type Ia supernovae (SNe Ia) models predict an exces_         _ More           We present an analysis of nine star-forming galaxies with $\\langle z \\rangle = 3.95$ from the JWST EXCELS survey for which we obtain robust chemical abundance estimates for the $_$-elements O, Ne and Ar. The $_$-elements are primarily produced via core-collapse supernovae (CCSNe) which should result in $_$-element abundance ratios that do not vary significantly across cosmic time. However, Type Ia supernovae (SNe Ia) models predict an excess production of Ar relative to O and Ne. The Ar/O abundance ratio can therefore be used as a tracer of the relative enrichment of CCSNe and SNe Ia in galaxies. Our sample approximately doubles the number of sources with measurements of ${\\rm Ar/O}$ at $z > 2$, and we find that our sample exhibits sub-solar Ar/O ratios on average, with $\\rm{Ar/O} = 0.62 \\pm 0.10 \\, (\\rm{Ar/O})_{\\odot}$. In contrast, the average Ne/O abundance is fully consistent with the solar ratio, with $\\rm{Ne/O} = 1.07 \\pm 0.12 \\, (\\rm{Ne/O})_{\\odot}$. Our results support a scenario in which Ar has not had time to build up in the interstellar medium of young high-redshift galaxies, which are dominated by CCSNe enrichment. We show that these abundance estimates are in good agreement with recent Milky Way chemical evolution models, and with Ar/O trends observed for planetary nebulae in the Andromeda galaxy. These results highlight the potential for using multiple element abundance ratios to constrain the chemical enrichment pathways of early galaxies with JWST.         _ Less","","arXiv","https://arxiv.org/abs/2411.11837","2","2","multiple"
"Open Catalyst Experiments 2024 (OCx24): Bridging Experiments and Computational Models","Abstract:                _RR) and hydrogen evolution reactions (HER) at current densities up to $300$ mA/cm$^2$. To find correlations with experimental outcomes and to perform computational screens, DFT-verified adsorption energies for six adsorbates were calculated on $\\sim$20,000 inorganic materials requiring 685 million AI-accelerated relaxations. Remarkably from this large set of_         _ More           The search for low-cost, durable, and effective catalysts is essential for green hydrogen production and carbon dioxide upcycling to help in the mitigation of climate change. Discovery of new catalysts is currently limited by the gap between what AI-accelerated computational models predict and what experimental studies produce. To make progress, large and diverse experimental datasets are needed that are reproducible and tested at industrially-relevant conditions. We address these needs by utilizing a comprehensive high-throughput characterization and experimental pipeline to create the Open Catalyst Experiments 2024 (OCX24) dataset. The dataset contains 572 samples synthesized using both wet and dry methods with X-ray fluorescence and X-ray diffraction characterization. We prepared 441 gas diffusion electrodes, including replicates, and evaluated them using zero-gap electrolysis for carbon dioxide reduction (CO$_2$RR) and hydrogen evolution reactions (HER) at current densities up to $300$ mA/cm$^2$. To find correlations with experimental outcomes and to perform computational screens, DFT-verified adsorption energies for six adsorbates were calculated on $\\sim$20,000 inorganic materials requiring 685 million AI-accelerated relaxations. Remarkably from this large set of materials, a data driven Sabatier volcano independently identified Pt as being a top candidate for HER without having any experimental measurements on Pt or Pt-alloy samples. We anticipate the availability of experimental data generated specifically for AI training, such as OCX24, will significantly improve the utility of computational models in selecting materials for experimental screening.         _ Less","","arXiv","https://arxiv.org/abs/2411.11783","1","2","synthetic_biology"
"AQUILA: A Laboratory Facility for the Irradiation of Astrochemical Ice Analogues by keV Ions","Abstract:                _In this article, we describe a new facility called AQUILA (Atomki-Queen's University Ice Laboratory for Astrochemistry) which has been purposefully designed to study the chemical evolution of ices analogous to those that may be found in the dense interstellar medium or the outer Solar System as a result of their e_         _ More           The detection of various molecular species, including complex organic molecules relevant to biochemical and geochemical processes, in astronomical settings such as the interstellar medium or the outer Solar System has led to the increased need for a better understanding of the chemistry occurring in these cold regions of space. In this context, the chemistry of ices prepared and processed at cryogenic temperatures has proven to be of particular interest due to the fact that many interstellar molecules are believed to originate within the icy mantles adsorbed on nano- and micro-scale dust particles. The chemistry leading to the formation of such molecules may be initiated by ionising radiation in the form of galactic cosmic rays or stellar winds, and thus there has been an increased interest in commissioning experimental set-ups capable of simulating and better characterising this solid-phase radiation astrochemistry. In this article, we describe a new facility called AQUILA (Atomki-Queen's University Ice Laboratory for Astrochemistry) which has been purposefully designed to study the chemical evolution of ices analogous to those that may be found in the dense interstellar medium or the outer Solar System as a result of their exposure to keV ion beams. The results of some ion irradiation studies of CH3OH ice at 20 K are discussed to exemplify the experimental capabilities of the AQUILA as well as to highlight its complementary nature to another laboratory astrochemistry set-up at our institute.         _ Less","","arXiv","https://arxiv.org/abs/2411.11765","2","1","origin_of_life"
"Cosmological insights into the early accretion of r-process-enhanced stars II. Dynamical identification of lost members of Reticulum II","Abstract:                _for these stars and the dynamical mass-loss model of Reticulum II during its orbital motion for 11.5 Gyr of lookback time. The dynamical orbital modelling together with the chemical abundance analysis proved to be useful tools for the progenitor identification of the peculiar stars in our Galaxy. Methods. To reproduce the Reticulum II orbital mass loss, we u_         _ More           Aims. We identify the possible dynamical connection between individual r-process-enhanced stars and the ultra-faint dwarf galaxy Reticulum II based on the current phase-space information for these stars and the dynamical mass-loss model of Reticulum II during its orbital motion for 11.5 Gyr of lookback time. The dynamical orbital modelling together with the chemical abundance analysis proved to be useful tools for the progenitor identification of the peculiar stars in our Galaxy. Methods. To reproduce the Reticulum II orbital mass loss, we used our high-precision N-body phi-GPU code to integrate almost 1 million stars into the system evolution inside a external Galactic potential. We also investigated the orbits of r-process-enhanced stars using the same code. Results. We present our Reticulum II dynamical modelling results in the context of the stars energies - angular momentum phase-space and phase-space overlapping of the currently observed r-process-enhanced stars with Reticulum II stellar tidal tails. Of the 530 r-stars known today, at least 93 are former members of the Reticulum II dynamical progenitor system.         _ Less","","arXiv","https://arxiv.org/abs/2411.11134","1","1","multiple"
"Distribution of Europium in The Milky Way Disk; Its Connection to Planetary Habitability and The Source of The R-Process","Abstract:                _in planetary mantles, sustains geodynamics important for surface habitability such as the generation of a planetary magnetic dynamo. In order to better understand the thermal evolution of nearby exoplanets, stellar photospheric abundances can be used to infer the material composition of orbiting planets. Here we constrain the intrinsic dispersion of the r-pr_         _ More           The energy provided in the radioactive decay of thorium (Th) and uranium (U) isotopes, embedded in planetary mantles, sustains geodynamics important for surface habitability such as the generation of a planetary magnetic dynamo. In order to better understand the thermal evolution of nearby exoplanets, stellar photospheric abundances can be used to infer the material composition of orbiting planets. Here we constrain the intrinsic dispersion of the r-process element europium (Eu) (measured in relative abundance [Eu/H]) as a proxy for Th and U in local F, G, and K type dwarf stars. Adopting stellar-chemical data from two high quality spectroscopic surveys, we have determined a small intrinsic scatter of 0.025 dex in [Eu/H] within the disk. We further investigate the stellar anti-correlation in [Eu/$_$] vs [$_$/H] at late metallicities to probe in what regimes planetary radiogenic heating may lead to periods of extended dynamo collapse. We find that only near-solar metallicity stars in the disk have Eu inventories supportive of a persistent dynamo in attendant planets, supporting the notion of a ``metallicity Goldilocks zone'' in the galactic disk. The observed anti-correlation further provides novel evidence regarding the nature of r-processes injection by substantiating $_$ element production is decoupled from Eu injection. This suggests either a metallicity-dependent r-process in massive core-collapse supernovae, or that neutron-star merger events dominate r-process production in the recent universe.         _ Less","","arXiv","https://arxiv.org/abs/2411.10711","1","2","synthetic_biology"
"Terrestrial planet surfaces and interiors","Abstract:                _a silicate crust, a silicate mantle, and an iron-rich core. However, while all terrestrial planets share a common structure, the thickness of their interior layers, their bulk chemical composition, and surface expressions of geological processes are often unique to each of them. In this chapter we provide an overview of the surfaces and interiors of rocky pl_         _ More           Rocky planets in our Solar System, namely Mercury, Venus, Earth, Mars, and the Moon, which is generally added to this group due to its geological complexity, possess a solid surface and share a common structure divided into major layers, namely a silicate crust, a silicate mantle, and an iron-rich core. However, while all terrestrial planets share a common structure, the thickness of their interior layers, their bulk chemical composition, and surface expressions of geological processes are often unique to each of them. In this chapter we provide an overview of the surfaces and interiors of rocky planets in the Solar System. We list some of the major discoveries in planetary exploration and discuss how they have helped to answer fundamental questions about planetary evolution while at the same time opening new avenues. For each of the major planetary layers, i.e., the surface, the crust and lithosphere, the mantle, and the core, we review key geological and geophysical processes that have shaped the planets that we observe today. Understanding the similarities and differences between the terrestrial planets in the Solar System will teach us about the diversity of evolutionary paths a planet could follow, helping us to better understand our own home, the Earth.         _ Less","","arXiv","https://arxiv.org/abs/2411.10577","2","3","synthetic_biology"
"Mass-loss, composition and observational signatures of stellar winds from X-ray bursts","Abstract:                _wind model and coupled it to an XRB hydrodynamic simulation. We now apply this technique to another model featuring consecutive bursts. We determine the mass-loss and chemical composition of the wind ejecta. Results show that, for a representative XRB, about $0.1\\%$ of the envelope mass is ejected per burst, at an average rate of_         _ More           X-Ray bursts (XRBs) are powerful thermonuclear events on the surface of accreting neutron stars (NSs), which can synthesize intermediate-mass elements. Although the high surface gravity prevents an explosive ejection, a small fraction of the envelope may be ejected by radiation-driven winds. In our previous works, we have developed a non-relativistic radiative wind model and coupled it to an XRB hydrodynamic simulation. We now apply this technique to another model featuring consecutive bursts. We determine the mass-loss and chemical composition of the wind ejecta. Results show that, for a representative XRB, about $0.1\\%$ of the envelope mass is ejected per burst, at an average rate of $3.9 \\times 10^{-12}\\,M_\\odot \\texttt{yr}^{-1}$. Between $66\\%$ and $76\\%$ of the ejecta composition is $^{60}$Ni, $^{64}$Zn, $^{68}$Ge, $^{4}$He and $^{58}$Ni. We also report on the evolution of observational quantities during the wind phase and simulate NICER observations that resemble those of 4U 1820-40.         _ Less","","arXiv","https://arxiv.org/abs/2411.10256","0","1","synthetic_biology"
"Constraints on the history of Galactic spiral arms revealed by Gaia GSP-Spec alpha-elements","Abstract:                The distribution of chemical elements in the Galactic disc can reveal fundamental clues on the physical processes that led to the current configuration of our Galaxy. We map_         _ More           The distribution of chemical elements in the Galactic disc can reveal fundamental clues on the physical processes that led to the current configuration of our Galaxy. We map chemical azimuthal variations in the disc using individual stellar chemical abundances and discuss their possible connection with the spiral arms and other perturbing mechanisms. Using Gaia Data Release 3, we examine [Ca/Fe] and [Mg/Fe] fluctuations in a ~4 kpc region around the Sun, focusing on bright giant stars. We implemented a kernel density estimator technique to enhance the chemical inhomogeneities. We observe radial gradients and azimuthal fluctuations in [alpha/Fe] for young (<150 Myr) and old (>2 Gyr) stars, with amplitudes varying according to the studied element. In young stars, those within spiral arms (e.g., Sagittarius-Carina and Local arms) are generally more metal and calcium-rich (~0-0.19 dex) but show lower [Ca/Fe] (~0.06 dex) and [Mg/Fe] (~0.05 dex) compared to inter-arm regions, suggesting enhanced iron production in spiral arms. These [alpha/Fe] depletions are analysed in light of theoretical scenarios and compared to a 2D chemical evolution model with multiple spiral patterns. For the old sample, [Ca/Fe] maps reveal deficiencies along a segment of the Local arm identified by young stars. We caution that, for this old sample, the quality of the obtained maps might be limited along a specific line-of-sight, due to the Gaia scanning law. This study transitions our understanding of disc chemical evolution from a 1D radial view to a more detailed 2D framework incorporating radial, azimuthal, and small-scale variations. Individual chemical abundances prove essential for tracing spiral arms in disc galaxies. We recommend models and simulations incorporate alpha-abundance trends to better address spiral arm lifetimes.         _ Less","","arXiv","https://arxiv.org/abs/2411.10007","1","1","multiple"
"Maximum entropy inference of reaction-diffusion models","Abstract:                Reaction-diffusion equations are commonly used to model a diverse array of complex systems, including biological, chemical, and physical processes. Typically, these models are phenomenological, requiring the fitting of parameters to experimental data. In the present work, we introduce a novel formalism to construct reaction-diffusion models that is grounded_         _ More           Reaction-diffusion equations are commonly used to model a diverse array of complex systems, including biological, chemical, and physical processes. Typically, these models are phenomenological, requiring the fitting of parameters to experimental data. In the present work, we introduce a novel formalism to construct reaction-diffusion models that is grounded in the principle of maximum entropy. This new formalism aims to incorporate various types of experimental data, including ensemble currents, distributions at different points in time, or moments of such. To this end, we expand the framework of Schr_dinger bridges and Maximum Caliber problems to nonlinear interacting systems. We illustrate the usefulness of the proposed approach by modeling the evolution of (i) a morphogen across the fin of a zebrafish and (ii) the population of two varieties of toads in Poland, so as to match the experimental data.         _ Less","","arXiv","https://arxiv.org/abs/2411.09880","0","1","synthetic_biology"
"Type Ia supernovae","Abstract:                _distance indicators and led to the discovery of the accelerated expansion of the universe. SNe Ia are also the main producers of iron and hence play a fundamental role in the chemical evolution of galaxies. While recent observations have confirmed the basic theoretical picture of an exploding C-O WD star whose luminosi_         _ More           Type Ia supernovae (SNe Ia) correspond to the thermonuclear explosion of a carbon-oxygen white dwarf (C-O WD) star in a binary system, triggered by the accretion of material from another star, or the merger/collision with a secondary WD. Their phenomenal luminosity -- several billion times that of the sun -- has motivated their use as cosmological distance indicators and led to the discovery of the accelerated expansion of the universe. SNe Ia are also the main producers of iron and hence play a fundamental role in the chemical evolution of galaxies. While recent observations have confirmed the basic theoretical picture of an exploding C-O WD star whose luminosity is powered by the radioactive decay of $^{56}$Ni, a number of uncertainties remain concerning the nature of the binary companion and the explosion mechanism. Several lines of evidence point towards the existence of multiple progenitor channels in order to explain the full range of the observed diversity. A complete physical understanding of these energetic stellar explosions remains a long-lasting goal of modern astrophysics.         _ Less","","arXiv","https://arxiv.org/abs/2411.09740","1","1","multiple"
"High-temperature $^{205}$Tl decay clarifies $^{205}$Pb dating in early Solar System","Abstract:                _Pb yields. Propagating those yields with basic galactic chemical evolution (GCE) and comparing with the $^{205}$Pb/$^{204}$Pb ratio from meteorites, we determined the isolation time of solar material inside its parent molecular cloud. We find positive isolation times that are consistent with the other s-process short-l_         _ More           Radioactive nuclei with lifetimes on the order of millions of years can reveal the formation history of the Sun and active nucleosynthesis occurring at the time and place of its birth. Among such nuclei whose decay signatures are found in the oldest meteorites, $^{205}$Pb is a powerful example, as it is produced exclusively by slow neutron captures (the s process), with most being synthesized in asymptotic giant branch (AGB) stars. However, making accurate abundance predictions for $^{205}$Pb has so far been impossible because the weak decay rates of $^{205}$Pb and $^{205}$Tl are very uncertain at stellar temperatures. To constrain these decay rates, we measured for the first time the bound-state $_^-$ decay of fully ionized $^{205}$Tl$^{81+}$, an exotic decay mode that only occurs in highly charged ions. The measured half-life is 4.7 times longer than the previous theoretical estimate and our 10% experimental uncertainty has eliminated the main nuclear-physics limitation. With new, experimentally backed decay rates, we used AGB stellar models to calculate $^{205}$Pb yields. Propagating those yields with basic galactic chemical evolution (GCE) and comparing with the $^{205}$Pb/$^{204}$Pb ratio from meteorites, we determined the isolation time of solar material inside its parent molecular cloud. We find positive isolation times that are consistent with the other s-process short-lived radioactive nuclei found in the early Solar System. Our results reaffirm the site of the Sun's birth as a long-lived, giant molecular cloud and support the use of the $^{205}$Pb--$^{205}$Tl decay system as a chronometer in the early Solar System.         _ Less","","arXiv","https://arxiv.org/abs/2411.08856","2","1","origin_of_life"
"Leidenfrost drop dynamics: An approach to follow the complete evolution","Abstract:                A new model to follow the complete evolution of a drop in Leidenfrost state is presented in this work. The main ingredients of the phenomenon were considered, including: 1) the shape and weight of a sessile drop, according to its size, compared to the capillary length, using the Young-Laplace equation; 2) the evaporation at the entire surface of the drop, du_         _ More           A new model to follow the complete evolution of a drop in Leidenfrost state is presented in this work. The main ingredients of the phenomenon were considered, including: 1) the shape and weight of a sessile drop, according to its size, compared to the capillary length, using the Young-Laplace equation; 2) the evaporation at the entire surface of the drop, due to the heat transfer across the vapor film, to the proximitiy of a hot plate and to the diffusion in air; 3) the velocity, pressure and temperature fields at the vapor film, between the drop and the hot plate, which are recovered by means of a Hankel transform method, being valid for any size of drops and any thickness of vapor films (below the vapor film stability threshold); 4) an estimation of the thermo-capillary Marangoni convection flow, without simulating numerically the flow within the drop. The aforementioned features were addressed and calculated, in order to include their effect within a single non-linear ODE, describing the temporal evolution of the size of the drop, through the Bond number. Three dimensionless parameters, relating the thermophysical properties of the drop fluid and the surrounding air, control the development of the phenomenon. All those properties were calculated according to the ideal gas approximation and to widely used empirical correlations, without any fitting parameter. The model predictions were compared against experimental results, using different organic and inorganic compounds, for which a good agreement has been found, when no bounce or rotation of the drop spontaneously occurs.         _ Less","","arXiv","https://arxiv.org/abs/2411.08153","0","1","synthetic_biology"
"Cosmology with HI","Abstract:                Hydrogen, the most abundant element in the Universe, has traditionally been used to investigate astrophysical processes within and around our own Galaxy. In its chemically neutral, atomic form (known as HI in the astronomical literature), it has tremendous potential today as a tool for precision cosmology and testing theories of fundamental physics. Cosmolog_         _ More           Hydrogen, the most abundant element in the Universe, has traditionally been used to investigate astrophysical processes within and around our own Galaxy. In its chemically neutral, atomic form (known as HI in the astronomical literature), it has tremendous potential today as a tool for precision cosmology and testing theories of fundamental physics. Cosmological HI is accessed through two of its main spectral lines: the Lyman-$_$, with a rest wavelength of 1216 $_$, in the ultraviolet and visible part of the spectrum, and the 21-cm, which manifests in the radio frequency band. A plethora of radio telescopes worldwide are focused on detecting the faint 21 cm signal from the dark ages and Cosmic Dawn, some of the earliest epochs of the Universe. This chapter will describe the formalism for doing cosmology with HI, the recent results from the facilities and their prospects for studying the evolution of the Universe.         _ Less","","arXiv","https://arxiv.org/abs/2411.08113","0","1","synthetic_biology"
"Tracing back a second-generation star stripped from Terzan 5 by the Galactic bar","Abstract:                _oldest stars, possibly coming from disrupted globular clusters (GCs) or the bulge's primordial building blocks, making these stars witnesses to the Galaxy's early chemical enrichment. The Galactic bar currently dominates the bulge's region, altering the orbits of objects formed before its formation and complicating the trace of the field stars_         _ More           The Galactic bulge hosts the Milky Way's oldest stars, possibly coming from disrupted globular clusters (GCs) or the bulge's primordial building blocks, making these stars witnesses to the Galaxy's early chemical enrichment. The Galactic bar currently dominates the bulge's region, altering the orbits of objects formed before its formation and complicating the trace of the field stars' original clusters. Here, we present the discovery of a fossil record of this evolution, SOS1 -- a star trapped in the bar, exhibiting significant enhancements in nitrogen, sodium, and aluminum, typical of second-generation GC stars. SOS1 also shows an s-process Ce enhancement, suggesting an old age and early enrichment by fast-rotating massive stars in the Galaxy's earliest phases. With the purpose of finding the SOS1's parent GC, we derive its precise chemodynamical properties by combining high-precision proper motions from Gaia with APOGEE detailed chemical abundances. Our analysis suggests that SOS1 was possibly stripped from the GC Terzan 5 by the Galactic bar's gravitational influence approximately 350 Myr ago. We also found chemical similarities suggesting that SOS1 belonged to the most metal-poor, ancient, and peripheral stellar population of Terzan 5. These results not only support the hypothesis that Terzan 5 is a remnant of a primordial building block of the Galactic bulge, but also suggest this cluster continues losing stars to the bar. Our method highlights how powerful the use of chemodynamical properties in the Gaia era is for tracing the Galaxy's evolutionary history.         _ Less","","arXiv","https://arxiv.org/abs/2411.08096","1","1","multiple"
"How grain structure evolution affects kinetics of a solid-state reaction: a case of interaction between iridium and zirconium carbide","Abstract:                _compound of great interest for modern high-temperature materials science. We have found a transition of kinetic regimes in this reaction: from linear kinetics (when the chemical reaction is a limiting stage) at 1500 and 1550_C to `non-parabolic kinetics' at 1600_C. Non-parabolic kinetics is characterized by thickness of a product layer being proportional_         _ More           This work investigates the solid-state reaction between iridium and zirconium carbide, resulting in the formation of carbon and $\\mathrm{ZrIr}_{3}$ -- an intermetallic compound of great interest for modern high-temperature materials science. We have found a transition of kinetic regimes in this reaction: from linear kinetics (when the chemical reaction is a limiting stage) at 1500 and 1550_C to `non-parabolic kinetics' at 1600_C. Non-parabolic kinetics is characterized by thickness of a product layer being proportional to a power of time less than 1/2. The nature of non-parabolic kinetics was still an open question, which motivated us to develop a model of this kinetic regime. The proposed model accounts for the grain growth in the product phase and how it leads to the time dependence of the interdiffusion coefficient. We have obtained a complete analytic solution for this model and an equation that connects the grain-growth exponent and the power-law exponent of non-parabolic kinetics. The measurements of the thickness of the product layer and the average grain size of the intermetallic phase confirm the results of the theoretical solution.         _ Less","","arXiv","https://arxiv.org/abs/2411.05711","1","2","synthetic_biology"
"Evolution of Chemistry in the envelope of HOt CorinoS (ECHOS) II. The puzzling chemistry of isomers as revealed by the HNCS/HSCN ratio","Abstract:                _when the stable isomer is not detected, highlights the importance of non-equilibrium chemistry. This challenges our understanding of the interstellar chemistry. We present a chemical study of isomers through the sulphur isomer pair HNCS and HSCN, since HSCN has been observed in regions where its stable isomer has not been detected, and the observed HNCS/HSCN_         _ More           The observational detection of some metastable isomers in the interstellar medium with abundances comparable to those of the most stable isomer, or even when the stable isomer is not detected, highlights the importance of non-equilibrium chemistry. This challenges our understanding of the interstellar chemistry. We present a chemical study of isomers through the sulphur isomer pair HNCS and HSCN, since HSCN has been observed in regions where its stable isomer has not been detected, and the observed HNCS/HSCN ratio seems to significantly vary from cold to warm regions. We have used the Nautilus chemical code to model the formation and destruction paths of HNCS and HSCN in different astrochemical scenarios, and the time evolution of the HNCS/HSCN ratio. We have also analysed the influence of the environmental conditions on their chemical abundances. We present an observational detection of the metastable isomer HSCN in the Class I object B1-a, but not of the stable isomer HNCS, despite HNCS lying 3200 K lower in energy than HSCN. Our results show an HNCS/HSCN ratio sensitive to the gas temperature and the evolutionary time, with the highest values obtained at early stages (t<10^4 yr) and low (Tg<20 K) temperatures. The results suggest a different efficiency of the isomerisation processes depending on the source temperature. The progressive decrease of HNCS/HSCN with gas temperature at early evolutionary times indicates that this ratio may be used as a tracer of cold young objects. This work also demonstrates the key role of grain surface chemistry in the formation of the isomer pair HNCS and HSCN in cold regions, and the importance of the ions H2NCS+ and HNCSH+ in warm/hot regions. Since most of the interstellar regions where HSCN is detected are cold regions, a larger sample including sources characterised by high temperatures are needed to corroborate the theoretical results.         _ Less","","arXiv","https://arxiv.org/abs/2411.05517","1","1","multiple"
"Fate and detectability of rare gas hydride ions in nova ejecta: A case study with nova templates","Abstract:                _suggests that the James Webb Space Telescope (JWST) could detect some of them, particularly in sources like RS Ophiuchi and V1716 Scorpii, which have similar physical and chemical conditions and evolution. It must be clearly noted that the sources studied are used as templates, and not as targets for observations. The_         _ More           HeH$^+$ was the first heteronuclear molecule to form in the metal-free Universe after the Big Bang. The molecule gained significant attention following its first circumstellar detection in the young and dense planetary nebula NGC 7027. We target some hydride ions associated with the noble gases (HeH$^+$, ArH$^+$, and NeH$^+$) to investigate their formation in harsh environments like the nova outburst region. We use a photoionization modeling (based on previously published best-fit physical parameters) of the moderately fast ONe type nova, QU Vulpeculae 1984, and the CO type novae, RS Ophiuchi and V1716 Scorpii. Our steady-state modeling reveals a convincing amount of HeH$^+$, especially in the dense clump of RS Ophiuchi and V1716 Scorpii. The calculated upper limit on the surface brightness of HeH$^+$ transitions suggests that the James Webb Space Telescope (JWST) could detect some of them, particularly in sources like RS Ophiuchi and V1716 Scorpii, which have similar physical and chemical conditions and evolution. It must be clearly noted that the sources studied are used as templates, and not as targets for observations. The detection of these lines could be useful for determining the physical conditions in similar types of systems and for validating our predictions based on new electron-impact ro-vibrational collisional data at temperatures of up to 20,000 K.         _ Less","","arXiv","https://arxiv.org/abs/2411.05498","1","1","multiple"
"Evolutionary tracks of binary neutron star progenitors across cosmic times","Abstract:                _advanced our knowledge about the formation of compact object binaries. At present, many questions about the stellar origins of binary neutron stars remain open. We explore the evolution of binary neutron star progenitors with the population synthesis code COSMIC. We identify three dominant evolutionary tracks to form neutron star binaries that merge within t_         _ More           Recent discoveries of gravitational wave sources have advanced our knowledge about the formation of compact object binaries. At present, many questions about the stellar origins of binary neutron stars remain open. We explore the evolution of binary neutron star progenitors with the population synthesis code COSMIC. We identify three dominant evolutionary tracks to form neutron star binaries that merge within the age of the Universe: a scenario that includes a common envelope phase between the first neutron star and its companion, a scenario with almost equal-mass progenitors that evolve quasi-simultaneously and which features a double-core common envelope, and a scenario involving the accretion-induced collapse of an oxygen-neon white dwarf into a neutron star. We show that the distribution of time delays between stellar formation and binary neutron star merger at a given progenitor metallicity does not follow a power-law, but instead features a complex structure that reflects the progenitor properties and the relative contribution of each evolutionary track. We also explore the evolution of the merger rate density with redshift and show that the scenario involving the accretion-induced collapse could be dominant at high redshifts. These results can have important implications for the study of the chemical enrichment of galaxies in r-process elements produced in kilonovae; and of short gamma-ray bursts offsets in their host galaxies.         _ Less","","arXiv","https://arxiv.org/abs/2411.04563","1","1","multiple"
"The Role of Metallicity in the Chemical Evolution of Star-Forming Regions","Abstract:                Understanding the interstellar chemistry in low-metallicity environments is crucial to unveil physical and chemical processes in the past Galaxy or those in high-redshift galaxies, where the metallicity was significantly lower compared to the present-day solar neighborhood. This is also important for the understanding of the diversity of the_         _ More           Understanding the interstellar chemistry in low-metallicity environments is crucial to unveil physical and chemical processes in the past Galaxy or those in high-redshift galaxies, where the metallicity was significantly lower compared to the present-day solar neighborhood. This is also important for the understanding of the diversity of the chemical evolution in various regions of our Galaxy. Nearby low-metallicity laboratories, such as the outskirts of our Galaxy, the Large and Small Magellanic Clouds, and the other gas-rich dwarf galaxies in the Local Group, will provide important insights for this purpose. In the last decade, there has been great progress in astrochemical studies of interstellar molecules in low-metallicity star-forming regions. Do molecular abundances simply scale with the metallicity? If not, which processes govern the chemistry in the low-metallicity interstellar medium? In this proceeding, I will discuss the role of metallicity in the chemical evolution of star-forming regions based on recent observations of interstellar molecules in low-metallicity environments.         _ Less","","arXiv","https://arxiv.org/abs/2411.04451","1","1","multiple"
"The Effect of a Knot on the Thermal Stability of Protein MJ0366: Insights from Molecular Dynamics and Monte Carlo Simulations","Abstract:                _a topological barrier that prevents the protein from unfolding at high temperatures. We also discuss the possible biological implications of the knot for the function and evolution of protein MJ0366.         _ More           Protein MJ0366 is a hypothetical protein from Methanocaldococcus jannaschii that has a rare and complex knot in its structure. The knot is a right-handed trefoil knot that involves about half of the protein's residues. In this article, we investigate the thermal stability of protein MJ0366 using numerical simulations based on molecular dynamics and Monte Carlo methods. We compare the results with those of a similar unknotted protein and analyze the effects of the knot on the folding and unfolding processes. We show that the knot in protein MJ0366 increases its thermal stability by creating a topological barrier that prevents the protein from unfolding at high temperatures. We also discuss the possible biological implications of the knot for the function and evolution of protein MJ0366.         _ Less","","arXiv","https://arxiv.org/abs/2411.04390","0","1","synthetic_biology"
"Chemical Evolution of R-process Elements in Stars (CERES) II. The impact of stellar evolution and rotation on light and heavy elements","Abstract:                _are the most abundant elements throughout the universe, after hydrogen and helium. Studying these elements in low-metallicity stars can provide crucial information on the chemical composition in the early Galaxy and possible internal mixing processes that can alter the surface composition of the stars. Aims. This work aims to investigate the_         _ More           Context. Carbon, nitrogen, and oxygen are the most abundant elements throughout the universe, after hydrogen and helium. Studying these elements in low-metallicity stars can provide crucial information on the chemical composition in the early Galaxy and possible internal mixing processes that can alter the surface composition of the stars. Aims. This work aims to investigate the chemical abundance patterns for CNO elements and Li in a homogeneously analyzed sample of 52 metal-poor halo giant stars. Methods. We used high-resolution spectra with a high signal-to-noise ratio (S/N) to carry out a spectral synthesis to derive detailed C, N, O, and Li abundances for a sample of stars with metallicities in the range of -3.58 <= [Fe/H] <= -1.79 dex. Our study was based on the assumption of one-dimensional (1D) local thermodynamic equilibrium (LTE) atmospheres. Results. Based on carbon and nitrogen abundances, we investigated the deep mixing taking place within stars along the red giant branch (RGB). The individual abundances of carbon decrease towards the upper RGB while nitrogen shows an increasing trend, indicating that carbon has been converted into nitrogen. No signatures of ON-cycle processed material were found for the stars in our sample. We computed a set of galactic chemical evolution (GCE) models, implementing different sets of massive star yields, both with and without including the effects of stellar rotation on nucleosynthesis. We confirm that stellar rotation is necessary to explain the highest [N/Fe] and [N/O] ratios observed in unmixed halo stars. The predicted level of N enhancement varies sensibly in dependence of the specific set of yields that are adopted. For stars with stellar parameters similar to those of our sample, heavy elements such as Sr, Y, and Zr appear to have unchanged abundances despite the stellar evolution mixing processes.         _ Less","","arXiv","https://arxiv.org/abs/2411.04180","2","1","origin_of_life"
"ALMA Spectral Survey of An eruptive Young star, V883 Ori (ASSAY): II. Freshly Sublimated Complex Organic Molecules (COMs) in the Keplerian Disk","Abstract:                _our results with various objects in different evolutionary stages, from Class 0 hot corinos to a Solar System comet 67P/Churyumov-Gerasimenko, to examine the effect of evolution on the COM compositions. In general, the COMs abundances relative to methanol in V883 Ori are higher than in the hot corinos and hot cores, while they are comparable to the cometary_         _ More           We present an investigation of Complex Organic Molecules (COMs) in the spatially resolved Keplerian disk around V883 Ori, an eruptive young star, based on a spectral survey carried out with ALMA in Band 6 (220.7$-$274.9 GHz). We identified about 3,700 molecular emission lines and discovered 23 COMs in the disk. We estimated the column densities of COMs detected through the iterative LTE line fitting method. According to our analyses, using only optically thin lines is critical to deriving the reliable column densities of COMs. Therefore, covering a large frequency range is important for the studies of COMs. The most distinct phenomenon found from the spectra of the V883 Ori disk is that nitrogen-bearing COMs other than CH$_{3}$CN are missing, whereas various oxygen-bearing COMs, except for the CH$_2$OH-bearing molecules, are detected. The missing CH$_2$OH-bearing COMs may indicate the warm water-ice dominant environment for forming COMs. We compared our results with various objects in different evolutionary stages, from Class 0 hot corinos to a Solar System comet 67P/Churyumov-Gerasimenko, to examine the effect of evolution on the COM compositions. In general, the COMs abundances relative to methanol in V883 Ori are higher than in the hot corinos and hot cores, while they are comparable to the cometary values. This may indicate the planet-forming material chemically evolves in the disk midplane after being accreted from the envelope. In addition, as found in the comet 67P/Churyumov-Gerasimenko, nitrogen might also be trapped as ammonium salt within the dust grains in the V883 Ori disk.         _ Less","","arXiv","https://arxiv.org/abs/2411.03826","1","2","synthetic_biology"
"Boosting electrode performance and bubble management via Direct Laser Interference Patterning","Abstract:                _electrode performance for pure Ni electrodes. The electrochemically active surface area could be increased by a factor of 12 compared to a non-structured electrode. For oxygen evolution reaction, a significantly lower onset potential and overpotential ($\\approx$-164 mV at 100 mA/cm$^2$) is found. This is explained by a lower number of active nucleation sites_         _ More           Laser-structuring techniques like Direct Laser Interference Patterning show great potential for optimizing electrodes for water electrolysis. Therefore, a systematic experimental study based on statistical design of experiments is performed to analyze the influence of the spatial period and the aspect ratio between spatial period and structure depth on the electrode performance for pure Ni electrodes. The electrochemically active surface area could be increased by a factor of 12 compared to a non-structured electrode. For oxygen evolution reaction, a significantly lower onset potential and overpotential ($\\approx$-164 mV at 100 mA/cm$^2$) is found. This is explained by a lower number of active nucleation sites and, simultaneously, larger detached bubbles, resulting in reduced electrode blocking and thus, lower ohmic resistance. It is found that the spatial distance between the laser-structures is the decisive processing parameter for the improvement of the electrode performance.         _ Less","","arXiv","https://arxiv.org/abs/2411.03373","0","1","synthetic_biology"
"The chemical evolution of the Milky Way thin disk using solar twins","Abstract:                _with age. We also show the presence (or absence) of two populations, as recently claimed using a relatively small dataset. Moreover, we studied the Milky Way thin disk's chemical_         _ More           In this study we address whether the age--metallicity relation (AMR) deviates from the expected trend of metallicity increasing smoothly with age. We also show the presence (or absence) of two populations, as recently claimed using a relatively small dataset. Moreover, we studied the Milky Way thin disk's chemical evolution using solar twins, including the effect of radial migration and accretion events. In particular, we exploited high-resolution spectroscopy of a large sample of solar twins in tandem with an accurate age determination to investigate the Milky Way thin disk age--metallicity relationship. Additionally, we derived the stars' birth radius and studied the chemical evolution of the thin disk. We discovered that statistical and selection biases can lead to a misinterpretation of the observational data. An accurate accounting of all the uncertainties led us to detect no separation in the AMR into different populations for solar twins around the Sun (-0.3 < [Fe/H] < 0.3 dex). This lead us to the conclusion that the thin disk was formed relatively smoothly. For the main scenario of the Milky Way thin disk formation, we suggest that the main mechanism for reaching today's chemical composition around the Sun is radial migration with the possible contribution of well-known accretion events such as Gaia-Enceladus/Sausage (GES) and Sagittarius (Sgr).         _ Less","","arXiv","https://arxiv.org/abs/2411.03067","2","1","origin_of_life"
"Not just winds: why models find binary black hole formation is metallicity dependent, while binary neutron star formation is not","Abstract:                _to a merging BHBH. We further find that the significance of metallicities in double compact object formation is a question of formation channel. The stable mass transfer and chemically homogeneous evolution channels mainly diminish at high metallicities due to changes in stellar radii, while the common envelope channel_         _ More           Both detailed and rapid population studies alike predict that binary black hole (BHBH) formation is orders of magnitude more efficient at low metallicity than high metallicity, while binary neutron star (NSNS) formation remains mostly flat with metallicity, and black hole-neutron star (BHNS) mergers show intermediate behavior. This finding is a key input to employ double compact objects as tracers of low-metallicity star formation, as spectral sirens, and for merger rate calculations. Yet, the literature offers various (sometimes contradicting) explanations for these trends. We investigate the dominant cause for the metallicity dependence of double compact object formation. We find that the BHBH formation efficiency at low metallicity is set by initial condition distributions, and conventional simulations suggest that about \\textit{one in eight interacting binary systems} with sufficient mass to form black holes will lead to a merging BHBH. We further find that the significance of metallicities in double compact object formation is a question of formation channel. The stable mass transfer and chemically homogeneous evolution channels mainly diminish at high metallicities due to changes in stellar radii, while the common envelope channel is primarily impacted by the combined effects of stellar winds and mass-scaled natal kicks. Outdated giant wind prescriptions exacerbate the latter effect, suggesting BHBH formation may be much less metallicity dependent than previously assumed. NSNS formation efficiency remains metallicity independent as they form exclusively through the common envelope channel, with natal kicks that are assumed uncorrelated with mass. Forthcoming GW observations will provide valuable constraints on these findings.         _ Less","","arXiv","https://arxiv.org/abs/2411.02484","1","2","synthetic_biology"
"Hints of spin-magnitude correlations and a rapidly spinning subpopulation of binary black holes","Abstract:                _to have spin-orientations aligned with the orbital angular momentum--potentially consistent with isolated binary formation channels capable of producing large spins, like chemically homogeneous evolution. This hint of a rapidly spinning subpopulation hinges on GW190517, a binary with large and well-measured spins. Our_         _ More           The complex astrophysical processes leading to the formation of binary black holes and their eventual merger are imprinted on the spins of the individual black holes. We revisit the astrophysical distribution of those spins based on gravitational waves from the third gravitational wave transient catalog GWTC-3, (Abbott et al. 2023a), looking for structure in the two-dimensional space defined by the dimensionless spin magnitudes of the heavier ($__1$) and lighter ($__2$) component black holes. We find support for two distinct subpopulations with greater than $95\\%$ credibility. The dominant population is made up of black holes with small spins, preferring $__1 \\approx 0.2$ for the primary and $__2 \\approx 0$ for the secondary; we report signs of an anticorrelation between $__1$ and $__2$, as well as as evidence against a subpopulation of binaries in which both components are nonspinning. The subdominant population consists of systems in which both black holes have relatively high spins and contains $20^{+18}_{-18}\\%$ of the binaries. The binaries that are most likely to belong in this subpopulation are massive and slightly more likely to have spin-orientations aligned with the orbital angular momentum--potentially consistent with isolated binary formation channels capable of producing large spins, like chemically homogeneous evolution. This hint of a rapidly spinning subpopulation hinges on GW190517, a binary with large and well-measured spins. Our results, which are enabled by novel hierarchical inference methods, represent a first step towards more descriptive population models for black hole spins, and will be strengthened or refuted by the large number of gravitational wave detections expected in the next several years.         _ Less","","arXiv","https://arxiv.org/abs/2411.02252","1","2","synthetic_biology"
"Graph Fourier Neural ODEs: Bridging Spatial and Temporal Multiscales in Molecular Dynamics","Abstract:                Molecular dynamics simulations are crucial for understanding complex physical, chemical, and biological processes at the atomic level. However, accurately capturing interactions across multiple spatial and temporal scales remains a significant challenge. We present a novel framework that jointly models spatial and temporal multiscale interactions in molecula_         _ More           Molecular dynamics simulations are crucial for understanding complex physical, chemical, and biological processes at the atomic level. However, accurately capturing interactions across multiple spatial and temporal scales remains a significant challenge. We present a novel framework that jointly models spatial and temporal multiscale interactions in molecular dynamics. Our approach leverages Graph Fourier Transforms to decompose molecular structures into different spatial scales and employs Neural Ordinary Differential Equations to model the temporal dynamics in a curated manner influenced by the spatial modes. This unified framework links spatial structures with temporal evolution in a flexible manner, enabling more accurate and comprehensive simulations of molecular systems. We evaluate our model on the MD17 dataset, demonstrating consistent performance improvements over state-of-the-art baselines across multiple molecules, particularly under challenging conditions such as irregular timestep sampling and long-term prediction horizons. Ablation studies confirm the significant contributions of both spatial and temporal multiscale modeling components. Our method advances the simulation of complex molecular systems, potentially accelerating research in computational chemistry, drug discovery, and materials science.         _ Less","","arXiv","https://arxiv.org/abs/2411.01600","1","2","synthetic_biology"
"Investigation of Microstructural Evolution in All-Solid-State Micro-Batteries through in situ Electrochemical TEM","Abstract:                All-solid-state batteries hold great promise for electric vehicle applications due to their enhanced safety and higher energy density. However, further performance optimization requires a deeper understanding of their degradation mechanisms, particularly at the nanoscale. This study investigates the real-time degradation processes of an oxide-based all-solid-state micro-battery, using focused ion_         _ More           All-solid-state batteries hold great promise for electric vehicle applications due to their enhanced safety and higher energy density. However, further performance optimization requires a deeper understanding of their degradation mechanisms, particularly at the nanoscale. This study investigates the real-time degradation processes of an oxide-based all-solid-state micro-battery, using focused ion beam lamellae composed of LAGP as the solid electrolyte, LiFePO4 (LFP) composite as the positive electrode, and LiVPO4 (LVP) composite as the negative electrode. In situ electrochemical transmission electron microscopy (TEM) revealed critical degradation phenomena, including the formation of cracks along grain boundaries in the solid electrolyte due to lithium diffusion and mechanical stress. Additionally, the shrinkage of solid electrolyte particles and the formation of amorphous phases were observed. These findings highlight the importance of grain boundary dynamics and amorphization in the performance of solid electrolytes and provide insights into degradation mechanisms that can inform the design of more durable all-solid-state batteries.         _ Less","","arXiv","https://arxiv.org/abs/2411.01581","1","1","multiple"
"Understanding the Mechanisms Behind the Distribution of Galactic Metals","Abstract:                The evolution and distribution of metals within galaxies are critical for understanding galactic_         _ More           The evolution and distribution of metals within galaxies are critical for understanding galactic evolution and star formation processes, but the mechanisms responsible for shaping this distribution remain uncertain. In this study we carry out high-resolution simulations of an isolated Milky Way-like galaxy, including a star-by-star treatment of both feedback and element injection. We include seven key isotopes of observational and physical interest, and which are distributed across different nucleosynthetic channels. After running the simulations to statistical steady state, we examine the spatial and temporal statistics of the metal distributions and their fluctuations. We show that these statistics reflect a mixture properties dependent on the large-scale structure of the galaxy and those that vary depending on the particular nucleosynthetic channel that dominates production of a particular isotope. The former ensure that different elements are highly-correlated with one another even if they have different nucleosynthetic origins, and their spatial correlations vary together in time. The latter means that the small variations between elements that are present naturally break them into nucleosynthetic familiars, with elements that originate from different channels correlating better with each other than with elements with different origins. Our findings suggest both challenges and opportunities for ongoing efforts to use chemical measurements of gas and stars to unravel the history and physics of galaxy assembly.         _ Less","","arXiv","https://arxiv.org/abs/2411.01518","1","1","multiple"
"Caught in flagrante delicto: evidence for past mass transfer in massive binaries?","Abstract:                Many massive binary systems undergo mass and angular momentum transfer over the course of their evolution. This kind of interaction is expected to deeply affect the properties of the mass donor and mass gainer and to leave various observational signatures. The most common smoking guns of a past mass transfer episode are notably rapid rotation of the mass gai_         _ More           Many massive binary systems undergo mass and angular momentum transfer over the course of their evolution. This kind of interaction is expected to deeply affect the properties of the mass donor and mass gainer and to leave various observational signatures. The most common smoking guns of a past mass transfer episode are notably rapid rotation of the mass gainer and altered surface chemical abundances of the stripped mass donor star. Quantitative observational studies of evolved massive binaries are crucial to gain insight into poorly constrained parameters of binary evolution models such as the fraction of mass lost by the mass donor that is actually accreted by the mass gainer. Yet, drawing conclusions about a past mass transfer episode requires a detailed analysis of all aspects of a binary system which sometimes leads to unexpected results. In this contribution, we review the existing observational evidence for past mass exchange events in massive main-sequence and post main-sequence binaries.         _ Less","","arXiv","https://arxiv.org/abs/2411.00793","1","2","synthetic_biology"
"Dye Attenuation Without Dye: Quantifying Concentration Fields with Short-wave Infrared Imaging","Abstract:                _of the fluid motion and that its presence does not affect the behaviour of the system. However, in some systems, particularly living biological systems or those with strong chemical interactions and reactions, the addition of dye may non-trivially influence the system and may not follow the fluid containing it.   To overcome this, we demonstrate how short-wa_         _ More           Dye attenuation, or photometric imaging, is an optical technique commonly used in fluid dynamics to measure tracer concentration fields and fluid thicknesses under the assumption that the motion of the dye is representative of the fluid motion and that its presence does not affect the behaviour of the system. However, in some systems, particularly living biological systems or those with strong chemical interactions and reactions, the addition of dye may non-trivially influence the system and may not follow the fluid containing it.   To overcome this, we demonstrate how short-wave infrared imaging can be used to measure concentration and height profiles of water and other liquids without the introduction of dye for heights down to 0.2mm with spatial and temporal resolutions of the order of 50 microns per pixel and 120 fps respectively. We showcase the utility of this technique by demonstrating its ability to accurately track the temporal evolution of the total water content of two model systems, namely a water drop spreading on a glass slide and spreading within a hydrogel sheet, validating both against an analytical mass balance. Finally, we discuss how the spectral resolution of the present setup could be increased to the point that concentrations within a multi-component system containing more than one type of liquid could be quantified.         _ Less","","arXiv","https://arxiv.org/abs/2411.00740","0","1","synthetic_biology"
"Sulfur-bearing molecules in a sample of early star-forming cores","Abstract:                _clouds. The reason of this phenomenon is unclear, thus it is necessary to carry out observational studies of sulfur-bearing species towards dense regions, mainly at early evolutive stages to uncover the early sulfur chemistry. Using data from the Atacama Large Millimeter Array (ALMA) data archive, we investigated a sample of 37 dense cores embedded in the mo_         _ More           The sulfur content in dense molecular regions of the interstellar medium is highly depleted in comparison to diffuse clouds. The reason of this phenomenon is unclear, thus it is necessary to carry out observational studies of sulfur-bearing species towards dense regions, mainly at early evolutive stages to uncover the early sulfur chemistry. Using data from the Atacama Large Millimeter Array (ALMA) data archive, we investigated a sample of 37 dense cores embedded in the most massive infrared-quiet molecular clumps from the ATLASGAL survey. Lines of 34SO, SO2, NS, SO, SO+, and H2CS were analyzed and column densities of each molecular species were obtained. From the continuum emission, and two CH3OH lines, the 37 cores were characterized in density and temperature, and the corresponding H2 column densities were derived. The abundances of such sulfur-bearing species were derived and studied. We find that the abundances of the analyzed species increase with the growth of the gas temperature, suggesting that the chemistry involved in the formation of each of the analyzed molecule may have a similar dependence with Tk in the range 20 to 100 K. We find that the comparisons among abundances are, in general, highly correlated. Given that such correlation decreases in more evolved sources, we suggest that the sulfur-bearing species here analyzed should have a similar chemical origin. From the measured line widths we point out that molecules with oxygen content (34SO, SO2, SO, and SO+) may be associated with warmer and more turbulent gas than the other ones. H2CS and NS are associated with more quiescent gas, probably in the external envelopes of the cores. This work gives quantitative information about abundances that could be useful in chemical models pointing to explain the sulfur chemistry in the interstellar medium.         _ Less","","arXiv","https://arxiv.org/abs/2411.00539","2","2","multiple"
"Two-dimensional ASEP model to study density profiles in CVD growth","Abstract:                The growth of two-dimensional (2D) transition metal dichalcogenides using chemical vapor deposition has been an area of intense study, primarily due to the scalability requirements for potential device applications. One of the major challenges of such growths is the large-scale thickness variation of the grown film. To investigate the role of different growt_         _ More           The growth of two-dimensional (2D) transition metal dichalcogenides using chemical vapor deposition has been an area of intense study, primarily due to the scalability requirements for potential device applications. One of the major challenges of such growths is the large-scale thickness variation of the grown film. To investigate the role of different growth parameters computationally, we use a 2D asymmetric simple-exclusion process (ASEP) model with open boundaries as an approximation to the dynamics of deposition on the coarse-grained lattice. The variations in concentration of particles (growth profiles) at the lattice sites in the grown film are studied as functions of parameters like injection and ejection rate of particles from the lattice, time of observation, and the right bias (difference between the hopping probabilities towards right and towards left) imposed by the carrier gas. In addition, the deposition rates at a given coarse-grained site is assumed to depend on the occupancy of that site. The effect of the maximum deposition rate, i.e., the deposition rate at a completely unoccupied site on the substrate, has been explored. The growth profiles stretch horizontally when either the evolution time or the right bias is increased. An increased deposition rate leads to a step-like profile, with the higher density region close to the left edge. In 3D, the growth profiles become more uniform with the increase in the height of the precursor with respect to the substrate surface. These results qualitatively agree with the experimental observations.         _ Less","","arXiv","https://arxiv.org/abs/2411.00378","0","2","synthetic_biology"
"Capturing Turbulence with Numerical Dissipation: a Simple Dynamical Model for Unresolved Turbulence in Hydrodynamic Simulations","Abstract:                _the modeling of other subgrid processes dependent on the turbulent structure of gas: from flame propagation in the interiors of combusting white dwarfs to star formation and chemical reaction rates in the interstellar medium, and non-thermal pressure support of circum- and intergalactic gas. We present a simple method for modeling unresolved turbulence in hy_         _ More           Modeling unresolved turbulence in astrophysical gasdynamic simulations can improve the modeling of other subgrid processes dependent on the turbulent structure of gas: from flame propagation in the interiors of combusting white dwarfs to star formation and chemical reaction rates in the interstellar medium, and non-thermal pressure support of circum- and intergalactic gas. We present a simple method for modeling unresolved turbulence in hydrodynamic simulations via tracking its sourcing by local numerical dissipation and modeling its decay into heat. This method is physically justified by the generic property of turbulent flows that they dissipate kinetic energy at a rate set by the energy cascade rate from large scales, which is independent of fluid viscosity regardless of its nature, be it physical or numerical. We calibrate and test our model against decaying supersonic turbulence simulations. Despite its simplicity, the model quantitatively reproduces multiple non-trivial features of the high-resolution turbulence run: the temporal evolution of the average small-scale turbulence, its dependence on spatial scale, and the slope and scatter of the local correlation between subgrid turbulent velocities, gas densities, and local compression rates. As an example of practical applications, we use our model in isolated galactic disk simulations to model locally variable star formation efficiency at the subresolution scale. In the supersonic, star-forming gas, the new model performs comparably to a more sophisticated model where the turbulent cascade is described by explicit subgrid terms. Our new model is straightforward to implement in many hydrodynamic codes used in galaxy simulations as it utilizes already existing infrastructure to implicitly track the numerical dissipation in such codes.         _ Less","","arXiv","https://arxiv.org/abs/2410.23339","1","1","multiple"
"Quantitative spectroscopy of multiple OB stars: I. The quadruple system HD 37061 at the centre of Messier 43","Abstract:                _to single stars, these objects pose additional challenges to quantitative analyses based on model atmospheres. In particular, little information is currently available on the chemical composition of such systems. The members of the quadruple star system HD 37061, which excites the H II region Messier 43 in Orion, are fully characterised. Accurate and precise_         _ More           The majority of massive stars are located in binary or multiple star systems. Compared to single stars, these objects pose additional challenges to quantitative analyses based on model atmospheres. In particular, little information is currently available on the chemical composition of such systems. The members of the quadruple star system HD 37061, which excites the H II region Messier 43 in Orion, are fully characterised. Accurate and precise abundances for all elements with lines traceable in the optical spectrum are derived for the first time. A hybrid non-local thermodynamic equilibrium (non-LTE) approach, using line-blanketed hydrostatic model atmospheres computed with the ATLAS12 code in combination with non-LTE line-formation calculations with DETAIL and SURFACE, was employed. A high-resolution composite spectrum was analysed for the atmospheric parameters and elemental abundances of the individual stars. Fundamental stellar parameters were derived based on stellar evolution tracks, and the interstellar reddening was characterised. We determined the fundamental parameters and chemical abundances for three stars in the HD 37061 system. The fourth and faintest star in the system shows no distinct spectral features, as a result of its fast rotation. However, this star has noticeable effects on the continuum. The derived element abundances and determined ages of the individual stars are consistent with each other, and the abundances coincide with the cosmic abundance standard. We find an excellent agreement between our spectroscopic distance and the Gaia Data Release 3 parallax distance.         _ Less","","arXiv","https://arxiv.org/abs/2410.23229","1","1","multiple"
"Massive star evolution models incorporating $_$-enhanced composition -- I. BPASS Single star models","Abstract:                Stellar evolution modelling is fundamental to many areas of astrophysics including stellar populations in both nearby and distant galaxies. It is heavily influenced by chemical composition. Observations of distant galaxies and nucleosynthesis calculations show that $_$-process elements are enriched faster than iron gro_         _ More           Stellar evolution modelling is fundamental to many areas of astrophysics including stellar populations in both nearby and distant galaxies. It is heavily influenced by chemical composition. Observations of distant galaxies and nucleosynthesis calculations show that $_$-process elements are enriched faster than iron group elements. We present a dense grid of single-star models calculated using the BPASS stellar evolution code and covering masses ($0.1\\le\\mathrm{M/M}_\\odot\\le316$), metallicity mass fractions ($10^{-5} \\le Z \\le 0.04$) and $_$-to-iron abundance ratios ($-0.2\\le[_/\\mathrm{Fe}]\\le+0.6$). By comparing Solar-scaled models to ones enriched in $_$-process elements, we find that stellar radii, surface temperatures, Main Sequence lifetimes, supernova progenitor properties and supernova rates are all sensitive to changes in [$_$/Fe]. Lifetimes of low-mass stars differ by up to 0.4 dex, while surface temperatures of massive stars at the end of the Main Sequence also differ by around 0.4 dex. Inferred supernova rates when [Fe/H] is unknown can be highly uncertain. Models with different [$_$/Fe] but comparable iron abundances show smaller variations, indicating that while iron primarily defines the course of evolution; $_$-enhancement nonetheless has an impact of up to 0.1 dex on stellar properties. Such changes are small for individual stars, but have a large cumulative effect when considering an entire stellar population as demonstrated by isochrone fitting to nearby clusters. Changes in radii and lifetimes have further consequences for a stellar population including binary stars, as they influence the timing, nature and occurrence rate of mass transfer events.         _ Less","","arXiv","https://arxiv.org/abs/2410.23167","0","1","synthetic_biology"
"Reactivity of chondritic meteorites under H2-rich atmospheres: Formation of H2S","Abstract:                Current models of chemical evolution during star and planetary formation rely on the presence of dust grains to act as a third body. However, they generally ignore the reactivity of the dust grains themselves. Dust grains present in the protoplanetary phase will evolve as the solar system forms and, after protoplanets_         _ More           Current models of chemical evolution during star and planetary formation rely on the presence of dust grains to act as a third body. However, they generally ignore the reactivity of the dust grains themselves. Dust grains present in the protoplanetary phase will evolve as the solar system forms and, after protoplanets have appeared, they will be constantly delivered to their surfaces in the form of large aggregates or meteorites. Chondritic meteorites are mostly unaltered samples of the dust present in the first stages of the Solar System formation, that still arrive nowadays to the surface of Earth and allow us to study the properties of the materials forming the early Solar System. These materials contain, amongst others, transition metals that can potentially act as catalysts, as well as other phases that can potentially react in different astrophysical conditions, such as FeS. In this work, we present the reactivity of chondritic meteorites under \\hydrogen-rich atmospheres, particularly towards the reduction of FeS for the formation of H2S and metallic Fe during the early phases of the planetary formation. We present the obtained results on the reaction rates and the percentage of FeS available to react in the materials. Additionally, we include a computational study of the reaction mechanism and the energetics. Finally, we discuss the implications of an early formation of H2S in planetary surfaces.         _ Less","","arXiv","https://arxiv.org/abs/2410.23012","2","1","origin_of_life"
"Direct-method metallicity gradients derived from spectral stacking with SDSS-IV MaNGA","Abstract:        Chemical abundances are key tracers of the cycle of baryons driving the evolution of galaxies. Most measurements of interstellar medium (ISM) abundance and metallicity gradients in galaxies are based, however, on model-dependent strong-line methods. Direct chemical abundances can_         _ More   Chemical abundances are key tracers of the cycle of baryons driving the evolution of galaxies. Most measurements of interstellar medium (ISM) abundance and metallicity gradients in galaxies are based, however, on model-dependent strong-line methods. Direct chemical abundances can be obtained via the detection of weak auroral lines, but such lines are too faint to be detected across large spectroscopic surveys of the local Universe. In this work we overcome this limitation and obtain metallicity gradients from direct method abundances by stacking spectra from the MaNGA integral field spectroscopy survey. In particular we stack 4140 star-forming galaxies across the star formation rate-stellar mass (SFR-M$_\\star$) plane and across six radial bins. We calculate electron temperatures for [OII], [SII], [NII], [SIII] and [OIII] across the majority of stacks. We find that the T[OII] $\\sim$ T[SII] $\\sim$ T[OII], as expected since these ions all trace the low-ionization zone of nebulae. The [OIII] temperatures become substantially larger than those of other ions at high metallicity, indicating potentially unaccounted for spectral contamination or additional physics. In light of this uncertainty we base our abundance calculation on the temperatures of [SIII] and the low-ionization ions. We recover a mass-metallicity relation (MZR) similar to that obtained with different empirical calibrations. We do not find evidence, however, for a secondary dependence on SFR using direct metallicities. Finally, we derive metallicity gradients that becomes steeper with stellar mass for $\\log(M_\\star/M_\\odot) < 10.5$. At higher masses, the gradients flatten again, confirming with auroral line determinations the trends previously defined with strong-line calibrators.         _ Less","","arXiv","https://arxiv.org/abs/2410.22407","2","2","multiple"
"Structural and Nucleosynthetic Evolution of Metal-poor & Metal-free Low- and Intermediate-Mass Stars","Abstract:                In this PhD thesis we investigate stellar evolution and nucleosynthesis in the low- and extremely-low metallicity regime - including models of stars with a pure Big Bang composition (i.e. $\\rm{Z} = 0$). The metallicity range of the extremely metal-poor (EMP) models calculated is $-6.5 < \\rm{[Fe/H]} < -3.0$, with a mass range_         _ More           In this PhD thesis we investigate stellar evolution and nucleosynthesis in the low- and extremely-low metallicity regime - including models of stars with a pure Big Bang composition (i.e. $\\rm{Z} = 0$). The metallicity range of the extremely metal-poor (EMP) models calculated is $-6.5 < \\rm{[Fe/H]} < -3.0$, with a mass range $0.85 < \\rm{M} < 3.0~\\rm{M}_{\\odot}$. We have also calculated a series of models with a metallicity of $\\rm{[Fe/H]} = -1.4$, to compare with observations of abundance patterns in Galactic globular cluster stars. Many of the extremely metal-poor (EMP) and $\\rm{Z} = 0$ models experience violent evolutionary episodes not seen at higher metallicities. We refer to these events as `Dual Flashes' (DF) since they are characterised by peaks in the hydrogen and helium burning luminosities occurring at the same time. Some of the material processed by these events is later dredged up by the convective envelope, causing very significant surface pollution. We have calculated the entire evolution of the $\\rm{Z} = 0$ and EMP models, including detailed nucleosynthesis and yields. Although subject to many uncertainties these are, as far as we are aware, the only yields available in this mass and metallicity range. We find that our models predict an increased number of carbon-rich stars at the lowest metallicities. This is mainly due to the extra pollution provided by the DF events - which do not occur in higher metallicity models. This concurs well with the observations that show the proportion of carbon-enhanced metal-poor (CEMP) stars in the Galactic Halo to be higher at lower metallicities. We also compare the chemical pollution arising from our models with the detailed abundance patterns available for some of the most metal-poor CEMP stars, and find mixed results. Fluid dynamics calculations are likely needed to model the violent DF episodes. [Abridged]         _ Less","","arXiv","https://arxiv.org/abs/2410.21972","0","1","synthetic_biology"
"Two stellar populations with different metallicities in the low-mass globular cluster Gran 5","Abstract:                _and it is thought to be an accreted object associated with the Gaia-Enceladus structure. This study aims to investigate the stellar populations of Gran 5 and their detailed chemical properties. Methods. We performed high-resolution near-infrared spectroscopy on seven stars in the field of Gran 5 using IGRINS on the Gemini-South telescope. Results. We identi_         _ More           Context. With the increasing number of discoveries of globular clusters in the inner Milky Way, the need for spectroscopic confirmation and further investigation of their stellar populations and chemodynamical properties has become crucial. Aims. Gran 5 is a newly reported low-mass globular cluster located close to the Galactic center, and it is thought to be an accreted object associated with the Gaia-Enceladus structure. This study aims to investigate the stellar populations of Gran 5 and their detailed chemical properties. Methods. We performed high-resolution near-infrared spectroscopy on seven stars in the field of Gran 5 using IGRINS on the Gemini-South telescope. Results. We identified six stars as cluster members and reveal that they are divided into two stellar populations with different metallicities, with mean [Fe/H] values of -0.76 dex and -0.55 dex, respectively. In addition, the chemodynamical properties of Gran 5 agree with those of in situ globular clusters. Conclusions. Our findings represent the first detection of two stellar populations with different metallicities in a low-mass globular cluster. This suggests that the metallicity variation in Gran 5 may have arisen from processes different from those in other globular clusters with metallicity variation, or that it may have lost a substantial amount of its initial mass during its evolution.         _ Less","","arXiv","https://arxiv.org/abs/2410.21578","0","1","synthetic_biology"
"Blind source separation of the stellar halo","Abstract:                The stellar halo of the Milky Way comprises an abundance of chemical signatures from accretion events and \\textit{in-situ} evolution, that form an interweaving tapestry in kinematic space. To untangle this, we consider the mixtures of chemical information, in a given region of in_         _ More           The stellar halo of the Milky Way comprises an abundance of chemical signatures from accretion events and \\textit{in-situ} evolution, that form an interweaving tapestry in kinematic space. To untangle this, we consider the mixtures of chemical information, in a given region of integral of motion space, as a variant of the blind source separation problem and utilise non-negative matrix factorisation (NMF). Specifically, we examine the variation in [Fe/H], [Mg/Fe], and [Al/Fe] distributions of APOGEE DR17 stars across the $(E,L_z)$ plane of the halo. When 2 components are prescribed, the NMF algorithm splits stellar halo into low- and high-energy components in the $(E,L_z)$ plane which approximately correspond to the accreted and \\textit{in-situ} halo respectively. We use these two components to define a new boundary between the \\textit{in-situ} and the accreted stellar halo. Moreover, we calculate the components fractional contribution to the stellar halo as a function of energy, galactocentric spherical radius, height, and galactocentric cylindrical radius. Using a stellar halo defined by kinematic cuts, we find that the halo transitions from \\textit{in-situ} dominated to accretion dominated at $E \\approx -1.67 \\times 10^5$ (km/s)$^2$ (using the potential in McMillan 2017), and at $(r,z,R) \\approx (8.7, 3.0, 8.1)$ kpc. The low-energy component is found to span a range of [Al/Fe] that falls beyond the typically accepted \\textit{in-situ} floor of [Al/Fe] $=0$. Upon prescribing more components to the NMF model, we find hints of the existence of overlapping chemical evolution sequences that other techniques struggle to find. We also examine features within these components that resemble known substructures in the halo, such as \\textit{Eos} and \\textit{Aurora}. This work provides insight into their origin and the part they play in the Milky Way's formation.         _ Less","","arXiv","https://arxiv.org/abs/2410.21365","2","1","origin_of_life"
"Stellar Loci. VIII. Photometric Metallicities for 100 Million Stars Based on Synthetic Gaia Colors","Abstract:                _and about three times better than our previous work based on Gaia EDR3 colors. This opens up new opportunities for investigations of stellar populations, the formation and chemical evolution of the Milky Way, the chemistry of stars and star clusters, and the identification of candidate stars for subsequent high-resolu_         _ More           We apply the stellar locus method to synthetic $(BP-RP)_{XPSP}$ and $(BP-G)_{XPSP}$ colors derived from corrected Gaia BP/RP (XP) spectra to obtain accurate and precise estimates of metallicity for about 100 million stars in the Milky Way (34 million giants in the color range $0.6 < (BP-RP)_0 < 1.75$ and 65 million dwarfs in the color range $0.2 < (BP-RP)_0 < 1.5$). The sub milli-magnitude precision of the derived synthetic stellar colors enables estimates of metallicity for stars as low as [Fe/H] $\\sim -4$. Multiple validation tests indicate that the typical metallicity precision is between 0.05 -- 0.1 dex for both dwarfs and giants at [Fe/H] = 0 as faint as G $\\sim$ 17, and decreases to 0.15 -- 0.25 dex at [Fe/H] = $-$2.0. For $-4.0 <$ [Fe/H] $ < -3.0$, the typical metallicity precision decreases to on the order of 0.4 -- 0.5 dex, based on the results from the training sample. Our achieved precision is comparable to or better than previous efforts using the entire XP spectra, and about three times better than our previous work based on Gaia EDR3 colors. This opens up new opportunities for investigations of stellar populations, the formation and chemical evolution of the Milky Way, the chemistry of stars and star clusters, and the identification of candidate stars for subsequent high-resolution spectroscopic follow-up.         _ Less","","arXiv","https://arxiv.org/abs/2410.19895","2","1","origin_of_life"
"Self-Shielding Enhanced Organics Synthesis in an Early Reduced Earth's Atmosphere","Abstract:                _Fe and/or the gravitational trapping of surrounding nebula gas. Such an early, wet, reduced atmosphere that covers a proto-ocean would then ultimately evolve toward oxidized chemical compositions through photochemical processes that involve reactions with H2O-derived oxidant radicals and the selective escape of hydrogen to space. During this time, atmospheri_         _ More           Earth is expected to have acquired a reduced proto-atmosphere enriched in H2 and CH4 through the accretion of building blocks that contain metallic Fe and/or the gravitational trapping of surrounding nebula gas. Such an early, wet, reduced atmosphere that covers a proto-ocean would then ultimately evolve toward oxidized chemical compositions through photochemical processes that involve reactions with H2O-derived oxidant radicals and the selective escape of hydrogen to space. During this time, atmospheric CH4 could be photochemically reprocessed to generate not only C-bearing oxides but also organics. However, the branching ratio between organic matter formation and oxidation remains unknown despite its significance on the abiotic chemical evolution of early Earth. Here, we show via numerical analyses that UV absorptions by gaseous hydrocarbons such as C2H2 and C3H4 significantly suppress H2O photolysis subsequent CH4 oxidation during the photochemical evolution of a wet proto-atmosphere enriched in H2 and CH4. As a result, nearly half of the initial CH4 converted to heavier organics along with the deposition of prebiotically essential molecules such as HCN and H2CO on the surface of a primordial ocean for a geological timescale order of 10-100 Myr. Our results suggest that the accumulation of organics and prebiotically important molecules in the proto-ocean could produce a soup enriched in various organics, which might have eventually led to the emergence of living organisms.         _ Less","","arXiv","https://arxiv.org/abs/2410.19285","4","1","origin_of_life"
"Presolar Grains As Probes of Supernova Nucleosynthesis","Abstract:                _Within the context of presolar supernova grain data, we discuss (i) the production of 44Ti in supernovae and the impact of interstellar medium heterogeneities on the galactic chemical evolution of 44Ca/40Ca, (ii) the nucleosynthesis processes of neutron bursts and explosive H-burning in Type II supernovae, and (iii) c_         _ More           We provide an overview of the isotopic signatures of presolar supernova grains, specifically focusing on 44Ti-containing grains with robustly inferred supernova origins and their implications for nucleosynthesis and mixing mechanisms in supernovae. Recent technique advancements have enabled the differentiation between radiogenic (from 44Ti decay) and nonradiogenic 44Ca excesses in presolar grains, made possible by enhanced spatial resolution of Ca-Ti isotope analyses with the Cameca NanoSIMS (Nano-scale Secondary Ion Mass Spectrometer) instrument. Within the context of presolar supernova grain data, we discuss (i) the production of 44Ti in supernovae and the impact of interstellar medium heterogeneities on the galactic chemical evolution of 44Ca/40Ca, (ii) the nucleosynthesis processes of neutron bursts and explosive H-burning in Type II supernovae, and (iii) challenges in identifying the progenitor supernovae for 54Cr-rich presolar nanospinel grains. Drawing on constraints and insights derived from presolar supernova grain data, we also provide an overview of our current understanding of the roles played by various supernova types - including Type II, Type Ia, and electron capture supernovae - in accounting for the diverse array of nucleosynthetic isotopic variations identified in bulk meteorites and meteoritic components. We briefly overview the potential mechanisms that have been proposed to explain these nucleosynthetic variations by describing the transport and distribution of presolar dust carriers in the protoplanetary disk. We highlight existing controversies in the interpretation of presolar grain data and meteoritic nucleosynthetic isotopic variations, while also outlining potential directions for future research.         _ Less","","arXiv","https://arxiv.org/abs/2410.19254","2","2","multiple"
"Very massive stars and Nitrogen-emitting galaxies","Abstract:                _\\Msun. The He {\\sc ii} observed in the Sunburst Arc could also stem from the disproportionately large contribution of VMSs. We build an entirely new Framework for massive star evolution which is no longer set by Dutch or other mass-loss 'recipes' but which take the physics of $_$ or $L/M$-dependent winds into account. We discuss the mass-loss kink an_         _ More           Recent studies of high-redshift galaxies using JWST, such as GN-z11 revealed highly elevated levels of nitrogen (N). This phenomenon extends to gravitationally-lensed galaxies like the Sunburst Arc at z = 2.37, as well as to globular clusters (GCs). We propose that this originates from the presence of very massive stars (VMSs) with masses ranging from 100 to 1000\\,\\Msun. The He {\\sc ii} observed in the Sunburst Arc could also stem from the disproportionately large contribution of VMSs. We build an entirely new Framework for massive star evolution which is no longer set by Dutch or other mass-loss 'recipes' but which take the physics of $_$ or $L/M$-dependent winds into account. We discuss the mass-loss kink and the transition mass-loss rate between optically thin and thick winds, before we study the evaporative mass-loss history of VMSs. Our novel evolution models exhibit vertical evolution in the HR-diagram from the zero-age main sequence due to a self-regulatory effect driven by their wind-dominated nature, and we discuss what wind physics sets the stellar upper-mass limit. Our estimate for the Sunburst Arc in Vink (2023) suggests that the significant amounts of N found in star-forming galaxies likely arise from VMSs. We evaluate the strengths and weaknesses of previous hypotheses, including fast rotating massive stars and supermassive stars (SMSs), and we conclude that only our VMS model satisfies the relevant criteria. Finally, we advocate for the inclusion of VMSs in population synthesis and chemical evolution models, emphasizing the need for a self-consistent wind approach, which currently does not exist. Even minor inaccuracies in mass-loss rates dramatically impact the stellar evolution of VMS, as well as their ionizing and chemical feedback.         _ Less","","arXiv","https://arxiv.org/abs/2410.18980","1","1","multiple"
"Far-from-equilibrium attractors in kinetic theory with two different relaxation times","Abstract:                We solve a Boltzmann equation for massless quark and gluon fluids in a transversally homogeneous, longitudinally boost-invariant expansion. Quarks can be out of chemical equilibrium and the relaxation times of the two species are assumed to be connected by Casimir scaling. We numerically calculate moments of the distribution functions, identifying their earl_         _ More           We solve a Boltzmann equation for massless quark and gluon fluids in a transversally homogeneous, longitudinally boost-invariant expansion. Quarks can be out of chemical equilibrium and the relaxation times of the two species are assumed to be connected by Casimir scaling. We numerically calculate moments of the distribution functions, identifying their early- and late-time attractors and reconstructing also the full distributions. These attractors appear when the system is still far from local thermalization, before hydrodynamics traditionally would be expected to apply. We also analyze the evolution of entropy production for different initial momentum anisotropies and quark abundances.         _ Less","","arXiv","https://arxiv.org/abs/2410.18566","0","1","synthetic_biology"
"Atomistic understanding of hydrogen coverage on RuO2(110) surface under electrochemical conditions from ab initio statistical thermodynamics","Abstract:                Understanding the dehydrogenation of transition metal oxide surfaces under electrochemical potential is critical to the control of important chemical processes such as the oxygen evolution reaction (OER). Using first principles computations, we model the thermodynamic dehydrogenation process on RuO$_2$(110) and compare_         _ More           Understanding the dehydrogenation of transition metal oxide surfaces under electrochemical potential is critical to the control of important chemical processes such as the oxygen evolution reaction (OER). Using first principles computations, we model the thermodynamic dehydrogenation process on RuO$_2$(110) and compare the results to experimental cyclic voltammetry (CV) on single crystal. We use a cluster expansion model trained on *ab initio* energy data coupled with Monte Carlo (MC) sampling to derive the macroscopic electrochemical observables, i.e., experimental CV, from the energetics of different hydrogen coverage microstates on well-defined RuO$_2$(110). Our model reproduces the unique 'two-peaks' cyclic voltammogram observed experimentally with current density peak positions and shapes in good qualitative agreement. We show that RuO$_2$(110) starts as a water-covered surface with hydrogen on bridge (BRG) and coordination-unsaturated sites (CUS) at low potential (less than 0.4 V vs. reversible hydrogen electrode, RHE). As the potential increases, the hydrogens on BRG desorb, becoming the main contributor to the first CV peak with smaller contributions from CUS. When all BRG hydrogens are desorbed (before 1.2 V vs. RHE), the remaining CUS hydrogens desorb abruptly in a very small potential window leading to the sharp second peak observed during CV. Our work shows that above 1.23 V, the OER proceeds on a fully dehydrogenated RuO$_2$(110) surface.         _ Less","","arXiv","https://arxiv.org/abs/2410.18421","0","1","synthetic_biology"
"ExoMol Line Lists -- LXII: Ro-Vibrational Energy Levels and Line-Strengths for the Propadienediylidene (C3) in its Ground Electronic State","Abstract:                Improved opacities are needed for modelling the atmospheres and evolution of cool carbon-rich stars and extra-solar planets; in particular, contributions made by the astrophysically important propadienediylidene (C$_3$) molecule need, at a minimum, to be determined using a line list which includes all significant transitions in the energy range of interest._         _ More           Improved opacities are needed for modelling the atmospheres and evolution of cool carbon-rich stars and extra-solar planets; in particular, contributions made by the astrophysically important propadienediylidene (C$_3$) molecule need, at a minimum, to be determined using a line list which includes all significant transitions in the energy range of interest. We report variational calculations giving ro-vibrational energy levels and corresponding line-strengths for $^{12}$C$_3$, $^{12}$C$^{13}$C$^{12}$C and $^{12}$C$^{12}$C$^{13}$C. In the $^{12}$C$_3$ case we obtain 2166503 ro-vibrational state energies $\\le$ 20000 cm$^{-1}$ for the electronic $\\tilde{X}^1 __g^+$ ground-state. Comparison with experiment indicates a maximum error of +/- 0.03 cm$^{-1}$ in calculated positions of lines involving an upper state energy $\\lesssim$ 4000 cm$^{-1}$. For lines with upper state energies $\\gtrsim$ 4000 cm$^{-1}$ to have comparable line-position accuracies, conical intersections would need to be accounted for in an adopted potential energy surface. Line lists and associated opacities are provided in the ExoMol Database http://www.exomol.com ).         _ Less","","arXiv","https://arxiv.org/abs/2410.18250","0","1","synthetic_biology"
"HIP 8522: A Puzzling Young Solar Twin with the Lowest Detected Lithium","Abstract:                _) and chemical composition were determined via spectroscopic equilibrium using high resolution spectra ($R = 60~000-165~000$). The age of HIP 8522 was estimated to be an upper limit of $<$1 Gyr through isochrone fitting and was further confirmed using chemical clocks. Spectral synthesis of the lithium line at_         _ More           We present HIP 8522, a young solar twin with the lowest detected lithium, potentially a field blue straggler or the result of episodic early accretion. Its stellar parameters ($T_{\\rm eff} = 5729 \\pm 7$ K, $\\log g = 4.532 \\pm 0.016$ dex, $\\rm{[Fe/H]} = 0.005 \\pm 0.010$ dex, $v_{t} = 1.08 \\pm 0.02$ km s$^{-1}$) and chemical composition were determined via spectroscopic equilibrium using high resolution spectra ($R = 60~000-165~000$). The age of HIP 8522 was estimated to be an upper limit of $<$1 Gyr through isochrone fitting and was further confirmed using chemical clocks. Spectral synthesis of the lithium line at $\\sim$6707.8 _ yielded an upper lithium abundance limit of $A(\\rm{Li}) <$ 0.8 dex. This value is unusually low for solar twins of similar age, which typically have $A(\\rm{Li})$ values ranging from 2.0 to 3.3 dex, suggesting that $\\sim$2 dex of lithium is missing. We investigate various scenarios, such as planet engulfment, sub-stellar mergers, and extra mixing. However, two distinct hypotheses provide plausible explanations for the significant depletion of lithium: one suggests that HIP 8522 is a field blue straggler formed by the merger of a close binary, while the other proposes that HIP 8522 experienced early episodic accretion. The young solar twin HIP 8522 presents an exceptional opportunity to rigorously test stellar evolution models and gain crucial insights into the internal mixing mechanisms responsible for the significant destruction of lithium.         _ Less","","arXiv","https://arxiv.org/abs/2410.17590","0","1","synthetic_biology"
"From Phytochemicals to Recipes: Health Indications and Culinary Uses of Herbs and Spices","Abstract:                _and spices with health indications. Our top 100 inferred indication-phytochemical relationships rediscover 40% known relationships and 20% that have been inferred via gene-chemical interactions with high confidence. The remaining 40% are hypotheses generated in a principled way for further experimental investigations. We also develop an algorithm to find the_         _ More           Herbs and spices each contain about 3000 phytochemicals on average and there is much traditional knowledge on their health benefits. However, there is a lack of systematic study to understand the relationship among herbs and spices, their phytochemical constituents, their potential health benefits, and their usage in regional cuisines. Here we use a network-based approach to elucidate established relationships and predict novel associations between the phytochemicals present in herbs and spices with health indications. Our top 100 inferred indication-phytochemical relationships rediscover 40% known relationships and 20% that have been inferred via gene-chemical interactions with high confidence. The remaining 40% are hypotheses generated in a principled way for further experimental investigations. We also develop an algorithm to find the minimum set of spices needed to cover a target group of health conditions. Drawing on spice usage patterns in several regional Indian cuisines, and a copy-mutate model for regional cuisine evolution, we characterize the spectrum of health conditions covered by existing regional cuisines. The spectrum of health conditions can expand through the nationalization/globalization of culinary practice.         _ Less","","arXiv","https://arxiv.org/abs/2410.17286","0","1","synthetic_biology"
"Directing the Electrode-Electrolyte Interface Towards Active Nickel-Based Electrocatalysts for Oxygen Evolution Reaction","Abstract:                _solvation effects considerably affects the predicted overpotential in a roughly linear relationship between overpotential and dielectric constant. By incorporating quantum chemical simulations with kinetic modeling, we demonstrate that tuning the local solvation environment can significantly enhance the OER activity, opening new routine ways for elucidation_         _ More           A comprehensive understanding of the electrode-electrolyte interface in energy conversion systems remains challenging due to the complex and multifaceted nature of interfacial processes. This complexity hinders the development of more efficient electrocatalysts. In this work, we propose a hybrid approach to the theoretical description of the OER process on nickel-iron-based oxyhydroxides ($_$-Ni$_{1-x}$Fe$_x$OOH) electrodes in alkaline media as a model system. Multiple reaction pathways represented by the single- and dual-site mechanisms were investigated by taking into account the realistic structure of the catalyst, the doping, and the solvation effects using a simple and computationally feasible strategy. Accounting for the variable solvation effects considerably affects the predicted overpotential in a roughly linear relationship between overpotential and dielectric constant. By incorporating quantum chemical simulations with kinetic modeling, we demonstrate that tuning the local solvation environment can significantly enhance the OER activity, opening new routine ways for elucidation of the emerging issues of OER processes on transition metal oxide surfaces and design of cost-effective, efficient electrocatalytic systems.         _ Less","","arXiv","https://arxiv.org/abs/2410.16715","1","3","synthetic_biology"
"Nonlinear semiclassical spectroscopy of ultrafast molecular polariton dynamics","Abstract:                _coupled to the cavity photon mode. Our approach is based on a semiclassical, mean-field evolution of the molecular Hamiltonian and the cavity field, which is complemented by a perturbative expansion of both light and matter counterparts in the input fields entering the cavity. In addition, expansion in terms of the pulse phases enables us to disentangle dif_         _ More           We introduce a theoretical framework that allows for the systematic and efficient description of the ultrafast nonlinear response of molecular polaritons, i.e., hybrid light-matter states, in the collective regime of large numbers of molecules $\\mathcal N$ coupled to the cavity photon mode. Our approach is based on a semiclassical, mean-field evolution of the molecular Hamiltonian and the cavity field, which is complemented by a perturbative expansion of both light and matter counterparts in the input fields entering the cavity. In addition, expansion in terms of the pulse phases enables us to disentangle different excitation pathways in Liouville space, thereby distinguishing contributions to the nonlinear response. The formalism extends traditional free-space nonlinear spectroscopy by incorporating the feedback of matter onto the light field via the induced polarization. We demonstrate the utility of the framework by applying it to the calculation of pump-probe polariton spectra and show how, by storing the pulses, the cavity facilitates additional excitation pathways which are not possible in free space. Our method, which does not scale with $\\mathcal N$, is broadly applicable and can be extended to a wide range of current experiments investigating the dynamical nonlinear response of hybrid light-matter states.         _ Less","","arXiv","https://arxiv.org/abs/2410.16630","0","1","synthetic_biology"
"The Impact of Initial Composition on Massive Star Evolution and Nucleosynthesis","Abstract:                We study the sensitivity of presupernova evolution and supernova nucleosynthesis yields of massive stars to variations of the initial composition. We use the solar abundances from Lodders (2009), and compute two different initial stellar compositions: i) scaled solar abundances, and ii) the isotopic galactic_         _ More           We study the sensitivity of presupernova evolution and supernova nucleosynthesis yields of massive stars to variations of the initial composition. We use the solar abundances from Lodders (2009), and compute two different initial stellar compositions: i) scaled solar abundances, and ii) the isotopic galactic chemical history model (GCH) developed by West and Heger (2013b). We run a grid of models using the KEPLER stellar evolution code, with 7 initial stellar masses, 12 initial metallicities, and two for each scaling method to explore the effects on nucleosynthesis over a metallicity range of $-4.0\\leq[Z]\\leq+0.3$. We find that the compositions from the GCH model better reproduce the weak \\emph{s}-process peak than the scaled solar models. The model yields are then used in the OMEGA Galactic Chemical Evolution (GCE) code to assess this result further. We find that initial abundances used in computing stellar structure have more of an impact on GCE results than initial abundances used in the burn network, with the GCH model again being favored when compared to observations. Lastly, a machine learning algorithm was used to verify the free parameter values of the GCH model, which were previously found by West and Heger (2013b) using a stochastic fitting process. The updated model is provided as an accessible tool for further nucleosynthesis studies.         _ Less","","arXiv","https://arxiv.org/abs/2410.16594","1","1","multiple"
"Quench dynamics of stripes and phase separation in the two-dimensional $t$-$J$ model","Abstract:                We investigate the fundamental dynamical process of an initial quench of the chemical potential of the two-dimensional $t$-$J$ model. Depending on the ground state phase, sharply different dynamical behavior of the charge distribution and entanglement properties are observed. In the stripe phase, the intertwining of the spin and charge density waves remains_         _ More           We investigate the fundamental dynamical process of an initial quench of the chemical potential of the two-dimensional $t$-$J$ model. Depending on the ground state phase, sharply different dynamical behavior of the charge distribution and entanglement properties are observed. In the stripe phase, the intertwining of the spin and charge density waves remains stable under time evolution. A ballistic spreading of the charge density is observed with a propagation speed that is only weakly dependent on the coupling ratio, $J/t$. Moreover, in the phase-separated regime for large $J/t$, we report a complete dynamical freezing of charge degrees of freedom within, where even under long time evolution the entanglement entropy remains bounded. Our results are obtained by combining large-scale exact diagonalizations and matrix product state techniques for time evolution.         _ Less","","arXiv","https://arxiv.org/abs/2410.16387","0","1","synthetic_biology"
"AEOS: Star-by-Star Cosmological Simulations of Early Chemical Enrichment and Galaxy Formation","Abstract:                The AEOS project introduces a series of high-resolution cosmological simulations that model star-by-star chemical enrichment and galaxy formation in the early Universe, achieving 1 pc resolution. These simulations capture the complexities of galaxy_         _ More           The AEOS project introduces a series of high-resolution cosmological simulations that model star-by-star chemical enrichment and galaxy formation in the early Universe, achieving 1 pc resolution. These simulations capture the complexities of galaxy evolution within the first ~300 Myr by modeling individual stars and their feedback processes. By incorporating chemical yields from individual stars, AEOS generates galaxies with diverse stellar chemical abundances, linking them to hierarchical galaxy formation and early nucleosynthetic events. These simulations underscore the importance of chemical abundance patterns in ancient stars as vital probes of early nucleosynthesis, star formation histories, and galaxy formation. We examine the metallicity floors of various elements resulting from Pop III enrichment, providing best-fit values for eight different metals (e.g., [O/H] = -4.0) to guide simulations without Pop III models. Additionally, we identify galaxies that begin star formation with Pop II after external enrichment and investigate the frequency of CEMP stars at varying metallicities. The AEOS simulations offer detailed insights into the relationship between star formation, feedback, and chemical enrichment. Future work will extend these simulations to later epochs to interpret the diverse stellar populations of the Milky Way and its satellites.         _ Less","","arXiv","https://arxiv.org/abs/2410.16366","1","1","multiple"
"Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics","Abstract:                _challenging task that requires the solution of highly involved equations of motion. While machine learning techniques are being applied with some success to simulate the time evolution of individual quantum states, their use to approximate time-dependent operators (that can evolve various states) remains largely unexplored. In this work, we develop driven ne_         _ More           Describing the dynamics of strong-laser driven open quantum systems is a very challenging task that requires the solution of highly involved equations of motion. While machine learning techniques are being applied with some success to simulate the time evolution of individual quantum states, their use to approximate time-dependent operators (that can evolve various states) remains largely unexplored. In this work, we develop driven neural quantum propagators (NQP), a universal neural network framework that solves driven-dissipative quantum dynamics by approximating propagators rather than wavefunctions or density matrices. NQP can handle arbitrary initial quantum states, adapt to various external fields, and simulate long-time dynamics, even when trained on far shorter time windows. Furthermore, by appropriately configuring the external fields, our trained NQP can be transferred to systems governed by different Hamiltonians. We demonstrate the effectiveness of our approach by studying the spin-boson and the three-state transition Gamma models.         _ Less","","arXiv","https://arxiv.org/abs/2410.16091","0","1","synthetic_biology"
"New stellar age estimates using SPInS based on Gaia DR3 photometry and LAMOST DR8 abundances","Abstract:                Reliable stellar age estimates are fundamental for testing several problems in modern astrophysics, in particular since they set the time scales of Galactic dynamical and chemical evolution. In this study, we determine ages using only Gaia DR3 photometry and parallaxes, in combination with interstellar extinction maps,_         _ More           Reliable stellar age estimates are fundamental for testing several problems in modern astrophysics, in particular since they set the time scales of Galactic dynamical and chemical evolution. In this study, we determine ages using only Gaia DR3 photometry and parallaxes, in combination with interstellar extinction maps, spectroscopic metallicities and $_$ abundances from the latest data release (DR8) of the LAMOST survey. In contrast with previous age estimates, we do not use spectroscopic effective temperatures or surface gravities, thus relying on the excellent precision and accuracy of the Gaia photometry. We use a new version of the publicly available SPInS code with improved features, including the on-the-fly computation of the autocorrelation time and the automatic convergence evaluation. We determine reliable age estimates for 35,096 and 243,768 sub-giant and main-sequence turn-off stars in the LAMOST DR8 low- and medium-resolution surveys with typical uncertainties smaller than 10%. In addition, we successfully test our method on more than 4,000 stars of 14 well-studied open and globular star clusters covering a wide range of ages, confirming the reliability of our age and uncertainty estimates.         _ Less","","arXiv","https://arxiv.org/abs/2410.15781","2","2","multiple"
"Simulating and investigating various dynamic aspects of $\\rm{H}_2\\rm{O}$-related hydrogen bond model","Abstract:                _probabilities of reaction channels involving hydrogen bond depending on the parameters of the external environment, are obtained. Differences between unitary and dissipative evolutions are discussed. Consideration is given to the effect of all kinds of potential interactions and dissipations on evolution. Consideration_         _ More           A simple $\\rm{H}_2\\rm{O}$-related hydrogen bond model, modified from the Jaynes-Cummings model, is proposed and its various dynamic aspects are investigated theoretically. In this model, the formation and breaking processes of hydrogen bond are accompanied by the creation and annihilation of the thermal phonon of the medium. A number of simplifying assumptions about the dynamics of the molecules involved are used. Rotating wave approximation is applied under consideration of the strong-coupling condition. Dissipative dynamics under the Markovian approximation is obtained through solving the quantum master equation - Lindbladian. The probabilities of reaction channels involving hydrogen bond depending on the parameters of the external environment, are obtained. Differences between unitary and dissipative evolutions are discussed. Consideration is given to the effect of all kinds of potential interactions and dissipations on evolution. Consideration is also given to the reverse processes (inflows) of dissipations. The results show that the magnitude changes of the interactions and dissipations have a slight effect on the formation of hydrogen bond, but the variation of the inflows significantly affects the formation of hydrogen bond. According to the findings, the dynamics of $\\rm{H}_2\\rm{O}$-related hydrogen bond model can be controlled by selectively choosing system parameters. The results will be used as a basis to extend the research to more complex chemical and biological models in the future.         _ Less","","arXiv","https://arxiv.org/abs/2410.15121","1","2","synthetic_biology"
"Early Bright Galaxies from Helium Enhancements in High-Redshift Star Clusters","Abstract:                _compared to expectations from most (pre-JWST) theoretical models. Moreover, some of the brightest high-redshift spectroscopically confirmed galaxies exhibit peculiar chemical abundance patterns, most notably extremely high N/O ratios. Since N/O has been empirically shown to scale strongly with He/H, as expected for hot hydrogen burning, these same bright hi_         _ More           The first few cycles of JWST have identified an overabundance of UV-bright galaxies and a general excess of UV luminosity density at $z\\gtrsim10$ compared to expectations from most (pre-JWST) theoretical models. Moreover, some of the brightest high-redshift spectroscopically confirmed galaxies exhibit peculiar chemical abundance patterns, most notably extremely high N/O ratios. Since N/O has been empirically shown to scale strongly with He/H, as expected for hot hydrogen burning, these same bright high-redshift galaxies are likely also helium-enhanced. Under simplistic assumptions for stellar evolution, the bolometric luminosity of a star scales as $L\\propto(2-\\frac{5}{4}Y)^{-4}(2-Y)^{-1}$ -- hence a higher He/H leads to brighter stars. In this Letter, we evolve a series of MESA models to the zero-age main-sequence and highlight that the helium enhancements at the levels measured and inferred for high-redshift galaxies can boost the 1500 $\\mathring{\\rm A}$ UV luminosity by up to $\\sim50\\%$, while simultaneously increasing the stellar effective temperature. The combination of helium enhancements with nebular continuum emission expected for intense bursts of star formation have the potential to help reduce the tension between JWST observations and certain galaxy formation models.         _ Less","","arXiv","https://arxiv.org/abs/2410.14846","1","1","multiple"
"Quokka-based understanding of outflows (QED) -- II. X-ray metallicity gradients as a signature of galactic wind metal loading","Abstract:                Supernova-driven galactic outflows play a vital but still poorly-understood role in galactic chemical evolution, and one of the largest uncertainties about them is the extent to which they consist of supernova ejecta that are unmixed, or only poorly-mixed, with the remainder of the interstellar medium (ISM). Simulation_         _ More           Supernova-driven galactic outflows play a vital but still poorly-understood role in galactic chemical evolution, and one of the largest uncertainties about them is the extent to which they consist of supernova ejecta that are unmixed, or only poorly-mixed, with the remainder of the interstellar medium (ISM). Simulations of wind launching make a range of predictions about the extent of mixing between the wind and the ISM, but thus far these have proven challenging to test observationally. In this study, we post-process high-resolution simulations of outflows from the QED simulation suite to generate synthetic X-ray spectra from galactic winds, which we then analyse using standard observational procedures, in order to search for detectable markers of wind mixing. Our synthetic observations reveal that partially-mixed winds show significant and detectable metallicity gradients when viewed edge-on, with metallicity decreasing away from the central galactic disc. We explore how this signature results from imperfect mixing and the extent to which measurements of it can be used to diagnose the level of mixing in winds. We determine the signal-to-noise ratio (SNR) requirements for such measurements to be reliable, and provide a simple quantitative model that can be used to connect metallicity gradients to mixing between the hot ($T>10^{6}$ K) and cold ($T<10^{4}$ K) phases in observations that reach the required SNR, providing a framework to interpret current and future observations.         _ Less","","arXiv","https://arxiv.org/abs/2410.14376","1","1","multiple"
"Quantifying systematic uncertainties in white dwarf cooling age determinations","Abstract:                _hydrogen-atmosphere white dwarfs with carbon-oxygen cores under different assumptions regarding the chemical stratification of their core, the thickness of their helium envelope, their hydrogen content, and the conductive opacities employed in the calculations. The parameter space explored is constrained by the range of values predicted by a variety of stel_         _ More           Cooling ages of white dwarfs are routinely determined by mapping effective temperatures and masses to ages using evolutionary models. Typically, the reported uncertainties on cooling ages only consider the error propagation of the uncertainties on the spectroscopically or photometrically determined $T_{\\rm eff}$ and mass. However, cooling models are themselves uncertain, given their dependence on many poorly constrained inputs. This paper estimates these systematic model uncertainties. We use MESA to generate cooling sequences of $0.5-1.0 M_{\\odot}$ hydrogen-atmosphere white dwarfs with carbon-oxygen cores under different assumptions regarding the chemical stratification of their core, the thickness of their helium envelope, their hydrogen content, and the conductive opacities employed in the calculations. The parameter space explored is constrained by the range of values predicted by a variety of stellar evolution models and inferred from asteroseismological studies. For a $0.6 M_{\\odot}$ white dwarf, we find an uncertainty of 0.03 Gyr at 10,000 K (corresponding to a 5% relative uncertainty) and 0.8 Gyr at 4000 K (9%). This uncertainty is significant, as it is comparable to the age uncertainty obtained by propagating the measurement errors on $T_{\\rm eff}$ and mass for a typical white dwarf. We also separately consider the potential impact of $^{22}$Ne shell distillation, which plausibly leads to an additional uncertainty of $\\sim 1$ Gyr for crystallized white dwarfs. We provide a table of our simulation results that can be used to evaluate the systematic model uncertainty based on a white dwarf's $T_{\\rm eff}$ and mass. We encourage its use in all future studies where white dwarf cooling ages are measured.         _ Less","","arXiv","https://arxiv.org/abs/2410.14014","0","1","synthetic_biology"
"Abundances of iron-peak elements in 58 bulge spheroid stars from APOGEE","Abstract:                Stars presently identified in the bulge spheroid are probably very old, and their abundances can be interpreted as due to the fast chemical enrichment of the early Galactic bulge. The abundances of the iron-peak elements are important tracers of nucleosynthesis processes, in particular oxygen burning, silicon burning, the weak s-process, and alpha-rich freez_         _ More           Stars presently identified in the bulge spheroid are probably very old, and their abundances can be interpreted as due to the fast chemical enrichment of the early Galactic bulge. The abundances of the iron-peak elements are important tracers of nucleosynthesis processes, in particular oxygen burning, silicon burning, the weak s-process, and alpha-rich freeze-out. Aims. The aim of this work is to derive the abundances of V, Cr, Mn, Co, Ni, and Cu in 58 bulge spheroid stars and to compare them with the results of a previous analysis of data from APOGEE. We selected the best lines for V, Cr, Mn, Co, Ni, and Cu located within the H-band of the spectrum, identifying the most suitable ones for abundance determination, and discarding severe blends. Using the stellar physical parameters available for our sample from the DR17 release of the APOGEE project, we derived the individual abundances through spectrum synthesis. We then complemented these measurements with similar results from different bulge field and globular cluster stars, in order to define the trends of the individual elements and compare with the results of chemical-evolution models. We verify that the H-band has useful lines for the derivation of the elements V, Cr, Mn, Co, Ni, and Cu in moderately metal-poor stars. The resulting abundances indicate that: V, Cr, and Ni vary in lockstep with Fe; Co tends to vary in lockstep with Fe, but could be showing a slight decrease with decreasing metallicity; and Mn and Cu decrease with decreasing metallicity. These behaviours are well reproduced by chemical-evolution models except for Cu, which appears to drop faster than the models predict for moderate metallicities. Finally, abundance indicators combined with kinematical and dynamical criteria appear to show that our 58 sample stars are likely to have originated in situ.         _ Less","","arXiv","https://arxiv.org/abs/2410.13751","0","1","synthetic_biology"
"The Milky Way Radial Metallicity Gradient as an Equilibrium Phenomenon: Why Old Stars are Metal-Rich","Abstract:                Metallicities of both gas and stars decline toward large radii in spiral galaxies, a trend known as the radial metallicity gradient. We quantify the evolution of the metallicity gradient in the Milky Way as traced by APOGEE red giants with age estimates from machine learning algorithms. Stars up to ages of $\\sim$9 Gyr follow a similar relation between metall_         _ More           Metallicities of both gas and stars decline toward large radii in spiral galaxies, a trend known as the radial metallicity gradient. We quantify the evolution of the metallicity gradient in the Milky Way as traced by APOGEE red giants with age estimates from machine learning algorithms. Stars up to ages of $\\sim$9 Gyr follow a similar relation between metallicity and Galactocentric radius. This constancy challenges current models of Galactic chemical evolution, which typically predict lower metallicities for older stellar populations. Our results favor an equilibrium scenario, in which the gas-phase gradient reaches a nearly constant normalization early in the disk lifetime. Using a fiducial choice of parameters, we demonstrate that one possible origin of this behavior is an outflow that more readily ejects gas from the interstellar medium with increasing Galactocentric radius. A direct effect of the outflow is that baryons do not remain in the interstellar medium for long, which causes the ratio of star formation to accretion, $\\dot__\\star / \\dot__\\text{in}$, to quickly become constant. This ratio is closely related to the local equilibrium metallicity, since its numerator and denominator set the rates of metal production by stars and hydrogen gained through accretion, respectively. Building in a merger event results in a perturbation that evolves back toward the equilibrium state on $\\sim$Gyr timescales. Under the equilibrium scenario, the radial metallicity gradient is not a consequence of the inside-out growth of the disk but instead reflects a trend of declining $\\dot__\\star / \\dot__\\text{in}$ with increasing Galactocentric radius.         _ Less","","arXiv","https://arxiv.org/abs/2410.13256","2","2","multiple"
"A New Angle on Benchmarking Noncovalent Interactions","Abstract:                _CCSDT(Q) are cost-prohibitive, which requires us to consider alternative means of estimating post-CCSD(T) contributions. In this work, we take a step back by considering the evolution of the correlation energy with respect to the number of subunits for such $_$-stacked sequences as acene dimers and alkadiene dimers. We show it to be almost perfectly linear,_         _ More           For noncovalent interactions (NCIs), the CCSD(T) coupled cluster method is widely regarded as the `gold standard'. With localized orbital approximations, benchmarks for ever larger NCI complexes are being published; yet tantalizing evidence from quantum Monte Carlo (QMC) results appears to indicate that as the system size grows, CCSD(T) overbinds NCIs by progressively larger amounts, particularly when $_$-stacking is involved. Alas, post-CCSD(T) methods like CCSDT(Q) are cost-prohibitive, which requires us to consider alternative means of estimating post-CCSD(T) contributions. In this work, we take a step back by considering the evolution of the correlation energy with respect to the number of subunits for such $_$-stacked sequences as acene dimers and alkadiene dimers. We show it to be almost perfectly linear, and propose the slope of the line as a probe for the behavior of a given electron correlation method. By comparison with rank-reduced CCSDT(Q) results for benzene and naphthalene dimers, we show that while CCSD(T) does slightly overbind, it does not at the level suggested by the QMC results.         _ Less","","arXiv","https://arxiv.org/abs/2410.12603","0","1","synthetic_biology"
"Fate of thermalization of ultracold fermions with two-body dissipation","Abstract:                Two-body dissipation due to chemical reactions occurs in both ultracold fermionic and bosonic molecular gases. Despite recent advances in achieving quantum degeneracy, the loss dynamics are typically described phenomenologically using rate equations, often assuming thermalization during_         _ More           Two-body dissipation due to chemical reactions occurs in both ultracold fermionic and bosonic molecular gases. Despite recent advances in achieving quantum degeneracy, the loss dynamics are typically described phenomenologically using rate equations, often assuming thermalization during chemical reactions. From the first principles, we analyze particle loss, temperature evolution, and momentum distributions in single-component Fermi gases using the inelastic quantum Boltzmann equation. Our results prove that the conventional two-body loss model is valid for trapped systems, though it fails to describe the dynamics in homogeneous systems accurately. Interestingly, we find that systems prepared near or above quantum degeneracy can thermalize spontaneously, even in the absence of elastic collisions, while systems initialized deep in degeneracy display non-equilibrium behavior. Our calculations are in good agreement with recent experimental data from trapped systems and could be further tested in atomic systems with induced two-body loss in box potentials.         _ Less","","arXiv","https://arxiv.org/abs/2410.12204","0","1","synthetic_biology"
"Counting stars from the integrated spectra of galaxies","Abstract:                _models have powered an unmatched leap forward in our understanding of galaxies. From dating the age of the first galaxies in the Universe to detailed measurements of the chemical composition of nearby galaxies, the success of this approach built upon simple stellar population (SSP) spectro-photometric models is unquestionable. However, the internal constrain_         _ More           Over the last decades, evolutionary population synthesis models have powered an unmatched leap forward in our understanding of galaxies. From dating the age of the first galaxies in the Universe to detailed measurements of the chemical composition of nearby galaxies, the success of this approach built upon simple stellar population (SSP) spectro-photometric models is unquestionable. However, the internal constraints inherent to the construction of SSP models may hinder our ability to analyze the integrated spectra of galaxies in situations where the SSP assumption does not sufficiently hold. Thus, here we revisit the possibilities of fitting galaxy spectra as a linear combination of stellar templates without assuming any a priori knowledge on stellar evolution. We showcase the sensitivity of this alternative approach to changes in the stellar population properties, in particular the direct connection to variations in the stellar initial mass function, as well as its advantages when dealing with non-canonical integrated populations and semi-resolved observations. Furthermore, our analysis demonstrates that the absorption spectra of galaxies can be used to independently constrain tellar evolution theory beyond the limited conditions of the solar neighborhood.         _ Less","","arXiv","https://arxiv.org/abs/2410.11961","0","1","synthetic_biology"
"Metal pollution in Sun-like stars from destruction of ultra-short-period planets","Abstract:        Chemical evidence indicates that an appreciable fraction of Sun-like stars have engulfed rocky planets during their main-sequence lifetimes. We investigate whether the tidal evolution and destruction of ultra-short-period planets (USPs) can explain this phenomenon. We develop a simple parameterized model for the format_         _ More   Chemical evidence indicates that an appreciable fraction of Sun-like stars have engulfed rocky planets during their main-sequence lifetimes. We investigate whether the tidal evolution and destruction of ultra-short-period planets (USPs) can explain this phenomenon. We develop a simple parameterized model for the formation and engulfment of USPs in a population of MS stars. With this model, it is possible to reproduce both the observed occurrence rate of USPs and the frequency of planet-engulfing Sun-like stars for a reasonable range of USP formation rates and tidal decay lifetimes. Our results support a theory of USP formation through gradual inward migration over many Gyr and suggest that engulfment occurs $\\sim 0.1$-$1 \\, {\\rm Gyr}$ after formation. This lifetime is set by tidal dissipation in the USP itself instead of the host star, due to the perturbing influence of external companions. If USP engulfment is the main source of pollution among Sun-like stars, we predict a correlation between pollution and compact multi-planet systems; some $5$-$10\\%$ of polluted stars should have a transiting planet of mass $\\gtrsim 5 M_{\\oplus}$ and period $\\sim 4$-$12$ days.         _ Less","","arXiv","https://arxiv.org/abs/2410.11935","1","1","multiple"
"Multi-Scale Molecular Dynamics Simulations","Abstract:                In molecular dynamics (MD), systems are molecules made up of    atoms, and the aim is to determine their evolution over time.  MD    is based on a numerical resolution algorithm, whose role is to    apply the forces generated by the various components, according to    the equations of Newtonian physics. Molecular Dynamics is    currently mainly used in mater_         _ More           In molecular dynamics (MD), systems are molecules made up of    atoms, and the aim is to determine their evolution over time.  MD    is based on a numerical resolution algorithm, whose role is to    apply the forces generated by the various components, according to    the equations of Newtonian physics. Molecular Dynamics is    currently mainly used in materials science and molecular biology.  In this document, we limit ourselves to {\\it alkanes} which are  non-cyclic carbon-hydrogenated chains. In the basic ``All-atom''  (AA) scale, all the atoms are directly simulated. In the  ``United-atom'' (UA) scale, one considers grains that are composed  of a carbon atom with the hydrogen atoms attached to it. Grains in  the ``Coarse-grained'' (CG) scale are composed of two consecutive UA  grains. In the multi-scale approach, one tries to use as much as  possible the UA and CG scales which can be more efficiently  simulated than the AA scale.  In this document, we mainly put the focus on three topics.  First, we describe an MD system, implemented in the Java  programming language, according to the Synchronous Reactive  Programming approach in which there exists a notion of a global  logical time.  This system is used to simulate molecules and also to  build the potentials functions at the UA and CG scales.  Second, two methods to derive UA and CG potentials from AA  potentials are proposed and analysed. Basically, both methods rely  on strong geometrical links with the AA scale. We use these links  with AA to determine the forms and values of the UA and CG  potentials.  In the first method (called ``inverse-Boltzmann''), one  considers data produced during several AA scale molecule  simulations, and one processes these data using a statistical  approach. In the second method (``minimisation method''), one  applies a constrained-minimisation technique to AA molecules. The  most satisfactory method clearly appears to be the  minimisation-based one.  The UA potentials we have determined have  standard forms: they only differ from AA potentials by parameter  values. On the opposite, CG potentials are non-standard  functions. We show how to implement them with functions defined ``by  cases''.  Finally, we consider ``reconstructions'' which are means to  dynamically change molecule scales during simulations.  In  particular, we consider automatic reconstructions based on the  proximity of molecules.         _ Less","","arXiv","https://arxiv.org/abs/2410.11342","0","1","synthetic_biology"
"Direct High-resolution Observation of Feedback and Chemical Enrichment in the Circumgalactic Medium at Redshift 2.8","Abstract:                Although the circumgalactic medium (CGM) plays a vital role in galaxy evolution, studying the emission from CGM is challenging due to its low surface brightness and the complexities involved in interpreting resonant lines like Ly$_$. The near-infrared coverage, unprecedented sensitivity, and high spatial resolution of the JWST enable us to study the optical_         _ More           Although the circumgalactic medium (CGM) plays a vital role in galaxy evolution, studying the emission from CGM is challenging due to its low surface brightness and the complexities involved in interpreting resonant lines like Ly$_$. The near-infrared coverage, unprecedented sensitivity, and high spatial resolution of the JWST enable us to study the optical strong lines associated with the extended Ly$_$ 'nebulae' at redshift 2-3. These lines serve as diagnostic tools to infer the physical conditions in the massive CGM gas reservoir of these systems. In deep medium-band images taken by the JWST, we serendipitously discover the [O III] emission from the CGM surrounding a massive interacting galaxy system at redshift z ~ 2.8, known to be embedded in a bright extended (100 kpc) Ly$_$ 'nebula'. This is the first time that the [O III] lines are detected from a Ly$_$ 'nebula', and the JWST images reveal that the CGM gas actually resides in narrow (~ 2.5 kpc) filamentary structures with strong [O III] emission, tracing the same extent as the Ly$_$ emission. Analysis of the [O III] suggests that the emitting CGM is fully ionized and is energetically dominated by mechanical heating. We also find that the inferred density and pressure are higher than those commonly predicted by simulations of the CGM. We conclude that the observed CGM emission originates from the gas expelled by the episodic feedback processes, cooling down and enriching the CGM, while travelling to a distance of at least 60 kpc. These observations demonstrate how fierce feedback processes shape gas distribution and properties in the CGM around massive halos. While the deep high-resolution imaging opens up a new discovery space for investigating the CGM, it also challenges numerical simulations to explain and reproduce the exquisitely complex structures revealed by the observations.         _ Less","","arXiv","https://arxiv.org/abs/2410.10993","0","1","synthetic_biology"
"A possible formation scenario of the Gaia BH1: inner binary merger in triple systems","Abstract:                _G) merger product, we find that, at typical Galactic metallicity, the merger product can undergo efficient chemically homogeneous_         _ More           Based on astrometric measurements and spectral analysis from $Gaia$ DR3, two quiescent black hole (BH) binaries, $Gaia$ BH1 and BH2, have been identified. Their origins remain controversial, particularly for $Gaia$ BH1. By considering a rapidly rotating ($_/__{\\rm crit} = 0.8$) and strongly magnetized ($B_{\\rm 0} = 5000$ G) merger product, we find that, at typical Galactic metallicity, the merger product can undergo efficient chemically homogeneous evolution (CHE). This results in the merger product having a significantly smaller radius during its evolution compared to that of a normally evolving massive star. Under the condition that the initial triple stability is satisfied, we use the Multiple Stellar Evolution (MSE) code and the MESA code to identify an initial hierarchical triple that can evolve into $Gaia$ BH1. It initially consists of three stars with masses of 9.03 $M_{\\odot}$, 3.12 $M_{\\odot}$, and 1 $M_{\\odot}$, with inner and outer orbital periods of 2.21 days and 121.92 days, and inner and outer eccentricities of 0.41 and 0.45, respectively. This triple initially experiences triple evolution dynamics instability (TEDI) followed by Roche lobe overflow (RLOF). During RLOF, the inner orbit shrinks, and tidal effects gradually suppress the TEDI. Eventually, the inner binary undergoes a merger through contact (or collision). Finally, using models of rapidly rotating and strongly magnetic stars, along with standard core-collapse supernova (SN) or failed supernova (FSN) models, we find that a PMB consisting of an 12.11 $M_{\\odot}$ merger product and a 1 $M_{\\odot}$ companion star (originally an outer tertiary) can avoid RLOF. After a SN or FSN with a low ejected mass of $\\sim$0.22 $M_{\\odot}$ and a low kick velocity ($46^{+25}_{-33}$ ${\\rm km/s}$ or $9^{+16}_{-8}$ ${\\rm km/s}$), the PMB can form $Gaia$ BH1 in the Galactic disk.         _ Less","","arXiv","https://arxiv.org/abs/2410.10581","1","1","multiple"
"Anharmonic Vibrational States of Double-Well Potentials in the Solid State from DFT Calculations","Abstract:                _to structural changes between the two phases are found in the terahertz region of the electromagnetic spectrum, which exhibit strong anharmonic character in their thermal evolution, as measured by temperature-dependent terahertz time-domain spectroscopy.         _ More           We introduce a general approach for the simulation of quantum vibrational states of (symmetric and asymmetric) double-well potentials in molecules and materials for thermodynamic and spectroscopic applications. The method involves solving the nuclear Schr_dinger equation associated with a one-mode potential of the type $V (Q) = aQ^2 + bQ^3 + cQ^4$ (with $a < 0$ and $c > 0$), and thus explicitly includes nuclear quantum effects. The potential, $V (Q)$, is obtained from density functional theory (DFT) calculations performed at displaced nuclear configurations along the selected normal mode, $Q$. The strategy has been implemented into the CRYSTAL electronic structure package and allows for i) the use of many density functional approximations, including hybrid ones, and ii) integration with a quasi-harmonic module. The method is applied to the spectroscopic characterization of soft lattice modes in two phases of the molecular crystal of thiourea: a low-temperature ferroelectric phase and a high-temperature paraelectric phase. Signature peaks associated to structural changes between the two phases are found in the terahertz region of the electromagnetic spectrum, which exhibit strong anharmonic character in their thermal evolution, as measured by temperature-dependent terahertz time-domain spectroscopy.         _ Less","","arXiv","https://arxiv.org/abs/2410.10379","0","1","synthetic_biology"
"Photochemical Hazes in Exoplanetary Skies with Diamonds: Microphysical Modeling of Haze Composition Evolution via Chemical Vapor Deposition","Abstract:                _have reflective compositions, unlike the conventionally assumed haze analogs, such as tholin and soot. In this study, I propose a novel hypothesis: diamond formation through chemical vapor deposition (CVD) may be happening in exoplanetary atmospheres. Using an aerosol microphysical model combined with the theory of CVD diamond and soot formation established_         _ More           Observational efforts in the last decade suggest the prevalence of photochemical hazes in exoplanetary atmospheres. Recent JWST observations raise growing evidence that exoplanetary hazes tend to have reflective compositions, unlike the conventionally assumed haze analogs, such as tholin and soot. In this study, I propose a novel hypothesis: diamond formation through chemical vapor deposition (CVD) may be happening in exoplanetary atmospheres. Using an aerosol microphysical model combined with the theory of CVD diamond and soot formation established in the industry community, I study how the haze composition evolves in exoplanetary atmospheres for various planetary equilibrium temperature, atmospheric metallicity, and C/O ratio. I find that CVD diamond growth dominates over soot growth in a wide range of planetary parameters. Diamond haze formation is most efficient at $T_{\\rm eq}\\sim1000~{\\rm K}$ and low atmospheric metallicity ([M/H]$\\le2.0$), while soot could be the main haze component only if the atmosphere is hot ($T_{\\rm eq}\\ge1200~{\\rm K}$) and carbon rich (C/O$>1$). I also compute transmission, emission, and reflected light spectra, thereby suggesting possible observational signatures of diamond hazes, including the $3.53~{\\rm _m}$ feature of hydrogenated diamonds, anomalously faint thermal emission due to thermal scattering, and a drastic increase in geometric albedo. This study suggests that warm exoplanetary atmospheres may be favorable sites for forming CVD diamonds, which would be testable by future observations by JWST and Ariel as well as haze synthesis experiments under hot hydrogen-rich conditions.         _ Less","","arXiv","https://arxiv.org/abs/2410.10197","1","2","synthetic_biology"
"A data-driven sparse learning approach to reduce chemical reaction mechanisms","Abstract:                Reduction of detailed chemical reaction mechanisms is one of the key methods for mitigating the computational cost of reactive flow simulations. Exploitation of species and elementary reaction sparsity ensures the compactness of the reduced mechanisms. In this work, we propose a novel sparse statistical learning approach for_         _ More           Reduction of detailed chemical reaction mechanisms is one of the key methods for mitigating the computational cost of reactive flow simulations. Exploitation of species and elementary reaction sparsity ensures the compactness of the reduced mechanisms. In this work, we propose a novel sparse statistical learning approach for chemical reaction mechanism reduction. Specifically, the reduced mechanism is learned to explicitly reproduce the dynamical evolution of detailed chemical kinetics, while constraining on the sparsity of the reduced reactions at the same time. Compact reduced mechanisms are be achieved as the collection of species that participate in the identified important reactions. We validate our approach by reducing oxidation mechanisms for $n$-heptane (194 species) and 1,3-butadiene (581 species). The results demonstrate that the reduced mechanisms show accurate predictions for the ignition delay times, laminar flame speeds, species mole fraction profiles and turbulence-chemistry interactions across a wide range of operating conditions. Comparative analysis with directed relation graph (DRG)-based methods and the state-of-the-art (SOTA) methods reveals that our sparse learning approach produces reduced mechanisms with fewer species while maintaining the same error limits. The advantages are particularly evident for detailed mechanisms with a larger number of species and reactions. The sparse learning strategy shows significant potential in achieving more substantial reductions in complex chemical reaction mechanisms.         _ Less","","arXiv","https://arxiv.org/abs/2410.09901","0","1","synthetic_biology"
"EquiJump: Protein Dynamics Simulation via SO(3)-Equivariant Stochastic Interpolants","Abstract:                Mapping the conformational dynamics of proteins is crucial for elucidating their functional mechanisms. While Molecular Dynamics (MD) simulation enables detailed time evolution of protein motion, its computational toll hinders its use in practice. To address this challenge, multiple deep learning models for reproducing and accelerating MD have been proposed_         _ More           Mapping the conformational dynamics of proteins is crucial for elucidating their functional mechanisms. While Molecular Dynamics (MD) simulation enables detailed time evolution of protein motion, its computational toll hinders its use in practice. To address this challenge, multiple deep learning models for reproducing and accelerating MD have been proposed drawing on transport-based generative methods. However, existing work focuses on generation through transport of samples from prior distributions, that can often be distant from the data manifold. The recently proposed framework of stochastic interpolants, instead, enables transport between arbitrary distribution endpoints. Building upon this work, we introduce EquiJump, a transferable SO(3)-equivariant model that bridges all-atom protein dynamics simulation time steps directly. Our approach unifies diverse sampling methods and is benchmarked against existing models on trajectory data of fast folding proteins. EquiJump achieves state-of-the-art results on dynamics simulation with a transferable model on all of the fast folding proteins.         _ Less","","arXiv","https://arxiv.org/abs/2410.09667","1","1","multiple"
"A modified cellular automaton using activation and inhibition regions geometrically compatible with biaxial anisotropy","Abstract:                Young's cellular automaton, recently applied to study the spatiotemporal evolution of binary patterns for favorable/hostile environments, has now been modified from a different point of view. In this model, each differentiated cell (DC) produces two diffusing morphogens: a short-range activator and a long-range inhibitor. Their combination creates the so_         _ More           Young's cellular automaton, recently applied to study the spatiotemporal evolution of binary patterns for favorable/hostile environments, has now been modified from a different point of view. In this model, each differentiated cell (DC) produces two diffusing morphogens: a short-range activator and a long-range inhibitor. Their combination creates the so-called local 'w' field. Undifferentiated cells (UCs) are passive. The question arises how to adapt it to modelling patterning processes in anisotropic substrates with a biaxial dependence of the morphogen diffusion rate. We use activation/inhibition regions with appropriate shape geometry defined by the so-called deformation parameter p. We complement this model by adding a physically reasonable transition zone with controlled local field slope. The patterning process uses the morphogenetic field W calculated separately for each cell, which is the sum of the 'w' values generated by all regional DCs surrounding the cell. It acts as a chemical signal determining the next state of the cell. We also introduce a threshold W* defining the required absolute chemical signal strength. The state of each cell can change depending on the rules for W and W*. This improves the stability of the model evolution and extends its applications. Using two pairs of two-point orthogonal correlation functions, we reveal their directional sensitivity to changes in biaxial anisotropy. Finally, we illustrate the general two-parameter dependence of the average final DC concentration on the geometry of the activation/inhibition regions and on the value of the long-range inhibitor. This facilitates the recognition of characteristic features of the evolution of DC concentration in our model.         _ Less","","arXiv","https://arxiv.org/abs/2410.09624","1","1","multiple"
"Regulating protocols of globally coupled continuum systems: Effects on dynamics and thermodynamics","Abstract:                Controlling and understanding phenomena in coupled systems remains a significant challenge across diverse fields. This study investigates a simple globally coupled chemical system that exhibits a range of rich collective dynamics, from coherence to chimera states, controllable by a system parameter. We explore the effects of altering this control parameter u_         _ More           Controlling and understanding phenomena in coupled systems remains a significant challenge across diverse fields. This study investigates a simple globally coupled chemical system that exhibits a range of rich collective dynamics, from coherence to chimera states, controllable by a system parameter. We explore the effects of altering this control parameter using two different protocols. In protocol-I, a continuous variation of the control parameter leads to memory effects, resulting in two distinct sets of phenomena in the forward and reverse directions. In contrast, protocol-II, which includes a resetting feature, yields an entirely distinct collection of behaviors. Additionally, we capture the evolution of key elements of nonequilibrium thermodynamics associated with these dynamical states under both protocols, revealing distinct signatures for each. This work highlights the complexity and uniqueness of regulating coupled systems via control parameters compared to corresponding single systems, and it carries potential implications for the manipulation and application of collective behaviors.         _ Less","","arXiv","https://arxiv.org/abs/2410.08678","0","1","synthetic_biology"
"Eridanus III and DELVE 1: Carbon-rich Primordial Star Clusters or the Smallest Dwarf Galaxies?","Abstract:                _Because their metallicities are well below those of the Milky Way globular cluster population, and because no CEMP-no stars have been identified in globular clusters, these chemical abundances could suggest that Eri III and DELVE 1 are dwarf galaxies. On the other hand, the two systems have half-light radii of 8 pc and 6 pc, respectively, which is more comp_         _ More           We present spectroscopy of the ultra-faint Milky Way satellites Eridanus III (Eri III) and DELVE 1. We identify eight member stars in each satellite and place non-constraining upper limits on their velocity and metallicity dispersions. The brightest star in each object is very metal-poor, at [Fe/H] = -3.1 for Eri III and [Fe/H] = -2.8 for DELVE 1. Both of these stars exhibit large overabundances of carbon and very low abundances of the neutron-capture elements Ba and Sr, and we classify them as CEMP-no stars. Because their metallicities are well below those of the Milky Way globular cluster population, and because no CEMP-no stars have been identified in globular clusters, these chemical abundances could suggest that Eri III and DELVE 1 are dwarf galaxies. On the other hand, the two systems have half-light radii of 8 pc and 6 pc, respectively, which is more compact than any known ultra-faint dwarfs. We conclude that Eri III and DELVE 1 are either the smallest dwarf galaxies yet discovered, or they are representatives of a new class of star clusters that underwent chemical evolution distinct from that of ordinary globular clusters. In the latter scenario, such objects are likely the most primordial star clusters surviving today. These possibilities can be distinguished by future measurements of carbon and/or iron abundances for larger samples of stars or improved stellar kinematics for the two systems.         _ Less","","arXiv","https://arxiv.org/abs/2410.08276","1","1","multiple"
"First-Principles Phase-Field Modeling","Abstract:                Phase-field methods offer a versatile computational framework for simulating large-scale microstructure evolution. However, the applicability and predictability of phase-field models are inherently limited by their ad hoc nature, and there is currently no bottom-up theory available that enables truly first-principles predictive modeling of large-scale non-eq_         _ More           Phase-field methods offer a versatile computational framework for simulating large-scale microstructure evolution. However, the applicability and predictability of phase-field models are inherently limited by their ad hoc nature, and there is currently no bottom-up theory available that enables truly first-principles predictive modeling of large-scale non-equilibrium processes. Here, we present a bottom-up framework that provides a route to the construction of mesoscopic phase-field models entirely based on atomistic information. By introducing a molecular coarse-grained system as an intermediate step, we demonstrate the approach on the example of ice nucleation dynamics, with a spatiotemporal scale-up of nearly $10^8$ times compared to the microscopic model. Our framework offers a unique approach for incorporating atomistic details into mesoscopic models, systematically bridging the gap between microscopic particle-based simulations and field-theoretic models.         _ Less","","arXiv","https://arxiv.org/abs/2410.08180","1","2","synthetic_biology"
"The mystery of water in the atmosphere of $_$ Bo_tis b continues: insights from revisiting archival CRIRES observations","Abstract:                The chemical abundances of gas-giant exoplanet atmospheres hold clues to the formation and evolution pathways that sculpt the exoplanet population. Recent ground-based high-resolution spectroscopic observations of the non-transiting hot Jupiter $_$ Bo_tis b from different instruments have resulted in a tension on the p_         _ More           The chemical abundances of gas-giant exoplanet atmospheres hold clues to the formation and evolution pathways that sculpt the exoplanet population. Recent ground-based high-resolution spectroscopic observations of the non-transiting hot Jupiter $_$ Bo_tis b from different instruments have resulted in a tension on the presence of water vapour in the planet's atmosphere, which impact the planet's inferred C/O and metallicity. To investigate this, we revisit the archival CRIRES observations of the planet's dayside in the wavelength range 2.28 to 2.33 $_$m. We reanalyse them using the latest methods for correcting stellar and telluric systematics, and free-chemistry Bayesian atmospheric retrieval. We find that a spurious detection of CH$_{4}$ can arise from inadequate telluric correction. We confirm the detection of CO and constrain its abundance to be near solar $\\log_{10}(\\mathrm{CO})$ = -3.44$^{+1.63}_{-0.85}$ VMR. We find a marginal evidence for H$_{2}$O with $\\log_{10}(\\mathrm{H_{2}O})$ = -5.13$^{+1.22}_{-6.37}$ VMR. This translates to super solar C/O (0.95$^{+0.06}_{-0.31}$), marginally sub-solar metallicity (-0.21 $^{+1.66}_{-0.87}$). Due to the relatively large uncertainty on H$_{2}$O abundance, we cannot confidently resolve the tension on the presence of H$_{2}$O and the super-solar atmospheric metallicity of $_$ Bo_tis b. We recommend further observations of $_$ Bo_tis b in the wavelength ranges simultaneously covering CO and $\\mathrm{H_{2}O}$ to confirm the peculiar case of the planet's super-solar C/O and metallicity.         _ Less","","arXiv","https://arxiv.org/abs/2410.08178","1","1","multiple"
"The initial mass function of stars","Abstract:                _to the galaxy-wide IMF connects the molecular clumps to the cosmological scale. The extraction of the IMF from observational data requires a thorough understanding of stellar evolution, the time-dependent stellar multiplicity, the stellar-dynamical_         _ More           The initial mass function (IMF) is one of the most important functions in astrophysics because it is key to reconstructing the cosmological matter cycle, understanding the formation of super-massive black holes, and deciphering the light from high-redshift observations. The IMF's dependency on the physical conditions of the gas and its connection to the galaxy-wide IMF connects the molecular clumps to the cosmological scale. The extraction of the IMF from observational data requires a thorough understanding of stellar evolution, the time-dependent stellar multiplicity, the stellar-dynamical evolution of dense stellar populations, and the structures, star formation histories, and chemical enrichment histories of galaxies. The IMF in galaxies, referred to as the galaxy-wide IMF (gwIMF), and the IMF in individual star-forming regions (the stellar IMF) need not be the same, although the former must be related to the latter. Observational surveys inform on whether star-forming regions provide evidence for the stellar IMF being a probability density distribution function. They may also indicate star formation to optimally follow an IMF shaped by the physical conditions of the star-forming gas. Both theoretical and observational evidence suggest a relationship between the initial mass function of brown dwarfs and that of stars. Late-type stars may arise from feedback-regulated fragmentation of molecular cloud filaments, which build up embedded clusters. In contrast, early-type stars form under more violent accretion and feedback-regulated conditions near the centers of these clusters. The integration over all star-forming molecular cloud clumps and their stellar IMFs in a galaxy via the IGIMF theory yields its gwIMF which sensitively depends on the physical properties of the molecular cloud clumps and the range of their masses that depends on the SFR of the galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2410.07311","2","2","multiple"
"Chemical composition of planetary hosts: C, N, and $_$-element abundances","Abstract:                Accurate atmospheric parameters and chemical composition of planet-hosting stars are crucial for characterising exoplanets and understanding their formation and evolution. Our objective is to uniformly determine the atmospheric parameters and chemical abundances of carbon, nitrog_         _ More           Accurate atmospheric parameters and chemical composition of planet-hosting stars are crucial for characterising exoplanets and understanding their formation and evolution. Our objective is to uniformly determine the atmospheric parameters and chemical abundances of carbon, nitrogen, oxygen, and the $_$-elements, magnesium and silicon, along with C/O, N/O and Mg/Si abundance ratios in planet-hosts. We aim to investigate the potential links between stellar chemistry and the presence of planets using high-resolution spectra of 149 F, G, and K dwarf and giant stars hosting planets or planetary systems. The spectra were obtained with the Vilnius University Echelle Spectrograph on the 1.65 m Mol_tai Observatory telescope. Stellar parameters were determined through standard analysis using equivalent widths and one-dimensional, plane-parallel model atmospheres calculated under the assumption of local thermodynamical equilibrium. The differential synthetic spectrum method was used to uniformly determine carbon C(C2), nitrogen N(CN), oxygen [O I], magnesium Mg I, and silicon Si I elemental abundances as well as the C/O, N/O, and Mg/Si ratios. We found that [C/Fe], [O/Fe], and [Mg/Fe] are lower in metal-rich dwarf hosts; whereas [N/Fe] is close to the Solar ratio. Giants show smaller scatter in [C/Fe] and [O/Fe] and lower than the Solar average [C/Fe] and C/O ratios. The (C+N+O) abundances increase with [Fe/H] in giant stars, with a minimal scatter. We also noted an overabundance of Mg and Si in planet hosting stars, particularly at lower metallicities, and a lower Mg/Si ratio in stars with planets. In giants hosting high-mass planets, nitrogen shows a moderate positive relationship with planet mass. C/O and N/O ratios show moderate negative and positive slopes in giant stars, respectively. The Mg/Si ratio shows a negative correlation with planet mass across the entire stellar sample.         _ Less","","arXiv","https://arxiv.org/abs/2410.07100","1","1","multiple"
"Towards simultaneous imaging of ultrafast nuclear and electronic dynamics in small molecules","Abstract:                When a chemical bond is broken, the molecular structure undergoes a transformation. An ideal experiment should probe the change in the electronic and nuclear structure simultaneously. Here, we present a method for the simultaneous time-resolved imaging of nuclear and electron dynamics by combining Coulomb explosion imaging with strong-field photoelectron mom_         _ More           When a chemical bond is broken, the molecular structure undergoes a transformation. An ideal experiment should probe the change in the electronic and nuclear structure simultaneously. Here, we present a method for the simultaneous time-resolved imaging of nuclear and electron dynamics by combining Coulomb explosion imaging with strong-field photoelectron momentum imaging. The simplest chemical reaction, H$_2^+$ $\\rightarrow$ H$^+ +$ H, is probed experimentally for the delay-dependent kinetic energy release, and numerically for the transient change in the photoelectron spectra during the dissociation process. The three-dimensional Schr_dinger equation is solved in the fixed-nuclei approximation numerically and the results are compared to those from a simple imaging model. The numerical results reflect the evolution in the electron density in the molecular ion as its bond is first stretched and then brakes apart. Our work shows how simple gas-phase chemical dynamics can be captured in complete molecular movies.         _ Less","","arXiv","https://arxiv.org/abs/2410.07088","1","1","multiple"
"Application of a Temporal Multiscale Method for Efficient Simulation of Degradation in PEM Water Electrolysis under Dynamic Operation","Abstract:                Hydrogen is vital for sectors like chemicals and others, driven by the need to reduce carbon emissions. Proton Electrolyte Membrane Water Electrolysis (PEMWE) is a key technology for the production of green hydrogen under fluctuating conditions of renewable power sources. However, due to the scarcity of noble metal materials, the stability of the anode catal_         _ More           Hydrogen is vital for sectors like chemicals and others, driven by the need to reduce carbon emissions. Proton Electrolyte Membrane Water Electrolysis (PEMWE) is a key technology for the production of green hydrogen under fluctuating conditions of renewable power sources. However, due to the scarcity of noble metal materials, the stability of the anode catalyst layer under dynamic operating conditions must be better understood. Model-aided investigation approaches are essential due to the back-box nature of the electrochemical system and the high costs of experimental long-term testing. In this work, a temporal multiscale method based on a Heterogeneous technique is applied to reduce the computational effort of simulating long-term degradation, focused on catalyst dissolution. Such an approach characterizes the problem in fast locally periodic processes, influenced by the dynamic operation and slow processes attributed to the gradual degradation of the catalyst layer. A mechanistic model that includes the oxygen evolution reaction, catalyst dissolution and hydrogen permeation from the cathode to the anode side is hypothesized and implemented. The multiscale approach notably reduces computational effort of simulation from hours to mere minutes. This efficiency gain is ascribed to the limited evolution of Slow-Scale variables during each period of time of the Fast-Scale variables. Consequently, simulation of the fast processes is required only until local periodicity is achieved within each Slow-Scale time step. Thus, the developed temporal multiscale approach proves to be highly effective in accelerating parameter estimation and predictive simulation steps, as could be verified through the results of this article. In this way, the method can support systematic model development to describe degradation in PEMWE under dynamic operating conditions.         _ Less","","arXiv","https://arxiv.org/abs/2410.06863","0","1","synthetic_biology"
"The warm-hot intergalactic medium (WHIM) in inter-cluster filaments -- A forecast for HUBS observations based on eRASS1 superclusters","Abstract:                _to < +-0.03 solar, and density constrained to < +-10%. Elemental abundance of O, Ne, Mg, and Fe can be measured separately, providing unprecedented insights into the chemical history of the filament gas. We also showed that direct mapping of the WHIM distribution is promising with narrow-band imaging of the O viii line. Our work forecasts that next-gen_         _ More           Cosmological simulations indicate that nearly half of the baryons in the nearby Universe are in the warm-hot intergalactic medium (WHIM) phase, with about half of which residing in cosmic filaments. Recent observational studies using stacked survey data and deep exposures of galaxy cluster outskirts have detected soft X-ray excess associated with optically identified filaments. However, the physical characteristics of WHIM in filaments remain largely undetermined due to the lack of direct spectral diagnostics. In this work, we aim to select appropriate targets for WHIM characterization through pointing observations with the future Hot Universe Baryon Surveyor (HUBS) mission, which is designed with eV level energy resolution in the 0.1-2.0 keV band and a 1 square degree field-of-view. We built a sample of 1577 inter-cluster filaments based on the first eROSITA All-Sky Survey (eRASS1) supercluster catalog and estimated their soft X-ray emission, and used their modeled geometrical properties and oxygen line intensities to select four most appropriate candidate targets for HUBS observations. By simulating and analyzing their mock observations, we demonstrated that with 200 ks HUBS exposure for each candidate, the gas properties of individual filaments can be accurately determined, with the temperature constrained to +-0.01 keV, metallicity constrained to < +-0.03 solar, and density constrained to < +-10%. Elemental abundance of O, Ne, Mg, and Fe can be measured separately, providing unprecedented insights into the chemical history of the filament gas. We also showed that direct mapping of the WHIM distribution is promising with narrow-band imaging of the O viii line. Our work forecasts that next-generation X-ray missions such as HUBS will provide substantial improvement in our understanding of the physical status and evolution history of the diffuse WHIM gas in cosmic large-scale structure.         _ Less","","arXiv","https://arxiv.org/abs/2410.06836","1","2","synthetic_biology"
"DUNE: Dust depletion UNified method across cosmic time and Environments","Abstract:                _for characterizing dust depletion across cosmic time and diverse galactic environments, offering a valuable new approach to the study of dust depletion in studies of the chemical evolution of galaxies.         _ More           We present a novel method to characterize dust depletion, namely, the depletion of metals into dust grains. We used observed correlations among relative abundances combining a total of 17 metals in diverse galactic environments, including the Milky Way (MW), Large Magellanic Cloud (LMC), Small Magellanic Cloud (SMC), and damped Lyman-$_$ absorbers (DLAs) towards quasars and gamma-ray bursts (GRBs). We only considered the relative abundances of metals that qualify as tracers of dust and we used all available dust tracers. We find linear correlations among all studied dust tracers in a multidimensional space, where each dimension corresponds to an individual dust tracer. The fit to the linear correlations among the dust tracers describes the tendencies of different elements when depleting into dust grains. We determined the overall strength of dust depletion, $_$, along individual lines of sight, based on the correlations among different dust tracers. We avoided any preference for specific dust tracers or any other assumptions by including all available dust tracers in this multidimensional space. We also determined the dust depletion of Kr, C, O, Cl, P, Zn, Ge, Mg, Cu, Si, Fe, Ni, and Ti. Finally, we offer simple guidelines for the application of the method to the study of the observed patterns of abundances and relative abundances. This has allowed for a straightforward determination of the overall strength of depletion and the dust depletion of individual elements. We also obtained an estimate for the gas-phase metallicity and identified any additional deviations due to the nucleosynthesis of specific stellar populations. Thus, we have established a unified methodology for characterizing dust depletion across cosmic time and diverse galactic environments, offering a valuable new approach to the study of dust depletion in studies of the chemical evolution of galaxies.         _ Less","","arXiv","https://arxiv.org/abs/2410.06155","1","1","multiple"
"Gas phase Elemental abundances in Molecular cloudS (GEMS). X. Observational effects of turbulence on the chemistry of molecular clouds","Abstract:                _the turbulent steady-state of a turbulent box with properties typical of a molecular filament before collapse. We post-process the results of the MHD simulation with a chemical code to predict molecular abundances, and then post-process this cube with a radiative transfer code to create synthetic emission maps for a series of rotational transitions observed_         _ More           (Abridged) We explore the chemistry of the most abundant C, O, S, and N bearing species in molecular clouds, in the context of the IRAM 30 m Large Programme Gas phase Elemental abundances in Molecular Clouds (GEMS). In this work, we aim to assess the limitations introduced in the observational works when a uniform density is assumed along the line of sight for fitting the observations, developing a very simple numerical model of a turbulent box. We perform a MHD simulation in order to reproduce the turbulent steady-state of a turbulent box with properties typical of a molecular filament before collapse. We post-process the results of the MHD simulation with a chemical code to predict molecular abundances, and then post-process this cube with a radiative transfer code to create synthetic emission maps for a series of rotational transitions observed during the GEMS project. From the chemical point of view, we find that turbulence produces variations on the predicted abundances, but they are more or less critical depending on the chosen transition and the chemical age. When compared to real observations, the results from the turbulent simulation provides a better fit than when assuming a uniform gas distribution along the line of sight. In the view of our results, we conclude that taking into account turbulence when fitting observations might significantly improve the agreement with model predictions. This is especially important for sulfur bearing species that are very sensitive to the variations of density produced by turbulence at early times (0.1 Myr). The abundance of CO is also quite sensitive to turbulence when considering the evolution beyond a few 0.1 Myr.         _ Less","","arXiv","https://arxiv.org/abs/2410.04226","0","1","synthetic_biology"
"Mixed-mode coupling in the Red Clump I. Standard single star models","Abstract:                _properties of core-helium burning (CHeB) stars by examining how the coupling between gravity- and pressure-mode cavities depends on several stellar properties, including mass, chemical composition, and evolutionary state. Using the structure of models computed with the stellar evolution code MESA we calculate the coupl_         _ More           The investigation of global, resonant oscillation modes in red giant stars offers valuable insights into their internal structures. In this study, we investigate in detail the information we can recover on the structural properties of core-helium burning (CHeB) stars by examining how the coupling between gravity- and pressure-mode cavities depends on several stellar properties, including mass, chemical composition, and evolutionary state. Using the structure of models computed with the stellar evolution code MESA we calculate the coupling coefficient implementing analytical expressions, which are appropriate for the strong coupling regime and the structure of the evanescent region in CHeB stars. Our analysis reveals a notable anti-correlation between the coupling coefficient and both the mass and metallicity of stars in the regime $M \\lesssim 1.8~\\mathrm{M}_\\odot$, in agreement with Kepler data. We attribute this correlation primarily to variations in the density contrast between the stellar envelope and core. The strongest coupling is expected thus for red-horizontal branch stars, partially stripped stars, and stars in the higher-mass range exhibiting solar-like oscillations ($M \\gtrsim 1.8~\\mathrm{M}_\\odot$). While our investigation emphasises some limitations of current analytical expressions, it also presents promising avenues. The frequency dependence of the coupling coefficient emerges as a potential tool for reconstructing the detailed stratification of the evanescent region.         _ Less","","arXiv","https://arxiv.org/abs/2410.02865","1","1","multiple"
"Chemo-dynamical abundance analysis of the very metal-poor halo star HE 2315-4240","Abstract:                Learning about the chemical evolution of the universe is crucial to understanding the formation of the first stars and structure formation in the early universe. To find out how elements are produced via nucleosynthesis and how their relative amounts have evolved with time, abundance trends of stars with different meta_         _ More           Learning about the chemical evolution of the universe is crucial to understanding the formation of the first stars and structure formation in the early universe. To find out how elements are produced via nucleosynthesis and how their relative amounts have evolved with time, abundance trends of stars with different metallicities can be established and compared. In this study, we present a spectrum of a very metal-poor star, HE 2315$-$4240, with [Fe/H] = $-$2.89 based on a Magellan/MIKE high-resolution visual light spectrum. The star has a radial velocity of +41.9 km s$^{-1}$, an effective temperature of 5181 K, a surface gravity of 2.24 dex, and a microturbulence of 1.61 km s$^{-1}$. The $_$-elements and the iron peak elements agree well with the abundance trend. The low abundance of [Sr/Ba] and [C/Fe] suggests that HE 2315$-$4240 is accreted and formed in a dwarf galaxy. The value of [Ba/Eu] suggests the operation of a limited r-process. The abundance pattern of [Mg/Fe] and [Si/Fe] in HE 2315$-$4240 and its metallicity indicated that the star is formed from the gas enriched by a Type II supernova of a massive Pop III star. The abundance pattern fits Population III supernova yields moderately. The star's kinematic behavior shows that the star has a retrograde orbit and is moving away from the galactic center and out of the galactic disk to the south, and although the star is located in the halo of the Milky Way, it didn't form in the Milky Way but was rather formed in a small dwarf galaxy that was later absorbed by the Milky Way.         _ Less","","arXiv","https://arxiv.org/abs/2410.02586","2","1","origin_of_life"
"Evolution of lithium in the disc of the Galaxy and the role of novae","Abstract:                Lithium plays a crucial role in probing stellar physics and stellar and primordial nucleosynthesis, as well as the chemical_         _ More           Lithium plays a crucial role in probing stellar physics and stellar and primordial nucleosynthesis, as well as the chemical evolution of our Galaxy. Stars are considered to be the main source of Li, still the identity of its primary stellar producer has long been a matter of debate. In light of recent theoretical and observational results, we investigate in this study the role of two candidate sources of Li enrichment in the Milky Way, namely AGB stars and, in particular, novae. We utilize a one-zone Galactic chemical evolution model to assess the viability of AGB stars and novae as stellar sources of Li. We use recent theoretical Li yields for AGB stars, while for novae we adopt observationally inferred Li yields and recently derived Delay Time Distributions (DTDs). Subsequently, we extend our analysis using a multi-zone model with radial migration to investigate spatial variations in the evolution of Li across the Milky Way disc and compare the results with observational data for field stars and open clusters. Our analysis shows that AGB stars fail by far to reproduce the meteoritic Li abundance. In contrast, novae appear as promising candidates within the adopted framework, allowing us to quantify the contribution of each Li source at Sun's formation and today. Our multi-zone model reveals the role of the differences in the DTDs of SN Ia and novae in shaping the evolution of Li in the various galactic zones. Its results are in fair agreement with the observational data for most open clusters, but small discrepancies appear in the outer disc.         _ Less","","arXiv","https://arxiv.org/abs/2410.01880","2","1","origin_of_life"
"Nanohertz gravitational waves and primordial quark nuggets from dense QCD matter in the early universe","Abstract:                _stochastic gravitational waves typically lying in the LISA range. High baryon density in the early universe can be generated through Affleck-Dine baryogenesis. The baryon chemical potential enhances the potential barrier and significantly reduces the transition rate, which decreases from infinity at the critical end point (CEP) to zero at the critical nuclea_         _ More           The first-order QCD phase transition at high temperature features a large transition rate in the magnitude of $_/H \\sim 10^4$ with induced stochastic gravitational waves typically lying in the LISA range. High baryon density in the early universe can be generated through Affleck-Dine baryogenesis. The baryon chemical potential enhances the potential barrier and significantly reduces the transition rate, which decreases from infinity at the critical end point (CEP) to zero at the critical nucleation point (CNP). Nanohertz gravitational waves can be produced in a narrow window of high baryon chemical potential with transition rate in the order of $_/H \\sim 10^1$. When the phase transition rate reaches zero, the false vacuum of high baryon density quark matter is unlikely to decay and can persist over cosmological time scales. Therefore the primordial quark nuggets (PQN) can form and survive in the early universe as the seeds of compact stars, thereby dramatically accelerating the evolution of compact stars and the formation of galaxies, which may explain the high red-shift massive galaxies observed by the James Webb Space Telescope.         _ Less","","arXiv","https://arxiv.org/abs/2410.00874","1","1","multiple"
"Chemical interaction and molecular growth of a highly dipolar merocyanine molecule on metal surfaces: A photoelectron spectroscopy study","Abstract:                _of substrate-molecule interaction on the subsequent film growth. Therefore, this study offers a detailed understanding of the interface formation and electronic structure evolution for merocyanine films on different metal surfaces.         _ More           The growth and ordering of molecules on surfaces is an intriguing research topic as insights gained here can be of significant relevance for organic electronic devices. While often simple, rigid molecules are employed as model systems, we show results for a highly dipolar merocyanine which is studied on top of Au(100), Ag(100) and Cu(100) metal single crystals. Film thicknesses ranging from submonolayer to multilayer regimes are analyzed using UV (UPS) and X ray photoelectron spectroscopy (XPS). For the monolayer regime, there is strong indication of face on orientation, with both of the molecules sulfur atoms bonding to the metal surfaces. Here, on Ag and Au(100) the sulfur atoms lose some or all of their intrinsic charges due to a charge transfer with the substrate, while on Cu(100) a strong metal sulfur bond forms. The interaction between the substrate and the molecules can also be seen in the intensity and width of the highest occupied molecular orbital features in UPS. Upon multilayer deposition, a gradual lowering in ionization energy is observed, likely due to the formation of antiparallel dimers followed by an increased charge carrier delocalization due to the formation of an extended molecular aggregate for thicker layers. Interestingly, on Cu(100) the aggregated phase is already observed for much lower deposition, showing the importance of substrate-molecule interaction on the subsequent film growth. Therefore, this study offers a detailed understanding of the interface formation and electronic structure evolution for merocyanine films on different metal surfaces.         _ Less","","arXiv","https://arxiv.org/abs/2410.00855","1","2","synthetic_biology"
"APOKASC-3: The Third Joint Spectroscopic and Asteroseismic catalog for Evolved Stars in the Kepler Fields","Abstract:                _additional stars which either have lower quality data or are outside of our primary calibration domain. Using lower red giant branch (RGB) stars, we find a median age for the chemical thick disk of $9.14 \\pm 0.05 ({\\rm ran}) \\pm 0.9 ({\\rm sys})$ Gyr with an age dispersion of 1.1 Gyr, consistent with our error model. We calibrate our red clump (RC) mass loss_         _ More           In the third APOKASC catalog, we present data for the complete sample of 15,808 evolved stars with APOGEE spectroscopic parameters and Kepler asteroseismology. We used ten independent asteroseismic analysis techniques and anchor our system on fundamental radii derived from Gaia $L$ and spectroscopic $T_{\\rm eff}$. We provide evolutionary state, asteroseismic surface gravity, mass, radius, age, and the spectroscopic and asteroseismic measurements used to derive them for 12,418 stars. This includes 10,036 exceptionally precise measurements, with median fractional uncertainties in \\nmax, \\dnu, mass, radius and age of 0.6\\%, 0.6\\%, 3.8\\%, 1.8\\%, and 11.1\\% respectively. We provide more limited data for 1,624 additional stars which either have lower quality data or are outside of our primary calibration domain. Using lower red giant branch (RGB) stars, we find a median age for the chemical thick disk of $9.14 \\pm 0.05 ({\\rm ran}) \\pm 0.9 ({\\rm sys})$ Gyr with an age dispersion of 1.1 Gyr, consistent with our error model. We calibrate our red clump (RC) mass loss to derive an age consistent with the lower RGB and provide asymptotic GB and RGB ages for luminous stars. We also find a sharp upper age boundary in the chemical thin disk. We find that scaling relations are precise and accurate on the lower RGB and RC, but they become more model dependent for more luminous giants and break down at the tip of the RGB. We recommend the usage of multiple methods, calibration to a fundamental scale, and the usage of stellar models to interpret frequency spacings.         _ Less","","arXiv","https://arxiv.org/abs/2410.00102","0","1","synthetic_biology"
"Spatially-resolved gas-phase metallicity in Seyfert galaxies","Abstract:                _Seyferts have undergone seamless gas accretion histories, resulting in positive metallicity profile over an extended period of time, thereby providing insights into galaxy evolution and the chemical enrichment or depletion of the universe. Additionally, we argue that metal-poor gas inflow from the local interstellar me_         _ More           We explore the relations between the gas-phase metallicity radial profiles (few hundred inner parsec) and multiple galaxy properties for 15 Seyfert galaxies from the AGNIFS (Active Galactic Nuclei Integral Field Spectroscopy) sample using optical Integral Field Unit (IFU) observations from Gemini Multi-Object Spectrographs (GMOS) and Multi Unit Spectroscopic Explorer (MUSE) processed archival data. The data were selected at $z \\lesssim 0.013$ within black hole mass range $\\left[6<\\log \\left(M_{\\rm BH}/{\\rm M_\\odot} \\right)<9\\right]$ with moderate 14--150\\,keV X-ray luminosities $\\left[42\\,\\lesssim\\,\\log L_X (\\rm erg\\,s^{-1})\\,\\lesssim\\,44\\right]$. We estimated the gas-phase metallicity using the strong-line methods and found mean values for the oxygen dependent ($Z \\sim 0.75Z_\\odot$) and nitrogen dependent ($Z \\sim 1.14Z_\\odot$) calibrations. These estimates show excellent agreement with $_Z \\approx 0.19$ dex and $_Z \\approx 0.18$ dex between the mean values from the two strong-line calibrations for GMOS and MUSE respectively, consistent with the order of metallicity uncertainty via the strong-line methods. We contend that our findings align with a scenario wherein local Seyferts have undergone seamless gas accretion histories, resulting in positive metallicity profile over an extended period of time, thereby providing insights into galaxy evolution and the chemical enrichment or depletion of the universe. Additionally, we argue that metal-poor gas inflow from the local interstellar medium (ISM) and accreted through the circumgalactic medium (CGM) onto the galaxy systems regulates the star formation processes by diluting their central metallicity and inverting their metallicity gradients, producing a more prominent anti-correlation between gas-phase metallicity and Eddington ratio.         _ Less","","arXiv","https://arxiv.org/abs/2409.20465","1","1","multiple"
"$K^*/K$ ratio and the time between freeze-outs for intermediate-mass Ar+Sc system at the SPS energy range","Abstract:                _resonance allows us to better understand the time evolution of high-energy nucleus-nucleus collision. Namely, the ratio of $K^*(892)^0$ to charged kaons is used to determine the time between chemical and kinetic freeze-outs.   In this article, the first results on the analysis of $K^*(892)^0$ production in central Ar+_         _ More           Resonance production is one of the key observables to study the dynamics of high-energy collisions. In dense systems created in heavy nucleus-nucleus collisions, the properties of some of them (widths, masses, branching ratios) were predicted to be modified due to partial restoration of chiral symmetry. The resonance spectra and yields are also important inputs for Blast-Wave and Hadron Resonance Gas models. Finally, the analysis of strange $K^*(892)^0$ resonance allows us to better understand the time evolution of high-energy nucleus-nucleus collision. Namely, the ratio of $K^*(892)^0$ to charged kaons is used to determine the time between chemical and kinetic freeze-outs.   In this article, the first results on the analysis of $K^*(892)^0$ production in central Ar+Sc collisions at three SPS energies ($\\sqrt{s_{\\mathrm{NN}}}$ = 8.8, 11.9, 16.8 GeV) are presented. The $K^*(892)^0/K^{+/-}$ yield ratios are compared with corresponding results in $p$+$p$ collisions, allowing us to estimate the time between chemical and thermal freeze-outs in Ar+Sc collisions. These first results for intermediate-mass nucleus-nucleus systems at the SPS energy range are compared with the results of heavier systems at a similar energy range.         _ Less","","arXiv","https://arxiv.org/abs/2409.20229","0","1","synthetic_biology"
"Extracting Dynamical Maps of Non-Markovian Open Quantum Systems","Abstract:                The most general description of quantum evolution up to a time $_$ is a completely positive tracing preserving map known as a dynamical map $\\hat_(_)$. Here we consider $\\hat_(_)$ arising from suddenly coupling a system to one or more thermal baths with a strength that is neither weak nor strong. Given no clear separation of characteristic system/bath time s_         _ More           The most general description of quantum evolution up to a time $_$ is a completely positive tracing preserving map known as a dynamical map $\\hat_(_)$. Here we consider $\\hat_(_)$ arising from suddenly coupling a system to one or more thermal baths with a strength that is neither weak nor strong. Given no clear separation of characteristic system/bath time scales $\\hat_(_)$ is generically expected to be non-Markovian, however we do assume the ensuing dynamics has a unique steady state implying the baths possess a finite memory time $__{\\rm m}$. By combining several techniques within a tensor network framework we directly and accurately extract $\\hat_(_)$ for a small number of interacting fermionic modes coupled to infinite non-interacting Fermi baths. We employ the Choi-Jamiolkowski isomorphism so that $\\hat_(_)$ can be fully reconstructed from a single pure state calculation of the unitary dynamics of the system, bath and their replica auxillary modes up to time $_$. From $\\hat_(_)$ we also compute the time local propagator $\\hat{\\mathcal{L}}(_)$. By examining the convergence with $_$ of the instantaneous fixed points of these objects we establish their respective memory times $_^__{\\rm m}$ and $_^{\\mathcal{L}}_{\\rm m}$. Beyond these times, the propagator $\\hat{\\mathcal{L}}(_)$ and dynamical map $\\hat_(_)$ accurately describe all the subsequent long-time relaxation dynamics up to stationarity. Our numerical examples of interacting spinless Fermi chains and the single impurity Anderson model demonstrate regimes where our approach can offer a significant speedup in determining the stationary state compared to directly simulating the long-time limit.         _ Less","","arXiv","https://arxiv.org/abs/2409.17051","0","1","synthetic_biology"
"Optimised neural network predictions of galaxy formation histories using semi-stochastic corrections","Abstract:                _by incorporating semi-stochastic corrections to account for short-timescale variability. Our paper addresses limitations in existing models that capture broad trends in galaxy evolution, but fail to reproduce the bursty nature of star formation and_         _ More           We present a novel methodology to improve neural network (NN) predictions of galaxy formation histories by incorporating semi-stochastic corrections to account for short-timescale variability. Our paper addresses limitations in existing models that capture broad trends in galaxy evolution, but fail to reproduce the bursty nature of star formation and chemical enrichment, resulting in inaccurate predictions of key observables such as stellar masses, optical spectra, and colour distributions. We introduce a simple technique to add stochastic components by utilizing the power spectra of galaxy formation histories. We justify our stochastic approach by studying the correlation between the phases of the halo mass assembly and star-formation histories in the IllustrisTNG simulation, and we find that they are correlated only on timescales longer than 6 Gyr, with a strong dependence on galaxy type. Building on NNs developed in Chittenden & Tojeiro (2023), trained on hydrodynamical simulations from the IllustrisTNG project, which predict time-resolved star formation and stellar metallicity histories for central and satellite galaxies based solely on the properties and evolution of their dark matter halos and environments, this approach successfully recovers realistic variability in galaxy properties at short timescales. It significantly improves the accuracy of predicted stellar masses, metallicities, spectra, and colour distributions and provides a powerful framework for generating large, realistic mock galaxy catalogs, while also enhancing our understanding of the complex interplay between galaxy evolution and dark matter halo assembly.         _ Less","","arXiv","https://arxiv.org/abs/2409.16548","1","1","multiple"
"Nonequilibrium chemical short-range order in metallic alloys","Abstract:                _to nonequilibrium processes during manufacturing, such as rapid solidification and thermomechanical processing. It has been suggested in the high-entropy alloy literature that chemical short-range order (SRO) could offer a ''new knob'' to tailor materials properties. While evidence of the effect of SRO on materials properties accumulates, the_         _ More           Metallic alloys are routinely subjected to nonequilibrium processes during manufacturing, such as rapid solidification and thermomechanical processing. It has been suggested in the high-entropy alloy literature that chemical short-range order (SRO) could offer a ''new knob'' to tailor materials properties. While evidence of the effect of SRO on materials properties accumulates, the state of SRO evolution during alloy manufacturing remains obscure. Here, we employ high-fidelity atomistic simulations to track SRO evolution during the solidification and thermomechanical processing of alloys. Our investigation reveals that alloy processing can lead to nonequilibrium steady-states of SRO that are different from any equilibrium state. The mechanism behind nonequilibrium SRO formation is shown to be an inherent ordering bias present in nonequilibrium events. These results demonstrate that conventional manufacturing processes provide pathways for tuning SRO that lead to a broad nonequilibrium spectrum of SRO states beyond the equilibrium design space of alloys.         _ Less","","arXiv","https://arxiv.org/abs/2409.15474","1","1","multiple"
"Smallest [5,6]fullerene as building blocks for 2D networks with superior stability and enhanced photocatalytic performance","Abstract:                The assembly of molecules to form covalent networks can create varied lattice structures with distinct physical and chemical properties from conventional atomic lattices. Using the smallest stable [5,6]fullerene units as building blocks, various 2D C$_{24}$ networks can be formed with superior stability and strength compared to the recently synthesised monol_         _ More           The assembly of molecules to form covalent networks can create varied lattice structures with distinct physical and chemical properties from conventional atomic lattices. Using the smallest stable [5,6]fullerene units as building blocks, various 2D C$_{24}$ networks can be formed with superior stability and strength compared to the recently synthesised monolayer polymeric C$_{60}$. Monolayer C$_{24}$ harnesses the properties of both carbon crystals and fullerene molecules, such as stable chemical bonds, suitable band gaps and large surface area, facilitating photocatalytic water splitting. The electronic band gaps of C$_{24}$ are comparable to TiO$_2$, providing appropriate band edges with sufficient external potential for overall water splitting over the acidic and neutral pH range. Upon photoexcitation, strong solar absorption enabled by strongly bound bright excitons can generate carriers effectively, while the type-II band alignment between C$_{24}$ and other 2D monolayers can separate electrons and holes in individual layers simultaneously. Additionally, the number of surface active sites of C$_{24}$ monolayers are three times more than that of their C$_{60}$ counterparts in a much wider pH range, providing spontaneous reaction pathways for hydrogen evolution reaction. Our work provides insights into materials design using tunable building blocks of fullerene units with tailored functions for energy generation, conversion and storage.         _ Less","","arXiv","https://arxiv.org/abs/2409.15421","0","1","synthetic_biology"
"Learning to Simulate Aerosol Dynamics with Graph Neural Networks","Abstract:                _(GNS), a machine learning framework that has been used to simulate particle-based fluid dynamics models. In GLAD, each particle is represented as a node in a graph, and the evolution of the particle population over time is simulated through learned message passing. We demonstrate our GNS approach on a simple aerosol system that includes condensation of sulfu_         _ More           Aerosol effects on climate, weather, and air quality depend on characteristics of individual particles, which are tremendously diverse and change in time. Particle-resolved models are the only models able to capture this diversity in particle physiochemical properties, and these models are computationally expensive. As a strategy for accelerating particle-resolved microphysics models, we introduce Graph-based Learning of Aerosol Dynamics (GLAD) and use this model to train a surrogate of the particle-resolved model PartMC-MOSAIC. GLAD implements a Graph Network-based Simulator (GNS), a machine learning framework that has been used to simulate particle-based fluid dynamics models. In GLAD, each particle is represented as a node in a graph, and the evolution of the particle population over time is simulated through learned message passing. We demonstrate our GNS approach on a simple aerosol system that includes condensation of sulfuric acid onto particles composed of sulfate, black carbon, organic carbon, and water. A graph with particles as nodes is constructed, and a graph neural network (GNN) is then trained using the model output from PartMC-MOSAIC. The trained GNN can then be used for simulating and predicting aerosol dynamics over time. Results demonstrate the framework's ability to accurately learn chemical dynamics and generalize across different scenarios, achieving efficient training and prediction times. We evaluate the performance across three scenarios, highlighting the framework's robustness and adaptability in modeling aerosol microphysics and chemistry.         _ Less","","arXiv","https://arxiv.org/abs/2409.13861","0","1","synthetic_biology"
"oMEGACat IV: Constraining Ages of Omega Centauri sub-giant branch stars with HST and MUSE","Abstract:                _the most critical consideration for constraining the AMR. We also present the SGB chromosome map with age information. In the future, these stellar ages could be combined with chemical abundances to study age differences in subpopulations, and uncover the chemical evolution histo_         _ More           We present age estimates for over 8100 sub-giant branch (SGB) stars in Omega Centauri ($_$ Cen) to study its star formation history. Our large data set, which combines multi-wavelength HST photometry with MUSE metallicities, provides an unprecedented opportunity to measure individual stellar ages. We do this by fitting each star's photometry and metallicity with theoretical isochrones, that are embedded with an empirical [C+N+O]-[Fe/H] relation specifically for $_$ Cen. The bulk of the stars have ages between 13 and 10 Gyr, with the mean stellar age being 12.08$\\pm$0.01 Gyrs and the median age uncertainty being 0.68 Gyrs. From these ages we construct the most complete age-metallicity relation (AMR) for $_$ Cen to date. We find that the mean age of stars decreases with increasing metallicity and find two distinct streams in the age-metallicity plane, hinting at different star formation pathways. We derive an intrinsic spread in the ages of 0.75$\\pm$0.01 Gyr for the whole cluster, with the age spread showing a clear increase with metallicity. We verify the robustness of our age estimations by varying isochrone parameters and constraining our systematics. We find the C+N+O relation to be the most critical consideration for constraining the AMR. We also present the SGB chromosome map with age information. In the future, these stellar ages could be combined with chemical abundances to study age differences in subpopulations, and uncover the chemical evolution history of this massive nuclear star cluster.         _ Less","","arXiv","https://arxiv.org/abs/2409.13855","2","1","origin_of_life"
"Impacting Atmospheres: How Late-Stage Pollution Alters Exoplanet Composition","Abstract:                Atmospheric composition of exoplanets is often considered as a probe of the planet's formation condition. How exactly the initial chemical memory may be altered from the birth to the final state of the planet, however, remains unknown. Here, we develop a simple model of pollution of planetary atmosphere by the vaporization of infalling planetesimal of va_         _ More           Atmospheric composition of exoplanets is often considered as a probe of the planet's formation condition. How exactly the initial chemical memory may be altered from the birth to the final state of the planet, however, remains unknown. Here, we develop a simple model of pollution of planetary atmosphere by the vaporization of infalling planetesimal of varying sizes and composition (SiO$_2$ inside 1 au and H$_2$O outside 1 au), following their trajectory and thermal evolution through the upper advective and radiative layers of a sub-Neptune class planet during the late stage of disk evolution. We vary the rate of pollution by changing the solid content of the disk and by dialing the level of disk gas depletion which in turn determines the rate of planetary migration. We find that pollution by silicate grains will always be limited by the saturation limit set by the thermal state of the atmosphere. By contrast, pollution by water ice can lead to $\\sim$2--4 orders of magnitude variation in the atmospheric water mass fraction depending on the solid and gas content of the disk. Both cases suggest that post-formation pollution can erase the initial compositional memory of formation. Post-formation pollution can potentially transform sub-Neptunes with H/He-dominated envelope that initially formed beyond the iceline to waterworlds (water-enriched envelope) when the disk gas is depleted by $\\gtrsim$2 orders of magnitude, allowing gentle migration. We additionally discuss the expected C/O ratio profile under pollution by water and refractory carbon species.         _ Less","","arXiv","https://arxiv.org/abs/2409.13820","1","1","multiple"
"Loki: an ancient system hidden in the Galactic plane?","Abstract:                _). Their chemical abundances are consistent with those observed in the Galactic halo but show a smaller spread, with no notable difference between progrades and retrogrades. This suggests a common_         _ More           We analyse high-resolution ESPaDOnS/CFHT spectra of 20 very metal-poor stars ([Fe/H]~$<-2.0$) in the solar neighbourhood (within $\\sim2$ kpc) selected to be on planar orbits (with a maximum height of $\\lesssim4$ kpc). Targets include 11 prograde and 9 retrograde stars, spanning a wide range of eccentricities ($0.20-0.95$). Their chemical abundances are consistent with those observed in the Galactic halo but show a smaller spread, with no notable difference between progrades and retrogrades. This suggests a common chemical evolution and likely a shared formation site (except for one star). In this case, chemical evolution models indicate that the formation site would have had a baryonic mass of $\\sim1.4\\times10^9\\msun$, similar to classical dwarf galaxies. High-energy supernovae and hypernovae are needed to reproduce the [X/Fe] up to the Fe-peak, while fast-rotating massive stars and neutron star merger events explain the [X/Fe] of the neutron-capture elements. The absence of Type Ia supernova signatures suggests a star formation duration of $\\lesssim1$~Gyr. Cosmological zoom-in simulations support the scenario that an in-plane infall of a single system could disperse stars over a wide range of angular momenta during the early Galactic assembly. We propose that these stars originated in a proto-Galactic building block, which we name Loki. Less likely, if progrades and retrogrades formed in two different systems, their chemical evolution must have been very similar, with a combined baryonic mass twice that of a single system. Forthcoming surveys will provide a large and homogeneous dataset to investigate whether Loki is associated with any of the known detected structures. A comparison (primarily [$_$/Fe]) with other VMPs moving in planar orbits suggests multiple systems contributed to the Galactic planar population, presenting some differences in their kinematical parameters.         _ Less","","arXiv","https://arxiv.org/abs/2409.13813","3","2","origin_of_life"
"Optimizing a parameterized controlled gate with Free Quaternion Selection","Abstract:                _the Variational Quantum Eigensolver (VQE) for Ising and molecular Hamiltonians, Variational Quantum Algorithms (VQA) for fidelity maximization, and unitary compilation of time evolution operators. In these applications, the proposed method shows efficient optimization and greater expressibility with shallower circuits than other methods. Furthermore, this me_         _ More           In variational algorithms, quantum circuits are conventionally parametrized with respect to single-qubit gates. In this study, we parameterize a generalized controlled gate and propose an algorithm to estimate the optimal parameters for locally minimizing the cost value, where we extend the free quaternion selection method, an optimization method for a single-qubit gate. To benchmark the performance, we apply the proposed method to various optimization problems, including the Variational Quantum Eigensolver (VQE) for Ising and molecular Hamiltonians, Variational Quantum Algorithms (VQA) for fidelity maximization, and unitary compilation of time evolution operators. In these applications, the proposed method shows efficient optimization and greater expressibility with shallower circuits than other methods. Furthermore, this method is also capable of generalizing and fully optimizing particle-number-conserving gates, which are in demand in chemical systems applications. Taking advantage of this property, we have actually approximated time evolution operators of molecular Hamiltonian and simulated the dynamics with shallower circuits in comparison to the standard implementation by Trotter decomposition.         _ Less","","arXiv","https://arxiv.org/abs/2409.13547","0","1","synthetic_biology"
"Sulfur on Venus: Atmospheric, Surface, and Interior Processes","Abstract:                Sulfur-bearing species play critical roles in atmospheric physical-chemical processes, atmosphere-surface interactions, and the geological_         _ More           Sulfur-bearing species play critical roles in atmospheric physical-chemical processes, atmosphere-surface interactions, and the geological evolution of Venus. This chapter provides a comprehensive overview of (1) Instrumental data on the abundance and speciation of sulfur in atmospheric and crustal materials, (2) the behavior of sulfur-bearing species in the mesosphere, clouds, and lower atmosphere, (3) chemical and mineralogical aspects of atmosphere-surface interactions, (4) the fate of sulfur during the formation, differentiation, and geological evolution of Venus, including volcanic degassing, gas-solid reactions at the surface, a putative aqueous period, and subsequent evolution. The chapter also outlines outstanding questions and discusses further exploration of Venus in the context of sulfur-relevant investigations.         _ Less","","arXiv","https://arxiv.org/abs/2409.13256","3","3","multiple"
"Confirmation of interstellar phosphine towards asymptotic giant branch star IRC+10216","Abstract:                Phosphorus (P) is an important element for the chemical evolution of galaxies and many kinds of biochemical reactions. Phosphorus is one of the crucial chemical compounds in the formation of life on our planet. In an interstellar medium, phosphine (PH$_{3}$) is a crucial biomolec_         _ More           Phosphorus (P) is an important element for the chemical evolution of galaxies and many kinds of biochemical reactions. Phosphorus is one of the crucial chemical compounds in the formation of life on our planet. In an interstellar medium, phosphine (PH$_{3}$) is a crucial biomolecule that plays a major role in understanding the chemistry of phosphorus-bearing molecules, particularly phosphorus nitride (PN) and phosphorus monoxide (PO), in the gas phase or interstellar grains. We present the first confirmed detection of phosphine (PH$_{3}$) in the asymptotic giant branch (AGB) carbon-rich star IRC+10216 using the Atacama Large Millimeter/Submillimeter Array (ALMA) band 6. We detect the $J$ = 1$_{0}$$-$0$_{0}$ rotational transition line of PH$_{3}$ with a signal-to-noise ratio (SNR) of $\\geq$3.5$_$. This is the first confirmed detection of phosphine (PH$_{3}$) in the ISM. Based on LTE spectral modelling, the column density of PH$_{3}$ is (3.15$\\pm$0.20)$\\times$10$^{15}$ cm$^{-2}$ at an excitation temperature of 52$\\pm$5 K. The fractional abundance of PH$_{3}$ with respect to H$_{2}$ is (8.29$\\pm$1.37)$\\times$10$^{-8}$. We also discuss the possible formation pathways of PH$_{3}$ and we claim that PH$_{3}$ may be created via the hydrogenation of PH$_{2}$ on the grain surface of IRC+10216.         _ Less","","arXiv","https://arxiv.org/abs/2409.12907","2","1","origin_of_life"
"Enhanced Krylov Methods for Molecular Hamiltonians: Reduced Memory Cost and Complexity Scaling via Tensor Hypercontraction","Abstract:                _lowers the memory requirement and cost scaling of Krylov subspace methods. These can find low-lying eigenstates while avoiding local minima and simulate quantum time evolution with high accuracy. In our approach, the molecular Hamiltonian is represented as a sum of products of four MPOs, each with a bond dimension of only $2$. Iteratively applying the MPOs t_         _ More           We present a matrix product operator (MPO) construction based on the tensor hypercontraction (THC) format for ab initio molecular Hamiltonians. Such an MPO construction dramatically lowers the memory requirement and cost scaling of Krylov subspace methods. These can find low-lying eigenstates while avoiding local minima and simulate quantum time evolution with high accuracy. In our approach, the molecular Hamiltonian is represented as a sum of products of four MPOs, each with a bond dimension of only $2$. Iteratively applying the MPOs to the current quantum state in matrix product state (MPS) form, summing and re-compressing the MPS leads to a scheme with the same asymptotic memory cost as the bare MPS and reduces the computational cost scaling compared to the Krylov method based on a conventional MPO construction. We provide a detailed theoretical derivation of these statements and conduct supporting numerical experiments.         _ Less","","arXiv","https://arxiv.org/abs/2409.12708","0","1","synthetic_biology"
"Revisiting the Formaldehyde Masers II: Effects of an HII region and Beaming","Abstract:                _by a free-free radiation field. It is argued that the rarity of the Formaldehyde masers is not to be ascribed to the pumping scheme but to other factors such as, e.g., the evolution of the associated HII region or the chemical evolution of the star forming region which determines_         _ More           We present new results of a numerical study of the pumping of 4.8 GHz and 14.5 GHz maser of o-Formaldehyde in the presence of a free-free radiation field. It is shown that in the presence of a free-free radiation field inversion of not only the 4.8 GHz transition, but also the 14.5 GHz transition and other doublet state transitions occur. Further results are presented to illustrate how, as a consequence of the pumping scheme, the inversion of the 4.8 GHz and 14.5 GHz transitions respond to the free-free radiation fields associated with HII regions with different emission measures and levels of geometric dilution with respect to the masing region. We also discuss the criticism raised in the past by various authors against the pumping of the 4.8 GHz Formaldehyde masers by a free-free radiation field. It is argued that the rarity of the Formaldehyde masers is not to be ascribed to the pumping scheme but to other factors such as, e.g., the evolution of the associated HII region or the chemical evolution of the star forming region which determines the Formaldehyde abundance or a combination of both.         _ Less","","arXiv","https://arxiv.org/abs/2409.12637","1","1","multiple"
"Chemical evolution of a young super star cluster at the Sunburst Arc","Abstract:                _) and brightest of these as a strongly lensed object. In this work, we study the chemical history of this star cluster to determine the origin of the elevated gas-phase nitrogen using a chemical evolution model. Our model includes the enrichment of OB stars through stellar winds_         _ More           Recent observations of high-redshift galaxies have revealed starburst galaxies with excessive amounts of nitrogen, well above that expected in standard evolutionary models. The Sunburst Arc galaxy, particularly its young and massive star cluster, represents the closest ($z=2.4$) and brightest of these as a strongly lensed object. In this work, we study the chemical history of this star cluster to determine the origin of the elevated gas-phase nitrogen using a chemical evolution model. Our model includes the enrichment of OB stars through stellar winds and core-collapse supernovae assuming that massive stars ($M>25$ $M_\\odot$) collapse directly into black holes at the end of their lives. We fit the model parameters to the observed chemical abundances of the Sunburst Arc cluster: O/H, C/O, and N/O. We find that the observed chemical abundances can be explained by models featuring intense star formation events, characterized by rapid gas accretion and high star formation efficiencies. Additionally, the stellar population contributing to the gas enrichment must exclude Wolf-Rayet stars. These conditions might be present in other nitrogen-rich objects as their similar chemical abundances suggest a common history. As previous studies have proposed the presence of Wolf-Rayet stars in the new nitrogen-rich objects, further research using chemodynamic modeling is necessary to ascertain the true nature of these objects.         _ Less","","arXiv","https://arxiv.org/abs/2409.12605","2","1","origin_of_life"
"Narrowing band gap chemically and physically: Conductive dense hydrocarbon","Abstract:                _to metalize various small PAHs, but so far only pressure-induced amorphization well below the megabar region was observed. The wide band gap energy of the small PAHs and low chemical stability under simple compression are the bottlenecks. We have investigated the band gap energy_         _ More           Band gap energy of an organic molecule can be reduced by intermolecular interaction enhancement, and thus, certain polycyclic aromatic hydrocarbons (PAHs), which are insulators with wide band gaps, are expected to undergo insulator-metal transitions by simple compression. Such a pressure-induced electronic transition can be exploited to transform non-metallic organic materials into states featuring intriguing electronic characteristics such as high-temperature superconductivity. Numerous attempts have been made to metalize various small PAHs, but so far only pressure-induced amorphization well below the megabar region was observed. The wide band gap energy of the small PAHs and low chemical stability under simple compression are the bottlenecks. We have investigated the band gap energy evolution and the crystal structural compression of the large PAH molecules, where the band gap energy is significantly reduced by increasing the number of _-electrons and improved chemical stability with fully benzenoid molecular structure. Herein, we present a pressure-induced transition in dicoronylene, C48H20, an insulator at ambient conditions that transforms into a semi-metallic state above 23.0 GPa with a three-order-of-magnitude reduction in resistivity. In-situ UV-visible absorption, transport property measurement, Raman spectroscopy, X-ray diffraction and density functional theory calculations were performed to provide tentative explanations to the alterations in its electronic structure at high pressure. The discovery of an electronic transition at pressures well below the megabar is a promising step towards realization of a single component purely hydrocarbon molecular metal in the near future.         _ Less","","arXiv","https://arxiv.org/abs/2409.12424","0","1","synthetic_biology"
"Mixing processes in stars","Abstract:                Stars play a key role in the evolution of the Universe, as sources of radiation, as dynamical engines, and as chemical factories. Outputs of stellar models are then central to various studies in astrophysics. Stellar physics links fundamental physical aspects to hydrodynamic and magnetohydrodynamic processes, and the v_         _ More           Stars play a key role in the evolution of the Universe, as sources of radiation, as dynamical engines, and as chemical factories. Outputs of stellar models are then central to various studies in astrophysics. Stellar physics links fundamental physical aspects to hydrodynamic and magnetohydrodynamic processes, and the validity of stellar models depends directly on the modelling of these complex mechanisms. We describe here the different transport processes at work in stellar interiors and how the modelling of these processes can be improved thanks to the unique ability of asteroseismology, the study of stellar oscillations, to probe the internal structure and dynamics of stars.         _ Less","","arXiv","https://arxiv.org/abs/2409.11354","0","1","synthetic_biology"
"Research evolution of metal organic frameworks: A scientometric approach with human-in-the-loop","Abstract:                This paper reports on a scientometric analysis bolstered by human in the loop, domain experts, to examine the field of metal organic frameworks (MOFs) research. Scientometric analyses reveal the intellectual landscape of a field. The study engaged MOF scientists in the design and review of our research workflow. MOF materials are an essential component in next generation renewable energy storage a_         _ More           This paper reports on a scientometric analysis bolstered by human in the loop, domain experts, to examine the field of metal organic frameworks (MOFs) research. Scientometric analyses reveal the intellectual landscape of a field. The study engaged MOF scientists in the design and review of our research workflow. MOF materials are an essential component in next generation renewable energy storage and biomedical technologies. The research approach demonstrates how engaging experts, via human in the loop processes, can help develop a comprehensive view of a field research trends, influential works, and specialized topics.         _ Less","","arXiv","https://arxiv.org/abs/2409.10776","2","3","synthetic_biology"
"On the existence of solutions for a parabolic-elliptic chemotaxis model with flux limitation and logistic source","Abstract:                _and a chemical stimulus $v$ in a bounded and regular domain $_$ of $\\mathbb{R}^N$. The equation for $u$ is a parabolic equation with a nonlinear second order term of chemotaxis type with flux limitation as $ -_div (u |\\nabla _|^{p-2} \\nabla v)$, for $p>1$. The chemical substance distribution $v$ satisfies the ellip_         _ More           In this paper we study the existence of solutions of a parabolic-elliptic system of partial differential equations describing the behaviour of a biological species $u$ and a chemical stimulus $v$ in a bounded and regular domain $_$ of $\\mathbb{R}^N$. The equation for $u$ is a parabolic equation with a nonlinear second order term of chemotaxis type with flux limitation as $ -_div (u |\\nabla _|^{p-2} \\nabla v)$, for $p>1$. The chemical substance distribution $v$ satisfies the elliptic equation $-_v+v=u$. The evolution of $u$ is also determined by a logistic type growth term $_u(1-u)$. The system is studied under homogeneous Neumann boundary conditions. The main result of the article is the existence of uniformly bounded solutions for $p<3/2$ and any $N\\ge 2$.         _ Less","","arXiv","https://arxiv.org/abs/2409.10121","0","2","synthetic_biology"
"First map of D$_2$H$^+$ emission revealing the true centre of a prestellar core: further insights into deuterium chemistry","Abstract:                _can be used to estimate the stage of the chemical evolution of the core.Results. We have obtained the first complete map of para-D$_2$H$^+$ emission in a prestellar core. We compare it to a map of ortho-H$_2$D$^+$ and show their partial anti-correlation. This reveals a strongly evolved core with a para-D$_2$H$^+$/orth_         _ More           Context. IRAS 16293E is a rare case of a prestellar core being subjected to the effects of at least one outflow.Aims. We want to disentangle the actual structure of the core from the outflow impact and evaluate the evolutionary stage of the core. Methods. Prestellar cores being cold and depleted, the best tracers of their central regions are the two isotopologues of trihydrogren cation which are observable from the ground, ortho-H$_2$D and para-D$_2$H . We used the Atacama Pathfinder EXperiment (APEX) telescope to map the para-D$_2$H$^+$ emission in IRAS 16293E and collected James Clerk Maxwell Telescope (JCMT) archival data of ortho-H$_2$D$^+$ . We compare their emission to that of other tracers, including dust emission, and analyse their abundance with the help of a 1D radiative transfer tool. The ratio of the abundances of ortho-H$_2$D$^+$ and para-D$_2$H$^+$ can be used to estimate the stage of the chemical evolution of the core.Results. We have obtained the first complete map of para-D$_2$H$^+$ emission in a prestellar core. We compare it to a map of ortho-H$_2$D$^+$ and show their partial anti-correlation. This reveals a strongly evolved core with a para-D$_2$H$^+$/ortho-H$_2$D$^+$ abundance ratio towards the centre for which we obtain a conservative lower limit from 3.9 (at 12 K) up to 8.3 (at 8 K) while the high extinction of the core is indicative of a central temperature below 10 K. This ratio is higher than predicted by the known chemical models found in the literature. Para-D$_2$H$^+$ (and indirectly ortho-H$_2$D$^+$) is the only species that reveals the true centre of this core, while the emission of other molecular tracers and dust are biased by the temperature structure that results from the impact of the outflow.Conclusions. This study invites to reconsider the analysis of previous observations of this source and possibly questions the validity of the deuteration chemical models or of the reaction and inelastic collisional rate coefficients of the H$^{+3}$ isotopologue family. This could impact the deuteration clock predictions for all sources.         _ Less","","arXiv","https://arxiv.org/abs/2409.10093","1","1","multiple"
"Hydrostatic and chemical pressure driven crossover from commensurate to the incommensurate state of the Weyl semimetal Mn$_{3+x}$Sn$_{1-x}$","Abstract:                _real space magnetic ordering and the momentum space band structure. Previous studies show that changes in the magnetic structure induced by the application of hydrostatic and chemical pressure can significantly affect the AHC of Mn$_{3+x}$Sn$_{1-x}$ system. Here, we employ the muon spin relaxation/rotation ($_^+$SR) technique to systematically investigate th_         _ More           The observation of large intrinsic anomalous Hall conductivity (AHC) in the non-collinear antiferromagnetic (AFM) phase of the Weyl semimetal Mn$_3$Sn generates enormous interest in uncovering the entanglement between the real space magnetic ordering and the momentum space band structure. Previous studies show that changes in the magnetic structure induced by the application of hydrostatic and chemical pressure can significantly affect the AHC of Mn$_{3+x}$Sn$_{1-x}$ system. Here, we employ the muon spin relaxation/rotation ($_^+$SR) technique to systematically investigate the evolution of different magnetic states in the Mn$_{3+x}$Sn$_{1-x}$ as a function of hydrostatic and chemical pressure. We find two muon sites experimentally, which is also supported by our \\textit{ab initio} calculations. Our $_^+$SR experiments affirm that the $x = 0.05$ compound exhibits a commensurate magnetic state throughout the magnetically ordered phase below the Neel temperature $T_N \\approx 420$~K in ambient pressure. In contrast, we observe an incommensurate magnetic state below $T_{IC} \\sim 175$~K when a hydrostatic pressure of 1.5~GPa is applied. A similar transition from the commensurate to incommensurate state is also found with chemical pressure for $x = 0.04$ and $x = 0.03$, using $_^+$SR and elastic neutron scattering experiments. Using band structure calculations, we have shown the emergence of Fermi nesting in Mn$_3$Sn and the subsequent development of incommensurate magnetic ordering under hydrostatic/chemical pressure.         _ Less","","arXiv","https://arxiv.org/abs/2409.10012","1","1","multiple"
"Exploring Dimensionality Reduction of SDSS Spectral Abundances","Abstract:                High-resolution stellar spectra offer valuable insights into atmospheric parameters and chemical compositions. However, their inherent complexity and high-dimensionality present challenges in fully utilizing the information they contain. In this study, we utilize data from the Apache Point Observatory Galactic_         _ More           High-resolution stellar spectra offer valuable insights into atmospheric parameters and chemical compositions. However, their inherent complexity and high-dimensionality present challenges in fully utilizing the information they contain. In this study, we utilize data from the Apache Point Observatory Galactic Evolution Experiment (APOGEE) within the Sloan Digital Sky Survey IV (SDSS-IV) to explore latent representations of chemical abundances by applying five dimensionality reduction techniques: PCA, t-SNE, UMAP, Autoencoder, and VAE. Through this exploration, we evaluate the preservation of information and compare reconstructed outputs with the original 19 chemical abundance data. Our findings reveal a performance ranking of PCA < UMAP < t-SNE < VAE < Autoencoder, through comparing their explained variance under optimized MSE. The performance of non-linear (Autoencoder and VAE) algorithms has approximately 10\\% improvement compared to linear (PCA) algorithm. This difference can be referred to as the 'non-linearity gap.' Future work should focus on incorporating measurement errors into extension VAEs, thereby enhancing the reliability and interpretability of chemical abundance exploration in astronomical spectra.         _ Less","","arXiv","https://arxiv.org/abs/2409.09227","2","2","multiple"
"Constraining the Initial-Mass Function via Stellar Transients","Abstract:                _and cosmology, describing the mass distribution of stars from low to very-high masses. It is intimately linked to a wide variety of topics, including stellar and binary evolution, galaxy evolution, chemical enrichment, and cosmological reionization. Nonetheless, the IMF still rem_         _ More           The stellar initial-mass function (IMF) represents a fundamental quantity in astrophysics and cosmology, describing the mass distribution of stars from low to very-high masses. It is intimately linked to a wide variety of topics, including stellar and binary evolution, galaxy evolution, chemical enrichment, and cosmological reionization. Nonetheless, the IMF still remains highly uncertain. In this work, we aim at determining the IMF with a novel approach based on the observed rates of transients of stellar origin. We parametrize the IMF with a simple, but flexible, Larson shape, and insert it into a parametric model for the cosmic UV luminosity density, local stellar mass density, type Ia supernova (SN Ia), core-collapse supernova (CCSN), and long gamma-ray burst (LGRB) rates as function of redshift. We constrain our free parameters by matching the model predictions to a set of empirical determinations for the corresponding quantities, via a Bayesian Markov-Chain Monte Carlo method. Remarkably, we are able to provide an independent IMF determination, with characteristic mass $m_c=0.10^{+0.24}_{-0.08}\\:M_{\\odot}$, and high-mass slope $_=-2.53^{+0.24}_{-0.27}$, that is in accordance with the widely-used IMF parameterizations (e.g. Salpeter, Kroupa, Chabrier). Moreover, the adoption of an up-to-date recipe for the cosmic metallicity evolution, allows us to constrain the maximum metallicity of LGRB progenitors to $Z_{max}=0.12^{+0.29}_{-0.05}\\:Z_{\\odot}$. We also find what progenitor fraction actually leads to SN Ia or LGRB emission, put constraints on the CCSN and LGRB progenitor mass ranges, and test the IMF universality. These results show the potential of this kind of approach for studying the IMF, its putative evolution with galactic environment and cosmic history, and the properties of SN Ia, CCSN and LGRB progenitors, especially considering the wealth of data incoming in the future.         _ Less","","arXiv","https://arxiv.org/abs/2409.09118","0","1","synthetic_biology"
"Hot Leptogenesis","Abstract:                _is the temperature of the Standard Model sector. We study the reheating processes which realise this 'hot leptogenesis' and the conditions under which kinetic and chemical equilibrium can be maintained. We derive and solve two sets of_         _ More           We investigate a class of leptogenesis scenarios in which the sector containing the lightest right-handed neutrino establishes kinetic equilibrium at a temperature $T_{N_1} > T_\\text{SM}$, where $T_\\text{SM}$ is the temperature of the Standard Model sector. We study the reheating processes which realise this 'hot leptogenesis' and the conditions under which kinetic and chemical equilibrium can be maintained. We derive and solve two sets of evolution equations, depending on the presence of chemical equilibrium within the hot sector, and numerically solve these for benchmark scenarios. We compare the viable parameter space of this model with standard leptogenesis scenarios with a thermal initial condition and find that hot leptogenesis resolves the neutrino and Higgs mass fine-tuning problems present in the standard scenario.         _ Less","","arXiv","https://arxiv.org/abs/2409.09113","0","1","synthetic_biology"
"High-Temperature Non-Equilibrium Atom-Diatom Collisional Energy Transfer","Abstract:                The change of the vibrational energy within a molecule after collisions with another molecule plays an essential role in the evolution of molecular internal energy distributions, which is also the limiting process in the relaxation of the gas towards equilibrium. Here we investigate the energy transfer between the translational motion and the vibrational mot_         _ More           The change of the vibrational energy within a molecule after collisions with another molecule plays an essential role in the evolution of molecular internal energy distributions, which is also the limiting process in the relaxation of the gas towards equilibrium. Here we investigate the energy transfer between the translational motion and the vibrational motion of the diatom during the atom-diatom collision, the simplest case involving the transfer between inter-molecular and intra-molecular energies. We are interested in the situation when the translational temperature of the gas is high, in which case there are significant probabilities for the vibrational energy to change over widely separated energy levels after a collision. Data from quasi-classical trajectory simulations of the N+N$_2$ system with \\textit{ab initio} potential energies suggest that the transition probability dependence on the collisional energy possesses an ``activation-saturation'' behavior and can be described by a simple model. The model allows for explicit evaluation of the vibrational state-to-state transition rate coefficients, from which the evolution of the vibrational energy distribution from any initial conditions can be solved by the master equation approach. An example of the vibrational energy relaxation in the N+N$_2$ system mimicking the gas behind strong shocks in a hypersonic flow is shown and the results are in good agreement with available data.         _ Less","","arXiv","https://arxiv.org/abs/2409.08955","0","2","synthetic_biology"
"Is there a genetic relationship between chondrules and matrix?","Abstract:                Chondritic components such as chondrules and matrix are the key time capsules that can help us understand the evolution and dynamics of the protoplanetary disk from which the Solar System originated. Knowledge of where and how these components formed and to what extent they were transported in the gaseous disk provides major constraints to astrophysical mode_         _ More           Chondritic components such as chondrules and matrix are the key time capsules that can help us understand the evolution and dynamics of the protoplanetary disk from which the Solar System originated. Knowledge of where and how these components formed and to what extent they were transported in the gaseous disk provides major constraints to astrophysical models that investigate planet formation. Here, we explore whether chondrules and matrix are genetically related to each other and formed from single reservoirs per chondrite group or if every chondrite represents a unique proportion of components transported from a small number of formation reservoirs in the disk. These static versus dynamic disk interpretations of cosmochemical data have profound implications for the accretion history of the planets in the Solar System. To fully understand the relationship between chondrules and matrix and their potential complementarity, we dive into the petrological nature and origin of matrix, the chemical and isotopic compositions of chondrules and matrix and evaluate these data considering the effect of secondary alteration observed in chondrites and the potential complexity of chondrule formation. Even though we, the authors, have used different datasets and arrived at differing interpretations of chondrule-matrix relationships in the past, this review provides clarity on the existing data and has given us new directions towards future research that can resolve the complementarity debate.         _ Less","","arXiv","https://arxiv.org/abs/2409.08662","2","2","multiple"
"JWST ice band profiles reveal mixed ice compositions in the HH 48 NE disk","Abstract:                _both H2O and CO2 ice. The HH 48 NE disk ice composition (pure vs. polar vs. apolar fractions) is markedly different from earlier protostellar stages, implying thermal and/or chemical reprocessing during the formation or evolution of the disk. We infer low ice-phase C/O ratios around 0.1 throughout the disk, and also de_         _ More           Planet formation is strongly influenced by the composition and distribution of volatiles within protoplanetary disks. With JWST, it is now possible to obtain direct observational constraints on disk ices, as recently demonstrated by the detection of ice absorption features towards the edge-on HH 48 NE disk as part of the Ice Age Early Release Science program. Here, we introduce a new radiative transfer modeling framework designed to retrieve the composition and mixing status of disk ices using their band profiles, and apply it to interpret the H2O, CO2, and CO ice bands observed towards the HH 48 NE disk. We show that the ices are largely present as mixtures, with strong evidence for CO trapping in both H2O and CO2 ice. The HH 48 NE disk ice composition (pure vs. polar vs. apolar fractions) is markedly different from earlier protostellar stages, implying thermal and/or chemical reprocessing during the formation or evolution of the disk. We infer low ice-phase C/O ratios around 0.1 throughout the disk, and also demonstrate that the mixing and entrapment of disk ices can dramatically affect the radial dependence of the C/O ratio. It is therefore imperative that realistic disk ice compositions are considered when comparing planetary compositions with potential formation scenarios, which will fortunately be possible for an increasing number of disks with JWST.         _ Less","","arXiv","https://arxiv.org/abs/2409.08117","1","1","multiple"
"EDGE-INFERNO: Simulating every observable star in faint dwarf galaxies and their consequences for resolved-star photometric surveys","Abstract:                _by observations limited to only the brightest stars. We present a major improvement to tackle this challenge by undertaking zoomed cosmological simulations that resolve the evolution of all individual stars more massive than $0.5\\,{\\rm M}_{\\odot}$, thereby explicitly tracking all observable stars for the Hubble time. For the first time, we predict observable_         _ More           Interpretation of data from faint dwarf galaxies is made challenging by observations limited to only the brightest stars. We present a major improvement to tackle this challenge by undertaking zoomed cosmological simulations that resolve the evolution of all individual stars more massive than $0.5\\,{\\rm M}_{\\odot}$, thereby explicitly tracking all observable stars for the Hubble time. For the first time, we predict observable color-magnitude diagrams and the spatial distribution of $\\approx 100,000$ stars within four faint ($M_{\\star} \\approx 10^5 \\, \\,{\\rm M}_{\\odot}$) dwarf galaxies directly from their cosmological initial conditions. In all cases, simulations predict complex light profiles with multiple components, implying that typical observational measures of structural parameters can make total V-band magnitudes appear up to 0.5 mag dimmer compared to estimates from simulations. Furthermore, when only small ($\\lessapprox100$) numbers of stars are observable, shot noise from realizations of the color-magnitude diagram introduces uncertainties comparable to the population scatter in, e.g., total magnitude, half-light radius, and mean iron abundance measurements. Estimating these uncertainties with fully self-consistent mass growth, star formation and chemical enrichment histories paves the way for more robust interpretation of dwarf galaxy data.         _ Less","","arXiv","https://arxiv.org/abs/2409.08073","2","3","synthetic_biology"
"How external photo-evaporation changes the chemical composition of the inner disc","Abstract:                Stars mostly form in clusters where neighboring stars can influence proto-planetary disc evolution. Besides gravitational interactions, external photoevaporation can shape these discs. Depending on the strength of photoevaporation, discs can be destroyed within 1-2 Myrs or more gradually. We use the chemcomp code, incorporating a viscous disc_         _ More           Stars mostly form in clusters where neighboring stars can influence proto-planetary disc evolution. Besides gravitational interactions, external photoevaporation can shape these discs. Depending on the strength of photoevaporation, discs can be destroyed within 1-2 Myrs or more gradually. We use the chemcomp code, incorporating a viscous disc evolution model with pebble drift and evaporation, to calculate the chemical composition of protoplanetary discs. This code is extended to include external photoevaporation based on the FRIED grid. Initially, the disc evolves purely viscously, with the inner disc's C/O ratio decreasing due to inward drifting and evaporating water ice pebbles. Over time, the C/O ratio increases as water vapor accretes onto the star and carbon-rich gas migrates inward. Once external photoevaporation starts, the outer disc disperses, but the inner disc's chemical evolution follows that of a purely viscous disc, as most pebbles have already drifted inward within 1 Myr. At low viscosity, the inner disc's C/O ratio remains sub-solar until dispersion by photoevaporation. At high viscosity, the C/O ratio can reach super-solar values, due to faster accretion of water vapor and inward migration of carbon-rich gas, provided the disc survives a few Myrs. In both cases, there is no significant difference in the inner disc's chemical composition compared to a purely viscous model due to the rapid inward drift of pebbles. Our model predicts that inner disc chemistry should be similar for discs subject to external photoevaporation and isolated discs, consistent with JWST observations.         _ Less","","arXiv","https://arxiv.org/abs/2409.07596","1","1","multiple"
"A survey of extremely metal-poor gas at cosmic noon: evidence of elevated [O/Fe]","Abstract:                We aim to study the high-precision chemical abundances of metal-poor gas clouds at cosmic noon (2<z<4) and investigate the associated enrichment histories. We analyse the abundances of four newly discovered metal-poor gas clouds utilising observations conducted with Keck/HIRES and VLT/UVES. These systems are classified as very metal-poor (VMP), with [F_         _ More           We aim to study the high-precision chemical abundances of metal-poor gas clouds at cosmic noon (2<z<4) and investigate the associated enrichment histories. We analyse the abundances of four newly discovered metal-poor gas clouds utilising observations conducted with Keck/HIRES and VLT/UVES. These systems are classified as very metal-poor (VMP), with [Fe/H]<-2.57, and one system qualifies as an extremely metal-poor (EMP) Damped Lyman-alpha (DLA) system with [Fe/H]=-3.13+/-0.06. In combination with new high-resolution data of two previously known EMP DLAs and 2 systems reported in the literature, we conduct a comprehensive analysis of eight of the most metal-poor gas clouds currently known. We focus on high-precision abundance measurements using the elements: C, N, O, Al, Si, and Fe. Our findings indicate increasing evidence of elevated [O/Fe] abundances when [Fe/H]<-3. EMP DLAs are well-modelled with a mean value of [O/Fe]=+0.50 +/- 0.04 and an intrinsic scatter of $__{int,[O/Fe]}=0.13^{+0.06}_{-0.04}$. While VMP DLAs are well-modelled with [O/Fe]=+0.40 +/- 0.02 and $__{int,[O/Fe]}$=0.06 +/- 0.02. We further find tentative evidence of a redshift evolution of [C/O] across these most metal-poor DLAs with lower redshift systems showing elevated [C/O] ratios. Using the measured abundances, combined with a stochastic chemical enrichment model, we investigate the properties of the stellar population responsible for enriching EMP gas at cosmic noon. We find that the chemistry of these systems is best explained via the enrichment of just two massive progenitors, N_*=2+/-1, that ended their lives as core collapse SNe with a typical explosion energy E_exp=(1.6 +/- 0.6)x10$^{51}$ erg. These progenitors formed obeying a Salpeter-like power-law IMF, where all stars of mass greater than M_max=32$^{+10}_{-4}$ M_sun collapse directly to black holes and do not contribute to the metal enrichment.         _ Less","","arXiv","https://arxiv.org/abs/2409.07525","2","3","synthetic_biology"
"The inflated, eccentric warm Jupiter TOI-4914 b orbiting a metal-poor star, and the hot Jupiters TOI-2714 b and TOI-2981 b","Abstract:                Recent observations of giant planets have revealed unexpected bulk densities. Hot Jupiters, in particular, appear larger than expected for their masses compared to planetary evolution models, while warm Jupiters seem denser than expected. These differences are often attributed to the influence of the stellar incident flux, but could they also result from dif_         _ More           Recent observations of giant planets have revealed unexpected bulk densities. Hot Jupiters, in particular, appear larger than expected for their masses compared to planetary evolution models, while warm Jupiters seem denser than expected. These differences are often attributed to the influence of the stellar incident flux, but could they also result from different planet formation processes? Is there a trend linking the planetary density to the chemical composition of the host star? In this work we present the confirmation of three giant planets in orbit around solar analogue stars. TOI-2714 b ($P \\simeq 2.5$ d, $R_{\\rm p} \\simeq 1.22 R_{\\rm J}$, $M_{\\rm p} = 0.72 M_{\\rm J}$) and TOI-2981 b ($P \\simeq 3.6$ d, $R_{\\rm p} \\simeq 1.2 R_{\\rm J}$, $M_{\\rm p} = 2 M_{\\rm J}$) are hot Jupiters on nearly circular orbits, while TOI-4914 b ($P \\simeq 10.6$ d, $R_{\\rm p} \\simeq 1.15 R_{\\rm J}$, $M_{\\rm p} = 0.72 M_{\\rm J}$) is a warm Jupiter with a significant eccentricity ($e = 0.41 \\pm 0.02$) that orbits a star more metal-poor ([Fe/H]$~= -0.13$) than most of the stars known to host giant planets. Our radial velocity (RV) follow-up with the HARPS spectrograph allows us to detect their Keplerian signals at high significance (7, 30, and 23$_$, respectively) and to place a strong constraint on the eccentricity of TOI-4914 b (18$_$). TOI-4914 b, with its large radius and low insolation flux ($F_\\star < 2 \\times 10^8~{\\rm erg~s^{-1}~cm^{-2}}$), appears to be more inflated than what is supported by current theoretical models for giant planets. Moreover, it does not conform to the previously noted trend that warm giant planets orbiting metal-poor stars have low eccentricities. This study thus provides insights into the diverse orbital characteristics and formation processes of giant exoplanets, in particular the role of stellar metallicity in the evolution of planetary systems.         _ Less","","arXiv","https://arxiv.org/abs/2409.07520","1","1","multiple"
"A new analytic approach to infer the cosmic-ray ionization rate in hot molecular cores from HCO$^+$, N$_2$H$^+$, and CO observations","Abstract:                _) is one of the key parameters in star formation, since it regulates the chemical and dynamical evolution of molecular clouds by ionizing molecules and determining the coupling between the magnetic field and gas. However, measurements of $__2$ in dense clouds (e.g., $n_{\\rm H} \\geq 10^4$ cm$^{-3}$) are difficult and se_         _ More           The cosmic-ray ionization rate ($__2$) is one of the key parameters in star formation, since it regulates the chemical and dynamical evolution of molecular clouds by ionizing molecules and determining the coupling between the magnetic field and gas. However, measurements of $__2$ in dense clouds (e.g., $n_{\\rm H} \\geq 10^4$ cm$^{-3}$) are difficult and sensitive to the model assumptions. The aim is to find a convenient analytic approach that can be used in high-mass star-forming regions (HMSFRs), especially for warm gas environments such as hot molecular cores (HMCs). We propose a new analytic approach to calculate $__2$ through HCO$^+$, N$_2$H$^+$, and CO measurements. Our method gives a good approximation, to within $50$\\%, of $__2$ in dense and warm gas (e.g., $n_{\\rm H} \\geq 10^4$ cm$^{-3}$, $T = 50, 100$ K) for $A_{\\rm V} \\geq 4$ mag and $t \\geq 2\\times10^4$ yr at Solar metallicity. The analytic approach gives better results for higher densities. However, it starts to underestimate the CRIR at low metallicity ($Z = 0.1Z_\\odot$) and high CRIR ($__2 \\geq 3\\times10^{-15}$ s$^{-1}$). By applying our method to the OMC-2 FIR4 envelope and the L1157-B1 shock region, we find $__2$ values of $(1.0\\pm0.3)\\times10^{-14}$ s$^{-1}$ and $(2.2\\pm0.4)\\times10^{-16}$ s$^{-1}$, consistent with those previously reported. We calculate $__2$ toward a total of 82 samples in HMSFRs, finding that the average value of $__2$ toward all HMC samples ($__2$ = (7.4$\\pm$5.0)$\\times$10$^{-16}$ s$^{-1}$) is more than an order of magnitude higher than the theoretical prediction of cosmic-ray attenuation models, favoring the scenario that locally accelerated cosmic rays in embedded protostars should be responsible for the observed high $__2$.         _ Less","","arXiv","https://arxiv.org/abs/2409.07181","1","1","multiple"
"Diverse Transient Chiral Dynamics in Evolutionary distinct Photosynthetic Reaction Centers","Abstract:                The evolution of photosynthetic reaction centers (RCs) from anoxygenic bacteria to oxygenic cyanobacteria and plants reflects their structural and functional adaptation to environmental conditions. Chirality plays a significant role in influencing the arrangement and function of key molecules in these RCs. This study investigates chirality-related energy tra_         _ More           The evolution of photosynthetic reaction centers (RCs) from anoxygenic bacteria to oxygenic cyanobacteria and plants reflects their structural and functional adaptation to environmental conditions. Chirality plays a significant role in influencing the arrangement and function of key molecules in these RCs. This study investigates chirality-related energy transfer in two distinct RCs: Thermochromatium tepidum (BRC) and Thermosynechococcus vulcanus (PSII RC) using two-dimensional electronic spectroscopy (2DES). Circularly polarized laser pulses reveal transient chiral dynamics, with 2DCD spectroscopy highlighting chiral contributions. BRC displays more complex chiral behavior, while PSII RC shows faster coherence decay, possibly as an adaptation to oxidative stress. Comparing the chiral dynamics of BRC and PSII RC provides insights into photosynthetic protein evolution and function.         _ Less","","arXiv","https://arxiv.org/abs/2409.06996","0","3","synthetic_biology"
"Sifting the debris: Patterns in the SNR population with unsupervised ML methods","Abstract:                Supernova remnants (SNRs) carry vast amounts of mechanical and radiative energy that heavily influence the structural, dynamical, and chemical evolution of galaxies. To this day, more than 300 SNRs have been discovered in the Milky Way, exhibiting a wide variety of observational features. However, existing classificati_         _ More           Supernova remnants (SNRs) carry vast amounts of mechanical and radiative energy that heavily influence the structural, dynamical, and chemical evolution of galaxies. To this day, more than 300 SNRs have been discovered in the Milky Way, exhibiting a wide variety of observational features. However, existing classification schemes are mainly based on their radio morphology. In this work, we introduce a novel unsupervised deep learning pipeline to analyse a representative subsample of the Galactic SNR population ($\\sim$ 50% of the total) with the aim of finding a connection between their multi-wavelength features and their physical properties. The pipeline involves two stages: (1) a representation learning stage, consisting of a convolutional autoencoder that feeds on imagery from infrared and radio continuum surveys (WISE 22$_$m, Hi-GAL 70 $_$m and SMGPS 30 cm) and produces a compact representation in a lower-dimensionality latent space; and (2) a clustering stage that seeks meaningful clusters in the latent space that can be linked to the physical properties of the SNRs and their surroundings. Our results suggest that this approach, when combined with an intermediate uniform manifold approximation and projection (UMAP) reprojection of the autoencoded embeddings into a more clusterable manifold, enables us to find reliable clusters. Despite a large number of sources being classified as outliers, most clusters relate to the presence of distinctive features, such as the distribution of infrared emission, the presence of radio shells and pulsar wind nebulae, and the existence of dust filaments.         _ Less","","arXiv","https://arxiv.org/abs/2409.06383","2","2","multiple"
"The Potential of Geminate Pairs in Lead Halide Perovskite revealed via Time-resolved Photoluminescence","Abstract:                Photoluminescence (PL) under continuous illumination is commonly employed to assess voltage losses in solar energy conversion materials. However, the early temporal evolution of these losses remains poorly understood. Therefore, we extend the methodology to time-resolved PL, introducing the concepts of geminate PL, doping PL, and sibling PL to quantify the t_         _ More           Photoluminescence (PL) under continuous illumination is commonly employed to assess voltage losses in solar energy conversion materials. However, the early temporal evolution of these losses remains poorly understood. Therefore, we extend the methodology to time-resolved PL, introducing the concepts of geminate PL, doping PL, and sibling PL to quantify the transient chemical potential of photogenerated electron-hole pairs and key optoelectronic properties. Analyzing the initial PL amplitudes reveals hot charge carrier separation for around 100 nm and is likely limited by the grain size of the triple cation perovskite. The following PL decay is caused by the diffusive separation of non-excitonic geminate pairs and time-resolves a fundamental yet often overlooked energy loss by increasing entropy. For triple-cation halide perovskite, we measure a 'geminate correlation energy' of up to 90 meV, persisting for ~ten nanoseconds. This energy is unutilized in standard solar cells and is considered lost in the Shockley-Queisser model. Therefore, this geminate energy could substantially enhance the device's efficiency, particularly under maximum power point and low-illumination conditions.         _ Less","","arXiv","https://arxiv.org/abs/2409.06382","0","2","synthetic_biology"
"Mechanistic Modeling of Continuous Lyophilization for Pharmaceutical Manufacturing","Abstract:                _drying. The state-of-the-art lyophilization technology is considered, in which vials are suspended and moved continuously through the process. The model can describe the evolution of several critical process parameters, namely the product temperature, ice/water fraction, sublimation front position, and concentration of bound water, for the entire lyophilizat_         _ More           Lyophilization (also known as freeze drying) is a process that is commonly used to increase the stability of drug products, e.g., mRNA vaccines, in pharmaceutical manufacturing. While extensive efforts have been dedicated to shift the pharmaceutical industry towards continuous manufacturing, the majority of industrial-scale lyophilization is still being operated in a batch mode. This article proposes the first mechanistic model for a complete continuous lyophilization process, which includes freezing, primary drying, and secondary drying. The state-of-the-art lyophilization technology is considered, in which vials are suspended and moved continuously through the process. The model can describe the evolution of several critical process parameters, namely the product temperature, ice/water fraction, sublimation front position, and concentration of bound water, for the entire lyophilization process. The model is also demonstrated for several applications related to process design and optimization. Ultimately, the framework and results presented in this work can serve as a solid foundation to guide the design and development of future continuous lyophilization processes.         _ Less","","arXiv","https://arxiv.org/abs/2409.06251","0","1","synthetic_biology"
"Characterizing Turbulence at a Forest Edge: A Vorticity Budget Analysis around a Canopy","Abstract:                Vorticity is a key characteristic of flow patterns that determine wildland fire behavior, frontal evolution, and wind-canopy interaction. Investigating the role of vorticity in the flow fields around vegetation can help us better understand fire-atmosphere feedback and the influences of vegetation on this feedback. In modeling vorticity, ``perhaps the greate_         _ More           Vorticity is a key characteristic of flow patterns that determine wildland fire behavior, frontal evolution, and wind-canopy interaction. Investigating the role of vorticity in the flow fields around vegetation can help us better understand fire-atmosphere feedback and the influences of vegetation on this feedback. In modeling vorticity, ``perhaps the greatest knowledge gap exists in understanding which terms in the vorticity equation dominate [...] (and) when one or the other might dominate' (Potter, 2012). In this study, we investigate the role of vorticity in boundary layer dynamics and canopy/forest edge effects using HIGRAD/FIRETEC, a three-dimensional, two-phase transport model that conserves mass, momentum, energy, and chemical species. A vorticity transport equation was derived and discretized. Simulations were performed over a cuboidal homogeneous canopy surrounded by surface vegetation. This derivation led to the discovery of a drag tilting and stretching term, which shows that gradients in the aerodynamic drag of the vegetation, tied to heterogeneities in surface area-to-volume ratio, play an important role in the generation of vorticity. Results from the vorticity budget analysis show that this term contributes significantly in the areas where these gradients are present, namely the edges of the canopy.         _ Less","","arXiv","https://arxiv.org/abs/2409.06044","0","1","synthetic_biology"
"Mapping Evolution of Molecules Across Biochemistry with Assembly Theory","Abstract:        Evolution is often understood through genetic mutations driving changes in an organism's fitness, but there is potential to extend this understanding beyond the genetic code. We propose that natural products - complex molecules central to Earth's biochemistry can be used to uncover evolutionary mechanisms beyond genes. By applying Assembly Theory (AT_         _ More   Evolution is often understood through genetic mutations driving changes in an organism's fitness, but there is potential to extend this understanding beyond the genetic code. We propose that natural products - complex molecules central to Earth's biochemistry can be used to uncover evolutionary mechanisms beyond genes. By applying Assembly Theory (AT), which views selection as a process not limited to biological systems, we can map and measure evolutionary forces in these molecules. AT enables the exploration of the assembly space of natural products, demonstrating how the principles of the selfish gene apply to these complex chemical structures, selecting vastly improbable and complex molecules from a vast space of possibilities. By comparing natural products with a broader molecular database, we can assess the degree of evolutionary contingency, providing insight into how molecular novelty emerges and persists. This approach not only quantifies evolutionary selection at the molecular level but also offers a new avenue for drug discovery by exploring the molecular assembly spaces of natural products. Our method provides a fresh perspective on measuring the evolutionary processes both, shaping and being read out, by the molecular imprint of selection.         _ Less","","arXiv","https://arxiv.org/abs/2409.05993","0","1","synthetic_biology"
"Controlling molecular dynamics by exciting atoms in a cavity","Abstract:                _rich dynamics. The cavity photon plays the role of a mediator between the atom and the molecule and it is found that the photonic population is rather low throughout and its evolution follows that of the molecule. Cavities are known to be subject to losses. In spite of the losses it is demonstrated that the presence of the atom gives rise to a long-lived dyn_         _ More           Placing an atom and a molecule in a cavity opens the door to initialize molecular dynamics by exciting a level of the atom. This approach enlarges the range of choosing the light source to trigger molecular dynamics substantially. The interplay of the atomic, molecular and photonic populations gives rise to rich dynamics. The cavity photon plays the role of a mediator between the atom and the molecule and it is found that the photonic population is rather low throughout and its evolution follows that of the molecule. Cavities are known to be subject to losses. In spite of the losses it is demonstrated that the presence of the atom gives rise to a long-lived dynamics which should be of relevance for experimental investigations. The presence of more atoms and molecules is expected to further enrich the dynamics.         _ Less","","arXiv","https://arxiv.org/abs/2409.05690","0","1","synthetic_biology"
"A new atmospheric characterization of the sub-stellar companion HR\\,2562\\,B with JWST/MIRI observations","Abstract:                _companion located 0.56arcsec (19au) from its host star. It is one of a few L/T transitional objects orbiting a young star. This companion provides insight into the evolution of young objects in the L/T transition. However, its key physical properties, such as Teff and mass, remain poorly constrained, with large uncertainties (34% for Teff, 22% for log(g)) ba_         _ More           Context: HR2562B is a planetary-mass companion located 0.56arcsec (19au) from its host star. It is one of a few L/T transitional objects orbiting a young star. This companion provides insight into the evolution of young objects in the L/T transition. However, its key physical properties, such as Teff and mass, remain poorly constrained, with large uncertainties (34% for Teff, 22% for log(g)) based on near-infrared observations alone. Aims: We aim to refine these uncertainties, especially for Teff (1200-1700K) and log(g) (4-5), using new MIR data from the JWST/MIRI filters (10.65, 11.40, and 15.50 microns), and better understand the companion's chemical composition and its role in the L/T transition. Methods: MIRI data were processed using reference star differential imaging, revealing HR2562B at high S/N (16) in all 3 filters. We used 2 atmospheric models, ATMO and ExoREM, to fit the SED, combining MIR and NIR datasets. Additionally, we used CMD with brown dwarfs to explore the chemical composition of HR2562B's atmosphere and compare it to another L/T transition object, VHS1256b. Results: Our analysis improved the temperature precision (Teff=1255+-15K) by 6x compared to previous estimates. We also narrowed its luminosity to -4.69+-0.01 dex. Surface gravity remains uncertain (4.4-4.8), and its mass is estimated between 8 and 18.5Mj, depending on modeling and astrometry. Sensitivity analysis revealed the ability to detect objects between 2-5Mj at 100au. Conclusions: HR2562B likely has a near cloud-free atmosphere, with the ATMO model fitting better than ExoREM. Silicate absorption features are weak, requiring further spectroscopic observations. While HR2562B and VHS1256b share similarities, they are in different evolutionary stages, making HR2562B key to understanding young objects in the L/T transition. It is likely a planetary-mass companion, suggesting a reclassification as HR2562b.         _ Less","","arXiv","https://arxiv.org/abs/2409.04524","0","1","synthetic_biology"
"BH-BH mergers with & without EM counterpart: A model for stable tertiary mass transfer in hierarchical triple systems","Abstract:                Triple stars are prevalent within the population of observed stars. Their evolution, compared to binaries, is notably more complex, influenced by unique dynamical, tidal, and mass transfer processes. Understanding these phenomena is essential for a comprehensive insight into multistar_         _ More           Triple stars are prevalent within the population of observed stars. Their evolution, compared to binaries, is notably more complex, influenced by unique dynamical, tidal, and mass transfer processes. Understanding these phenomena is essential for a comprehensive insight into multistar evolution and the formation of energetic transients, including gravitational-wave mergers. Our study probes the evolution of triple star systems when the tertiary fills its Roche lobe and transfers mass to the inner binary, potentially forming GW sources with distinct properties. We develop an analytical model for hierarchical triples undergoing stable mass transfer from the tertiary. Using population synthesis simulations, we investigate triples with a Roche-lobe filling tertiary and an inner binary black hole. These systems originate from inner binaries undergoing chemically homogeneous evolution. Our analysis includes populations with metallicities of Z=0.005 and Z=0.0005, focusing on primary components with initial masses of 20 to 100 M_sun, and inner and outer orbital separations up to 40 R_sun and 10^5 R_sun, respectively. Our results show that mass transfer predominantly leads to orbital shrinkage of the inner binary, non-zero eccentricities, and expansion of the outer orbit. Among systems with CHE inner binaries, 9.5% result in mass transfer from the tertiary onto an inner BBH. We predict high formation efficiency of GW mergers, ranging from 85.1% to 100% at Z=0.005 and 100% at Z=0.0005, with short delay times. Local merger rates are projected to be between 0.69 to 1.74 Gpc^-3 yr^-1. A fraction of these BBH mergers, entering the LISA and aLIGO frequency bands, may still be accreting gas, potentially producing a strong electromagnetic counterpart. EM signals vary significantly based on model assumptions, ranging from less than 0.03% to 46.8% of all mergers if circumbinary disk formation is allowed.         _ Less","","arXiv","https://arxiv.org/abs/2409.03826","2","2","multiple"
"Gaia/GSP-spec spectroscopic properties of gamma Doradus pulsators","Abstract:                _stars should preferentially be found. The stellar luminosities, radii, and astrometric surface gravities were estimated without adopting any priors from uncertain stellar evolution models. These parameters, combined with the GSP-spec effective temperatures, spectroscopic gravities, and metallicities were then validated by comparison with recent literature st_         _ More           Gaia/DR3 has provided a large sample of new g-mode pulsators, among which~11,600 are Gam Dor stars. This work present the spectroscopic parameters of these Gam Dor pulsators estimated by the GSP-spec module that analysed millions of Gaia spectra. The Galactic positions, kinematics, and orbital properties of these new Gaia pulsators were examined in order to define a sub-sample belonging to the Milky Way thin disc, in which these young stars should preferentially be found. The stellar luminosities, radii, and astrometric surface gravities were estimated without adopting any priors from uncertain stellar evolution models. These parameters, combined with the GSP-spec effective temperatures, spectroscopic gravities, and metallicities were then validated by comparison with recent literature studies. Most stars are found to belong to the Galactic thin disc, as expected. It is also found that the derived luminosities, radii, and astrometric surface gravities are of high quality and have values typical of genuine Gam Dor pulsators. Moreover, we have shown that Teff and [M/H] of pulsators with high enough SNR spectra or slow to moderate rotation rates are robust. This allowed to define a sub-sample of genuine slow-rotating Gaia Gam Dor pulsators. Their Teff are found between ~6500 and ~7800K, log(g) around 4.2 and luminosities and stellar radii peak at ~5Lsun and ~1.7Rsun. [M/H] is close to the Solar value, although 0.5dex more metal-poor and metal-rich Gam Dor are identified. The [alpha/Fe] content is fully consistent with the chemical properties of the Galactic disc. Gaia/DR3 spectroscopic properties of Gam Dor stars therefore confirm the nature of these pulsators and allow to chemo-physically parametrise a new large sample of such stars. Moreover, future Gaia DR should drastically increase the number of Gam Dor stars with good-precision spectroscopically derived parameters.         _ Less","","arXiv","https://arxiv.org/abs/2409.03361","0","1","synthetic_biology"
"Alpha helices are more evolutionarily robust to environmental perturbations than beta sheets: Bayesian learning and statistical mechanics to protein evolution","Abstract:                _susceptible/resistant they are to environmental changes, are significant issues in evolutionary biology, structural biology, and biophysics. According to Darwinian evolution, natural selection and genetic mutations are the primary drivers of biological_         _ More           How typical elements that shape organisms, such as protein secondary structures, have evolved, or how evolutionarily susceptible/resistant they are to environmental changes, are significant issues in evolutionary biology, structural biology, and biophysics. According to Darwinian evolution, natural selection and genetic mutations are the primary drivers of biological evolution. However, the concept of ``robustness of the phenotype to environmental perturbations across successive generations,'' which seems crucial from the perspective of natural selection, has not been formalized or analyzed. In this study, through Bayesian learning and statistical mechanics we formalize the stability of the free energy in the space of amino acid sequences that can design particular protein structure against perturbations of the chemical potential of water surrounding a protein as such robustness. This evolutionary stability is defined as a decreasing function of a quantity analogous to the susceptibility in the statistical mechanics of magnetic bodies specific to the amino acid sequence of a protein. Consequently, in a two-dimensional square lattice protein model composed of 36 residues, we found that as we increase the stability of the free energy against perturbations in environmental conditions, the structural space shows a steep step-like reduction. Furthermore, lattice protein structures with higher stability against perturbations in environmental conditions tend to have a higher proportion of $_$-helices and a lower proportion of $_$-sheets. The latter result shows that protein structures rich in $_$-helices are more robust to environmental perturbations through successive generations than those rich in $_$-sheets.         _ Less","","arXiv","https://arxiv.org/abs/2409.03297","0","1","synthetic_biology"
"The YMDB catalog: Young massive detached binaries for the determination of high-precision absolute stellar parameters","Abstract:                Massive stars play a crucial role in the cosmic dynamics and chemical_         _ More           Massive stars play a crucial role in the cosmic dynamics and chemical evolution of galaxies, however our understanding of their evolution and properties remains limited. An accurate determination of stellar parameters is essential for advancing our knowledge. Detached eclipsing binaries (DEBs) are particularly valuable for these determinations due to the minimal interaction between their stellar components, allowing for precise measurements. This study introduces the Young Massive Detached Binary (YMDB) catalog, designed to address the gap in the high-precision absolute parameter determination for young massive stars. By focusing on DEBs within the spectral range O9-B1, this catalog seeks to provide a reliable database for future studies and improve our understanding of massive star evolution. We conducted a photometric analysis of 87 young massive stars in DEBs using TESS light curves (LCs) that were processed through a custom pipeline. This analysis involved determining the amplitude of magnitude variations, orbital periods, times of minima, eccentricities, and the presence of apsidal motion and heartbeat phenomena. A thorough literature review was performed to obtain MK spectral classifications. We performed our own spectral classification of 19 systems to support the sample where a new classification was lacking or inconclusive. The analysis identified 20 previously unreported binary systems, with 13 newly recognized as variables. Among the 87 stars examined, 30 are confirmed as YMDB members, and 25 are candidates pending spectral classification. The remaining 32 stars belong to unsuitable spectral types or nondetached binary nature. Notable findings include the identification of new LC classifications, eccentricities in 13 systems, and heartbeat phenomena in several targets. The YMDB catalog offers a resource of high-quality LCs and reliable stellar classifications.         _ Less","","arXiv","https://arxiv.org/abs/2409.03205","2","2","multiple"
"Doping-Induced Enhancement of Hydrogen Evolution at MoS2 Electrodes","Abstract:                Rate theory and DFT calculations of hydrogen evolution reaction (HER) on MoS2 with Co, Ni and Pt impurities show the significance of dihydrogen (H2*) complex where both hydrogen atoms are interacting with the surface. Stabilization of such a complex affects the competing Volmer-Heyrovsky (direct H2 release) and Volmer-Tafel (H2* intermediate) pathways. The r_         _ More           Rate theory and DFT calculations of hydrogen evolution reaction (HER) on MoS2 with Co, Ni and Pt impurities show the significance of dihydrogen (H2*) complex where both hydrogen atoms are interacting with the surface. Stabilization of such a complex affects the competing Volmer-Heyrovsky (direct H2 release) and Volmer-Tafel (H2* intermediate) pathways. The resulting evolution proceeds with a very small overpotential for all dopants ($_$ = 0.1 to 0.2 V) at 25% edge substitution, significantly reduced from the already low $_$ = 0.27 V for the undoped edge. At full edge substitution, Co-MoS2 remains highly active ($_$ = 0.18 V) while Ni- and Pt-MoS2 are deactivated ($_$ = 0.4 to 0.5 V) due to unfavorable interaction with H2*. Instead of the single S-vacancy, the site of intrinsic activity in the basal plane was found to be the undercoordinated central Mo-atom in threefold S-vacancy configurations, enabling hydrogen evolution with $_$ = 0.52 V via a H2* intermediate. The impurity atoms interact favorably with the intrinsic sulfur vacancies on the basal plane, stabilizing but simultaneously deactivating the triple vacancy configuration. The calculated shifts in overpotential are consistent with reported measurements, and the dependence on doping level may explain variations in experimental observations.         _ Less","","arXiv","https://arxiv.org/abs/2409.02749","0","1","synthetic_biology"
"Phosphorus Abundances of B-Type Stars in the Solar Neighborhood","Abstract:                _in comparison with the reference solar abundance (A_sun = 5.45). These sample stars turned out to be divided into two distinct groups with respect to their P abundances: (1) chemically peculiar late B-type stars of HgMn group show considerable overabundances of P (supersolar by ~0.5--1.5 dex), the extent of which progressively increases with T_eff. (2) In co_         _ More           Phosphorus abundances of ~80 apparently bright sharp-lined early-to-late B-type stars on the upper main sequence are determined by applying the non-LTE analysis to the P II line at 6043.084 A, with an aim of getting information on the P abundance of the galactic gas (from which these young stars were formed) in comparison with the reference solar abundance (A_sun = 5.45). These sample stars turned out to be divided into two distinct groups with respect to their P abundances: (1) chemically peculiar late B-type stars of HgMn group show considerable overabundances of P (supersolar by ~0.5--1.5 dex), the extent of which progressively increases with T_eff. (2) In contrast, the P abundances of normal B-type stars are comparatively homogeneous, though a notable difference is observed between the LTE and non-LTE cases. Although their LTE abundances are near-solar, a slight gradual trend with T_eff is observed. However, after applying the negative non-LTE corrections (amounting ~0.1-0.5 dex), this T_eff-dependence is successfully removed, but the resulting non-LTE abundances (their mean is ~5.20) are appreciably underabundant relative to the Sun by ~0.2--0.3 dex. The cause of this systematic discrepancy (contradicting the galactic chemical evolution) is yet to be investigated.         _ Less","","arXiv","https://arxiv.org/abs/2409.02742","2","1","origin_of_life"
"Astrochemistry on Galactic scales","Abstract:                _works, are improving our knowledge of the astrochemical processes in the interstellar medium (ISM). In this chapter we report some of the main projects to study the chemical complexity and isotopic ratios across the Galaxy. High-sensitivity spectral surveys covering broad bandwidths towards Galactic Center molecular clouds (e.g. G+0.693-0.027) and star-formi_         _ More           The increasing number of observations towards different environments in the Milky Way, as well as theoretical and experimental works, are improving our knowledge of the astrochemical processes in the interstellar medium (ISM). In this chapter we report some of the main projects to study the chemical complexity and isotopic ratios across the Galaxy. High-sensitivity spectral surveys covering broad bandwidths towards Galactic Center molecular clouds (e.g. G+0.693-0.027) and star-forming regions (e.g. the hot core G31.41+0.31) are revealing very rich astrochemical reservoirs, which include molecules of prebiotic interest. At the same time, isotopic ratios (e.g. $^{12}$C/$^{13}$C and $^{14}$N/$^{15}$N) can give important information on the Galactic chemical evolution, as well as on chemical local processes due to the physical conditions of the molecular clouds. We also highlight the role of cosmic rays as a key agent affecting the interstellar chemistry described above.         _ Less","","arXiv","https://arxiv.org/abs/2409.02537","4","2","origin_of_life"
"Nucleosynthesis contribution of neutrino-dominated accretion flows to the solar neighborhood","Abstract:                _stars reflect the complex enrichment history of the galaxy. To explore and explain the metal enrichment history of the cosmic environment near our solar system, we study the evolution of $^{56} \\mathrm{Fe}$ abundance over time and [Mg/Fe] versus [Fe/H] evolution in the solar neighborhood. Core-collapse supernovae make_         _ More           The elemental abundances of stars reflect the complex enrichment history of the galaxy. To explore and explain the metal enrichment history of the cosmic environment near our solar system, we study the evolution of $^{56} \\mathrm{Fe}$ abundance over time and [Mg/Fe] versus [Fe/H] evolution in the solar neighborhood. Core-collapse supernovae make the dominant contribution in the early stages, while Type Ia supernovae (SNe Ia) have a delayed and dominant impact in the later stages. In this work, we consider the nucleosynthesis contribution of neutrino-dominated accretion flows (NDAFs) formed at the end of the lives of massive stars. The results show that the [Fe/H] gradually increases over time and eventually reaches $\\rm [Fe/H]=0$ and above, reproducing the chemical enrichment process in the solar neighborhood. Before the onset of SNe Ia, the ratio of $^{56} \\mathrm{Fe}$ mass to the total gas mass increases by a factor of at most $\\sim 1.44$ when NDAFs are taken into account. We find that by including NDAF in our models, the agreement with the observed metallicity distribution of metal-poor stars in the solar neighborhood ($\\rm < 1~kpc$) is improved, while not significantly altering the location of the metallicity peak. This inclusion can also reproduce the observed evolutionary change of [Mg/Fe] at [Fe/H] $\\sim -1.22$, bringing the ratio to match the solar abundance. Our results provide an extensive understanding of metallicity evolution in the solar environments by highlighting the nucleosynthesis contribution of NDAF outflows in the solar neighborhood.         _ Less","","arXiv","https://arxiv.org/abs/2409.02040","0","1","synthetic_biology"
"Binary progenitor systems for Type Ic supernovae","Abstract:                Core-collapse supernovae are explosions of massive stars at the end of their evolution. They are responsible for metal production and for halting star formation, having a significant impact on galaxy_         _ More           Core-collapse supernovae are explosions of massive stars at the end of their evolution. They are responsible for metal production and for halting star formation, having a significant impact on galaxy evolution. The details of these processes depend on the nature of supernova progenitors, but it is unclear if Type Ic supernovae (without hydrogen or helium lines in their spectra) originate from core-collapses of very massive stars (> 30 Msun) or from less massive stars in binary systems. Here we show that Type II (with hydrogen lines) and Ic supernovae are located in environments with similar molecular gas densities, therefore their progenitors have comparable lifetimes and initial masses. This supports a binary interaction for most Type Ic supernova progenitors, which explains the lack of hydrogen and helium lines. This finding can be implemented in sub-grid prescriptions in numerical cosmological simulations to improve the feedback and chemical mixing.         _ Less","","arXiv","https://arxiv.org/abs/2409.01906","1","1","multiple"
"Proximity to an orbital order with charge disorder state in optimally-doped \\textit{RE}\\textsubscript{5/8}Ca\\textsubscript{3/8}MnO\\textsubscript{3} perovskites","Abstract:                The evolution of charge and orbital ordering phenomena in optimally-doped \\textit{RE}\\textsubscript{5/8}Ca\\textsubscript{3/8}MnO\\textsubscript{3} (RECMO, \\textit{RE} $=$ rare-earth) manganite perovskites has been investigated through average structure synchrotron x-ray and neutron powder diffraction techniques. We demonstrate the intricate relationship betwe_         _ More           The evolution of charge and orbital ordering phenomena in optimally-doped \\textit{RE}\\textsubscript{5/8}Ca\\textsubscript{3/8}MnO\\textsubscript{3} (RECMO, \\textit{RE} $=$ rare-earth) manganite perovskites has been investigated through average structure synchrotron x-ray and neutron powder diffraction techniques. We demonstrate the intricate relationship between the \\textit{B}O\\textsubscript{6} octahedral rotation magnitude and lattice strain distortions acting in this series and how they tune macroscopic signatures describing ordering behavior. Through careful symmetry-motivated crystallographic analysis, we show that for the range of RECMO compositions which famously contain maxima in the colossal magnetoresistance (CMR) response, their lattice strain states are in close proximity to that associated with a novel orbital order:charge disordered state we have recently unveiled in the quadruple manganite perovskites Na\\textsubscript{1-\\textit{x}}Ca\\textsubscript{\\textit{x}}Mn\\textsubscript{7}O\\textsubscript{12}. We establish that this order is the primary state which competes with the ferromagnetic metallic state which ultimately leads to phase coexistence and the emergence of CMR. Our results lend themselves to aiding a further understanding of how particular chemical complexities can control charge and orbital ordering phenomena, and also the general properties of manganite perovskites and other related systems \\textit{via} strain effects.         _ Less","","arXiv","https://arxiv.org/abs/2409.01718","1","1","multiple"
"Cosmic-ray induced sputtering of interstellar formaldehyde ices","Abstract:                _Using a heavy-ion beam as a cosmic-ray analogue at the GANIL accelerator, we irradiated pure H2CO ice films at 10 K under high vacuum conditions and monitored the ice film evolution with infrared spectroscopy and the composition of the sputtered species in the gas phase using mass spectrometry. We derived both the effective and intact sputtering yield of pu_         _ More           H2CO is a ubiquitous molecule in the ISM and in the gas phase of prestellar cores, and is likely present in ice mantles, but its main desorption mechanism is unknown. In this paper our aim is to quantify the desorption efficiency of H2CO upon cosmic-ray impact in order to determine whether cosmic-ray induced sputtering could account for the H2CO abundance observed in prestellar cores. Using a heavy-ion beam as a cosmic-ray analogue at the GANIL accelerator, we irradiated pure H2CO ice films at 10 K under high vacuum conditions and monitored the ice film evolution with infrared spectroscopy and the composition of the sputtered species in the gas phase using mass spectrometry. We derived both the effective and intact sputtering yield of pure H2CO ices. We find that H2CO easily polymerises under heavy-ion irradiation in the ice, and is also radiolysed into CO and CO2. In the gas phase, the dominant sputtered species is CO and intact H2CO is only a minor species. We determine an intact sputtering yield for pure H2CO ices $2.5\\times 10^3$ molecules ion$^{-1}$ for an electronic stopping power of $S_e\\sim2830$ eV ($10^{15}$ molecules cm$^{-2}$)$^{-1}$. The corresponding cosmic-ray sputtering rate is $__\\mathrm{CRD}=1.5\\times 10^{18}_$ molecules cm$^{-2}$ s$^{-1}$, where $_$ is the rate of cosmic-ray ionisation of molecular hydrogen in the ISM. In the frame of a simple steady-state chemical model of freeze-out and non-thermal desorption, we find that this experimental cosmic-ray sputtering rate is too low (by an order of magnitude) to account for the observed H2CO gas-phase abundance we derived in the prestellar core L1689B. We find however that this abundance can be reproduced if we assume that H2CO diluted in CO or CO2 ices co-desorbs at the same sputtering rate as pure CO or pure CO2 ices.         _ Less","","arXiv","https://arxiv.org/abs/2409.01700","0","1","synthetic_biology"
"MSA-3D: Metallicity Gradients in Galaxies at $z\\sim1$ with JWST/NIRSpec Slit-stepping Spectroscopy","Abstract:                The radial gradient of gas-phase metallicity is a powerful probe of the chemical and structural evolution of star-forming galaxies, closely tied to disk formation and gas kinematics in the early universe. We present spatially resolved chemical and dynamical properties for a sampl_         _ More           The radial gradient of gas-phase metallicity is a powerful probe of the chemical and structural evolution of star-forming galaxies, closely tied to disk formation and gas kinematics in the early universe. We present spatially resolved chemical and dynamical properties for a sample of 25 galaxies at $0.5 \\lesssim z \\lesssim 1.7$ from the \\msasd survey. These innovative observations provide 3D spectroscopy of galaxies at a spatial resolution approaching JWST's diffraction limit and a high spectral resolution of $R\\simeq2700$. The metallicity gradients measured in our galaxy sample range from $-$0.03 to 0.02 dex~kpc$^{-1}$. Most galaxies exhibit negative or flat radial gradients, indicating lower metallicity in the outskirts or uniform metallicity throughout the entire galaxy. We confirm a tight relationship between stellar mass and metallicity gradient at $z\\sim1$ with small intrinsic scatter of 0.02 dex~kpc$^{-1}$. Our results indicate that metallicity gradients become increasingly negative as stellar mass increases, likely because the more massive galaxies tend to be more ``disky'. This relationship is consistent with the predictions from cosmological hydrodynamic zoom-in simulations with strong stellar feedback. This work presents the effort to harness the multiplexing capability of JWST NIRSpec/MSA in slit-stepping mode to map the chemical and kinematic profiles of high-redshift galaxies in large samples and at high spatial and spectral resolution.         _ Less","","arXiv","https://arxiv.org/abs/2409.01616","2","2","multiple"
"Different aspects of entropic cosmology","Abstract:                _horizon, namely the first and the second laws of thermodynamics. The first law essentially provides the change of the entropy of the apparent horizon during the cosmic evolution of the universe, in particular, it is given by: $TdS = -d(_V) + W dV$ (where $W$ is the work density and other quantities have their usual meaning). In this way, the first law actual_         _ More           We give a short review of the recent developments of entropic cosmology based on two thermodynamic laws of the apparent horizon, namely the first and the second laws of thermodynamics. The first law essentially provides the change of the entropy of the apparent horizon during the cosmic evolution of the universe, in particular, it is given by: $TdS = -d(_V) + W dV$ (where $W$ is the work density and other quantities have their usual meaning). In this way, the first law actually links various theories of gravity with the entropy of the apparent horizon. This leads to a natural question -- ``what will be the form of the horizon entropy corresponding to a general modified theory of gravity?'' The second law of horizon thermodynamics states that the change of total entropy (the sum of horizon entropy $+$ matter fields' entropy) with respect to cosmic time must be positive, where the matter fields behave like an open system characterised by a non-zero chemical potential. The second law of horizon thermodynamics importantly provides model-independent constraints on entropic parameters. Finally, we discuss the standpoint of entropic cosmology on inflation (or bounce), reheating and primordial gravitational waves from the perspective of generalised entropy function.         _ Less","","arXiv","https://arxiv.org/abs/2409.01090","1","2","synthetic_biology"
"Monitoring of water sorption and swelling of potato starch-glycerol extruded blend by magnetic resonance imaging and multivariate curve resolution","Abstract:                _and distribution maps of the components involved in the water uptake process that occurs over time with various kinetics. This approach allowed the description of the system evolution at a global (image) and a local (pixel) level, hence, permitted the resolution of two waterfronts, at two different times into the blend that could not be resolved by any other_         _ More           Magnetic resonance microimaging (MR mu I) is an outstanding technique for studying water transfers in millimetric bio-based materials in a non-destructive and non-invasive manner. However, depending on the composition of the material, monitoring and quantification of these transfers can be very complex, and hence reliable image processing and analysis tools are necessary. In this study, a combination of MR mu I and multivariate curve resolution-alternating least squares (MCR-ALS) is proposed to monitor the water ingress into a potato starch extruded blend containing 20% glycerol that was shown to have interesting properties for biomedical, textile, and food applications. In this work, the main purpose of MCR is to provide spectral signatures and distribution maps of the components involved in the water uptake process that occurs over time with various kinetics. This approach allowed the description of the system evolution at a global (image) and a local (pixel) level, hence, permitted the resolution of two waterfronts, at two different times into the blend that could not be resolved by any other mathematical processing method usually used in magnetic resonance imaging (MRI). The results were supplemented by scanning electron microscopy (SEM) observations in order to interpret these two waterfronts in a biological and physico-chemical point of view.         _ Less","","arXiv","https://arxiv.org/abs/2409.01018","0","1","synthetic_biology"
"The GAPS Programme at TNG. LXI. Atmospheric parameters and elemental abundances of TESS young exoplanet host stars","Abstract:                The study of exoplanets at different evolutionary stages can shed light on their formation, migration, and evolution. The determination of exoplanet properties depends on the properties of their host stars. It is therefore important to characterise the host stars for accurate knowledge on their planets. Our final goal is to derive, in a homogeneous and accur_         _ More           The study of exoplanets at different evolutionary stages can shed light on their formation, migration, and evolution. The determination of exoplanet properties depends on the properties of their host stars. It is therefore important to characterise the host stars for accurate knowledge on their planets. Our final goal is to derive, in a homogeneous and accurate way, the stellar atmospheric parameters and elemental abundances of ten young TESS transiting planet-hosting GK stars followed up with the HARPS-N at TNG spectrograph within the GAPS programme. We derived stellar kinematic properties, atmospheric parameters, and abundances of 18 elements. Lithium line measurements were used as approximate age estimations. We exploited chemical abundances and their ratios to derive information on planetary composition. Elemental abundances and kinematic properties are consistent with the nearby Galactic thin disk. All targets show C/O<0.8 and 1.0<Mg/Si<1.5, compatible with silicate mantles made of a mixture of pyroxene and olivine assemblages. The Fe/Mg ratios, with values of $\\sim$0.7-1.0, show a propensity for the planets to have big (iron) cores. All stars hosting very low-mass planets show Mg/Si values consistent with the Earth values, thus demonstrating their similar mantle composition. Hot Jupiter host stars show a lower content of O/Si, which could be related to the lower presence of water content. We confirm a trend found in the literature between stellar [O/Fe] and total planetary mass, implying an important role of the O in shaping the mass fraction of heavy elements in stars and their disks. The detailed host star abundances provided can be employed for further studies on the composition of the planets within the current sample, when their atmospheres will be exploited.         _ Less","","arXiv","https://arxiv.org/abs/2409.00675","1","1","multiple"
"Electrolyte spraying within H$_2$ bubbles during water electrolysis","Abstract:                _mechanism where coalescence with microbubbles drives electrolyte droplets, resulting from the fragmentation of the Worthington jet, into the gas phase during hydrogen evolution reaction, both in normal and microgravity environments. This indicates that the H$_2$ bubble is not only composed of hydrogen gas and vapor but also includes electrolyte fractions. Re_         _ More           Electrolytically generated gas bubbles can significantly hamper the overall electrolysis efficiency. Therefore it is crucial to understand their dynamics in order to optimise water electrolyzer systems. Here we demonstrate a distinct transport mechanism where coalescence with microbubbles drives electrolyte droplets, resulting from the fragmentation of the Worthington jet, into the gas phase during hydrogen evolution reaction, both in normal and microgravity environments. This indicates that the H$_2$ bubble is not only composed of hydrogen gas and vapor but also includes electrolyte fractions. Reminiscent of bursting bubbles on a liquid-gas interface, this behavior results in a flow inside the bubble, which is further affected by Marangoni convection at the gas-electrolyte interface, highlighting interface mobility. In the case of electrode-attached bubbles, the sprayed droplets form electrolyte puddles at the bubble-electrode contact area, affecting the dynamics near the three-phase contact line and favoring bubble detachment from the electrode. The results of this work unravel important insights into the physicochemical aspects of electrolytic gas bubbles, integral for optimizing gas-evolving electrochemical systems. Besides, our findings are essential for studying the limits of jet formation and rupture relevant to acid mist formation in electrowinning, generation of sea spray aerosols, impact of droplets on liquid surfaces, etc.         _ Less","","arXiv","https://arxiv.org/abs/2409.00515","1","1","multiple"
"The Ones That Got Away: Chemical Tagging of Globular Cluster-Origin Stars with Gaia BP/RP Spectra","Abstract:                _they significantly contributed to the early Milky Way's stellar mass build-up. Although their role has since diminished, GCs' impact on the Galaxy's initial evolution can be traced today by identifying their most chemically unique stars--those with anomalous nitrogen and aluminum overabundances and oxygen d_         _ More           Globular clusters (GCs) are sites of extremely efficient star formation, and recent studies suggest they significantly contributed to the early Milky Way's stellar mass build-up. Although their role has since diminished, GCs' impact on the Galaxy's initial evolution can be traced today by identifying their most chemically unique stars--those with anomalous nitrogen and aluminum overabundances and oxygen depletion. While they are a perfect tracer of clusters, be it intact or fully dissolved, these high-[N/O], high-[Al/Fe] GC-origin stars are extremely rare within the current Galaxy. To address the scarcity of these unusual, precious former GC members, we train a neural network (NN) to identify high-[N/O], high-[Al/Fe] stars using low-resolution Gaia BP/RP spectra. Our NN achieves a classification accuracy of approximately $\\approx99\\%$ and a false positive rate of around $\\approx7\\%$, identifying 878 new candidates in the Galactic field. We validate our results with several physically-motivated sanity checks, showing, for example, that the incidence of selected stars in Galactic GCs is significantly higher than in the field. Moreover, we find that most of our GC-origin candidates reside in the inner Galaxy, having likely formed in the proto-Milky Way, consistent with previous research. The fraction of GC candidates in the field drops at a metallicity of [Fe/H]$\\approx-1$, approximately coinciding with the completion of spin-up, i.e. the formation of the Galactic stellar disk.         _ Less","","arXiv","https://arxiv.org/abs/2409.00197","1","1","multiple"
"Mapping radial abundance gradients with Gaia-ESO open clusters: Evidence of recent gas accretion in the Milky Way disk","Abstract:                Context. Recent evidences from spectroscopic surveys point towards the presence of a metal-poor, young stellar population in the chemical thin disk. In this context, the investigation of the spatial distribution and time_         _ More           Context. Recent evidences from spectroscopic surveys point towards the presence of a metal-poor, young stellar population in the chemical thin disk. In this context, the investigation of the spatial distribution and time evolution of precise, unbiased abundances is fundamental to disentangle the scenarios of evolution of the Galaxy. Aims. We study the evolution of abundance gradients in the Milky Way by taking advantage of a large sample of open clusters, which are among the best tracers for this purpose. In particular, we use data from the last release of the Gaia-ESO survey. Methods. We perform careful selection of open cluster stars excluding those that may be affected by biases in spectral analysis. The cleaned open clusters sample is compared with detailed chemical evolution models for the Milky Way, using well tested stellar yields and prescription for radial migration. Different scenarios of Galaxy evolution are tested to explain the data, i.e. the two-infall and the three-infall frameworks, suggesting that the chemical thin disk is formed by one or two subsequent gas accretion episodes, respectively. Results. With the performed selection in cluster stars, we still find a metallicity decrease between intermediate age (1<Age/Gyr<3) and young (Age<1Gyr) open clusters. This decrease cannot be explained in the context of the two-infall scenario, even by accounting for the effect of migration and yield prescriptions. The three-infall model, with its late gas accretion in the last 3 Gyr, can explain the low metallic content in young clusters. However, we invoke a milder metal dilution relative to previous findings. Conclusions. To explain the observed low metallic content in young clusters, we propose that a late gas accretion episode triggering metal dilution should have taken place, extending the framework of the three-infall model for the first time to the entire Galactic disk.         _ Less","","arXiv","https://arxiv.org/abs/2408.17395","2","2","multiple"
"Impact of ice growth on the physical and chemical properties of dense cloud cores","Abstract:                _hence on the dust temperature in a collapsing molecular cloud core, with the aim of quantifying the effect of the dust temperature variations on ice abundances as well as the evolution of the collapse. We employed a one-dimensional collapse model that self-consistently and time-dependently combines hydrodynamics with_         _ More           We investigated the effect of time-dependent ice growth on dust grains on the opacity and hence on the dust temperature in a collapsing molecular cloud core, with the aim of quantifying the effect of the dust temperature variations on ice abundances as well as the evolution of the collapse. We employed a one-dimensional collapse model that self-consistently and time-dependently combines hydrodynamics with chemical and radiative transfer simulations. The dust opacity was updated on-the-fly based on the ice growth as a function of location in the core. The results of the fully dynamical model were compared against simulations assuming fixed ice thickness. We found that the ice thickness increases fast and reaches a saturation value of approximately 90 monolayers in the central core (volume density $\\sim$$10^4\\,\\rm cm^{-3}$), and several tens of monolayers at a volume density of $\\sim$$10^3\\,\\rm cm^{-3}$, after only a few $10^5\\,\\rm yr$ of evolution. The results thus exclude the adoption of thin ($\\sim$10 monolayer) ices in molecular cloud simulations except at very short timescales. The differences in abundances and dust temperature between the fully dynamic simulation and those with fixed dust opacity are small; abundances change between the solutions generally within a factor of two. The assumptions on the dust opacity do have an effect on the collapse dynamics through the influence of the photoelectric effect on the gas temperature, and the simulations take a different time to reach a common central density. In conclusion, carrying out chemical simulations using a dust temperature corresponding to a fixed opacity seems to be a good approximation. Still, although at least in the present case its effect on the overall results is limited - as long as the grains are monodisperse - ice growth should be considered to obtain the most accurate representation of the collapse dynamics.         _ Less","","arXiv","https://arxiv.org/abs/2408.17202","0","2","synthetic_biology"
"The masses, structure and lifetimes of cold clouds in a high-resolution simulation of a low metallicity starburst","Abstract:                _0.1 pc spatial resolution) the multi-phase interstellar medium with a non-equilibrium chemical heating/cooling network at temperatures below $10^4$ K. Massive stars are sampled individually and interact with the ISM through the formation of HII regions and supernova explosions. In the extended starburst phase, the ISM is dominated by cold (_         _ More           We present an analysis of the cold gas phase in a low metallicity starburst generated in a high-resolution hydrodynamical simulation of a gas-rich dwarf galaxy merger as part of the GRIFFIN project. The simulations resolve (4 M$_\\odot$ gas phase mass resolution, $\\sim$ 0.1 pc spatial resolution) the multi-phase interstellar medium with a non-equilibrium chemical heating/cooling network at temperatures below $10^4$ K. Massive stars are sampled individually and interact with the ISM through the formation of HII regions and supernova explosions. In the extended starburst phase, the ISM is dominated by cold ($T_\\mathrm{gas} < 300$ K) filamentary clouds with self-similar internal structures. The clouds have masses of $10^{2.6}$ - $10^{5.6}$ M$_\\odot$ with a power law mass function, $dN/dM \\propto M^_$ with $_= -1.78 (\\pm 0.08)$. They also follow the Larson relations, in good agreement with observations. We trace the lifecycle of the cold clouds and find that they follow an exponential lifetime distribution and an e-folding time of $\\sim$ 3.5 Myr. Clouds with peak masses below $10^4$ M$_\\odot$ follow a power law relation with their average lifetime $__\\mathrm{life} \\propto M^{0.3}_\\mathrm{max}$ which flattens out for higher cloud masses at $ < 10$ Myr. A similar relation exists between cloud size at peak mass and lifetime. This simulation of the evolution of a realistic galactic cold cloud population supports the rapid formation and disruption of star-forming clouds by stellar radiation and supernovae on a timescale less than 10 Myr.         _ Less","","arXiv","https://arxiv.org/abs/2408.16887","1","1","multiple"
"The cosmic rate of Pair-Instability Supernovae","Abstract:                _supernovae (PISNe) have crucial implications for many astrophysical topics, including the search for very massive stars, the black hole mass spectrum, and galaxy chemical enrichment. To this end, we need to understand where PISNe are across cosmic time, and what are their favourable galactic environments. We present a new determination of the PISN rate as a_         _ More           Pair-instability supernovae (PISNe) have crucial implications for many astrophysical topics, including the search for very massive stars, the black hole mass spectrum, and galaxy chemical enrichment. To this end, we need to understand where PISNe are across cosmic time, and what are their favourable galactic environments. We present a new determination of the PISN rate as a function of redshift, obtained by combining up-to-date stellar evolution tracks from the PARSEC and FRANEC codes, with an up-to-date semi-empirical determination of the star formation rate and metallicity evolution of star-forming galaxies throughout cosmic history. We find the PISN rate to exhibit a huge dependence on the model assumptions, including the criterion to identify stars unstable to pair production, and the upper limit of the stellar initial mass function. Remarkably, the interplay between the maximum metallicity at which stars explode as PISNe, and the dispersion of the galaxy metallicity distribution, dominates the uncertainties, causing a $\\sim$ seven-orders-of-magnitude PISN rate range. Furthermore, we show a comparison with the core-collapse supernova rate, and study the properties of the favourable PISN host galaxies. According to our results, the main contribution to the PISN rate comes from metallicities between $\\sim 10^{-3}$ and $10^{-2}$, against the common assumption that views very-low-metallicity, Population III stars as exclusive or dominant PISN progenitors. The strong dependencies we find offer the opportunity to constrain stellar and galaxy evolution models based on possible future (or the lack of) PISN observations.         _ Less","","arXiv","https://arxiv.org/abs/2408.16823","1","1","multiple"
"The AMBRE Project: Lead abundance in Galactic stars","Abstract:                The chemical_         _ More           The chemical evolution of neutron capture elements in the Milky Way is still a matter of debate. Although more and more studies investigate their chemical behaviour, there is still a lack of a significant large sample of abundances of a key heavy element: lead. Lead is the final product of the s-process nucleosynthesis channel and is one of the most stable heavy elements. We analysed high-resolution spectra from the ESO UVES and FEROS archives. Atmospheric parameters were taken from the AMBRE parametrisation. We used the automated abundance method GAUGUIN to derive lead abundances in 653 slow-rotating FGK-type stars from the 368.34nm Pb I line. We present the largest catalogue of homogeneous LTE and non-LTE lead abundances ever published with metallicities ranging from -2.9 to 0.6dex and [Pb/Fe] from -0.7 to 3.3dex. Within this sample, no lead-enhanced Asymptotic Giant Branch (AGB) stars were found, but nine lead-enhanced metal-poor stars ([Pb/Fe] > 1.5) were detected. Most of them were already identified as carbon-enhanced metal-poor stars with enrichments in other s-process species. The lead abundance of 13 Gaia Benchmark Stars are also provided. We then investigated the Pb content of the Milky Way disc by computing vertical and radial gradients and found a slightly decreasing [Pb/Fe] radial trend with metallicity. This trend together with other related ratios ([Pb/Eu], [Pb/Ba], and [Pb/alpha]) are interpreted thanks to chemical evolution models. The two-infall model closely reproduces the observed trends with respect to the metallicity. It is also found that the AGB contribution to the Pb Galactic enrichment has to be strongly reduced. Moreover, the contribution of massive stars with rather high rotational velocities should be favoured in the low-metallicity regime.         _ Less","","arXiv","https://arxiv.org/abs/2408.16292","1","1","multiple"
"HR-GO I: Comprehensive NLTE abundance analysis of the Cetus stream","Abstract:                _Due to the variation in the timescales of star formation history in their progenitors, stellar streams serve as `snapshots' that record different stages of galactic chemical_         _ More           Dwarf galaxy streams encode vast amounts of information essential to understanding early galaxy formation and nucleosynthesis channels. Due to the variation in the timescales of star formation history in their progenitors, stellar streams serve as `snapshots' that record different stages of galactic chemical evolution. This study focusses on the Cetus stream, stripped from a low-mass dwarf galaxy. We carried out a comprehensive analysis of the chemical composition of 22 member stars based on their high-resolution spectra. We derived abundances for up to 28 chemical species from C to Dy and, for 20 of them, we account for the departures from local thermodynamic equilibrium. We confirm that the Cetus stream has a mean metallicity of [Fe/H] = $-2.11$ $\\pm$ 0.21. All observed Cetus stars are $_$ enhanced with [$_$/Fe] $\\simeq$ 0.3. The absence of the $_$-`knee' implies that star formation stopped before iron production in type Ia supernovae (SNe Ia) became substantial. Neutron capture element abundances suggest that both the rapid (r-) and the main slow (s-) processes contributed to their origin. The decrease in [Eu/Ba] from a typical r-process value of [Eu/Ba] = 0.7 to 0.3 with increasing [Ba/H] indicates a distinct contribution of the r- and s-processes to the chemical composition of different Cetus stars. For barium, the r-process contribution varies from 100 % to 20 % in different sample stars, with an average value of 50 %. Our abundance analysis indicates that the star formation in the Cetus progenitor ceased after the onset of the main s-process in low- to intermediate-mass asymptotic giant branch stars but before SNe Ia played an important role. A distinct evolution scenario is revealed by comparing the abundances in the Ursa Minor dwarf spheroidal galaxy, showing the diversity in the chemical evolution of low-mass dwarf galaxies.         _ Less","","arXiv","https://arxiv.org/abs/2408.16107","3","2","origin_of_life"
"Analysis of Stochastic Chemical Reaction Networks with a Hierarchy of Timescales","Abstract:                We investigate a class of stochastic chemical reaction networks with $n{\\ge}1$ chemical species $S_1$, \\ldots, $S_n$, and whose complexes are only of the form $k_iS_i$, $i{=}1$,\\ldots, $n$, where $(k_i)$ are integers. The time_         _ More           We investigate a class of stochastic chemical reaction networks with $n{\\ge}1$ chemical species $S_1$, \\ldots, $S_n$, and whose complexes are only of the form $k_iS_i$, $i{=}1$,\\ldots, $n$, where $(k_i)$ are integers. The time evolution of these CRNs is driven by the kinetics of the law of mass action. A scaling analysis is done when the rates of external arrivals of chemical species are proportional to a large scaling parameter $N$. A natural hierarchy of fast processes, a subset of the coordinates of $(X_i(t))$, is determined by the values of the mapping $i{\\mapsto}k_i$. We show that the scaled vector of coordinates $i$ such that $k_i{=}1$ and the scaled occupation measure of the other coordinates are converging in distribution to a deterministic limit as $N$ gets large. The proof of this result is obtained by establishing a functional equation for the limiting points of the occupation measure, by an induction on the hierarchy of timescales and with relative entropy functions.         _ Less","","arXiv","https://arxiv.org/abs/2408.15697","0","2","synthetic_biology"
"Ice Chemistry Modeling of Active Phase Comets: Hale-Bopp","Abstract:                We present a chemical kinetics model of the solid-phase_         _ More           We present a chemical kinetics model of the solid-phase chemical evolution of a comet, beginning with a long period of cold-storage in the Oort Cloud, followed by five orbits that bring the comet close to the Sun. The chemical model is based on an earlier treatment that considered only the cold-storage phase, and which was based on the interstellar ice chemical kinetics model MAGICKAL. The comet is treated as 25 chemically distinct layers. Updates to the previous model includes: (i) Time- and depth-dependent temperature profiles according to heliocentric distance; (ii) a rigorous treatment of back-diffusion for species capable of diffusing through the bulk-ice layers; (iii) adoption of recent improvements in the kinetic treatment of nondiffusive chemical reaction rates. Starting from an initially simple ice composition, interstellar UV photons drive a rapid chemistry in the upper micron of material, but diminished by absorption of the UV by the dust component. Galactic cosmic rays (GCRs) drive a much slower chemistry in the deeper ices over the long cold-storage period down to 10 m. The first solar approach drives off the upper layers of ice material via thermal desorption and/or dissociation, bringing closer to the surface the deeper material that previously underwent long-term processing by GCRs. Subsequent orbits are more uniform in their chemical behavior. Loss of molecular material leads to concentration of the dust in the upper layers. Substantial quantities of complex organic molecules are formed in the upper 10 m during the cold storage phase, with some of this material released during solar approach; however, their abundances with respect to water appear too low to account for the observed gas-phase values for comet Hale-Bopp, indicating that the majority of complex molecular material observed, at least in comet Hale-Bopp, is an inheritance of primordial material.         _ Less","","arXiv","https://arxiv.org/abs/2408.15509","1","1","multiple"
"Tracking the Electron Density Changes in Excited States -- A Computational Study on Pyrazine","Abstract:                _combined X-ray scattering theory and trajectory surface hopping approach to resolve dynamical changes in the electronic structure of photo-excited molecules by studying time evolution of electron density changes between electronic excited states and ground state. Using pyrazine molecule as an example, we show that key features of reaction pathways can be ide_         _ More           The development of X-ray free-electron lasers (XFELs) has enabled ultrafast X-ray diffraction (XRD) experiments, which are capable of resolving electronic/vibrational transitions and structural changes in molecules, or capturing molecular movies. While time-resolved XRD has received increasing attention, the extraction of information content from signals is challenging and requires theoretical support. In this work, we combined X-ray scattering theory and trajectory surface hopping approach to resolve dynamical changes in the electronic structure of photo-excited molecules by studying time evolution of electron density changes between electronic excited states and ground state. Using pyrazine molecule as an example, we show that key features of reaction pathways can be identified, enabling the capture of structural changes associated with electronic transitions for a photo-excited molecule.         _ Less","","arXiv","https://arxiv.org/abs/2408.15494","1","1","multiple"
"Data-Driven Approach to Learning Optimal Forms of Constitutive Relations in Models Describing Lithium Plating in Battery Cells","Abstract:                _from the fundamental Doyle-Fuller-Newman (DFN) model, we use asymptotic reduction and spatial averaging techniques to derive a simplified representation to track the temporal evolution of two key concentrations in the system, namely, the total intercalated Lithium on the negative electrode particles and total plated Lithium. This model depends on an a priori_         _ More           In this study we construct a data-driven model describing Lithium plating in a battery cell, which is a key process contributing to degradation of such cells. Starting from the fundamental Doyle-Fuller-Newman (DFN) model, we use asymptotic reduction and spatial averaging techniques to derive a simplified representation to track the temporal evolution of two key concentrations in the system, namely, the total intercalated Lithium on the negative electrode particles and total plated Lithium. This model depends on an a priori unknown constitutive relations of the cell as a function of thestate variables. An optimal form of this constitutive relation is then deduced from experimental measurements of the time dependent concentrations of different Lithium phases acquired through Nuclear Magnetic Resonance spectroscopy. This is done by solving an inverse problem in which this constitutive relation is found subject to minimum assumptions as a minimizer of a suitable constrained optimization problem where the discrepancy between the model predictions and experimental data is minimized. This optimization problem is solved using a state-of-the-art adjoint-based technique. In contrast to some of the earlier approaches to modelling Lithium plating, the proposed model is able to predict non-trivial evolution of the concentrations in the relaxation regime when no current isapplied to the cell. When equipped with an optimal constitutive relation, the model provides accurate predictions of the time evolution of both intercalated and plated Lithium across a wide range of charging/discharging rates. It can therefore serve as a useful tool for prediction and control of degradation mechanism in battery cells.         _ Less","","arXiv","https://arxiv.org/abs/2408.14804","0","1","synthetic_biology"
"Soft X-ray emission from the classical nova AT 2018bej","Abstract:                _to the eRASS1 epoch. We aim to describe the eROSITA and XMM-Newton spectra of AT 2018bej with our local thermodynamic equilibrium (LTE) atmosphere models. We focused on the evolution of the hot WD properties between the eRASS1 and eRASS2 epochs, especially on the change of the carbon abundance. A grid of LTE model atmosphere spectra were calculated for diffe_         _ More           Classical novae are known to demonstrate a supersoft X-ray source (SSS) state following outbursts, which is associated with residual thermonuclear burning on the white dwarf (WD) surface. During its all-sky survey (eRASS1), the eROSITA telescope onboard the Spectrum-Roentgen-Gamma observatory discovered a bright new SSS, whose position is consistent with the known classical nova AT 2018bej in the Large Magellanic Cloud. There were two eROSITA spectra obtained during eRASS1 and eRASS2 monitoring epochs and one XMM-Newton grating spectrum close to the eRASS1 epoch. We aim to describe the eROSITA and XMM-Newton spectra of AT 2018bej with our local thermodynamic equilibrium (LTE) atmosphere models. We focused on the evolution of the hot WD properties between the eRASS1 and eRASS2 epochs, especially on the change of the carbon abundance. A grid of LTE model atmosphere spectra were calculated for different values of the effective temperature (from $T_{\\rm eff}= 525$ to $700\\,\\rm kK$), surface gravity (six values) and chemical composition with five different values of carbon and nitrogen abundances. Both eRASS1 and XMM $0.3-0.6$ keV spectral analyses yield a temperature of the WD of $T_{\\rm eff}{\\sim}\\,600\\, \\rm kK$ and a WD radius of $8000-8700\\,\\rm km$. Simultaneous fitting of the eROSITA spectra for two epochs (eRASS1 and eRASS2) with a common WD mass parameter demonstrates a decrease in $T_{\\rm eff}$ accompanied by an increase in the WD radius and a decrease in the carbon abundance. However, these changes are marginal and coincide within errors. The derived WD mass is estimated to be $1.05-1.15\\, M_\\odot$. We traced a minor evolution of the source on a half-year timescale accompanied by a decrease in carbon abundance and concluded that LTE model atmospheres can be used to analyse the available X-ray spectra of classical novae during their SSS stage.         _ Less","","arXiv","https://arxiv.org/abs/2408.14171","1","2","synthetic_biology"
"Laser-induced fragmentation of coronene cations","Abstract:                Polycyclic aromatic hydrocarbons are an important component of the interstellar medium of galaxies and photochemistry plays a key role in the evolution of these species in space. Here, we explore the photofragmentation behaviour of the coronene cation (C24H12+) using time of flight mass spectrometry. The experiments show photodissociation fragmentation chann_         _ More           Polycyclic aromatic hydrocarbons are an important component of the interstellar medium of galaxies and photochemistry plays a key role in the evolution of these species in space. Here, we explore the photofragmentation behaviour of the coronene cation (C24H12+) using time of flight mass spectrometry. The experiments show photodissociation fragmentation channels including the formation of bare carbon clusters (Cn+) and hydrocarbon chains (CnHx+). The mass spectrum of coronene is dominated by peaks from C11+ and C7H+. Density functional theory was used to calculate relative energies, potential dissociation pathways, and possible structures for relevant species. We identify 6-6 to 5-7 ring isomerisation as a key step in the formation of both the bare carbon clusters and the hydrocarbon chains observed in this study. We present the dissociation mechanism outlined here as a potential formation route for C60 and other astrochemically relevant species.         _ Less","","arXiv","https://arxiv.org/abs/2408.13141","1","2","synthetic_biology"
"The rates and host galaxies of pair-instability supernovae through cosmic time: Predictions from BPASS and IllustrisTNG","Abstract:                _PISN has been observed to date, leaving theoretical modelling validation open. To investigate the observability of these explosive transients, we combine detailed stellar evolution models for PISNe formation, computed from the Binary Population and Spectral Synthesis code suite, BPASS, with the star formation history of all individual computational elements_         _ More           Pair-instability supernovae (PISNe) have long been predicted to be the final fates of near-zero-metallicity very massive stars ($Z < Z_\\odot/3$, $\\mathrm{M}_\\mathrm{ZAMS} \\gtrsim 140 \\mathrm{M}_\\odot$). However, no definite PISN has been observed to date, leaving theoretical modelling validation open. To investigate the observability of these explosive transients, we combine detailed stellar evolution models for PISNe formation, computed from the Binary Population and Spectral Synthesis code suite, BPASS, with the star formation history of all individual computational elements in the Illustris-TNG simulation. This allows us to compute comic PISN rates and predict their host galaxy properties. Of particular importance is that IllustrisTNG galaxies do not have uniform metallicities throughout, with metal-enriched galaxies often harbouring metal-poor pockets of gas where PISN progenitors may form. Accounting for the chemical inhomogeneities within these galaxies, we find that the peak redshift of PISNe formation is $z=3.5$ instead of the value of $z=6$ when ignoring chemical inhomogeneities within galaxies. Furthermore, the rate increases by an order of magnitude from 1.9 to 29 PISN Gpc$^{-3}$ yr$^{-1}$ at $z=0$, if the chemical inhomogeneities are considered. Using state-of-the-art theoretical PISN light curves, we find an observed rate of $13.8$ (1.2) visible PISNe per year for the Euclid-Deep survey, or $83$ (7.3) over the six-year lifetime of the mission when considering chemically inhomogeneous (homogenous) systems. Interestingly, only 12 per cent of helium PISN progenitors are sufficiently massive to power a super-luminous supernova event, which can potentially explain why PISN identification in time-domain surveys remains elusive and progress requires dedicated strategies.         _ Less","","arXiv","https://arxiv.org/abs/2408.13076","2","2","multiple"
"M giants with IGRINS IV. Identification and characterization of a near-IR line of the s-element Barium","Abstract:                Neutron-capture elements represent an important nucleosynthetic channel in the study of the Galactic Chemical Evolution of stellar populations. For stellar populations behind significant extinction, such as those in the Galactic Center and along the Galactic plane, abundance analyses based on near-IR spectra are necess_         _ More           Neutron-capture elements represent an important nucleosynthetic channel in the study of the Galactic Chemical Evolution of stellar populations. For stellar populations behind significant extinction, such as those in the Galactic Center and along the Galactic plane, abundance analyses based on near-IR spectra are necessary. Previously, spectral lines from the neutron-capture elements such as copper (Cu), cerium (Ce), neodymium (Nd), and ytterbium (Yb) have been identified in the H band, while yttrium (Y) lines have been identified in the K band. Due to the scarcity of spectral lines from neutron-capture elements in the near-IR, the addition of useful spectral lines from other neutron-capture elements is highly desirable. The aim of this work is to identify and characterise a spectral line suitable for abundance determination from the most commonly used s-process element, namely barium. We observed near-IR spectra of 37 M giants in the solar neighbourhood at high S/N and high spectral resolution using the IGRINS spectrometer on the GEMINI South telescope. Using a manual spectral synthesis method, we determined the stellar parameters for these stars and derived the barium abundance from the Ba line (6s5d $^3$D$_2 \\rightarrow$ 6s6p $^3$P$^o_2$) at $__\\mathrm{air}=23\\,253.56\\,$_ in the K band. We demonstrate that the Ba line in the K band at 2.33\\,\\mic\\ ($_$23253.56) is useful for abundance analysis from spectra of M giants. The line becomes progressively weaker at higher temperatures and is only useful in M giants and the coolest K giants at supersolar metallicities. We can now add Ba to the trends of the heavy elements Cu, Zn, Y, Ce, Nd, and Yb, which can be retrieved from high-resolution H- and K-band spectra. This opens up the study of nucleosynthetic channels, including the s-process and the r-process, in dust-obscured populations such as the Galactic Center.         _ Less","","arXiv","https://arxiv.org/abs/2408.12971","1","1","multiple"
"An Analytic Model of Gravitational Collapse Induced by Radiative Cooling: Instability Scale, Infall Velocity, and Accretion Rate","Abstract:                _from the legitimate instability this contraction establishes in the envelope. We develop a refined criterion for the mass scale of this instability, based only on the chemical-thermal evolution in the core. We explicate our model in the context of a primordial mini-halo cooled by molecular hydrogen, and then provide tw_         _ More           We present an analytic description of the spherically symmetric gravitational collapse of radiatively cooling gas clouds, which illustrates the mechanism by which radiative cooling induces gravitational instability at a characteristic mass scale determined by the microphysics of the gas. The approach is based on developing the 'one-zone' density-temperature relationship of the gas into a full dynamical model. We convert this density-temperature relationship into a barotropic equation of state, which we use to calculate the density and velocity profiles of the gas. From these quantities, we calculate the time-dependent mass accretion rate onto the center of the cloud. The approach clarifies the mechanism by which radiative cooling induces gravitational instability. In particular, we distinguish the rapid, quasi-equilibrium contraction of a cooling gas core to high central densities from the legitimate instability this contraction establishes in the envelope. We develop a refined criterion for the mass scale of this instability, based only on the chemical-thermal evolution in the core. We explicate our model in the context of a primordial mini-halo cooled by molecular hydrogen, and then provide two further examples, a delayed collapse with hydrogen deuteride cooling and the collapse of an atomic cooling halo. In all three cases, we show that our results agree well with full hydrodynamical treatments.         _ Less","","arXiv","https://arxiv.org/abs/2408.12940","0","1","synthetic_biology"
"Mapping Hydrogen Evolution Activity Trends of V-based A15 Superconducting Alloys","Abstract:                Exploring high-efficiency and low-cost electrocatalysts is valuable for water-splitting technologies. Recently, Si-group compounds have attracted increasing attention in electrocatalysis, considering the abundant Si-group elements on Earth. However, Si-group compounds for HER electrocatalysis have not been systematically studied. In this study, we unveil the activity trends of non-noble metal cata_         _ More           Exploring high-efficiency and low-cost electrocatalysts is valuable for water-splitting technologies. Recently, Si-group compounds have attracted increasing attention in electrocatalysis, considering the abundant Si-group elements on Earth. However, Si-group compounds for HER electrocatalysis have not been systematically studied. In this study, we unveil the activity trends of non-noble metal catalyst A15-type V3M (i.e., V3Si, V3Ge, and V3Sn) superconductors and show that V3Si is the most efficient HER catalyst because of the high electronic conductivity and suitable d-band center. Among them, the V3Si only requires 33.4 mV to reach 10 mA cm-2, and only 57.6 mV and 114.6 mV are required to attain a high current density of 100 mA cm-2 and 500 mA cm-2, respectively. These low overpotentials are close to the 34.3 mV at 10 mA cm-2 of state-of-art Pt/C (20 %) but superior to 168.5 mV of Pt/C (20 %) at 100 mA cm-2. Furthermore, the V3Si illustrates exceptional durability with no obvious decay in the 120 h at the different current densities (i.e., 10 - 250 mA cm-2). The excellent HER activity of V3Si alloy can be ascribed to the synergies of superior electronic conductivity and suitable d-band center. Moreover, DFT calculations reveal that the absolute hydrogen adsorption Gibbs free energy is decreased after introducing the V to Si. Beyond offering a stable and high-performance electrocatalyst in an acidic medium, this work inspires the rational design of desirable silicide electrocatalysts.         _ Less","","arXiv","https://arxiv.org/abs/2408.12160","0","1","synthetic_biology"
"Variability and stellar pulsation incidence in Am/Fm stars using TESS and Gaia data","Abstract:                Aims. We aim to study chemically peculiar Am and Fm stars, distinguished by their unique abundance patterns, which are crucial for studying mixing processes in intermediate-mass stars. These stars provide a window into the atomic diffusion in their stellar envelopes, the evolution-dependent changes in mixing, and the r_         _ More           Aims. We aim to study chemically peculiar Am and Fm stars, distinguished by their unique abundance patterns, which are crucial for studying mixing processes in intermediate-mass stars. These stars provide a window into the atomic diffusion in their stellar envelopes, the evolution-dependent changes in mixing, and the resulting effects on pulsation mechanisms. Methods. This study examines the pulsation characteristics of the Am/Fm star group. Our analysis encompasses 1276 stars (available as catalogues on GitHub), utilising data from TESS and Gaia and focusing on stars from the Renson catalogue. Results. In our sample, 51% (649 stars) display no variability, thus categorised as constant stars. Among the remaining, 25% (318 stars) are pulsating Am/Fm and _ Puppis stars, including 20% (261 stars) that are exclusively Am/Fm stars. Additionally, 17% (210 stars) show variability indicative of binarity and/or rotational modulation and 7% (93 stars) are eclipsing binaries. Of the pulsating stars, 10% (32 stars) are _ Doradus type, 54% (172 stars) _ Scuti type, and 36% (114 stars) are hybrids, underlining a diverse pulsational behaviour of Am/Fm stars. Conclusions. Our findings indicate that pulsating stars predominantly occupy positions near the red edge of the classical instability strip, allowing us to ascertain the incidence of pulsations in this stellar population.         _ Less","","arXiv","https://arxiv.org/abs/2408.11657","0","1","synthetic_biology"
"Second-order spin hydrodynamics from Zubarev's nonequilibrium statistical operator formalism","Abstract:                _, contains the spin chemical potential. In this work, we have also taken the spin density ($S^{_}$) as an independent thermodynamic variable, in addition to the energy density and particle density, thereby resulting in an additional transport coefficient given by the correlation between $S^{_}$ and $_^{_}$. The newly found terms in $__{_}$ and $_$ are th_         _ More           Using the Zubarev's nonequilibrium statistical operator formalism, we derive the second-order dissipative tensors in relativistic spin hydrodynamics, {\\em viz.} rotational stress tensor ($__{_}$), boost heat vector ($q__$), shear stress tensor ($__{_}$) and bulk viscous pressure ($_$). The first two ($__{_}$ and $q__$) emerge due to the inclusion of the antisymmetric part in the energy-momentum tensor, which, in turn, governs the conservation of spin angular momentum ($_^{_}$). As a result, new thermodynamic forces, generated due to the antisymmetric part of $T_{_}$, contains the spin chemical potential. In this work, we have also taken the spin density ($S^{_}$) as an independent thermodynamic variable, in addition to the energy density and particle density, thereby resulting in an additional transport coefficient given by the correlation between $S^{_}$ and $_^{_}$. The newly found terms in $__{_}$ and $_$ are the artifacts of the new thermodynamic forces that arise due to the antisymmetric part of $T^{_}$. Finally we have derived the evolution equations for the aforesaid tensors - $__{_}$, $q__$, $__{_}$, and $_$.         _ Less","","arXiv","https://arxiv.org/abs/2408.11514","0","1","synthetic_biology"
"2-process Model and Residual Abundance Analysis of the Milky Way Massive Satellites","Abstract:                The ``2-process Model'' is a promising technique for interpreting stellar chemical abundance data from large-scale surveys (e.g., SDSS-IV/V, GALAH), enabling more quantitative empirical studies of differences in_         _ More           The ``2-process Model'' is a promising technique for interpreting stellar chemical abundance data from large-scale surveys (e.g., SDSS-IV/V, GALAH), enabling more quantitative empirical studies of differences in chemical enrichment history between galaxies without relying on detailed yield and evolution models. In this work, we fit 2-process model parameters to (1) a luminous giant Milky Way (MW) sample and (2) stars comprising the Sagittarius Dwarf Galaxy (Sgr). We then use these two sets of model parameters to predict the abundances of 14 elements of stars belonging to the MW and in five of its massive satellite galaxies, analyzing the residuals between the predicted and observed abundances. We find that the model fit to (1) results in large residuals (0.1-0.3 dex) for most metallicity-dependent elements in the metal-rich ([Mg/H] $>$ -0.8) stars of the satellite galaxies. However, the model fit to (2) results in small or no residuals for all elements across all satellite galaxies. Therefore, despite the wide variation in [X/Mg]-[Mg/H] abundance patterns of the satellite galaxies, the 2-process framework provides an accurate characterization of their abundance patterns across many elements, but these multi-element patterns are systematically different between the dwarf galaxy satellites and the MW disks. We consider a variety of scenarios for the origin of this difference, highlighting the possibility that a large inflow of pristine gas to the MW disk diluted the metallicity of star-forming gas without changing abundance ratios.         _ Less","","arXiv","https://arxiv.org/abs/2408.10393","1","2","synthetic_biology"
"Regularity Propagation of Global Weak Solutions to a Navier-Stokes-Cahn-Hilliard System for Incompressible Two-phase Flows with Chemotaxis and Active Transport","Abstract:                _the dynamics of incompressible viscous two-phase flows, incorporating mechanisms such as chemotaxis, active transport, and long-range interactions of Oono's type. The evolution system couples the Navier-Stokes equations for the volume-averaged fluid velocity $\\bm{v}$, a convective Cahn-Hilliard equation for the phase-field variable $\\varphi$, and an adve_         _ More           We analyze a diffuse interface model that describes the dynamics of incompressible viscous two-phase flows, incorporating mechanisms such as chemotaxis, active transport, and long-range interactions of Oono's type. The evolution system couples the Navier-Stokes equations for the volume-averaged fluid velocity $\\bm{v}$, a convective Cahn-Hilliard equation for the phase-field variable $\\varphi$, and an advection-diffusion equation for the density of a chemical substance $_$. For the initial-boundary value problem with a physically relevant singular potential in three dimensions, we demonstrate that every global weak solution $(\\bm{v}, \\varphi, _)$ exhibits a propagation of regularity over time. Specifically, after an arbitrary positive time, the phase-field $\\varphi$ transitions into a strong solution, whereas the chemical density $_$ only partially regularizes. Subsequently, the velocity field $\\bm{v}$ becomes regular after a sufficiently large time, followed by a further regularization of the chemical density $_$, which in turn enhances the spatial regularity of $\\varphi$. Furthermore, we show that every global weak solution stabilizes towards a single equilibrium as $t\\to +\\infty$. Our analysis uncovers the influence of chemotaxis, active transport, and long-range interactions on the propagation of regularity at different stages of time. The proof relies on several key points, including a novel regularity result for a convective Cahn-Hilliard-diffusion system with minimal regularity requirements on the velocity field $\\bm{v}$, the strict separation property of $\\varphi$ for large times, as well as two conditional uniqueness results pertaining to the full system and its subsystem for $(\\varphi, _)$ with a given velocity, respectively.         _ Less","","arXiv","https://arxiv.org/abs/2408.09514","0","1","synthetic_biology"
"Advancements in Molecular Property Prediction: A Survey of Single and Multimodal Approaches","Abstract:                _Prediction (MPP) plays a pivotal role across diverse domains, spanning drug discovery, material science, and environmental chemistry. Fueled by the exponential growth of chemical data and the evolution of artificial intelligence, recent years have witnessed remarkable strides in MPP. However, the multifaceted nature of_         _ More           Molecular Property Prediction (MPP) plays a pivotal role across diverse domains, spanning drug discovery, material science, and environmental chemistry. Fueled by the exponential growth of chemical data and the evolution of artificial intelligence, recent years have witnessed remarkable strides in MPP. However, the multifaceted nature of molecular data, such as molecular structures, SMILES notation, and molecular images, continues to pose a fundamental challenge in its effective representation. To address this, representation learning techniques are instrumental as they acquire informative and interpretable representations of molecular data. This article explores recent AI/-based approaches in MPP, focusing on both single and multiple modality representation techniques. It provides an overview of various molecule representations and encoding schemes, categorizes MPP methods by their use of modalities, and outlines datasets and tools available for feature generation. The article also analyzes the performance of recent methods and suggests future research directions to advance the field of MPP.         _ Less","","arXiv","https://arxiv.org/abs/2408.09461","2","4","synthetic_biology"
"On the Formation of Planets in the Milky Way's Thick Disk","Abstract:                _orders of magnitude more intense than in solar neighborhood conditions. Coupling the radiation field to a one-dimensional protoplanetary disk evolution model, we find that external UV photoevaporation destroys protoplanetary disks in just ${\\sim}$0.2--0.5 Myr, limiting the timescale over which planets can assemble. Disk temperatures exceed the sublimation t_         _ More           Exoplanet demographic surveys have revealed that close-in (${\\lesssim}$1 au) small planets orbiting stars in the Milky Way's thick disk are ${\\sim}50\\%$ less abundant than those orbiting stars in the Galactic thin disk. One key difference between the two stellar populations is the time at which they emerged: thick disk stars are the likely product of cosmic noon (redshift $z {\\sim}2$), an era characterized by high star formation rate, massive and dense molecular clouds, and strong supersonic turbulence. Solving for the background radiation field in these early star-forming regions, we demonstrate that protoplanetary disks at cosmic noon experienced radiation fields up to ${\\sim}7$ orders of magnitude more intense than in solar neighborhood conditions. Coupling the radiation field to a one-dimensional protoplanetary disk evolution model, we find that external UV photoevaporation destroys protoplanetary disks in just ${\\sim}$0.2--0.5 Myr, limiting the timescale over which planets can assemble. Disk temperatures exceed the sublimation temperatures of common volatile species for ${\\gtrsim}$Myr timescales, predicting more spatial homogeneity in gas chemical composition. Our calculations imply that the deficit in planet occurrence around thick disk stars should be even more pronounced for giant planets, particularly those at wide orbital separations, predicting a higher rocky-to-giant planet ratio in the Galactic thick disk vs.~thin disk.         _ Less","","arXiv","https://arxiv.org/abs/2408.09319","2","2","multiple"
"DIISC-IV: DIISCovery of Anomalously Low Metallicity H II Regions in NGC 99: Indirect Evidence of Gas Inflows","Abstract:                _. Chemical evolution modeling indicates gas accretion as the cause of the ALM regions. We find evidence for corotation between the interstellar medium of NGC 99 and Ly$_$ clouds in its circumgalactic medium, which suggests a possible pathway for low metallicity gas accretion. We also calculate the resolved Fundamental_         _ More           As a part of the Deciphering the Interplay between the Interstellar medium, Stars, and the Circumgalactic medium (DIISC) survey, we investigate indirect evidence of gas inflow into the disk of the galaxy NGC 99. We combine optical spectra from the Binospec spectrograph on the MMT telescope with optical imaging data from the Vatican Advanced Technology Telescope, radio HI 21 cm emission images from the NSF Karl G. Jansky's Very Large Array, and UV spectroscopy from the Cosmic Origins Spectrograph on the Hubble Space Telescope. We measure emission lines (H$_$, H$_$, [O III]$\\lambda5007$, [N II]$\\lambda6583$, and [S II]$\\lambda6717,31$) in 26 H II regions scattered about the galaxy and estimate a radial metallicity gradient of $-0.017$ dex kpc$^{-1}$ using the N2 metallicity indicator. Two regions in the sample exhibit an anomalously low metallicity (ALM) of 12+log(O/H) = 8.36 dex, which is $\\sim$0.16 dex lower than other regions at that galactocentric radius. They also show a high difference between their HI and H$_$ line of sight velocities on the order of 35 km s$^{-1}$. Chemical evolution modeling indicates gas accretion as the cause of the ALM regions. We find evidence for corotation between the interstellar medium of NGC 99 and Ly$_$ clouds in its circumgalactic medium, which suggests a possible pathway for low metallicity gas accretion. We also calculate the resolved Fundamental Metallicity Relation (rFMR) on sub-kpc scales using localized gas-phase metallicity, stellar mass surface density, and star-formation rate surface density. The rFMR shows a similar trend as that found by previous localized and global FMR relations.         _ Less","","arXiv","https://arxiv.org/abs/2408.08303","3","2","origin_of_life"
"Infrared Spectra of Solid HCN Embedded in Various Molecular Environments for Comparison with the Data Obtained with JWST","Abstract:                HCN molecules serve as an important tracer for chemical evolution of elemental nitrogen in the regions of star and planet formation. This is largely explained by the fact that N atoms and N$_2$ molecules are poorly accessible for the observation in the radio and infrared ranges. In turn, gas-phase HCN can be observed a_         _ More           HCN molecules serve as an important tracer for chemical evolution of elemental nitrogen in the regions of star and planet formation. This is largely explained by the fact that N atoms and N$_2$ molecules are poorly accessible for the observation in the radio and infrared ranges. In turn, gas-phase HCN can be observed at various stages of star formation including disks arounds young stars, cometary comas and atmospheres of the planetary satellites. Despite the large geography of gas-phase observations, an identification of interstellar HCN ice is still lacking. In this work we present a series of infrared spectroscopic measurements performed at the new ultra-high vacuum cryogenic apparatus aiming to facilitate the search for interstellar HCN ice. A series of high resolution laboratory infrared spectra of HCN molecules embedded in the H$_2$O, H$_2$O:NH$_3$, CO, CO$_2$ and CH$_3$OH ices at 10~K temperature is obtained. These interstellar ice analogues aim to simulate the surroundings of HCN molecules by the main constituents of the icy mantles on the surface of the interstellar grains. In addition, the spectra of HCN molecules embedded in the solid C$_6$H$_6$, C$_5$H$_5$N and C$_6$H$_5$NH$_2$ are obtained to somehow simulate the interaction of HCN molecules with carbonaceous material of the grains rich in polycyclic aromatic hydrocarbons. The acquired laboratory spectroscopic data are compared with the publicly available results of NIRSpec James Webb Space Telescope observations towards quiescent molecular clouds performed by the ICEAge team.         _ Less","","arXiv","https://arxiv.org/abs/2408.08166","2","1","origin_of_life"
"Chemical complexity and dust formation around evolved stars","Abstract:                The outflows of asymptotic giant branch (AGB) stars are rich astrochemical laboratories, hosting different chemical regimes: from non-equilibrium chemistry close to the star, to dust formation further out, and finally photochemistry in the outer regions. Chemistry is crucial for understanding the driving mechanism and dynamics of the outflow, as it is the sm_         _ More           The outflows of asymptotic giant branch (AGB) stars are rich astrochemical laboratories, hosting different chemical regimes: from non-equilibrium chemistry close to the star, to dust formation further out, and finally photochemistry in the outer regions. Chemistry is crucial for understanding the driving mechanism and dynamics of the outflow, as it is the small-scale chemical process of dust formation that launches the large-scale stellar outflow. However, exactly how dust condenses from the gas phase and grows is still unknown: an astrochemical problem with consequences for stellar evolution. Disagreements between observations and the predictions of chemical models drive the development of these models, helping to understand the link between dynamics and chemistry and paving the way to a 3D hydrochemical model.         _ Less","","arXiv","https://arxiv.org/abs/2408.08153","1","1","multiple"
"Imaging coupled vibrational, rotational, and electronic wave packet dynamics in a triatomic molecule","Abstract:                _challenge, even for small polyatomic systems. In this Letter, we demonstrate how the interplay between vibrational, rotational, and electronic degrees of freedom governs the evolution of molecular wave packets in the low-lying states of strong-field-ionized sulfur dioxide. Using time-resolved Coulomb explosion imaging (CEI) in combination with quantum mechan_         _ More           Molecular dynamics triggered by interaction with light often involve the excitation of several electronic, vibrational, and rotational states. Characterizing the resulting coupled electronic and nuclear wave packet motion represents a severe challenge, even for small polyatomic systems. In this Letter, we demonstrate how the interplay between vibrational, rotational, and electronic degrees of freedom governs the evolution of molecular wave packets in the low-lying states of strong-field-ionized sulfur dioxide. Using time-resolved Coulomb explosion imaging (CEI) in combination with quantum mechanical wave packet simulations, we directly map bending vibrations of the molecule, show how the vibrational wave packet is influenced by molecular alignment, and elucidate the role of the coupling between the two lowest electronic states of the cation. A conical intersection between these states couples the bending and asymmetric stretching coordinates, which is clearly reflected in the correlated fragment momenta. Our results suggest that multi-coincident CEI represents an efficient experimental tool for characterizing coupled electronic and nuclear motion in polyatomic molecules.         _ Less","","arXiv","https://arxiv.org/abs/2408.07958","0","1","synthetic_biology"
"Constraining SN Ia Progenitors from the Observed Fe-peak Elemental Abundances in the Milky Way Dwarf Galaxy Satellites","Abstract:        Chemical abundances of iron-peak elements in the red giants of ultra-faint dwarf galaxies (UFD) and dwarf spheroidal galaxies (dSph) are among the best diagnostics in the cosmos to probe the origin of Type Ia Supernovae (SNe Ia). We incorporate metallicity-dependent SN Ia nucleosynthesis models for different progenitor masses in our inhomogeneous galactic_         _ More   Chemical abundances of iron-peak elements in the red giants of ultra-faint dwarf galaxies (UFD) and dwarf spheroidal galaxies (dSph) are among the best diagnostics in the cosmos to probe the origin of Type Ia Supernovae (SNe Ia). We incorporate metallicity-dependent SN Ia nucleosynthesis models for different progenitor masses in our inhomogeneous galactic chemical evolution model, i-GEtool, to recreate the observed elemental abundance patterns and their spread in a sample of UFD and dSph galaxies with different average metallicities and star formation histories. Observations across different environments indicate that [Mn/Mg] increases on average with metallicity while [Ni/Mg] remains nearly constant. Chemical evolution models assuming SN Ia progenitors with Chandrasekhar mass (M$_{\\text{Ch}}$) produce similar to identical [Mn/Mg]-[Fe/H] and [Ni/Mg]-[Fe/H] patterns to those observed in the examined UFD and dSph galaxies, without needing to invoke a substantial fraction of sub-M$_{\\text{Ch}}$ progenitors that changes across the different environments, as claimed by some previous chemical evolution studies. We note though that the observed UFD sample is still statistically poor to draw firm conclusions. Sub-M$_{\\text{Ch}}$ progenitors in our dSph models systematically under produce both [Mn/Mg] and [Ni/Mg], with the 1M$_{\\odot}$ model explaining a number of outliers in [Ni/Fe], while the outliers in [Mn/Mg] require higher sub-M$_{\\text{Ch}}$ progenitor masses. The average dispersion of [X/Mg] from our UFD model ranges between $0.20$ and $0.25$ for iron-peak elements, with the exception of [Sc/Mg] that has $_\\approx 0.39$.         _ Less","","arXiv","https://arxiv.org/abs/2408.07443","2","1","origin_of_life"
"Quantifying Bursty Star Formation in Dwarf Galaxies","Abstract:                Dwarf galaxy star formation histories are theoretically expected to be bursty, potentially leaving distinct imprints on their chemical evolution. We propose that episodic starbursts with quiescent periods longer than $\\sim$100 Myr should lead to discontinuous tracks in a dwarf galaxy's [$_$/Fe]-[Fe/H]_         _ More           Dwarf galaxy star formation histories are theoretically expected to be bursty, potentially leaving distinct imprints on their chemical evolution. We propose that episodic starbursts with quiescent periods longer than $\\sim$100 Myr should lead to discontinuous tracks in a dwarf galaxy's [$_$/Fe]-[Fe/H] chemical abundance plane, with metallicity gaps as large as 0.3-0.5 dex at [Fe/H] = -2. This occurs due to continued Fe production by Type Ia supernovae during quiescent periods. We demonstrate that Gaussian mixture models can statistically distinguish discontinuous and continuous tracks based on the Akaike Information Criterion. Applying this method to APOGEE observations of the Sculptor dSph galaxy suggests an episodic star formation history with $\\sim$300 Myr quiescent periods. While current dwarf galaxy datasets are limited by small spectroscopic sample sizes, future surveys and extremely large telescopes will enable determining large numbers of precise chemical abundances, opening up the investigation of very short timescales in early dwarf galaxy formation. This unprecedentedly high time resolution of dwarf galaxy formation in the early Universe has important implications for understanding both reionization in the early Universe and the episodic star formation cycle of dwarf galaxies.         _ Less","","arXiv","https://arxiv.org/abs/2408.06807","3","2","origin_of_life"
"Planetary Nebulae Research: Past, Present, and Future","Abstract:                We review the evolution of our understanding of the planetary nebulae phenomenon and their place in the scheme of stellar_         _ More           We review the evolution of our understanding of the planetary nebulae phenomenon and their place in the scheme of stellar evolution. The historical steps leading to our current understanding of central star evolution and nebular formation are discussed. Recent optical imaging, X-ray, ultraviolet, infrared, millimeter wave, radio observations have led to a much more complex picture of the structure of planetary nebulae. The optically bright regions have multiple shell structures (rims, shells, crowns, and haloes), which can be understood within the interacting winds framework. However, the physical mechanism responsible for bipolar and multipolar structures that emerged during the proto-planetary nebulae phase is yet to be identified. Our morphological classifications of planetary nebulae are hampered by the effects of sensitivity, orientation, and field-of-view coverage, and the fraction of bipolar or multipolar nebulae may be much higher than commonly assumed. The optically bright bipolar lobes may represent low-density, ionization-bounded cavities carved out of a neutral envelope by collimated fast winds. Planetary nebulae are sites of active synthesis of complex organic compounds, suggesting that planetary nebulae play a major role in the chemical enrichment of the Galaxy. Possible avenues of future advancement are discussed.         _ Less","","arXiv","https://arxiv.org/abs/2408.06448","2","2","multiple"
"PDRs4All. X. ALMA and JWST detection of neutral carbon in the externally irradiated disk d203-506: Undepleted gas-phase carbon","Abstract:                _planets. The majority of protoplanetary disks are born in clusters and, as a result, are exposed to external FUV radiation. These FUV photons potentially affect the disk's evolution, chemical composition, and line excitation. We present the first detection of the [CI]609um fine-structure line of neutral carbon (CI)_         _ More           The gas-phase abundance of carbon, x_C = C/H, and its depletion factors are essential parameters for understanding the gas and solid compositions that are ultimately incorporated into planets. The majority of protoplanetary disks are born in clusters and, as a result, are exposed to external FUV radiation. These FUV photons potentially affect the disk's evolution, chemical composition, and line excitation. We present the first detection of the [CI]609um fine-structure line of neutral carbon (CI), achieved with ALMA, toward one of these disks, d203-506, in the Orion Nebula Cluster. We also report the detection of CI forbidden and permitted lines (from electronically excited states up to 10 eV) observed with JWST in the IR. These lines trace the irradiated outer disk and photo-evaporative wind. Contrary to the common belief that these IR lines are C+ recombination lines, we find that they are dominated by FUV-pumping of CI followed by fluorescence cascades. They trace the transition from atomic to molecular gas, and their intensities scale with G0. The lack of outstanding IR OI fluorescent emission, however, implies a sharper attenuation of external FUV radiation with E > 12 eV (~Lyman-beta). This is related to a lower effective FUV dust absorption cross section compared to that of interstellar grains, implying a more prominent role for FUV shielding by the CI photoionization continuum. The [CI]609um intensity is proportional to N(CI) and can be used to infer x_C. We derive x_C ~ 1.4E-4. This implies that there is no major depletion of volatile carbon compared to x_C measured in the natal cloud, hinting at a young disk. We also show that external FUV radiation impacts the outer disk and wind by vertically shifting the water freeze-out depth, which results in less efficient grain growth and settling. This shift leads to nearly solar gas-phase C/O abundance ratios in these irradiated layers.         _ Less","","arXiv","https://arxiv.org/abs/2408.06279","0","2","synthetic_biology"
"A combined study of thermohaline mixing and envelope overshooting with PARSEC: Calibration to NGC 6397 and M4","Abstract:                Thermohaline mixing is one of the main processes in low-mass red giant stars that affect the transport of chemicals and, thus, the surface abundances along the evolution. The interplay of thermohaline mixing with other processes, such as the downward overshooting from the convective envelope, should be carefully invest_         _ More           Thermohaline mixing is one of the main processes in low-mass red giant stars that affect the transport of chemicals and, thus, the surface abundances along the evolution. The interplay of thermohaline mixing with other processes, such as the downward overshooting from the convective envelope, should be carefully investigated. This study aims to understand the combined effects of thermohaline mixing and envelope overshooting. After implementing the thermohaline mixing process in the \\textsc{parsec} stellar evolutionary code, we compute tracks and isochrones (with \\textsc{trilegal} code) and compare them with observational data. To constrain the efficiencies of both processes, we perform a detailed modelling that is suitable for globular clusters NGC 6397 and M4. Our results indicate that an envelope overshooting efficiency parameter, $__\\mathrm{e}=0.6$, and a thermohaline efficiency parameter, $__\\mathrm{th}=50$, are necessary to reproduce the RGB bump magnitudes and lithium abundances observed in these clusters. We find that both envelope overshooting and thermohaline mixing have a significant impact on the variation of $^7$Li abundances. Additionally, we also explore the effects of adopting solar-scaled or $_$-enhanced mixtures on our models. The $^{12}$C and the $^{12}$C/$^{13}$C ratio are also effective indicators to probe extra mixing in RGB stars. Although, their usefulness is currently limited by the lack of precise and accurate C-isotopes abundances.         _ Less","","arXiv","https://arxiv.org/abs/2408.05039","0","1","synthetic_biology"
"Pore-resolved CFD in Digital Twin of Porous Monoliths Reconstructed by Micro-computed Tomography","Abstract:                Porous media are ubiquitous in the fields of energy storage and conversion, catalysis, biomechanics, hydrogeology, and other chemical engineering processes. These media possess high surface-to-volume ratios and their complex channels can restrict and direct the flow. This makes them key components of multiple equipment despite the challenges in selecting des_         _ More           Porous media are ubiquitous in the fields of energy storage and conversion, catalysis, biomechanics, hydrogeology, and other chemical engineering processes. These media possess high surface-to-volume ratios and their complex channels can restrict and direct the flow. This makes them key components of multiple equipment despite the challenges in selecting design parameters for specific applications. Pore-resolved CFD reveals the effects of their structure at the microscopic scale, but is currently limited by high computing costs and the performance of mesh generation algorithms. This work introduces a RBF-based representation of solids in a massively parallel immersed-boundary framework, enabling both the usage of non-conformal grids and dynamic mesh adaptation. We verify it using the method of manufactured solutions. We validate it using pressure drop measurements through porous silicone monoliths digitized by X-ray computed microtomography for Reynolds numbers up to 30, using grids of 200 M cells distributed over 8 k cores. The reliable model is then used to highlight that pore network structure is the main factor describing pressure evolution and that preferential channels are present at this scale of the porous media. This work opens the door to design and optimize processes by linking microscopic flow to macroscopic properties through the usage of physics-based digital twins of complex porous media.         _ Less","","arXiv","https://arxiv.org/abs/2408.04711","0","2","synthetic_biology"
"JWST/NIRSpec WIDE survey: a z=4.6 low-mass star-forming galaxy hosting a jet-driven shock with low ionisation and solar metallicity","Abstract:                _luminosity. The nebular metallicity is near solar - three times higher than that predicted by the mass-metallicity relation at z=4.6, possibly related to fast-paced chemical evolution near the galaxy nucleus. We find no evidence for a recent decline in the SFR of the galaxy, meaning that, already at this early epoch,_         _ More           We present NIRSpec/MSA observations from the JWST large-area survey WIDE, targeting the rest-frame UV-optical spectrum of Ulema, a radio-AGN host at redshift z=4.6348. The low-resolution prism spectrum displays high equivalent width nebular emission, with remarkably high ratios of low-ionisation species of oxygen, nitrogen and sulphur, relative to hydrogen; auroral O$^+$ emission is clearly detected, possibly also C$^+$. From the high-resolution grating spectrum, we measure a gas velocity dispersion $_$~400 km s$^{-1}$, broad enough to rule out star-forming gas in equilibrium in the gravitational potential of the galaxy. Emission-line ratio diagnostics suggest that the nebular emission is due to a shock which ran out of pre-shock gas. To infer the physical properties of the system, we model simultaneously the galaxy spectral energy distribution (SED) and shock-driven line emission under a Bayesian framework. We find a relatively low-mass, star-forming system (M* = 1.4$\\times$10^{10} M$_\\odot$, SFR = 70 M$_\\odot$ yr$^{-1}$), where shock-driven emission contributes 50 per cent to the total H$_$ luminosity. The nebular metallicity is near solar - three times higher than that predicted by the mass-metallicity relation at z=4.6, possibly related to fast-paced chemical evolution near the galaxy nucleus. We find no evidence for a recent decline in the SFR of the galaxy, meaning that, already at this early epoch, fast radio-mode AGN feedback was poorly coupled with the bulk of the star-forming gas; therefore, most of the feedback energy must end up in the galaxy halo, setting the stage for future quenching.         _ Less","","arXiv","https://arxiv.org/abs/2408.03982","2","2","multiple"
"Role of time-frequency correlations in two-photon-two-atom resonance energy transfer","Abstract:                Excitation energy transfer is a photophysical process upon which many chemical and biological phenomena are built. From natural small systems to synthetic multichromophoric macromolecules, energy transfer deals with the process of migration of electronic excitation energy from an excited donor to an acceptor. Although this phenomenon has been extensively stu_         _ More           Excitation energy transfer is a photophysical process upon which many chemical and biological phenomena are built. From natural small systems to synthetic multichromophoric macromolecules, energy transfer deals with the process of migration of electronic excitation energy from an excited donor to an acceptor. Although this phenomenon has been extensively studied in the past, the rapid evolution of quantum-enabled technologies has motivated the question on whether nonclassical sources of light, such as entangled photon pairs, may provide us with a better control (or enhancement) of energy transfer at the nanoscale. In this work, we provide a comprehensive study of the joint excitation of two non-interacting two-level atoms by time-frequency correlated photon pairs -- whose central frequencies are not resonant with the individual particles -- generated by means of spontaneous parametric down conversion (SPDC). We demonstrate that while strong frequency anti-correlation between photons guarantees a large two-photon excitation (TPE) probability, photons bearing a sine cardinal spectral shape exhibit a $\\sim$3.8 times larger TPE signal than photons with a Gaussian spectrum. More importantly, we find that suppression of time-ordered excitation pathways does not substantially modify the TPE probability for two-photon states with a Gaussian spectral shape; whereas photons with a sine cardinal spectrum exhibit the strongest TPE signals when two-photon excitation pathways are not suppressed. Our results not only help elucidating the role of time-frequency correlations in resonance energy transfer with SPDC photons, but also provide valuable information regarding the optimal source to be used in its experimental implementation.         _ Less","","arXiv","https://arxiv.org/abs/2408.03903","2","3","synthetic_biology"
"The R-Process Alliance: Fifth Data Release from the Search for R-Process-Enhanced Metal-poor Stars in the Galactic Halo with the GTC","Abstract:                Understanding the abundance pattern of metal-poor stars and the production of heavy elements through various nucleosynthesis processes offers crucial insights into the chemical evolution of the Milky Way, revealing primary sites and major sources of rapid neutron-capture process ($r$-process) material in the Universe._         _ More           Understanding the abundance pattern of metal-poor stars and the production of heavy elements through various nucleosynthesis processes offers crucial insights into the chemical evolution of the Milky Way, revealing primary sites and major sources of rapid neutron-capture process ($r$-process) material in the Universe. In this fifth data release from the $R$-Process Alliance, we present the detailed chemical abundances of 41 faint (down to V = 15.8) and extremely metal-poor (down to [Fe/H] = -3.3) halo stars selected from the R-Process Alliance (RPA). We obtained high-resolution spectra for these objects with the HORuS spectrograph on the Gran Telescopio Canarias. We measure the abundances of light, alpha, Fe-peak, and neutron-capture elements. We report the discovery of five CEMP, one limited-$r$, three $r$-I, and four $r$-II stars, and six Mg-poor stars. We also identify one star of a possible globular cluster origin at an extremely low metallicity at [Fe/H] = -3.0. This adds to the growing evidence of a lower limit metallicity floor for globular cluster abundances. We use the abundances of Fe-peak elements and the alpha-elements to investigate the contributions from different nucleosynthesis channels in the progenitor supernovae. We find the distribution of [Mg/Eu] as a function of [Fe/H] to have different enrichment levels, indicating different possible pathways and sites of their production. We also reveal differences in the trends of the neutron-capture element abundances of Sr, Ba, and Eu of various $r$-I and $r$-II stars from the RPA data releases, which provide constraints on their nucleosynthesis sites and subsequent evolution.         _ Less","","arXiv","https://arxiv.org/abs/2408.03731","1","1","multiple"
"Phase field simulations of thermal annealing for all-small molecule organic solar cells","Abstract:                _effect of thermal annealing (TA) on an all-small molecule DRCN5T: PC71 BM blend with phase field simulations. The objective is to determine the physical phenomena driving the evolution of the BHJ morphology for a better understanding of the posttreatment/morphology relationship. Phase-field simulation results are used to investigate the impact on the final B_         _ More           Interest in organic solar cells (OSCs) is constantly rising in the field of photovoltaic devices. The device performance relies on the bulk heterojunction (BHJ) nanomorphology, which develops during the drying process and additional post-treatment. This work studies the effect of thermal annealing (TA) on an all-small molecule DRCN5T: PC71 BM blend with phase field simulations. The objective is to determine the physical phenomena driving the evolution of the BHJ morphology for a better understanding of the posttreatment/morphology relationship. Phase-field simulation results are used to investigate the impact on the final BHJ morphology of the DRCN5T crystallization-related mechanisms, including nucleation, growth, crystal stability, impingement, grain coarsening, and Ostwald ripening, of the amorphous-amorphous phase separation (AAPS), and of diffusion limitations. The comparison of simulation results with experimental data shows that the morphological evolution of the BHJ under TA is dominated by dissolution of the smallest, unstable DRCN5T crystals and anisotropic growth of the largest crystals.         _ Less","","arXiv","https://arxiv.org/abs/2408.03190","0","2","synthetic_biology"
"Modeling the Plasma Composition of 67P/C-G at different Heliocentric Distances","Abstract:                _In this work, we aim to estimate the composition of the cometary ionosphere at different heliocentric distances of the comet. Lauter et al. (2020) derived the temporal evolution of the volatile sublimation rates for 50 separated time intervals on the orbit of 67P/C-G using the COPS and DFMS data. We use these sublimation rates as inputs in a multifluid_         _ More           The Rosetta spacecraft accompanied the comet 67P/C-G for nearly 2 years, collecting valuable data on the neutral and ion composition of the coma. The Rosetta Plasma Consortium (RPC) provided continuous measurements of the in situ plasma density while ROSINA-COPS monitored the neutral composition. In this work, we aim to estimate the composition of the cometary ionosphere at different heliocentric distances of the comet. Lauter et al. (2020) derived the temporal evolution of the volatile sublimation rates for 50 separated time intervals on the orbit of 67P/C-G using the COPS and DFMS data. We use these sublimation rates as inputs in a multifluid chemical-hydrodynamical model for 36 of the time intervals for heliocentric distances < 3 au. We compare the total ion densities obtained from our models with the local plasma density measured by the RPC instruments. We find that at the location of the spacecraft, our modeled ion densities match with the in situ measured plasma density within factors of 1 - 3 for many of the time intervals. We obtain the cometocentric distance variation of the ions H2O+ and H3O+ and the ion groups created respectively by the ionization and protonation of neutral species. We see that H3O+ is dominant at the spacecraft location for nearly all the time intervals while ions created due to protonation are dominant at low cometocentric distances for the intervals near perihelion. We also discuss our ion densities in the context of their detection by DFMS.         _ Less","","arXiv","https://arxiv.org/abs/2408.02338","0","1","synthetic_biology"
"J-PLUS: Beyond Spectroscopy III. Stellar Parameters and Elemental-abundance Ratios for Five Million Stars from DR3","Abstract:                _typical uncertainties of 0.25 dex and 0.40 dex for dwarfs and giants, respectively. This large photometric sample should prove useful for the exploration of the assembly and chemical-evolution history of our Galaxy.         _ More           We present a catalog of stellar parameters (effective temperature $T_{\\rm eff}$, surface gravity $\\log g$, age, and metallicity [Fe/H]) and elemental-abundance ratios ([C/Fe], [Mg/Fe], and [$_$/Fe]) for some five million stars (4.5 million dwarfs and 0.5 million giants stars) in the Milky Way, based on stellar colors from the Javalambre Photometric Local Universe Survey (J-PLUS) DR3 and \\textit{Gaia} EDR3. These estimates are obtained through the construction of a large spectroscopic training set with parameters and abundances adjusted to uniform scales, and trained with a Kernel Principal Component Analysis. Owing to the seven narrow/medium-band filters employed by J-PLUS, we obtain precisions in the abundance estimates that are as good or better than derived from medium-resolution spectroscopy for stars covering a wide range of the parameter space: 0.10-0.20 dex for [Fe/H] and [C/Fe], and 0.05 dex for [Mg/Fe] and [$_$/Fe]. Moreover, systematic errors due to the influence of molecular carbon bands on previous photometric-metallicity estimates (which only included two narrow/medium-band blue filters) have now been removed, resulting in photometric-metallicity estimates down to [Fe/H] $\\sim -4.0$, with typical uncertainties of 0.25 dex and 0.40 dex for dwarfs and giants, respectively. This large photometric sample should prove useful for the exploration of the assembly and chemical-evolution history of our Galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2408.02171","1","2","synthetic_biology"
"Neural Network Emulator for Atmospheric Chemical ODE","Abstract:                _chemistry is complex and computationally intense. Given the recent success of Deep neural networks in digital signal processing, we propose a Neural Network Emulator for fast chemical concentration modeling. We consider atmospheric chemistry as a time-dependent Ordinary Differential Equation. To extract the hidden correlations between initial states and futu_         _ More           Modeling atmospheric chemistry is complex and computationally intense. Given the recent success of Deep neural networks in digital signal processing, we propose a Neural Network Emulator for fast chemical concentration modeling. We consider atmospheric chemistry as a time-dependent Ordinary Differential Equation. To extract the hidden correlations between initial states and future time evolution, we propose ChemNNE, an Attention based Neural Network Emulator (NNE) that can model the atmospheric chemistry as a neural ODE process. To efficiently simulate the chemical changes, we propose the sinusoidal time embedding to estimate the oscillating tendency over time. More importantly, we use the Fourier neural operator to model the ODE process for efficient computation. We also propose three physical-informed losses to supervise the training optimization. To evaluate our model, we propose a large-scale chemical dataset that can be used for neural network training and evaluation. The extensive experiments show that our approach achieves state-of-the-art performance in modeling accuracy and computational speed.         _ Less","","arXiv","https://arxiv.org/abs/2408.01829","0","1","synthetic_biology"
"The mass-metallicity relation as a ruler for galaxy evolution: insights from the James Webb Space Telescope","Abstract:                Galaxy evolution emerges from the balance between cosmic gas accretion, fueling star formation, and supernova (SN) feedback, regulating the metal enrichment. Hence, the stellar mass ($M_*$) - gas metallicity relation (MZR) is key to understand the physics of galaxies. High-quality JWST data enable accurate measurements of the MZR up to redshift z=10. Our aim_         _ More           Galaxy evolution emerges from the balance between cosmic gas accretion, fueling star formation, and supernova (SN) feedback, regulating the metal enrichment. Hence, the stellar mass ($M_*$) - gas metallicity relation (MZR) is key to understand the physics of galaxies. High-quality JWST data enable accurate measurements of the MZR up to redshift z=10. Our aims are to understand the observed MZR, its connection with the star formation rate (SFR), the role played by SFR stochasticity, and how it is regulated by SN feedback. We compare the MZR from the JADES, CEERS, and UNCOVER surveys, which comprise about 180 galaxies at $z=3-10$ with $10^6<M_*/M_\\odot<10^{10}$, with 200 galaxies from the SERRA cosmological simulations. To interpret the MZR, we develop a minimal model for galaxy evolution that includes: cosmic accretion modulated with an amplitude $A_{100}$ on 100 Myr; a time delay $t_d$ between SFR and SN; SN-driven outflows with a varying mass loading factor $__{SN}$. Using our minimal model, we find the observed mean MZR is reproduced by weak outflows ($__{SN}=1/4$), in line with findings from JADES. Matching the observed MZR dispersion requires $t_d=20$ Myr and a $A_{100}=1/3$ modulation of the accretion rate. Successful models have low stochasticity ($__{SFR}=0.2$), yielding a MZR dispersion of $__{Z}=0.2$. Such values are close but lower than SERRA predictions ($__{SFR}=0.24$, $__{Z}=0.3$), clarifying why SERRA show no clear MZR trend and some tension with the observations. As the MZR is very sensitive to SFR stochasticity, models predicting high r.m.s. values ($__{SFR}=0.5$) result in a ``chemical chaos'' (i.e. $__{Z}=1.4$), virtually destroying the MZR. As a consequence, invoking a highly stochastic SFR ($__{SFR}=0.8$) to explain the overabundance of bright, super-early galaxies leads to inconsistencies with the observed MZR.         _ Less","","arXiv","https://arxiv.org/abs/2408.00061","2","2","multiple"
"Detection of Dimethyl Ether in the Central Region of the MWC 480 Protoplanetary Disk","Abstract:                Characterizing the chemistry of complex organic molecules (COMs) at the epoch of planet formation provides insights into the chemical evolution of the interstellar medium (ISM) and the origin of organic materials in our Solar System. We report a detection of dimethyl ether (CH$_3$OCH$_3$) in the disk around the Herbig_         _ More           Characterizing the chemistry of complex organic molecules (COMs) at the epoch of planet formation provides insights into the chemical evolution of the interstellar medium (ISM) and the origin of organic materials in our Solar System. We report a detection of dimethyl ether (CH$_3$OCH$_3$) in the disk around the Herbig Ae star MWC 480 with the sensitive Atacama Large Millimeter/submillimeter Array observations. This is the first detection of CH$_3$OCH$_3$ in a non-transitional Class II disk. The spatially unresolved, compact (${\\lesssim}$25 au in radius) nature, the broad line width ($\\sim$30 km s$^{-1}$), and the high excitation temperature (${\\sim}$200 K) indicate sublimation of COMs in the warm inner disk. Despite the detection of CH$_3$OCH$_3$, methanol (CH$_3$OH), the most abundant COM in the ISM, has not been detected, from which we constrain the column density ratio of CH$_3$OCH$_3$/CH$_3$OH ${\\gtrsim}$7. This high ratio may indicate the reprocessing of COMs during the disk phase, as well as the effect of the physical structure in the inner disk. We also find that this ratio is higher than in COM-rich transition disks recently discovered. This may indicate that, in the full disk of MWC 480, COMs have experienced substantial chemical reprocessing in the innermost region, while the COM emission in the transition disks predominantly traces the inherited ice sublimating at the dust cavity edge located at larger radii (${\\gtrsim}$20 au).         _ Less","","arXiv","https://arxiv.org/abs/2407.21518","2","1","origin_of_life"
"Real-time chiral dynamics at finite temperature from quantum simulation","Abstract:                _explore the real-time dynamics of the chiral magnetic effect (CME) at a finite temperature in the (1+1)-dimensional QED, the massive Schwinger model. By introducing a chiral chemical potential $__5$ through a quench process, we drive the system out of equilibrium and analyze the induced vector currents and their_         _ More           In this study, we explore the real-time dynamics of the chiral magnetic effect (CME) at a finite temperature in the (1+1)-dimensional QED, the massive Schwinger model. By introducing a chiral chemical potential $__5$ through a quench process, we drive the system out of equilibrium and analyze the induced vector currents and their evolution over time. The Hamiltonian is modified to include the time-dependent chiral chemical potential, thus allowing the investigation of the CME within a quantum computing framework. We employ the quantum imaginary time evolution (QITE) algorithm to study the thermal states, and utilize the Suzuki-Trotter decomposition for the real-time evolution. This study provides insights into the quantum simulation capabilities for modeling the CME and offers a pathway for studying chiral dynamics in low-dimensional quantum field theories.         _ Less","","arXiv","https://arxiv.org/abs/2407.21496","0","1","synthetic_biology"
"The possible coexistence of superconductivity and topological electronic states in 1T-RhSeTe","Abstract:                _phase, in particular, shows promise for superconductivity driven by electron-phonon coupling, strain, pressure, and chemical doping. In this theoretical investigation, we explore 1$T$-RhSeTe as a novel type of TMD superconductor with topological electronic states. The optimal doping structure and atomic arrangement of 1$T$-RhSeTe are constructed. Phonon cal_         _ More           Transition metal dichalcogenides (TMDs), exhibit a range of crystal structures and topological quantum states. The 1$T$ phase, in particular, shows promise for superconductivity driven by electron-phonon coupling, strain, pressure, and chemical doping. In this theoretical investigation, we explore 1$T$-RhSeTe as a novel type of TMD superconductor with topological electronic states. The optimal doping structure and atomic arrangement of 1$T$-RhSeTe are constructed. Phonon calculations validate the integrity of the constructed doping structure. The analysis of the electron-phonon coupling (EPC) using the Electron-phonon Wannier (EPW) method has confirmed the existence of a robust electron-phonon interaction in 1$T$-RhSeTe, resulting in total EPC constant $_$ = 2.02, the logarithmic average frequency $__{\\text{log}}$ = 3.15 meV and $T_c$ = 4.61 K, consistent with experimental measurements and indicative of its classification as a BCS superconductor. The band structure analysis revealed the presence of Dirac-like band crossing points. The topological non-trivial electronic structures of the 1$T$-RhSeTe are confirmed via the evolution of Wannier charge centers (WCCs). Collectively, these distinctive properties underscore 1$T$-RhSeTe as a possible candidate for a topological superconductor, warranting further investigation into its potential implications and applications.         _ Less","","arXiv","https://arxiv.org/abs/2407.21302","0","1","synthetic_biology"
"A phase-field model for wet snow metamorphism","Abstract:                _phase-change phenomena: sublimation (deposition), evaporation (condensation), and melting (solidification). The phase-field formulation allows one to track the temperature evolution amongst the three phases and the water vapor concentration in the air. Our three-phase model recovers the corresponding two-phase transition model when one phase is not present i_         _ More           The microstructure of snow determines its fundamental properties such as the mechanical strength, reflectivity, or the thermo-hydraulic properties. Snow undergoes continuous microstructural changes due to local gradients in temperature, humidity or curvature, in a process known as snow metamorphism. In this work, we focus on wet snow metamorphism, which occurs when temperature is close to the melting point and involves phase transitions amongst liquid water, water vapor, and solid ice. We propose a pore-scale phase-field model that simultaneously captures the three relevant phase-change phenomena: sublimation (deposition), evaporation (condensation), and melting (solidification). The phase-field formulation allows one to track the temperature evolution amongst the three phases and the water vapor concentration in the air. Our three-phase model recovers the corresponding two-phase transition model when one phase is not present in the system. 2D simulations of the model unveils the impact of humidity and temperature on the dynamics of wet snow metamorphism at the pore scale. We also explore the role of liquid melt content in controlling the dynamics of snow metamorphism in contrast to the dry regime, before percolation onsets. The model can be readily extended to incorporate two-phase flow and may be the basis for investigating other problems involving water phase transitions in a vapor-solid-liquid system such as airplane icing or thermal spray coating.         _ Less","","arXiv","https://arxiv.org/abs/2407.21213","0","1","synthetic_biology"
"Atmospheric characterization of the super-Jupiter HIP 99770 b with KPIC","Abstract:                Young, self-luminous super-Jovian companions discovered by direct imaging provide a challenging test of planet formation and evolution theories. By spectroscopically characterizing the atmospheric compositions of these super-Jupiters, we can constrain their formation histories. Here we present studies of the recently discovered HIP 99770 b, a 16 MJup high-co_         _ More           Young, self-luminous super-Jovian companions discovered by direct imaging provide a challenging test of planet formation and evolution theories. By spectroscopically characterizing the atmospheric compositions of these super-Jupiters, we can constrain their formation histories. Here we present studies of the recently discovered HIP 99770 b, a 16 MJup high-contrast companion on a 17 au orbit, using the fiber-fed high-resolution spectrograph KPIC (R~35,000) on the Keck II telescope. Our K-band observations led to detections of H2O and CO in the atmosphere of HIP 99770 b. We carried out free retrieval analyses using petitRADTRANS to measure its chemical abundances, including the metallicity and C/O ratio, projected rotation velocity (vsini), and radial velocity (RV). We found that the companion's atmosphere has C/O=0.55(-0.04/+0.06) and [M/H]=0.26(-0.23/+0.24) (1_ confidence intervals), values consistent with those of the Sun and with a companion formation via gravitational instability or core accretion. The projected rotation velocity < 7.8 km/s is small relative to other directly imaged companions with similar masses and ages. This may imply a near pole-on orientation or effective magnetic braking by a circumplanetary disk. In addition, we added the companion-to-primary relative RV measurement to the orbital fitting and obtained updated constraints on orbital parameters. Detailed characterization of super-Jovian companions within 20 au like HIP 99770 b is critical for understanding the formation histories of this population.         _ Less","","arXiv","https://arxiv.org/abs/2407.20952","1","1","multiple"
"The effects of surface fossil magnetic fields on massive star evolution: V. Models at low metallicity","Abstract:                _metallicities lower than that of the Small Magellanic Cloud, it remains essentially unexplored how fossil magnetic fields, forming large-scale magnetospheres, could affect the evolution of massive stars, thereby impacting the fundamental building blocks of the early Universe. We extend our stellar evolution model grid_         _ More           At metallicities lower than that of the Small Magellanic Cloud, it remains essentially unexplored how fossil magnetic fields, forming large-scale magnetospheres, could affect the evolution of massive stars, thereby impacting the fundamental building blocks of the early Universe. We extend our stellar evolution model grid with representative calculations of main-sequence, single-star models with initial masses of 20 and 60 M$_\\odot$, including appropriate changes for low-metallicity environments ($Z = 10^{-3}-10^{-6}$). We scrutinise the magnetic, rotational, and chemical properties of the models. When lowering the metallicity, the rotational velocities can become higher and the tendency towards quasi-chemically homogeneous evolution increases. While magnetic fields aim to prevent the development of this evolutionary channel, the weakening stellar winds lead to less efficient magnetic braking in our models. Since the stellar radius is almost constant during a blueward evolution caused by efficient chemical mixing, the surface magnetic field strength remains unchanged in some models. We find core masses at the terminal-age main sequence between 22 and 52 M$_\\odot$ for initially 60 M$_\\odot$ models. This large difference is due to the vastly different chemical and rotational evolution. We conclude that in order to explain chemical species and, in particular, high nitrogen abundances in the early Universe, the adopted stellar models need to be under scrutiny. The assumptions regarding wind physics, chemical mixing, and magnetic fields will strongly impact the model predictions.         _ Less","","arXiv","https://arxiv.org/abs/2407.20492","0","1","synthetic_biology"
"JOYS+: link between ice and gas of complex organic molecules. Comparing JWST and ALMA data of two low-mass protostars","Abstract:                _Observations of Young protoStars (JOYS+) program. By comparing the column density ratios w.r.t. CH3OH between both phases measured in the same sources, we can probe into the evolution of COMs from ice to gas in the early stages of star formation. We are able to fit the fingerprints range of COM ices between 6.8 and 8.8 um in the JWST/MIRI-MRS spectra of B1-c_         _ More           A rich inventory of complex organic molecules (COMs) has been observed in high abundances in the gas phase toward Class 0 protostars. These molecules are suggested to be formed in ices and sublimate in the warm inner envelope close to the protostar. However, only the most abundant COM, methanol (CH3OH), has been firmly detected in ices before the era of James Webb Space Telescope (JWST). Now it is possible to detect the interstellar ices of other COMs and constrain their ice column densities quantitatively. We aim to determine the column densities of several oxygen-bearing COMs (O-COMs) in both gas and ice for two low-mass protostellar sources, NGC 1333 IRAS 2A and B1-c, as case studies in our JWST Observations of Young protoStars (JOYS+) program. By comparing the column density ratios w.r.t. CH3OH between both phases measured in the same sources, we can probe into the evolution of COMs from ice to gas in the early stages of star formation. We are able to fit the fingerprints range of COM ices between 6.8 and 8.8 um in the JWST/MIRI-MRS spectra of B1-c using similar components as recently used for IRAS 2A. We claim detection of CH4, OCN-, HCOO-, HCOOH, CH3CHO, C2H5OH, CH3OCH3, CH3OCHO, and CH3COCH3 in B1-c, and upper limits are estimated for SO2, CH3COOH, and CH3CN. The comparison of O-COM ratios w.r.t CH3OH between ice and gas shows two different cases. 1) the column density ratios of CH3OCHO and CH3OCH3 match well between the two phases, which may be attributed to a direct inheritance from ice to gas or strong chemical links with CH3OH. 2) the ice ratios of CH3CHO and C2H5OH w.r.t. CH3OH are higher than the gas ratios by 1-2 orders of magnitudes. This difference can be explained by the gas-phase reprocessing following sublimation, or different spatial distributions of COMs in the envelope.         _ Less","","arXiv","https://arxiv.org/abs/2407.20066","1","1","multiple"
"The CARMENES search for exoplanets around M dwarfs: Magnesium and silicon abundances of K7-M5.5 stars","Abstract:                _the radiative transfer code Turbospectrum, and a state-of-the-art selection of atomic and molecular data. These Mg and Si abundances are critical for understanding both the chemical_         _ More           We present the abundances of magnesium (Mg) and silicon (Si) for 314 dwarf stars with spectral types in the interval K7.0-M5.5 (Teff range ~4200-3050 K) observed with the CARMENES high-resolution spectrograph at the 3.5 m telescope at the Calar Alto Observatory. Our analysis employs the BT-Settl model atmospheres, the radiative transfer code Turbospectrum, and a state-of-the-art selection of atomic and molecular data. These Mg and Si abundances are critical for understanding both the chemical evolution and assembly of the Milky Way and the formation and composition of rocky planets. Our chemical abundances show a line-to-line scatter at the level of 0.1 dex for all studied spectral types. The typical error bar of our chemical abundance measurements is +- 0.11 dex (Mg) and +- 0.16 dex (Si) for all spectral types based on the comparison of the results obtained for stellar components of multiple systems. The derived abundances are consistent with the galactic evolution trends and observed chemical abundance distribution of earlier FGK-type stars in the solar neighbourhood. Besides, our analysis provides compatible abundances for stars in multiple systems. In addition, we studied the abundances of different galactic stellar populations. In this paper, we also explore the relation of the Mg and Si abundances of stars with and without known planets.         _ Less","","arXiv","https://arxiv.org/abs/2407.19969","2","1","origin_of_life"
"Revision of calcium and scandium abundances in Am stars based on NLTE calculations and comparison with diffusion stellar evolution models","Abstract:                _the systematic difference between Am stars with surface gravity log g > 4 and log g < 4. The iron excess is nearly the same in the range 7200 K <= Teff <= 10030 K. Evolution diffusion models computed with the code MESA for stars with masses from 1.5 to 2Msun show the surface abundances that are in good agreement with Ca and Fe abundances observed_         _ More           The homogeneous data sets for the calcium and scandium abundances accounting for departures from LTE were obtained for a sample of 54 metallic-line (Am) stars. The Ca and Sc abundances were found to correlate with effective temperature Teff, the abundance growth with increasing Teff being higher in stars with surface gravity log g < 4 than in those with log g > 4. No correlation was found between Ca or Sc abundances and the iron abundance or the velocity of axial rotation. Am stars exhibit on average the higher values of [Ca/H] than those of [Sc/H] as well as the abundance ratio [Ca/Sc] = 0.41 +/- 0.30. However, at Teff > 9500 K there is an allusion to the systematic difference between Am stars with surface gravity log g > 4 and log g < 4. The iron excess is nearly the same in the range 7200 K <= Teff <= 10030 K. Evolution diffusion models computed with the code MESA for stars with masses from 1.5 to 2Msun show the surface abundances that are in good agreement with Ca and Fe abundances observed in Am stars of the three open clusters with the age > 600 Myr. Additional mechanisms of chemical separation should be considered for explanation of the Am phenomenon in young stars of the Pleiades cluster. We tested the published diffusion stellar evolution models. The diffusion models by Richer et al. (2000) and Hui-Bon-Hoa et al. (2022) are shown to agree with observations of Am stars in the open clusters at large values of the free turbulence parameter: omega=1000 for Ca and Fe, omega=500 for Sc. There is no model with the mass and age of the Am-type star Sirius that could reproduce its surface abundances from He to Ni. The results presented in the paper may be of importance for understanding the chemical peculiarity of Am stars.         _ Less","","arXiv","https://arxiv.org/abs/2407.18736","0","2","synthetic_biology"
"Nova contributions to the chemical evolution of the Milky Way","Abstract:                _eruptions results in unique nucleosynthesis that heavily over-produces certain isotopes relative to the solar abundance. However, novae are often ignored when considering the chemical_         _ More           Context. The explosive burning that drives nova eruptions results in unique nucleosynthesis that heavily over-produces certain isotopes relative to the solar abundance. However, novae are often ignored when considering the chemical evolution of our Galaxy due to their low ejecta masses. Aims. In this work, we use previously computed synthetic nova populations and the galactic chemical evolution code OMEGA+ to assess the impact that novae have on the evolution of stable elemental and isotopic abundances. Methods. We combine populations of novae computed using the binary population synthesis code binary_c with the galactic chemical evolution code OMEGA+ and detailed, white dwarf mass-dependent nova yields to model the nucleosynthetic contributions of novae to the evolution of the Milky Way. We consider three different nova yield profiles, each corresponding to a different set of nova yield calculations. Results. Despite novae from low-mass white dwarfs (WDs) dominating nova ejecta contributions, we find that novae occurring on massive WDs are still able to contribute significantly to many isotopes, particularly those with high mass numbers. We find that novae can produce up to 35% of the Galactic 13C and 15N mass by the time the model Galaxy reaches [Fe/H] = 0, and earlier in the evolution of the Galaxy (between [Fe/H] = -2 and -1) novae may have been the dominant source of 15N. Predictions for [13C/Fe], [15N/Fe], 12C/13C, and 14N/15N abundances ratios vary by up to 0.2 dex at [Fe/H] = 0 and by up to 0.7 dex in [15N/Fe] and 14N/15N between [Fe/H] = -2 and -1 (corresponding approximately to Galactic ages of 170 Myr and 1 Gyr in our model). The Galactic evolution of other stable isotopes (excluding Li) is not noticeably affected by including novae.         _ Less","","arXiv","https://arxiv.org/abs/2407.18718","1","1","multiple"
"Carbon enrichment in APOGEE disk stars as evidence of mass transfer in binaries","Abstract:                Carbon abundances in first-ascent giant stars are usually lower than those of their main-sequence counterparts. At moderate metallicities, stellar evolution of single stars cannot account for the existence of red-giant branch stars with enhanced carbon abundances. The phenomenon is usually interpreted as resulting from past mass transfer from an evolved bina_         _ More           Carbon abundances in first-ascent giant stars are usually lower than those of their main-sequence counterparts. At moderate metallicities, stellar evolution of single stars cannot account for the existence of red-giant branch stars with enhanced carbon abundances. The phenomenon is usually interpreted as resulting from past mass transfer from an evolved binary companion now in the white dwarf evolutionary stage. Aims: We aim to confirm the links between [C/O] enhancement, s-process element enhancement and binary fraction using large-scale catalogues of stellar abundances and probable binary stars. Methods: We use a large data set from the 17 data release of the SDSS-IV/APOGEE~2 survey to identify carbon-enhanced stars in the Galactic disk. We identify a continuum of carbon enrichment throughout three different sub-populations of disk stars and explore links between the degree of carbon enrichment and binary frequency, metallicity and chemical compositions. Results: We verify a clear correlation between binary frequency and enhancement in the abundances of both carbon and cerium, lending support to the scenario whereby carbon-enhanced stars are the result of mass transfer by an evolved binary companion. In addition, we identify clustering in the carbon abundances of high-$_$ disk stars, suggesting that those on the high metallicity end are likely younger, in agreement with theoretical predictions for the presence of a starburst population following the gas-rich merger of the Gaia-Enceladus/Sausage system.         _ Less","","arXiv","https://arxiv.org/abs/2407.18130","1","2","synthetic_biology"
"Isotopic abundance of carbon in the DLA towards QSO B1331+170","Abstract:        Chemical evolution models predict a gradual build-up of $^{13}$C in the universe, based on empirical nuclear reaction rates and assumptions on the properties of stellar populations. However, old metal-poor stars within the Galaxy contain more $^{13}$C than is predicted, suggesting that further refinements to the models_         _ More   Chemical evolution models predict a gradual build-up of $^{13}$C in the universe, based on empirical nuclear reaction rates and assumptions on the properties of stellar populations. However, old metal-poor stars within the Galaxy contain more $^{13}$C than is predicted, suggesting that further refinements to the models are necessary. Gas at high redshift provides important supplementary information at metallicities $-2\\lesssim$ [Fe/H] $\\lesssim-1$, for which there are only a few measurements in the Galaxy. We obtained new, high-quality, VLT/ESPRESSO observations of the QSO B1331+170 and used them to measure $^{12}$C/$^{13}$C in the damped Lyman-$_$ system (DLA) at $z_{abs}=1.776$, with [Fe/H]=-1.27. AI-VPFIT, an Artificial Intelligence tool based on genetic algorithms and guided by a spectroscopic information criterion, was used to explore different possible kinematic structures of the carbon gas. Three hundred independent AI-VPFIT models of the absorption system were produced using pre-set $^{12}$C/$^{13}$C values, ranging from 4 to 500. Our results show that $^{12}$C/$^{13}$C$=28.5^{+51.5}_{-10.4}$, suggesting a possibility of $^{13}$C production at low metallicity.         _ Less","","arXiv","https://arxiv.org/abs/2407.17953","2","1","origin_of_life"
"A tight N/O-potential relation in star-forming galaxies","Abstract:                _by metal-poor inflows. The potential-N/O relation thus appears to be both more resistant to short-timescale baryonic processes and also more reflective of a galaxy's chemical evolution state, when compared to previously-considered relations.         _ More           We report a significantly tighter trend between gaseous N/O and $M_*/R_e$ (a proxy for gravitational potential) than has previously been reported between gaseous metallicity and $M_*/R_e$, for star-forming galaxies in the MaNGA survey. We argue this result to be a consequence of deeper potential wells conferring greater resistance to metal outflows while also being associated with earlier star-formation histories, combined with N/O being comparatively unaffected by metal-poor inflows. The potential-N/O relation thus appears to be both more resistant to short-timescale baryonic processes and also more reflective of a galaxy's chemical evolution state, when compared to previously-considered relations.         _ Less","","arXiv","https://arxiv.org/abs/2407.17945","3","2","origin_of_life"
"Role of NH3 Binding Energy in the Early Evolution of Protostellar Cores","Abstract:                _abundances and, consequently, in the early evolution of protostellar cores. Using a gas-grain chemical network, we systematically vary the values of NH$_{3}$ binding energies in a model Class 0 protostellar core and study the effects of these binding energies on the NH$_{3}$ abundances. Our simulations indicate that a_         _ More           NH$_{3}$(ammonia) plays a critical role in the chemistry of star and planet formation, yet uncertainties in its binding energy (BE) values complicate accurate estimates of its abundances. Recent research suggests a multi-binding energy approach, challenging the previous single-value notion. In this work, we use different values of NH$_{3}$ binding energy to examine its effects on the NH$_{3}$ abundances and, consequently, in the early evolution of protostellar cores. Using a gas-grain chemical network, we systematically vary the values of NH$_{3}$ binding energies in a model Class 0 protostellar core and study the effects of these binding energies on the NH$_{3}$ abundances. Our simulations indicate that abundance profiles of NH$_{3}$ are highly sensitive to the binding energy used, particularly in the warmer inner regions of the core. Higher binding energies lead to lower gas-phase NH$_{3}$ abundances, while lower values of binding energy have the opposite effect. Furthermore, this BE-dependent abundance variation of NH$_{3}$ significantly affects the formation pathways and abundances of key species such as HNC, HCN, and CN. Our tests also reveal that the size variation of the emitting region due to binding energy becomes discernible only with beam sizes of 10 arcsec or less. These findings underscore the importance of considering a range of binding energies in astrochemical models and highlight the need for higher resolution observations to better understand the subtleties of molecular cloud chemistry and star formation processes.         _ Less","","arXiv","https://arxiv.org/abs/2407.17891","1","1","multiple"
"Far-from-equilibrium attractors in kinetic theory for a mixture of quark and gluon fluids","Abstract:                _massless quark and gluon fluids undergoing transversally homogeneous longitudinal boost-invariant expansion. We include a fugacity parameter that allows quarks to be out of chemical equilibrium and we account for the different collision rates of quarks and gluons, which are related by Casimir scaling. Based on these assumptions, we numerically determine the_         _ More           We exactly solve an RTA-Boltzmann equation that describes the dynamics of coupled massless quark and gluon fluids undergoing transversally homogeneous longitudinal boost-invariant expansion. We include a fugacity parameter that allows quarks to be out of chemical equilibrium and we account for the different collision rates of quarks and gluons, which are related by Casimir scaling. Based on these assumptions, we numerically determine the evolution of a large set of moments of the quark and gluon distribution functions and reconstruct their entire distribution functions. We find that both late and early-time attractors exist for all moments of the distribution functions containing more than one power of the squared longitudinal momentum. These attractors emerge long before the system reaches the regime where hydrodynamic approximations apply. In addition, we discuss how the shear viscous corrections and entropy density of the fluid mixture evolve and consider the properties of their respective attractors. Finally, the entropy production is also investigated for different initial values of momentum anisotropy and quark abundance.         _ Less","","arXiv","https://arxiv.org/abs/2407.17327","0","1","synthetic_biology"
"Operando probing of nanocracking in CuO-derived Cu during CO$_2$ electroreduction","Abstract:                Identifying and controlling active sites in electrocatalysis remains a grand challenge due to restructuring of catalysts in the complex chemical environments during operation. Inactive precatalysts can transform into active catalysts under reaction conditions, such as oxide-derived Cu (OD-Cu) for CO$_2$ electroreduction displaying improved production of mult_         _ More           Identifying and controlling active sites in electrocatalysis remains a grand challenge due to restructuring of catalysts in the complex chemical environments during operation. Inactive precatalysts can transform into active catalysts under reaction conditions, such as oxide-derived Cu (OD-Cu) for CO$_2$ electroreduction displaying improved production of multicarbon (C$_{2+}$) chemicals. Revealing the mechanism of active site origin in OD-Cu catalysts requires in situ/operando characterizations of structure, morphology, and valence state evolution with high spatial and temporal resolution. Applying newly developed electrochemical liquid cell transmission electron microscopy combined with X-ray absorption spectroscopy, our multimodal operando techniques unveil the formation pathways of OD-Cu active sites from CuO bicrystal nanowire precatalysts. Rapid reduction of CuO directly to Cu within 60 seconds generates a nanocrack network throughout the nanowire, via formation of 'boundary nanocracks' along the twin boundary and 'transverse nanocracks' propagating from the surface to the center of the nanowire. The nanocrack network further reconstructs, leading to a highly porous structure rich in Cu nanograins, with a boosted specific surface area and density of active sites for C$_{2+}$ products. These findings suggest a means to optimize active OD-Cu nanostructures through nanocracking by tailoring grain boundaries in CuO precatalysts. More generally, our advanced operando approach opens new opportunities for mechanistic insights to enable improved control of catalyst structure and performance.         _ Less","","arXiv","https://arxiv.org/abs/2407.16910","1","1","multiple"
"Tracing the Milky Way spiral arms with 26Al -- The role of nova systems in the 2D distribution of 26Al","Abstract:                _1 Myr half-life. Its short lifetime prevents us from observing its complete chemical history, and only the $^{26}$Al that was recently produced by massive stars can be observed. Hence, it is considered a tracer of star formation rate (SFR). However, important contributions to $^{26}$Al comes from nova systems that pollute the interstellar medium with a larg_         _ More           Massive stars are one of the most important and investigated astrophysical production sites of $^{26}$Al, a short-lived radioisotope with $\\sim$ 1 Myr half-life. Its short lifetime prevents us from observing its complete chemical history, and only the $^{26}$Al that was recently produced by massive stars can be observed. Hence, it is considered a tracer of star formation rate (SFR). However, important contributions to $^{26}$Al comes from nova systems that pollute the interstellar medium with a large delay, thus partly erasing the correlation between $^{26}$Al and SFR. In this work we describe the 2D distribution of the mass of $^{26}$Al as well as that of massive stars and nova systems in the Milky Way, to investigate their relative contributions to the production of $^{26}$Al. We use a detailed 2D chemical evolution model where the SFR is azimuthally dependent and is required to reproduce the spiral arm pattern observed in the Milky Way. We test two different models, one where the $^{26}$Al comes from massive stars and novae, and one with massive stars only. We then compare the predictions to the $\\sim$ 2 M$_{\\odot}$ of $^{26}$Al mass observed by the surveys COMPTEL and INTEGRAL. The results show that novae do not trace SFR and, in the solar vicinity, they concentrate in its minima. The effect of novae on the map of the $^{26}$Al mass consists in damping the spiral pattern by a factor of five. Regarding the nucleosynthesis, we find that $\\sim$75% of the $^{26}$Al is produced by novae and the $\\sim$25% by massive stars. We conclude that novae cannot be neglected as $^{26}$Al producers since the observations can only be reproduced by including their contribution. Moreover, we suggest that bulge novae should eject around six times more material than the disc ones to well reproduce the observed mass of $^{26}$Al.         _ Less","","arXiv","https://arxiv.org/abs/2407.16765","3","2","origin_of_life"
"Magneto-optical Control of Ordering Kinetics and Vacancy Behavior in Fe-Al Thin Films Quenched by Laser","Abstract:                One of issues arising in materials science is a behavior of non-equilibrium point defects in the atomic lattice, which defines the rates of chemical reactions and relaxation processes as well as affects the physical properties of solids. It is previously theoretically predicted that melting and rapid solidification of metals and alloys provides a vacancy con_         _ More           One of issues arising in materials science is a behavior of non-equilibrium point defects in the atomic lattice, which defines the rates of chemical reactions and relaxation processes as well as affects the physical properties of solids. It is previously theoretically predicted that melting and rapid solidification of metals and alloys provides a vacancy concentration in the quenched material, which can be comparable to that quantity at the point of melting. Here, the vacancy behavior is studied exerimentally in thin films of the near equiatomic Fe-Al alloy subjected to nanosecond laser annealing with intensities up to film ablation. The effects of laser irradiation are studied by monitoring magneto-optically the ordering kinetics in the alloy at the very ablation edge, within a narrow (micron-scale) ring-shaped region around the ablation zone. Quantitatively, the vacancy supersaturation in the quenched alloy has been estimated by fitting a simulated temporal evolution of the long-range chemical order to the obtained experimental data. Laser quenching (LQ) of alloys and single-element materials would be a tool for obtaining novel phase states within a small volume of the crystal.         _ Less","","arXiv","https://arxiv.org/abs/2407.16423","0","1","synthetic_biology"
"Three-Dimensional Venus Cloud Structure Simulated by a General Circulation Model","Abstract:                The clouds have a great impact on Venus's energy budget and climate evolution, but its three-dimensional structure is still not well understood. Here we incorporate a simple Venus cloud physics scheme into a flexible GCM to investigate the three-dimensional cloud spatial variability. Our simulations show good agreement with observations in terms of the v_         _ More           The clouds have a great impact on Venus's energy budget and climate evolution, but its three-dimensional structure is still not well understood. Here we incorporate a simple Venus cloud physics scheme into a flexible GCM to investigate the three-dimensional cloud spatial variability. Our simulations show good agreement with observations in terms of the vertical profiles of clouds and H2SO4 vapor. H2O vapor is overestimated above the clouds due to efficient transport in the cloud region. The cloud top decreases as latitude increases, qualitatively consistent with Venus Express observations. The underlying mechanism is the combination of H2SO4 chemical production and meridional circulation. The mixing ratios of H2SO4 at 50-60 km and H2O vapors in the main cloud deck basically exhibit maxima around the equator, due to the effect of temperature's control on the saturation vapor mixing ratios of the two species. The cloud mass distribution is subject to both H2SO4 chemical production and dynamical transport and shows a pattern that peaks around the equator in the upper cloud while peaks at mid-high latitudes in the middle cloud. At low latitudes, H2SO4 and H2O vapors, cloud mass loading and acidity show semidiurnal variations at different altitude ranges, which can be validated against future missions. Our model emphasizes the complexity of the Venus climate system and the great need for more observations and simulations to unravel its spatial variability and underlying atmospheric and/or geological processes.         _ Less","","arXiv","https://arxiv.org/abs/2407.15966","0","1","synthetic_biology"
"Shell mergers in the late stages of massive star evolution: new insight from 3D hydrodynamic simulations","Abstract:                One-dimensional (1D) stellar evolution models are widely used across various astrophysical fields, however they are still dominated by important uncertainties that deeply affect their predictive power. Among those, the merging of independent convective regions is a poorly understood phenomenon predicted by some 1D models but whose occurrence and impact in re_         _ More           One-dimensional (1D) stellar evolution models are widely used across various astrophysical fields, however they are still dominated by important uncertainties that deeply affect their predictive power. Among those, the merging of independent convective regions is a poorly understood phenomenon predicted by some 1D models but whose occurrence and impact in real stars remain very uncertain. Being an intrinsically multi-D phenomenon, it is challenging to predict the exact behaviour of shell mergers with 1D models. In this work, we conduct a detailed investigation of a multiple shell merging event in a 20 M$_\\odot$ star using 3D hydrodynamic simulations. Making use of the active tracers for composition and the nuclear network included in the 3D model, we study the merging not only from a dynamical standpoint but also considering its nucleosynthesis and energy generation. Our simulations confirm the occurrence of the merging also in 3D, but reveal significant differences from the 1D case. Specifically, we identify entrainment and the erosion of stable regions as the main mechanisms that drive the merging, we predict much faster convective velocities compared to the mixing-length-theory velocities, and observe multiple burning phases within the same merged shell, with important effects for the chemical composition of the star, which presents a strongly asymmetric (dipolar) distribution. We expect that these differences will have important effects on the final structure of massive stars and thus their final collapse dynamics and possible supernova explosion, subsequently affecting the resulting nucleosynthesis and remnant.         _ Less","","arXiv","https://arxiv.org/abs/2407.15544","0","1","synthetic_biology"
"Cross-diffusion systems coupled via a moving interface","Abstract:                _The motivation stems from the modelling of complex diffusion processes in the context of the vapor deposition of thin films. In our model, cross-diffusion of the various chemical species can be respectively modelled by a size-exclusion system for the solid phase and the Stefan-Maxwell system for the gaseous phase. The coupling between the two phases is mode_         _ More           We propose and study a one-dimensional model which consists of two cross-diffusion systems coupled via a moving interface. The motivation stems from the modelling of complex diffusion processes in the context of the vapor deposition of thin films. In our model, cross-diffusion of the various chemical species can be respectively modelled by a size-exclusion system for the solid phase and the Stefan-Maxwell system for the gaseous phase. The coupling between the two phases is modelled by linear phase transition laws of Butler-Volmer type, resulting in an interface evolution. The continuous properties of the model are investigated, in particular its entropy variational structure and stationary states. We introduce a two-point flux approximation finite volume scheme. The moving interface is addressed with a moving-mesh approach, where the mesh is locally deformed around the interface. The resulting discrete nonlinear system is shown to admit a solution that preserves the main properties of the continuous system, namely: mass conservation, nonnegativity, volume-filling constraints, decay of the free energy and asymptotics. In particular, the moving-mesh approach is compatible with the entropy structure of the continuous model. Numerical results illustrate these properties and the dynamics of the model.         _ Less","","arXiv","https://arxiv.org/abs/2407.15457","0","1","synthetic_biology"
"Abundances of neutron-capture elements in selected solar-type stars","Abstract:                _and age, while the [Cu/Fe] ratio increases with both metallicity and age. These observed trends agree well with published observational data and with predictions from Galactic chemical evolution models. A small [Ba/Fe] enhancement of 0.08 +/- 0.08 dex has been detected in seven younger stars with an average age of 2.8_         _ More           The primary objective of this study is to accurately determine the abundances of Cu, Sr, Y, Zr, Ba, La, and Ce in selected solar-type stars. This will allow us to establish observational abundance-metallicity and abundance-age relations and to explore the reasons for the excess of Ba compared to other s-elements in younger solar-type stars. We analysed HARPS spectra of main-sequence solar-type FGK stars with metallicities from -0.15 to +0.35 dex and ages from 2 to 14 Gyr using 1D LTE synthesis and MARCS atmospheric models. In the procedure of fitting synthetic to observed line profiles, the free parameters included abundance and microturbulent and macroturbulent velocity. The macroturbulent velocity can substantially compensate for NLTE effects in the line core. We find that the abundance [X/H] increases with metallicity and age. The ratio of the abundances of s-process elements [s/Fe] increases with decreasing metallicity and age, while the [Cu/Fe] ratio increases with both metallicity and age. These observed trends agree well with published observational data and with predictions from Galactic chemical evolution models. A small [Ba/Fe] enhancement of 0.08 +/- 0.08 dex has been detected in seven younger stars with an average age of 2.8 +/- 0.6 Gyr. Compared to the abundances of other s-process elements, [Ba/Fe] is 0.07 and 0.08 dex higher than La and Ce on average, respectively. Furthermore, we find that the [Ba/Fe] ratio increases with increasing chromospheric activity. The average [Ba/Fe] for the three most active stars is 0.15 +/- 0.10 dex higher than that of the other stars. Chromospheric activity can significantly alter the physical conditions in the formation layers of the Ba lines. Our primary conclusion is that to account for the observed excess of [Ba/Fe] abundance in younger stars, it is essential to use more complex atmospheric models that incorporate magnetic structures.         _ Less","","arXiv","https://arxiv.org/abs/2407.14808","2","1","origin_of_life"
"Stellar substructures in the Galactic disc and halo: Properties, origins, and evolution","Abstract:                Spatial, kinematic, and orbital properties, along with ages and chemical compositions of the thin disc, thick disc, and various stellar substructures in the halo, are studied based on data from the LAMOST and Gaia surveys. The star formation in the Galactic thin and thick disc, with peak metallicities of $-0.20$ and $-0.45$ dex, is found to have peaked about_         _ More           Spatial, kinematic, and orbital properties, along with ages and chemical compositions of the thin disc, thick disc, and various stellar substructures in the halo, are studied based on data from the LAMOST and Gaia surveys. The star formation in the Galactic thin and thick disc, with peak metallicities of $-0.20$ and $-0.45$ dex, is found to have peaked about 5.5 and 12.5 Gyr ago, respectively. The thin disc is also found to have experienced an initial star formation burst about 12.5 Gyr ago. The pro-grade population Splash and hot-disc (HD), with peak metallicity of about $-0.60$ and $-0.43$, are found to be about 13.03 and 12.21 Gyr old, respectively, with peak eccentricity of 0.70 and 0.35, are understood to be of in situ origin. The Gaia-Enceladus/Sausage (GE/S), Thamnos, and Sequoia, with peak metallicity of about $-1.31$, $-1.36$, and $-1.56$, are found to be about 11.66, 12.89, and 12.18 Gyr old, respectively, and are understood to be remnants of dwarf galaxies merged with the Milky Way. The HD, Splash, and Thamnos are found to have experienced chemical evolution similar to the thick disc while GE/S, Sequoia, and Helmi stream are found to have experienced distinct chemical enrichment of iron and $_$-process elements.         _ Less","","arXiv","https://arxiv.org/abs/2407.14508","3","2","origin_of_life"
"Neutrino-driven Core-collapse Supernova Yields in Galactic Chemical Evolution","Abstract:                _between 11 and 75 solar masses and three different metallicities. Our CCSN simulations have two main advantages compared to previous methods used for applications in Galactic chemical_         _ More           We provide yields from 189 neutrino-driven core-collapse supernova (CCSN) simulations covering zero-age main sequence masses between 11 and 75 solar masses and three different metallicities. Our CCSN simulations have two main advantages compared to previous methods used for applications in Galactic chemical evolution (GCE). Firstly, the mass cut between remnant and ejecta evolves naturally. Secondly, the neutrino luminosities and thus the electron fraction are not modified. Both is key to obtain an accurate nucleosynthesis. We follow the composition with an in-situ nuclear reaction network including the 16 most abundant isotopes and use the yields as input in a GCE model of the Milky Way. We adopt a GCE which takes into account infall of gas as well as nucleosynthesis from a large variety of stellar sources. The GCE model is calibrated to reproduce the main features of the solar vicinity. For the CCSN models, we use different calibrations and propagate the uncertainty. We find a big impact of the CCSN yields on our GCE predictions. We compare the abundance ratios of C, O, Ne, Mg, Si, S, Ar, Ca, Ti, and Cr with respect to Fe to an observational data set as homogeneous as possible. From this, we conclude that at least half of the massive stars have to explode to match the observed abundance ratios. If the explosions are too energetic, the high amount of iron will suppress the abundance ratios. With this, we demonstrate how GCE models can be used to constrain the evolution and deaths of massive stars.         _ Less","","arXiv","https://arxiv.org/abs/2407.14319","1","2","synthetic_biology"
"Evolution of stars with 60 and 200 Msun: predictions for WNh stars in the Milky Way","Abstract:                We study in detail the evolution of two massive stars at solar metallicity (Z=0.014) taken from Romagnolo et al. (2024, Paper I); by running_         _ More           We study in detail the evolution of two massive stars at solar metallicity (Z=0.014) taken from Romagnolo et al. (2024, Paper I); by running evolution models for initial masses 60 and 200 Msun, using MESA and GENEC. For the mass loss, we adopt the self-consistent m-CAK prescription for the optically thin winds of OB-stars, a semi-empirical formula for H-rich thick wind of WNh stars, and a hydrodynamically consistent formula for the H-poor thick wind of classical Wolf-Rayet stars. Both codes predict different tracks across the HRD. For the 60 Msun case, Genec models predict a more efficient rotational mixing and more chemically homogeneous evolution, whereas MESA model predicts a large radial expansion post-MS reaching the LBV phase. For the 200 Msun case, differences are less relevant because their evolution is dominated by wind mass loss with a weaker dependence on internal mixing, and only the treatment for superadiabacity creates an impact during the He-burning stage. The switch of the mass loss based on the proximity to the Eddington factor instead of the removal of outer layers, implies the existence of WNh stars with a large mass fraction of hydrogen at the surface formed from initial masses $\\gtrsim60$ Msun. These stars are constrained in a Teff range of the HR diagram which corresponds to the MS band, in agreement with the observations of Galactic WNh stars. While our models employ a fixed $__e$ threshold for the switch to thick winds, rather than a continuous thin-to-thick wind model, the good reproduction of observations supports the robustness of the wind model upgrades introduced in Paper I, allowing its application to studies of late-stage stellar evolution before core collapse.         _ Less","","arXiv","https://arxiv.org/abs/2407.14165","0","2","synthetic_biology"
"A mm and near-IR study of YSOs: from outbursting protostars to satellites","Abstract:                We are in a golden era observing Young Stellar Objects (YSOs), protoplanetary disks, and substellar objects, crucial for understanding their formation and evolution. This Ph.D. thesis explores two binary systems.   Firstly, we study an eruptive YSO, HBC 494, using ALMA band 6 (1.3 mm) observations. It's a FUor system in Orion Molecular Cloud with a resol_         _ More           We are in a golden era observing Young Stellar Objects (YSOs), protoplanetary disks, and substellar objects, crucial for understanding their formation and evolution. This Ph.D. thesis explores two binary systems.   Firstly, we study an eruptive YSO, HBC 494, using ALMA band 6 (1.3 mm) observations. It's a FUor system in Orion Molecular Cloud with a resolved binary system: HBC 494 N (primary) and HBC 494 S (secondary) separated by 75 au. The disks show hints of aligned formation scenarios, with HBC 494 N being brighter and larger. Molecular line observations reveal bipolar outflows and rotating envelopes. Cavity features within the continuum disks' area suggest continuum over-subtraction or slow-moving jets and chemical destruction along the line-of-sight.   Secondly, we examine the young binary system $_$ Tel using VLT/SPHERE H band imaging. It consists of an A-type star and a brown dwarf companion $_$ Tel B, separated by 208 au. Astrometric measurements over 19 years yield a low eccentric orbit with an inclination of 81.9 degrees. The mass of $_$ Tel B is determined to be 48 M$_{Jup}$, consistent with previous literature. No significant residual indicative of a satellite or disk surrounding the companion is detected, with limits ruling out massive objects around $_$ Tel B at separations down to 33 au with masses as low as 1.6M$_{Jup}$.   These studies employ sub-mm to near-IR observations, highlighting the complexity of (sub)stellar formation/evolution. This thesis contributes diverse analyses, providing insights into these intriguing processes.         _ Less","","arXiv","https://arxiv.org/abs/2407.13897","1","1","multiple"
"Atomistic evolution of active sites in multi-component heterogeneous catalysts","Abstract:                Multi-component metal nanoparticles (NPs) are of paramount importance in the chemical industry, as most processes therein employ heterogeneous catalysts. While these multi-component systems have been shown to result in higher product yields, improved selectivities, and greater stability through catalytic cycling, the structural dynamics of these materials in_         _ More           Multi-component metal nanoparticles (NPs) are of paramount importance in the chemical industry, as most processes therein employ heterogeneous catalysts. While these multi-component systems have been shown to result in higher product yields, improved selectivities, and greater stability through catalytic cycling, the structural dynamics of these materials in response to various stimuli (e.g. temperature, adsorbates, etc.) are not understood with atomistic resolution. Here, we present a highly accurate equivariant machine-learned force field (MLFF), constructed from ab initio training data collected using Bayesian active learning, that is able to reliably simulate PdAu surfaces and NPs in response to thermal treatment as well as exposure to reactive H$_2$ atmospheres. We thus provide a single model that is able to reliably describe the full space of geometric and chemical complexity for such a heterogeneous catalytic system across single crystals, gas-phase interactions, and NPs reacting with H$_2$, including catalyst degradation and explicit reactivity. Ultimately, we provide direct atomistic evidence that verifies existing experimental hypotheses for bimetallic catalyst deactivation under reaction conditions, namely that Pd preferentially segregates into the Au bulk through aggressive catalytic cycling and that this degradation is site-selective, as well as the reactivity for hydrogen exchange as a function of Pd ensemble size. We demonstrate that understanding of the atomistic evolution of these active sites is of the utmost importance, as it allows for design and control of material structure and corresponding performance, which can be vetted in silico.         _ Less","","arXiv","https://arxiv.org/abs/2407.13607","0","1","synthetic_biology"
"On the origin of univalent Mg$^+$ ions in solution and their role in anomalous anodic hydrogen evolution","Abstract:                _metal corrosion is a major economic concern in modern society. A phenomenon that has puzzled generations of scientists in this field is the so-called anomalous hydrogen evolution: the violent dissolution of magnesium under electron-rich (anodic) conditions, accompanied by strong hydrogen evolution, and a key mechanism_         _ More           Aqueous metal corrosion is a major economic concern in modern society. A phenomenon that has puzzled generations of scientists in this field is the so-called anomalous hydrogen evolution: the violent dissolution of magnesium under electron-rich (anodic) conditions, accompanied by strong hydrogen evolution, and a key mechanism hampering Mg technology. Experimental studies have indicated the presence of univalent Mg$^+$ in solution, but these findings have been largely ignored because they defy our common chemical understanding and evaded direct experimental observation. Using recent advances in the \\emph{ab initio} description of solid-liquid electrochemical interfaces under controlled potential conditions, we described the full reaction path of Mg atom dissolution from a kinked Mg surface under anodic conditions. Our study reveals the formation of a solvated [Mg$^{2+}$(OH)$^-$]$^+$ ion complex, challenging the conventional assumption of Mg$^{2+}$ ion. This insight provides an intuitive explanation for the postulated presence of (coulombically) univalent Mg$^+$ ions and the absence of protective oxide/hydroxide layers normally formed under anodic/oxidizing conditions. The discovery of this unexpected and unconventional reaction mechanism is crucial for identifying new strategies for corrosion prevention and can be transferred to other metals.         _ Less","","arXiv","https://arxiv.org/abs/2407.13472","1","1","multiple"
"A uniquely solvable and positivity-preserving finite difference scheme for the Flory-Huggins-Cahn-Hilliard equation with dynamical boundary condition","Abstract:                _equation with dynamical boundary condition. The singular logarithmic potential is included in the Flory-Huggins energy expansion. Meanwhile, a dynamical evolution equation for the boundary profile corresponds to a lower-dimensional singular energy potential. In turn, a theoretical analysis for the coupled system becomes very challenging, since it contains no_         _ More           In this paper we propose and analyze a finite difference numerical scheme for the Flory-Huggins-Cahn-Hilliard equation with dynamical boundary condition. The singular logarithmic potential is included in the Flory-Huggins energy expansion. Meanwhile, a dynamical evolution equation for the boundary profile corresponds to a lower-dimensional singular energy potential. In turn, a theoretical analysis for the coupled system becomes very challenging, since it contains nonlinear and singular energy potentials for both the interior region and on the boundary. In the numerical design, a convex splitting approach is applied to the chemical potential associated with the energy both at the interior region and on the boundary: implicit treatments for the singular and logarithmic terms, as well as the surface diffusion terms, combined with an explicit treatment for the concave expansive term. In addition, the discrete boundary condition for the phase variable is coupled with the evolutionary equation of the boundary profile. The resulting numerical system turns out to be highly nonlinear, singular and coupled. A careful finite difference approximation and convexity analysis reveals that such a numerical system could be represented as a minimization of a discrete numerical energy functional, which contains both the interior and boundary integrals. More importantly, all the singular terms correspond to a discrete convex functional. As a result, a unique solvability and positivity-preserving analysis could be theoretically justified, based on the subtle fact that the singular nature of the logarithmic terms around the singular limit values prevent the numerical solutions reaching these values. The total energy stability analysis could be established by a careful estimate over the finite difference inner product. Some numerical results are presented in this article.         _ Less","","arXiv","https://arxiv.org/abs/2407.13453","0","1","synthetic_biology"
"Chemical Potential Shift in Doped Mott-insulators for Energy Storage Applications","Abstract:                _of strongly correlated systems, specifically Mott-insulators, in the context of battery electrode materials. The study investigates the correlation between the proposed chemical potential_         _ More           This work explores the unique character of strongly correlated systems, specifically Mott-insulators, in the context of battery electrode materials. The study investigates the correlation between the proposed chemical potential evolution and charge storage performance in transition metal oxide-based electrodes. The hypothesis suggests that doping a Mott insulator reduces the Hubbard Coulomb interaction, which could slow down the chemical shift and result in enhanced charge storage capabilities compared to classic band insulators. The results support the hypothesis through a systematic comparison of selected transition metal oxide-based electrodes (Cu, Mn, Co, and Fe oxide electrodes). Furthermore, a toy model is employed to investigate the shift in chemical potential with doping-dependent U using DFT+U calculation, aiming to visualize the chemical potential evolution in Mott-insulators relevant to their application as battery electrodes. This study provides valuable insights into how strongly correlated materials, especially Mott-insulators, contribute to the advancement of energy storage technologies.         _ Less","","arXiv","https://arxiv.org/abs/2407.13172","0","1","synthetic_biology"
"MC-BLOS: Determination of the Line-of-Sight Component of Magnetic Fields Associated with Molecular Clouds","Abstract:                _the technique in an automated manner. The software's input are Faraday rotation of point sources (extra-galactic sources or pulsars), extinction or column density maps, chemical evolution code results, and a text/CSV file, which allows the user to specify the cloud name or other parameters pertaining to the techniq_         _ More           In recent years a number of surveys and telescopes have observed the plane-of-sky component of magnetic fields associated with molecular clouds. However, observations of their line-of-sight magnetic field remain limited. To address this issue, Tahani et al. (2018) developed a technique based on Faraday rotation. The technique incorporates an ON-OFF approach to identify the rotation measure induced by the magnetic fields associated with the cloud. The upcoming abundance of Faraday rotation observations from the Square Kilometer Array and its pathfinders necessitates robustly-tested software to automatically obtain line-of-sight magnetic fields of molecular clouds. We developed software, called MC-BLOS (Molecular Cloud Line-of-Sight Magnetic Field), to carry out the technique in an automated manner. The software's input are Faraday rotation of point sources (extra-galactic sources or pulsars), extinction or column density maps, chemical evolution code results, and a text/CSV file, which allows the user to specify the cloud name or other parameters pertaining to the technique. For each cloud, the software invokes a set of predefined initial parameters such as density, temperature, and surrounding boundary, which the user can modify. The software then runs the technique automatically, outputting line-of-sight magnetic field maps and tables (including uncertainties) at the end of the process. This automated approach significantly reduces analysis time compared to manual methods. We have tested the software on previously-published clouds, and the results are consistent within the reported uncertainty range. This software will facilitate the analysis of forthcoming Faraday rotation observations, enabling a better understanding of the role of magnetic fields in molecular cloud dynamics and star formation.         _ Less","","arXiv","https://arxiv.org/abs/2407.13005","3","2","origin_of_life"
"Scaling Properties of Gelling Systems in Nonlinear Shear Experiments","Abstract:                _polymer gelling systems made of gluten proteins dispersions stabilized at different distances from the gel point. We impose different shear rates and follow the time evolution of the stress. For sufficiently large shear rates, an intermediate stress overshoot is measured before reaching the steady state. We evidence self-similarity of the stress overshoot as_         _ More           We study model near-critical polymer gelling systems made of gluten proteins dispersions stabilized at different distances from the gel point. We impose different shear rates and follow the time evolution of the stress. For sufficiently large shear rates, an intermediate stress overshoot is measured before reaching the steady state. We evidence self-similarity of the stress overshoot as a function of the applied shear rate for samples with various distances from the gel point, which is related to the elastic energy stored by the samples, as for dense systems close to the jamming transition. In concordance with the findings for glassy and jammed systems, we also measure that the stress after flow cessation decreases as a power law with time with a characteristic relaxation time that depends on the shear rate previously imposed. These features revealed in non-linear rheology could be the signature of a mesoscopic dynamics, which would depend on the extent of gelation.         _ Less","","arXiv","https://arxiv.org/abs/2407.12367","0","1","synthetic_biology"
"Insights into the Mechanism, Selectivity, and Substituent Effects in the Diels-Alder Reaction of Azatrienes with Electron-rich Dienophiles: An MEDT Study","Abstract:                _on one hand and the characteristics of the reactions mechanism on the other hand. The influence of weak interactions on reaction activation barriers and bonding evolution are discussed in detail. We demonstrate that substituents enhancing the reverse electron density flux facilitate the feasibility of the reactions. The results lay ground for a meticulous co_         _ More           The reactivity and mechanistic intricacies of azatrienes in Diels-Alder reactions have been relatively unexplored despite their intriguing potential applications. In this study, we employ Molecular Electron Density Theory to theoretically investigate the hetero-Diels-Alder reaction involving azatrienes with ethyl vinyl ether and allenyl methyl ether. Analysis of Conceptual Density Functional Theory, energetic profiles, and the topological characteristics is conducted to elucidate the reactions. The revealed mechanism manifests as a polar one-step two-stages process under kinetic control. We establish a clear relationship of between the periselectivity, regioselectivity, and stereoselectivity on one hand and the characteristics of the reactions mechanism on the other hand. The influence of weak interactions on reaction activation barriers and bonding evolution are discussed in detail. We demonstrate that substituents enhancing the reverse electron density flux facilitate the feasibility of the reactions. The results lay ground for a meticulous control of the reaction of azatriene in similar synthetic scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2407.11230","0","1","synthetic_biology"
"Muon-induced collisional flavor instability in core-collapse supernova","Abstract:                _denotes the chemical potential of $i$ constitute ($n$ and $p$ represent neutrons and protons, respectively). Our result suggests that the non-linear evolution of CFI with on-shell muons would induce flavor conversions with the complex interplay among all three different neutrino-mixing sectors.         _ More           Neutrinos are known to undergo flavor conversion among their three flavors. In the theoretical modeling of core-collapse supernova (CCSN), there has been a great deal of attention to recent discoveries of a new type of neutrino flavor conversions, namely collisional flavor instability (CFI), in which the instability is induced by the flavor-dependent decoherence due to the disparity of neutrino-matter interactions among flavors. In this paper, we study how the appearance of on-shell muons and associated neutrino-matter interactions can impact CFIs based on linear stability analysis of flavor conversions. Some striking results emerge from the present study. First, we analytically show that breaking beta- and pair equilibrium is a necessary condition to trigger CFIs. This also indicates that CFIs with on-shell muons could appear in $e _$ and $_$ neutrino mixing sectors in very high-density region ($\\gtrsim 10^{13} {\\rm g/cm^{3}}$), exhibiting a possibility of large impacts of CFIs on CCSN. Second, resonance-like CFIs, having a much higher growth rate than normal CFIs, can be triggered by muons. The resonance point of CFIs is different between $e _$ and $_$ sectors; the former (latter) occurs at $__{e (_)} = __{n} - __{p}$, where $__{i}$ denotes the chemical potential of $i$ constitute ($n$ and $p$ represent neutrons and protons, respectively). Our result suggests that the non-linear evolution of CFI with on-shell muons would induce flavor conversions with the complex interplay among all three different neutrino-mixing sectors.         _ Less","","arXiv","https://arxiv.org/abs/2407.10604","0","2","synthetic_biology"
"Variational Quantum Imaginary Time Evolution for Matrix Product State Ansatz with Tests on Transcorrelated Hamiltonians","Abstract:                _of molecular Hamiltonians and solving quantum chemistry problems. Building on this concept, the proposed technique of quantum circuit MPS (QCMPS) enables the simulation of chemical systems using a relatively small number of qubits. In this study, we enhance the optimization performance of the QCMPS ansatz by employing the variational quantum imaginary time_         _ More           The matrix product state (MPS) ansatz offers a promising approach for finding the ground state of molecular Hamiltonians and solving quantum chemistry problems. Building on this concept, the proposed technique of quantum circuit MPS (QCMPS) enables the simulation of chemical systems using a relatively small number of qubits. In this study, we enhance the optimization performance of the QCMPS ansatz by employing the variational quantum imaginary time evolution (VarQITE) approach. Guided by McLachlan's variational principle, the VarQITE method provides analytical metrics and gradients, resulting in improved convergence efficiency and robustness of the QCMPS. We validate these improvements numerically through simulations of $\\rm H_2$, $\\rm H_4$, and $\\rm LiH$ molecules. Additionally, given that VarQITE is applicable to non-Hermitian Hamiltonians, we evaluate its effectiveness in preparing the ground state of transcorrelated (TC) Hamiltonians. This approach yields energy estimates comparable to the complete basis set (CBS) limit while using even fewer qubits. Specifically, we perform simulations of the beryllium atom and $\\rm LiH$ molecule using only three qubits, maintaining high fidelity with the CBS ground state energy of these systems. This qubit reduction is achieved through the combined advantages of both the QCMPS ansatz and transcorrelation. Our findings demonstrate the potential practicality of this quantum chemistry algorithm on near-term quantum devices.         _ Less","","arXiv","https://arxiv.org/abs/2407.10523","0","1","synthetic_biology"
"Exploring fluorine chemical evolution in the Galactic disk: the open cluster perspective","Abstract:                _clusters, adding six open clusters as well as eight field stars. The primary objective is to determine the abundance of fluorine (F) to gain insight into its production and evolution. The magnesium (Mg) abundances were derived to categorize the field stars into high and low alpha disk populations. Additionally, cerium (Ce) abundances are determined to better_         _ More           Open clusters are ideal tools for tracing the abundances of different elements because their stars are expected to have the same age, distance, and metallicity. Therefore, they serve as very powerful tracers for investigating the cosmic origins of elements. This paper expands on a recent study by us, where the element Fluorine was studied in seven previously open clusters, adding six open clusters as well as eight field stars. The primary objective is to determine the abundance of fluorine (F) to gain insight into its production and evolution. The magnesium (Mg) abundances were derived to categorize the field stars into high and low alpha disk populations. Additionally, cerium (Ce) abundances are determined to better understand the interplay between F and s-process elements. The spectra were obtained from the high-resolution near-infra-red GIANO-B instrument at the Telescopio Nazionale Galileo (TNG). For the derivation of the stellar parameters and abundances, the Python version of Spectroscopy Made Easy (PySME) was used. OH, CN, and CO molecular lines and band heads along with Fe I lines were used to determine the stellar parameters in the H-band region. Two HF lines in the K-band (_ 2.28, 2.33 _m), three K-band Mg I lines (_ 2.10, 2.11, 2.15 _m), and two Ce II lines in the H-band (_ 1.66, and 1.71 _m) were used to derive the abundances of F, Mg, and Ce, respectively. F, Mg, and Ce abundances were derived for 14 stars from 6 OCs, as well as 8 field stars. The F and Ce abundances were investigated as a function of metallicity, age, and Galactocentric distances. Our results indicate that asymptotic giant branch stars and massive stars, including a subset of fast rotators (whose rotation speed likely increases as metallicity decreases), are necessary to explain the cosmic origin of F.         _ Less","","arXiv","https://arxiv.org/abs/2407.10229","1","1","multiple"
"Practicality of quantum adiabatic algorithm for chemistry applications","Abstract:                _electronic structure Hamiltonians, as well as discretisation errors heating the state. We show that a recently proposed randomized algorithm, which implements exact adiabatic evolution without heating and with far fewer gates than Trotterisation, can overcome this problem. We develop three methods for measuring the energy of the prepared state in an efficien_         _ More           Despite its simplicity and strong theoretical guarantees, adiabatic state preparation has received considerably less interest than variational approaches for the preparation of low-energy electronic structure states. Two major reasons for this are the large number of gates required for Trotterising time-dependent electronic structure Hamiltonians, as well as discretisation errors heating the state. We show that a recently proposed randomized algorithm, which implements exact adiabatic evolution without heating and with far fewer gates than Trotterisation, can overcome this problem. We develop three methods for measuring the energy of the prepared state in an efficient and noise-resilient manner, yielding chemically accurate results on a 4-qubit molecule in the presence of realistic gate noise, without the need for error mitigation. These findings suggest that adiabatic approaches to state preparation could play a key role in quantum chemistry simulations both in the era of noisy as well as error-corrected quantum computers.         _ Less","","arXiv","https://arxiv.org/abs/2407.09993","0","1","synthetic_biology"
"Tensor networks enable the calculation of turbulence probability distributions","Abstract:                _simulation of all but the simplest turbulent flow-fields remains impossible: the fields are too chaotic and multi-scaled to directly store them in memory and perform time-evolution. An alternative is to treat turbulence $\\textit{probabilistically}$, viewing flow properties as random variables distributed according to joint probability density functions (PDFs_         _ More           Predicting the dynamics of turbulent fluid flows has long been a central goal of science and engineering. Yet, even with modern computing technology, accurate simulation of all but the simplest turbulent flow-fields remains impossible: the fields are too chaotic and multi-scaled to directly store them in memory and perform time-evolution. An alternative is to treat turbulence $\\textit{probabilistically}$, viewing flow properties as random variables distributed according to joint probability density functions (PDFs). Turbulence PDFs are neither chaotic nor multi-scale, but are still challenging to simulate due to their high dimensionality. Here we show how to overcome the dimensionality problem by parameterising turbulence PDFs into an extremely compressed format known as a 'tensor network' (TN). The TN paradigm enables simulations on single CPU cores that would otherwise be impractical even with supercomputers: for a $5+1$ dimensional PDF of a chemically reactive turbulent flow, we achieve reductions in memory and computational costs by factors of $\\mathcal{O}(10^6)$ and $\\mathcal{O}(10^3)$, respectively, compared to standard finite difference algorithms. A future path is opened towards something heretofore regarded as infeasible: directly simulating high-dimensional PDFs of both turbulent flows and other chaotic systems that are useful to describe probabilistically.         _ Less","","arXiv","https://arxiv.org/abs/2407.09169","0","1","synthetic_biology"
"New Wolf-Rayet wind yields and nucleosynthesis of Helium stars","Abstract:                Strong metallicity-dependent winds dominate the evolution of core He-burning, classical Wolf-Rayet (cWR) stars, which eject both H and He-fusion products such as 14N, 12C, 16O, 19F, 22Ne and 23Na during their_         _ More           Strong metallicity-dependent winds dominate the evolution of core He-burning, classical Wolf-Rayet (cWR) stars, which eject both H and He-fusion products such as 14N, 12C, 16O, 19F, 22Ne and 23Na during their evolution. The chemical enrichment from cWRs can be significant. cWR stars are also key sources for neutron production relevant for the weak s-process. We calculate stellar models of cWRs at solar metallicity for a range of initial Helium star masses (12-50M), adopting the recent hydrodynamical wind rates from Sander & Vink (2020). Stellar wind yields are provided for the entire post-main sequence evolution until core O-exhaustion. While literature has previously considered cWRs as a viable source of the radioisotope 26Al, we confirm that negligible 26Al is ejected by cWRs since it has decayed to 26Mg or proton-captured to 27Al. However, in Paper I, Higgins et al. (2023) we showed that very massive stars eject substantial quantities of 26Al, among other elements including N, Ne, and Na, already from the zero-age-main-sequence. Here, we examine the production of 19F and find that even with lower mass-loss rates than previous studies, our cWR models still eject substantial amounts of 19F. We provide central neutron densities (Nn) of a 30M cWR compared with a 32M post-VMS WR and confirm that during core He-burning, cWRs produce a significant number of neutrons for the weak s-process via the 22Ne(alpha,n)25Mg reaction. Finally, we compare our cWR models with observed [Ne/He], [C/He] and [O/He] ratios of Galactic WC and WO stars.         _ Less","","arXiv","https://arxiv.org/abs/2407.07983","0","1","synthetic_biology"
"Modeling the Ages and Chemical Abundances of Elliptical Galaxies","Abstract:                _-enhancement traced by [Mg/Fe] all increase with galaxy stellar mass or velocity dispersion. We use one-zone galactic chemical evolution (GCE) models with a flexible star formation history (SFH) to model the age, [Mg/H], and [Mg/Fe] inferred from simple stellar population (SSP) fits to observed ellipticals at_         _ More           Spectroscopic studies of elliptical galaxies show that their stellar population ages, mean metallicity, and $_$-enhancement traced by [Mg/Fe] all increase with galaxy stellar mass or velocity dispersion. We use one-zone galactic chemical evolution (GCE) models with a flexible star formation history (SFH) to model the age, [Mg/H], and [Mg/Fe] inferred from simple stellar population (SSP) fits to observed ellipticals at $z \\sim 0$ and $z \\sim 0.7$. We show that an SSP fit to the spectrum computed from a full GCE model gives ages and abundances close to the light-weighted, logarithmically averaged values of the composite stellar population, <age>, <[Mg/H]>, and <[Mg/Fe]>. With supernova Mg and Fe yields fixed to values motivated by Milky Way stellar populations, we find that predicted <[Mg/H]>-<age> and <[Mg/Fe]>-<age> relations are surprisingly insensitive to SFH parameters: older galaxies have higher <[Mg/Fe]>, but the detailed form of the SFH has limited impact. The star formation efficiency and outflow efficiency affect the early and late evolution of <[Mg/H]>, respectively; explaining observed trends requires higher star formation efficiency and lower outflows in more massive galaxies. With core collapse supernova yields calibrated to the plateau [Mg/Fe]$_{\\rm cc} \\approx0.45$ observed in many Milky Way studies, our models underpredict the observed <[Mg/Fe]> ratios of ellipticals by 0.05-0.1 dex. Increasing the core collapse yield ratio to [Mg/Fe]$_{\\rm cc} = 0.55$ improves the agreement, though the models still lie below the data. We discuss potential resolutions of this discrepancy, including the possibility that many ellipticals terminate their star formation with a self-enriching, terminating burst that reduces the light-weighted age and boosts <[Mg/Fe]>.         _ Less","","arXiv","https://arxiv.org/abs/2407.07971","2","1","origin_of_life"
"The [Y/Mg] chemical clock in the Galactic Disk: The influence of metallicity and Galactic population in the solar neighbourhood","Abstract:                Stellar ages are an important parameter to study the chemical_         _ More           Stellar ages are an important parameter to study the chemical evolution of the Galaxy. In recent years, several studies have established the existence of a relationship between chemical clocks and stellar ages. The [Y/Mg] clock is a promising technique, but there are still several open questions, such as its validity for metal-poor stars and differences between the thin and thick disk populations. Our aim is to study the behaviour of the [Y/Mg] chemical clock with stellar ages and the effect of metallicity and population on this chemical clock for a sample of solar-type disk stars. We have derived the precise stellar atmospheric parameters as well as the elemental abundances of Mg and Y through line-by-line differential spectroscopic analysis for a sample of 48 metal-poor solar-type stars based on high-quality, high-resolution ESO/HARPS spectra. From the high-precision Gaia astrometric data, stellar masses and ages were estimated through isochrone-fitting. A joint analysis of our sample, together with a sample of 185 solar-twins and analogues from our previous works, is performed to calibrate the [Y/Mg] chemical clock in the Galactic disk for $-$0.71 $\\leq$ [Fe/H] $<$ +0.34. Open clusters and stars with asteroseismic ages have been used to validate our relations. Two different populations could be clearly seen in the [Mg/Fe] - [Fe/H] plane - the thick and thin disks. We found a metallicity-dependent, strong anti-correlation between the [Y/Mg] ratio and stellar ages of our sample. For the first time in the literature, we report similar correlations for the thin and thick disk stars. The [Y/Mg] relation(s) found here for solar-type stars is compatible with the literature using solar-twins. Our relation provides higher accuracy and precision of 0.45 and 0.99 Gyr, respectively, comparable with the best accuracy achieved for the solar-twins till date.         _ Less","","arXiv","https://arxiv.org/abs/2407.07283","1","1","multiple"
"Molecular Formation in Low-Metallicity Hot Cores","Abstract:                The chemical complexity in low-metallicity hot cores has been confirmed by observations. We investigate the effect of varying physical parameters, such as temperature, density and the cosmic ray ionisation rate (CRIR), on the molecular abundance_         _ More           The chemical complexity in low-metallicity hot cores has been confirmed by observations. We investigate the effect of varying physical parameters, such as temperature, density and the cosmic ray ionisation rate (CRIR), on the molecular abundance evolution in low-metallicity hot cores using the UMIST gas phase chemical model. CRIR had the strongest effect on molecular abundance. The resultant molecular abundances were divided into three categories with different trends in time evolution. We compared our results with the observations of hot cores in the Large Magellanic Cloud (LMC). Our model fits best with the observations at a time of around $10^5$ years after the evaporation of ice and at the CRIR of $1.36 \\times 10^{-16}$ s$^{-1}$. The resultant abundances of the oxygen-bearing complex organic molecules (COMs), such as CH$_3$OH, HCOOCH$_3$ and CH$_3$OCH$_3$, do not fit with observations in the same physical condition and may be located in a different physical environment. Our results suggest that investigating the CRIR value is crucial to predict the molecular evolution in LMC hot cores.         _ Less","","arXiv","https://arxiv.org/abs/2407.06791","1","1","multiple"
"Laboratory and Computational Studies of Interstellar Ices","Abstract:                _role in shaping the astrochemical inventory of molecules during star and planet formation. Small-scale molecular processes have a profound impact on large-scale astronomical evolution. The areas of solid-state laboratory astrophysics and computational chemistry study these processes. We review the laboratory effort on ice spectroscopy; methodological advance_         _ More           Ice mantles play a crucial role in shaping the astrochemical inventory of molecules during star and planet formation. Small-scale molecular processes have a profound impact on large-scale astronomical evolution. The areas of solid-state laboratory astrophysics and computational chemistry study these processes. We review the laboratory effort on ice spectroscopy; methodological advances and challenges; and laboratory and computational studies of ice physics and ice chemistry. The latter we put in context with the ice evolution from clouds to disks. Three takeaway messages from this review are   - Laboratory and computational studies allow interpretation of astronomical ice spectra in terms of identification, ice morphology and, local environmental conditions as well as the formation of the involved chemical compounds.   - A detailed understanding of the underlying processes is needed to build reliable astrochemical models to make predictions on the abundances in space.   - The relative importance of the different ice processes studied in the laboratory and computationally changes along the process of star and planet formation.         _ Less","","arXiv","https://arxiv.org/abs/2407.06657","2","2","multiple"
"Once a Triple, Not Always a Triple: The Evolution of Hierarchical Triples that Yield Merged Inner Binaries","Abstract:                _in a close orbit (the inner binary) while a tertiary star orbits them on a wider orbit (the outer binary). In hierarchical triples, three-body dynamics combined with stellar evolution drives interactions and, in many cases, merges the inner binary entirely to create a renovated `Post-Merger Binary' (PMB). By leveraging dynamical simulations and tracking_         _ More           More than half of all main-sequence (MS) stars have one or more companions, and many of those with initial masses <8 M$_\\odot$ are born in hierarchical triples. These systems feature two stars in a close orbit (the inner binary) while a tertiary star orbits them on a wider orbit (the outer binary). In hierarchical triples, three-body dynamics combined with stellar evolution drives interactions and, in many cases, merges the inner binary entirely to create a renovated `Post-Merger Binary' (PMB). By leveraging dynamical simulations and tracking binary interactions, we explore the outcomes of merged triples and investigate whether PMBs preserve signatures of their three-body history. Our findings indicate that in 26-54% of wide double WD binaries (s>100 au), the more massive white dwarf (WD) is a merger product, implying that these DWD binaries were previously triples. Overall, we estimate that $44\\pm14\\%$ of observed wide DWDs originated in triple star systems and thereby have rich dynamical histories. Additionally, our results suggest that the separations of inner and outer binaries are uncorrelated at birth, providing insights into stellar formation processes. We also examine MS+MS and MS+Red Giant mergers manifesting as Blue Straggler stars (BSSs). These PMBs have orbital configurations and ages similar to most observed BSS binaries. While the triple+merger formation channel can explain the observed chemical abundances, moderate eccentricities, and companion masses in BSS binaries, it likely only accounts for $\\sim$20-25% of BSSs. Meanwhile, we predict that the majority of observed single BSSs formed as collisions in triples and harbor long-period (>10 yr) companions. Furthermore, both BSS binaries and DWDs exhibit signatures of WD birth kicks.         _ Less","","arXiv","https://arxiv.org/abs/2407.06257","1","2","synthetic_biology"
"Element abundances of galactic RGB stars in the APO-K2 catalogue. Dissimilarity in the scaling with [$_$/Fe]","Abstract:                We conducted an investigation on the chemical abundances of 4,316 stars in the red giant branch (RGB) phase from the recently released APO-K2 catalogue. Our aim was to characterize the abundance trends of the single elements with [$_$/Fe], mainly focusing on C, N, and O, which are the most relevant for the estimation of stellar ages. The_         _ More           We conducted an investigation on the chemical abundances of 4,316 stars in the red giant branch (RGB) phase from the recently released APO-K2 catalogue. Our aim was to characterize the abundance trends of the single elements with [$_$/Fe], mainly focusing on C, N, and O, which are the most relevant for the estimation of stellar ages. The chemical analysis of the RGB sample involved cross-matching data from the APO-K2 catalogue with individual element abundances from APOGEE DR17. The analysis detected a statistically significant difference in the [(C+N+O)/Fe] - [$_$/Fe] trend with respect to the simple $_$-enhancement scenario. This difference remained robust across different choices for the reference solar mixture and potential zero-point calibrations of C and N abundances. The primary discrepancy was a steeper increase in [O/Fe] with [$_$/Fe], reaching a 0.1 dex difference at [$_$/Fe] = 0.3. Notably, the impact on the evolutionary timescale of such oxygen over-abundance with respect to the commonly adopted uniform $_$-enhancement is rather limited. We verified that stellar models computed using an ad hoc O-rich mixture sped up the evolution by only 1% at [$_$/Fe] = 0.3, due to the counterbalancing effects of O enrichment on both the evolutionary timescale and the Z-to-[Fe/H] relationship.         _ Less","","arXiv","https://arxiv.org/abs/2407.05960","0","1","synthetic_biology"
"Quantized Acoustic Phonons Map the Dynamics of a Single Virus","Abstract:                _such as viruses and bacteria encode critical information about their mechanical and biological states as they interact with their local environment and undergo structural evolution. However, detecting and tracking these vibrations within a biological context at the single particle level has remained elusive. In this study, we track the vibrational motions of_         _ More           The natural vibrational frequencies of biological particles such as viruses and bacteria encode critical information about their mechanical and biological states as they interact with their local environment and undergo structural evolution. However, detecting and tracking these vibrations within a biological context at the single particle level has remained elusive. In this study, we track the vibrational motions of single, unlabeled virus particles under ambient conditions using ultrafast spectroscopy. The ultrasonic spectrum of an 80-100 nm lentiviral pseudovirus reveals vibrational modes in the 19-22 GHz range sensitive to virus morphology and 2-10 GHz modes with nanosecond dephasing times reflecting viral envelope protein interactions. By tracking virus trajectories over minutes, we observe acoustic mode coupling mediated by the local environment. Single particle tracking allows capture of viral disassembly through correlated mode softening and dephasing. The sensitivity, high resolution, and speed of this approach promise deeper insights into biological dynamics and early-stage diagnostics at the single microorganism level.         _ Less","","arXiv","https://arxiv.org/abs/2407.05149","1","1","multiple"
"Leveraging Data Mining, Active Learning, and Domain Adaptation in a Multi-Stage, Machine Learning-Driven Approach for the Efficient Discovery of Advanced Acidic Oxygen Evolution Electrocatalysts","Abstract:                Developing advanced catalysts for acidic oxygen evolution reaction (OER) is crucial for sustainable hydrogen production. This study introduces a novel, multi-stage machine learning (ML) approach to streamline the discovery and optimization of complex multi-metallic catalysts. Our method integrates data mining, active learning, and domain adaptation throughou_         _ More           Developing advanced catalysts for acidic oxygen evolution reaction (OER) is crucial for sustainable hydrogen production. This study introduces a novel, multi-stage machine learning (ML) approach to streamline the discovery and optimization of complex multi-metallic catalysts. Our method integrates data mining, active learning, and domain adaptation throughout the materials discovery process. Unlike traditional trial-and-error methods, this approach systematically narrows the exploration space using domain knowledge with minimized reliance on subjective intuition. Then the active learning module efficiently refines element composition and synthesis conditions through iterative experimental feedback. The process culminated in the discovery of a promising Ru-Mn-Ca-Pr oxide catalyst. Our workflow also enhances theoretical simulations with domain adaptation strategy, providing deeper mechanistic insights aligned with experimental findings. By leveraging diverse data sources and multiple ML strategies, we establish an efficient pathway for electrocatalyst discovery and optimization. This comprehensive, data-driven approach represents a paradigm shift and potentially new benchmark in electrocatalysts research.         _ Less","","arXiv","https://arxiv.org/abs/2407.04877","1","3","synthetic_biology"
"Metals in Star-Forming Galaxies with KCWI. I. Methodology and First Results on the Abundances of Iron, Magnesium, and Oxygen","Abstract:                Understanding the chemical enrichment of different elements is crucial to gaining a complete picture of galaxy chemical evolution. In this study, we present a new sample of 46 low-redshift, low-mass star-forming galaxies at $M_*\\sim 10^{8-10}M_{\\odot}$ along with two quiescent ga_         _ More           Understanding the chemical enrichment of different elements is crucial to gaining a complete picture of galaxy chemical evolution. In this study, we present a new sample of 46 low-redshift, low-mass star-forming galaxies at $M_*\\sim 10^{8-10}M_{\\odot}$ along with two quiescent galaxies at $M_*\\sim 10^{8.8}M_{\\odot}$ observed with the Keck Cosmic Web Imager (KCWI), aiming to investigate the chemical evolution of galaxies in the transition zone between Local Group satellites and massive field galaxies. We develop a novel method to simultaneously determine stellar abundances of iron and magnesium in star-forming galaxies. With the gas-phase oxygen abundance (O/H)$_{\\rm g}$ measured using the strong line method, we are able to make the first-ever apples-to-apples comparison of $_$ elements in the stars and the ISM. We find that the [Mg/H]$_*$-[O/H]$_{\\rm g}$ relation is much tighter than the [Fe/H]$_*$-[O/H]$_{\\rm g}$ relation, which can be explained by the similar production processes of $_$ elements. Most galaxies in our sample exhibit higher [O/H]$_{\\rm g}$ than [Fe/H]$_*$ and [Mg/H]$_*$. In addition, we construct mass-metallicity relations (MZRs) measured as three different elements (Fe$_*$, Mg$_*$, O$_{\\rm g}$). Compared to the gas O-MZR, the stellar Fe- and Mg-MZRs show larger scatter driven by variations in specific star formation rates (sSFR), with star-forming galaxies exhibiting higher sSFR and lower stellar abundances at fixed mass. The excess of [O/H]$_{\\rm g}$ compared to stellar abundances as well as the anti-correlation between sSFR and stellar abundance suggests that galaxy quenching of intermediate-mass galaxies at $M_*\\sim 10^{8-10}M_{\\odot}$ is primarily driven by starvation.         _ Less","","arXiv","https://arxiv.org/abs/2407.04782","2","1","origin_of_life"
"Flow fields around active droplets squeezing through tight confinements","Abstract:                _microswimmer length scale. Recently, it was shown that self-propelling active droplets can also squeeze through tight microconfinements by elongating their shape. However, the evolution of the hydrodynamic signature, or the velocity field, generated by the active droplet, as it deforms its shape to swim through increasingly tight microconfinements, has remai_         _ More           Biological microswimmers, like euglena, deform their body shape to swim through tight confinements having length scales comparable to the microswimmer length scale. Recently, it was shown that self-propelling active droplets can also squeeze through tight microconfinements by elongating their shape. However, the evolution of the hydrodynamic signature, or the velocity field, generated by the active droplet, as it deforms its shape to swim through increasingly tight microconfinements, has remained scarcely studied. Using high-resolution fluorescence microscopy and $_$-Particle Image Velocimetry (PIV) analysis, we show here that as the swimming active droplet deforms from a spherical shape to a `stadium'-like shape, and eventually to an elongated `capsule'-like shape in increasingly tighter microchannels, its hydrodynamic signature changes from a `pusher'-like velocity field to a `puller'-like velocity field, and finally to an asymmetric velocity field. We characterize such alterations in the active droplet dynamics using the distributions of the local velocity magnitude, axial and transverse components of the local flow velocity, vorticity, and the filled micelle concentration. Finally, we use finite-element based numerical simulations to explain the aforementioned evolution of the velocity field stemming from the underlying physico-chemical hydrodynamics in the presence of a thin lubrication film between the swimming active droplet and the tight microconfinement walls. The present work provides a comprehensive understanding of the chemo-hydrodynamic characteristics of active droplets navigating extreme confined spaces, which can be beneficial for many autonomous cargo-delivery applications.         _ Less","","arXiv","https://arxiv.org/abs/2407.04324","1","2","synthetic_biology"
"Simulating carbon mineralization at pore scale in capillary networks of digital rock","Abstract:                Predicting the geometrical evolution of the pore space in geological formations due to fluid-solid interactions has applications in reservoir engineering, oil recovery, and geological storage of carbon dioxide. However, modeling frameworks that combine fluid flow with physical and chemical processes at a rock's por_         _ More           Predicting the geometrical evolution of the pore space in geological formations due to fluid-solid interactions has applications in reservoir engineering, oil recovery, and geological storage of carbon dioxide. However, modeling frameworks that combine fluid flow with physical and chemical processes at a rock's pore scale are scarce. Here, we report a method for modeling a rock's pore space as a network of connected capillaries and to simulate the capillary diameter modifications caused by reactive flow processes. Specifically, we model mineral erosion, deposition, dissolution, and precipitation processes by solving the transport equations iteratively, computing diameter changes within each capillary of the network simultaneously. Our automated modeling framework enables simulations on digital rock samples as large as (1.125mm)$^3$ with 125$\\times 10^6$ voxels within seconds of CPU time per iteration. As an application of the computational method, we have simulated brine injection and calcium carbonate precipitation in sandstone. For quantitatively comparing simulation results obtained with models predicting either a constant or a flow-rate dependent precipitation, we track the time-dependent capillary diameter distribution as well as the permeability of the connected pore space. For validation and reuse, we have made the automated simulation workflow, the reactive flow model library, and the digital rock samples available in public repositories.         _ Less","","arXiv","https://arxiv.org/abs/2407.04238","1","1","multiple"
"SDSSJ0018-0939: A Clear Signature of Sub-Chandrasekhar Mass Type 1a Supernova","Abstract:                _SDSSJ0018-0939 is the only star that has a clear and unambiguous signature of SN1a. Interestingly, our results are consistent with constraints on SN1a from recent galactic chemical evolution studies that indicate that sub-${\\rm M_{Ch}}$ SN1a account for $\\sim 50\\hbox{--}75\\,\\%$ of all SN1a and are possibly the dominan_         _ More           Very metal-poor (VMP) stars (${\\rm [Fe/H]}\\leq -2$) that have sub-solar values of ${\\rm [X/Fe]}$ for $_$ elements such as Mg, Si, and Ca, are referred to as $_$-poor VMP stars. They are quite rare among VMP stars and are thought to have formed from gas enriched predominantly by a single Type Ia supernovae (SN1a) in contrast to most VMP stars which are $_$-enhanced and usually associated with core-collapse supernovae. The observed abundance pattern in such stars can provide a direct way to probe the nucleosynthesis in individual SN1a. Although the abundance patterns in some $_$-poor VMP stars have been shown to be consistent with SN1a ejecta, a clear nucleosynthetic signature for SN1a resulting from the explosion of a near Chandrasekhar mass (near-${\\rm M_{Ch}}$) or a sub-Chandrasekhar mass (sub-${\\rm M_{Ch}}$) white dwarf, has not been unambiguously detected. We perform a detailed analysis of various formation channels of VMP stars and find that the $_$-poor VMP star SDSSJ0018-0939, which was earlier reported as a star with potential pair-instability supernova origin, provides almost a smoking-gun signature of a sub-${\\rm M_{Ch}}$ SN1a resulting from He detonation. We find that compared to other $_$-poor VMP stars that were previously identified with SN1a, SDSSJ0018-0939 is the only star that has a clear and unambiguous signature of SN1a. Interestingly, our results are consistent with constraints on SN1a from recent galactic chemical evolution studies that indicate that sub-${\\rm M_{Ch}}$ SN1a account for $\\sim 50\\hbox{--}75\\,\\%$ of all SN1a and are possibly the dominant channel in the early Galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2407.04026","2","2","multiple"
"Application of Magnus expansion for the quantum dynamics of $_$-systems under periodic driving and assessment of the rotating wave approximation","Abstract:                Employing a sixth order expression for the differential time evolution operator based on the Magnus expansion (ME), we conducted quantum dynamics calculations of a $_$-system driven by two sinusoidal time dependent fields. For a closed system dynamics, we confirmed the equivalence of the dynamics in the Hilbert space and the Liouville space numerically. We a_         _ More           Employing a sixth order expression for the differential time evolution operator based on the Magnus expansion (ME), we conducted quantum dynamics calculations of a $_$-system driven by two sinusoidal time dependent fields. For a closed system dynamics, we confirmed the equivalence of the dynamics in the Hilbert space and the Liouville space numerically. We also conducted open system quantum dynamics calculation by generalizing the ME to the non-Hermitian dynamics in the Liouville space for the case where the effects of photonic bath are represented by Lindblad operators. In both cases, the accuracy of the rotating wave approximation (RWA) was assessed. We found significant errors of RWA during initial stages of the dynamics for representative cases where electromagnetically induced transparency or coherent population trapping can be observed. The presence of bath for open system quantum dynamics reduces the errors of RWA, but significant errors for off-diagonal elements of the density operator can still be seen. We also found that approaches to steady state limits of exact dynamics are slower than those for RWA. These results demonstrate the utility of the ME as a general and reliable tool for closed and open system quantum dynamics for time dependent Hamiltonians, and expose potential issues of drawing conclusions based solely on RWA.         _ Less","","arXiv","https://arxiv.org/abs/2407.03576","0","1","synthetic_biology"
"Planet Formation and Disk Chemistry: Dust and Gas Evolution during Planet Formation","Abstract:                _advancements, have transformed our comprehension of the physics and chemistry during planet formation. Despite these important steps forward, open questions persist on the chemical and physical evolution of solids in their journey from the collapsing molecular cores to disks and planetary bodies. This chapter is a repo_         _ More           Over the past decade, progress in observational capabilities, combined with theoretical advancements, have transformed our comprehension of the physics and chemistry during planet formation. Despite these important steps forward, open questions persist on the chemical and physical evolution of solids in their journey from the collapsing molecular cores to disks and planetary bodies. This chapter is a repository of such burning questions. It has the ambition to identify the most promising avenues for future research based on current observational and modeling opportunities.         _ Less","","arXiv","https://arxiv.org/abs/2407.03520","1","1","multiple"
"Evolution of Band Structure in a Kagome Superconductor Cs(V1-xCrx)3Sb5: Toward Universal Understanding of CDW and Superconducting Phase Diagrams","Abstract:                Kagome superconductors AV3Sb5 (A = K, Rb, Cs) exhibit a characteristic superconducting and charge-density wave (CDW) phase diagram upon carrier doping and chemical substitution. However, the key electronic states responsible for such a phase diagram have yet to be clarified. Here we report a systematic micro-focused angle-resolved photoemission spectroscopy_         _ More           Kagome superconductors AV3Sb5 (A = K, Rb, Cs) exhibit a characteristic superconducting and charge-density wave (CDW) phase diagram upon carrier doping and chemical substitution. However, the key electronic states responsible for such a phase diagram have yet to be clarified. Here we report a systematic micro-focused angle-resolved photoemission spectroscopy (ARPES) study of Cs(V1-xCrx)3Sb5 as a function of Cr content x, where Cr substitution causes monotonic reduction of superconducting and CDW transition temperatures. We found that the V-derived bands forming saddle points at the M point and Dirac nodes along high-symmetry cuts show an energy shift due to electron doping by Cr substitution, whereas the Sb-derived electron band at the Gamma point remains almost unchanged, signifying an orbital-selective band shift. We also found that band doubling associated with the emergence of three-dimensional CDW identified at x = 0 vanishes at x = 0.25, in line with the disappearance of CDW. A comparison of band diagrams among Ti-, Nb-, and Cr-substituted Cs(V1-xCrx)3Sb5 suggests the importance to simultaneously take into account the two saddle points at the M point and their proximity to the Fermi energy, to understand the complex phase diagram against carrier doping and chemical pressure.         _ Less","","arXiv","https://arxiv.org/abs/2407.03147","1","1","multiple"
"Turbulent Diffuse Molecular Media with Non-ideal Magnetohydrodynamics and Consistent Thermochemistry: Numerical Simulations and Dynamic Characteristics","Abstract:                _media, featuring time-dependent non-equilibrium thermochemistry co-evolved with magnetohydrodynamics (MHD). Simulation results exhibit the relative abundances of key chemical species (e.g., C, CO, OH) vary by more than one order of magnitude for the 'premature' epoch of_         _ More           Turbulent diffuse molecular clouds can exhibit complicated morphologies caused by the interactions among radiation, chemistry, fluids, and fields. We performed full 3D simulations for turbulent diffuse molecular interstellar media, featuring time-dependent non-equilibrium thermochemistry co-evolved with magnetohydrodynamics (MHD). Simulation results exhibit the relative abundances of key chemical species (e.g., C, CO, OH) vary by more than one order of magnitude for the 'premature' epoch of chemical evolution ($t\\lesssim 2\\times 10^5~{\\rm yr}$). Various simulations are also conducted to study the impacts of physical parameters. Non-ideal MHD effects are essential in shaping the behavior of gases, and strong magnetic fields ($\\sim 10~_{\\rm G}$) tend to inhibit vigorous compressions and thus reduce the fraction of warm gases ($T\\gtrsim 10^2~{\\rm K}$). Thermodynamical and chemical conditions of the gas are sensitive to modulation by dynamic conditions, especially the energy injection by turbulence. Chemical features, including ionization (cosmic ray and diffuse interstellar radiation), would not directly affect the turbulence power spectra. Nonetheless, their effects are prominent in the distribution profiles of temperatures and gas densities. Comprehensive observations are necessary and useful to eliminate the degeneracies of physical parameters and constrain the properties of diffuse molecular clouds with confidence.         _ Less","","arXiv","https://arxiv.org/abs/2407.02306","2","2","multiple"
"Quantum Electron Dynamics in Helium Ion Injection onto Tungsten Surfaces Based on Time-Dependent Density Functional Theory","Abstract:                _(TDDFT) simulation. We developed the TDDFT code QUMASUN for this study, simulating the process of electron transfer from the surface to the He nucleus by solving the time evolution of electron wave function and the classical motion of nuclei simultaneously. Our results show that the probabilities of injected $\\text{He}^{2+}$ changing into $\\text{He}^{1+}$ an_         _ More           The neutralization process of an ion particle on a surface is key issue of the plasma-wall interaction (PWI). We investigated helium (He) ion injection onto a tungsten surface using time-dependent density functional theory (TDDFT) simulation. We developed the TDDFT code QUMASUN for this study, simulating the process of electron transfer from the surface to the He nucleus by solving the time evolution of electron wave function and the classical motion of nuclei simultaneously. Our results show that the probabilities of injected $\\text{He}^{2+}$ changing into $\\text{He}^{1+}$ and $\\text{He}^{0}$ on the surface are approximately 40 percent and 25 percent, respectively. The captured electrons by $\\text{He}^{1+}$ and $\\text{He}^{0}$ predominantly occupy the 2s and 2p orbitals, corresponding to excited states. In addition, we stated some challenges for applying TDDFT to plasma-wall interactions.         _ Less","","arXiv","https://arxiv.org/abs/2407.02155","0","1","synthetic_biology"
"Manipulating crack formation in air-dried clay suspensions with tunable elasticity","Abstract:                _their microscopic structures evolve due to time-dependent inter-particle screened electrostatic interactions. The rate at which aging progresses is estimated from the rate of evolution of the mechanical moduli and can be controlled by changing clay concentration or by incorporating additives. Since physical aging and evaporation should both contribute to the_         _ More           Clay, the major ingredient of natural soils, is often used as a rheological modifier while formulating paints and coatings. When subjected to desiccation, colloidal clay suspensions and clayey soils crack due to the accumulation of drying-induced stresses. Even when desiccation is suppressed, aqueous clay suspensions exhibit physical aging, with their elastic and viscous moduli increasing over time as their microscopic structures evolve due to time-dependent inter-particle screened electrostatic interactions. The rate at which aging progresses is estimated from the rate of evolution of the mechanical moduli and can be controlled by changing clay concentration or by incorporating additives. Since physical aging and evaporation should both contribute to the consolidation of drying clay suspensions, we attempt to manipulate the desiccation process \\textit{via} alterations of clay and additive concentrations. For a desiccating sample with an accelerated rate of aging, we observe faster consolidation into a semi-solid state and earlier onset of cracks. We estimate the crack onset time, $t_c$, in direct visualization experiments and the elasticity of the drying sample layer, $E$, using microindentation in an atomic force microscope. We demonstrate that $t_c \\propto \\sqrt{\\frac{G_c}{E}}$, where $G_c$, the fracture energy, is estimated by fitting our experimental data to a linear poroelastic model that incorporates the Griffith's criterion for crack formation. Our work demonstrates that early crack onset is associated with lower sample ductility. The correlation between crack onset in a sample and its mechanical properties as uncovered here is potentially useful in preparing crack-resistant coatings and diverse clay structures.         _ Less","","arXiv","https://arxiv.org/abs/2407.01396","1","1","multiple"
"Creation, Control, and Modeling of NV Centers in Nanodiamonds","Abstract:                _the optical properties of NV centers in NDs through surface chemistry tuning and proton beam irradiation. Systematic thermal oxidations were performed to investigate the evolution of surface chemical groups using IR spectroscopy and their influence on optical properties using photoluminescence spectroscopy and PL decay_         _ More           Sensing based on Nitrogen-Vacancy (NV) centers in nanodiamonds (NDs) offers significant potential across various applications. However, optimizing their quantum-optical properties remains challenging. This study focuses on enhancing and controlling the optical properties of NV centers in NDs through surface chemistry tuning and proton beam irradiation. Systematic thermal oxidations were performed to investigate the evolution of surface chemical groups using IR spectroscopy and their influence on optical properties using photoluminescence spectroscopy and PL decay measurements. Proton irradiation was explored over a wide range of fluences (10^14 to 10^17 cm^-2) to precisely control the NV center concentration, identifying conditions that maximize creation and emission intensity. Furthermore, NV center charge state control was achieved by analyzing the NV-/NV0 ratio with varying surface terminations and NV center concentrations. A novel predictive mathematical model was developed to evaluate the efficiencies of forming NV- and NV0. Although tested specifically with proton-irradiated NDs, this model has broad applicability, representing a significant advancement in predicting the outcomes of ion-beam-based color center generation in diamond.         _ Less","","arXiv","https://arxiv.org/abs/2407.01362","0","1","synthetic_biology"
"Off-site production of plasma-activated water for efficient sterilization: the crucial role of high-valence NOx and new chemical pathways","Abstract:                _with cleaner methods is a critical concern for environmental disinfection and clinical anti-infective treatment. Plasma-activated water (PAW) is a promising alternative to chemical disinfectants and antibiotics for its strong sterilization ability and not inducing any acute toxicity, and only water and air are consumed during production. For more efficient w_         _ More           Efficient sterilization of pathogens with cleaner methods is a critical concern for environmental disinfection and clinical anti-infective treatment. Plasma-activated water (PAW) is a promising alternative to chemical disinfectants and antibiotics for its strong sterilization ability and not inducing any acute toxicity, and only water and air are consumed during production. For more efficient water activation, plasma sources are commonly placed near or fully in contact with water as possible, but the risks of electrode corrosion and metal contamination of water threaten the safety and stability of PAW production. Herein, plasma-activated gas rich in high-valence NOx is generated by a hybrid plasma configuration and introduced into water for off-site PAW production. Plasma-generated O3 is found to dominate the gas-phase reactions for the formation of high-valence NOx. With the time-evolution of O3 concentration, gaseous NO3 radicals are produced behind N2O5 formation, but will be decomposed before N2O5 quenching. By decoupling the roles of gaseous NO3, N2O5, and O3 in the water activation, results show that short-lived aqueous species induced by gaseous NO3 radicals play the most crucial role in PAW sterilization, and the acidic environment induced by N2O5 is also essential. Moreover, SEM photographs and biomacromolecule leakage assays demonstrate that PAW disrupts the cell membranes of bacteria to achieve inactivation. In real-life applications, an integrated device for off-site PAW production with a yield of 2 L/h and a bactericidal efficiency of >99.9% is developed. The PAW of 50mL produced in 3 minutes using this device is more effective in disinfection than 0.5% NaClO and 3% H2O2 with the same bacterial contact time. This work provides new avenues for efficient PAW production and deepens insights into the fundamental processes that govern the reactive chemistry in PAW sterilization.         _ Less","","arXiv","https://arxiv.org/abs/2407.01035","1","1","multiple"
"Direct Observation of Morphological and Chemical Changes During the Oxidation of Model Inorganic Ligand-Capped Particles","Abstract:                _X-ray scattering (GIXS) investigation of the oxidation of oleic acid ligands surrounding NaYF4 nanoparticles (NPs) deposited onto SiOx/Si substrates. While APXPS monitors the evolution of the oxidation products, GIXS provides insight into the morphology of the ligands and particles before and after the oxidation. Our investigation shows that the oxidation of_         _ More           Functionalization and volatilization are competing reactions during the oxidation of carbonaceous materials and are important processes in many different areas of science and technology. Here we present a combined ambient pressure X-ray photoelectron spectroscopy (APXPS) and grazing incidence X-ray scattering (GIXS) investigation of the oxidation of oleic acid ligands surrounding NaYF4 nanoparticles (NPs) deposited onto SiOx/Si substrates. While APXPS monitors the evolution of the oxidation products, GIXS provides insight into the morphology of the ligands and particles before and after the oxidation. Our investigation shows that the oxidation of the oleic acid ligands proceeds at O2 partial pressures of below 1 mbar in the presence of X-rays, with the oxidation eventually reaching a steady state in which mainly CHx and -COOH functional groups are observed. The scattering data reveal that the oxidation and volatilization reaction proceeds preferentially on the side of the particle facing the gas phase, leading to the formation of a chemically and morphologically asymmetric ligand layer. This comprehensive picture of the oxidation process could only be obtained by combining the X-ray scattering and APXPS data. The investigation presented here lays the foundation for further studies of the stability of NP layers in the presence of reactive trace gasses and ionizing radiation, and for other nanoscale systems where chemical and morphological changes happen simultaneously and cannot be understood in isolation.         _ Less","","arXiv","https://arxiv.org/abs/2407.00598","2","2","multiple"
"The AURORA Survey: A New Era of Emission-line Diagrams with JWST/NIRSpec","Abstract:                _and large, representative samples of individual galaxy detections, the AURORA emission-line diagrams presented here definitively confirm a physical picture in which chemically-young, alpha-enhanced, massive stars photoionize the ISM in distant galaxies with a harder ionizing spectrum at fixed nebular metallicity than in their z~0 counterparts. We also uncove_         _ More           We present results on the emission-line properties of z=1.4-7.5 star-forming galaxies in the Assembly of Ultradeep Rest-optical Observations Revealing Astrophysics (AURORA) Cycle 1 JWST/NIRSpec program. Based on its depth, continuous wavelength coverage from 1--5 microns, and medium spectral resolution (R~1000), AURORA includes detections of a large suite of nebular emission lines spanning a broad range in rest wavelength. We investigate the locations of AURORA galaxies in multiple different emission-line diagrams, including traditional 'BPT' diagrams of [OIII]/Hbeta vs. [NII]/Halpha, [SII]/Halpha, and [OI]/Halpha, and the 'ionization-metallicity' diagram of [OIII]/[OII] (O32) vs. ([OIII]+[OII])/Hbeta (R23). We also consider a bluer rest-frame 'ionization-metallicity' diagram introduced recently to characterize z>10 galaxies: [NeIII]/[OII] vs. ([NeIII]+[OII])/Hdelta; as well as longer-wavelength diagnostic diagrams extending into the rest-frame near-IR: [OIII]/Hbeta vs. [SIII]/[SII] (S32); and HeI/Pagamma and [SIII]/Pagamma vs. [FeII]/Pabeta. With a significant boost in signal-to-noise and large, representative samples of individual galaxy detections, the AURORA emission-line diagrams presented here definitively confirm a physical picture in which chemically-young, alpha-enhanced, massive stars photoionize the ISM in distant galaxies with a harder ionizing spectrum at fixed nebular metallicity than in their z~0 counterparts. We also uncover previously unseen evolution prior to z~2 in the [OIII]/Hbeta vs. [NII]/Halpha diagram, which motivates deep NIRSpec observations at even higher redshift. Finally, we present the first statistical sample of rest-frame near-IR emission-line diagnostics in star-forming galaxies at high redshift. In order to truly interpret rest-frame near-IR line ratios including [FeII], we must obtain better constraints on dust depletion in the high-redshift ISM.         _ Less","","arXiv","https://arxiv.org/abs/2407.00157","1","2","synthetic_biology"
"Shocks in the warm neutral medium II -- Origin of neutral carbon at high pressure","Abstract:                _Shock waves irradiated by the standard interstellar radiation field (ISRF) are modelled using the Paris-Durham shock code designed to follow the dynamical, thermal, and chemical evolutions of shocks with velocities up to 500 km s$^{-1}$. Each observed line of sight is decomposed into a high pressure and a low pressure_         _ More           Aims: Ultraviolet (UV) lines of neutral carbon observed in absorption in the local diffuse interstellar medium (ISM) have long revealed that a substantial fraction of the mass of the gas lies at a thermal pressure one to three orders of magnitude above that of the bulk of the ISM. In this paper, we propose that this enigmatic component originates from shocks propagating at intermediate ($V_S > 30$ km s$^{-1}$) and high velocities ($V_S \\geqslant 100$  km s$^{-1}$) in the Warm Neutral Medium (WNM).   Methods: Shock waves irradiated by the standard interstellar radiation field (ISRF) are modelled using the Paris-Durham shock code designed to follow the dynamical, thermal, and chemical evolutions of shocks with velocities up to 500 km s$^{-1}$. Each observed line of sight is decomposed into a high pressure and a low pressure components. The column density of carbon at high pressure is confronted to the model predictions to derive the number of shocks along the line of sight and their total dissipation rate.   Results: Phase transition shocks spontaneously lead to the presence of high pressure gas in the diffuse ISM and are found to naturally produce neutral carbon with excitation conditions and linewidths in remarkable agreement with the observations. The amounts of neutral carbon at high pressure detected over a sample of 89 lines of sight imply a dissipation rate of mechanical energy with a median of $\\sim 3x10^{-25}$ erg cm$^{-3}$ s$^{-1}$ and a dispersion of about a factor of three. This distribution of the dissipation rate weakly depends on the detailed characteristics of shocks as long as they propagate at velocities between 30 and 200 kms s$^{-1}$ in a medium with a preshock density $n_H^0 \\ge 0.3$ cm s$^{-3}$ and a transverse magnetic field $B_0 \\leqslant 3$ $_$G. We not only show that this solution is consistent with a scenario of shocks driven by supernovae remnants (SNR) but also that this scenario is, in fact, unavoidable. Any line of sight in the observational sample is bound to intercept SNRs, mostly distributed in the spiral arms of the Milky Way, and expanding in the diffuse ionized and neutral phases of the Galaxy. Surprisingly, the range of dissipation rate derived here, in events that probably drive turbulence in the WNM, is found to be comparable to the distribution of the kinetic energy transfer rate of the turbulent cascade derived from the observations of CO in the Cold Neutral Medium (CNM).   Conclusions: This work reveals a possible direct tracer of the mechanisms by which mechanical energy is injected in the ISM. It also suggests that a still unknown connection exists between the amount of energy dissipated during the injection process in the WNM and that used to feed interstellar turbulence and the turbulent cascade observed in the CNM.         _ Less","","arXiv","https://arxiv.org/abs/2406.19719","1","2","synthetic_biology"
"Core-hole Coherent Spectroscopy in Molecules","Abstract:                _before it dephases. We propose a proof-of-concept experiment using the harmonic up-conversion scheme available at X-ray free-electron laser facilities to trace the evolution of the created core-excited-state coherence through a time-resolved X-ray photoelectron spectroscopy.         _ More           We study the ultrafast dynamics initiated by a coherent superposition of core-excited states of nitrous oxide molecule. Using high-level \\textit{ab-initio} methods, we show that the decoherence caused by the electronic decay and the nuclear dynamics is substantially slower than the induced ultrafast quantum beatings, allowing the system to undergo several oscillations before it dephases. We propose a proof-of-concept experiment using the harmonic up-conversion scheme available at X-ray free-electron laser facilities to trace the evolution of the created core-excited-state coherence through a time-resolved X-ray photoelectron spectroscopy.         _ Less","","arXiv","https://arxiv.org/abs/2406.19387","0","1","synthetic_biology"
"Chemical Continuous Time Random Walks under Anomalous Diffusion","Abstract:        Chemical master equation plays an important role to describe the time_         _ More   Chemical master equation plays an important role to describe the time evolution of homogeneous chemical system. In addition to the reaction process, it is also accompanied by physical diffusion of the reactants in complex system that is generally not homogeneous, which will result in non-exponential waiting times for particle reactions and diffusion. In this paper we shall introduce a chemical continuous time random walk under anomalous diffusion model based on renewal process to describe the general reaction-diffusion process in the heterogeneous system, where the waiting times are arbitrary distributed. According to this model, we will develop the systematic stochastic theory including generalizing the chemical diffusion master equation, deriving the corresponding mass action law, and extending the Gillespie algorithm. As an example, we analyze the monomolecular $A\\leftrightarrow B$ reaction-diffusion system for exponential and power-law waiting times respectively, and show the strong fractional memory effect of the concentration of the reactants on the history of the concentration in power-law case.         _ Less","","arXiv","https://arxiv.org/abs/2406.18869","0","1","synthetic_biology"
"Evolution of Interfacial Hydration Structure Induced by Ion Condensation and Correlation Effects","Abstract:                _three-dimensional atomic force microscopy (3D-AFM), we provide the first observation for their interfacial hydration structures with molecular resolution. We observed the evolution of layered hydration structures at La(NO3)3 solution-mica interfaces with concentration. As concentration increases from 25 mM to 2 M, the layer number varies from 2 to 1 and back_         _ More           Interfacial hydration structures are crucial in wide-ranging applications, including battery, colloid, lubrication etc. Multivalent ions like Mg2+ and La3+ show irreplaceable roles in these applications, which are hypothesized due to their unique interfacial hydration structures. However, this hypothesis lacks experimental supports. Here, using three-dimensional atomic force microscopy (3D-AFM), we provide the first observation for their interfacial hydration structures with molecular resolution. We observed the evolution of layered hydration structures at La(NO3)3 solution-mica interfaces with concentration. As concentration increases from 25 mM to 2 M, the layer number varies from 2 to 1 and back to 2, and the interlayer thickness rises from 0.25 to 0.34 nm, with hydration force increasing from 0.27+-0.07 to 1.04+-0.24 nN. Theory and molecular simulation reveal that multivalence induces concentration-dependent ion condensation and correlation effects, resulting in compositional and structural evolution within interfacial hydration structures. Additional experiments with MgCl2-mica, La(NO3)3-graphite and Al(NO3)3-mica interfaces together with literature comparison confirm the universality of this mechanism for both multivalent and monovalent ions. New factors affecting interfacial hydration structures are revealed, including concentration and solvent dielectric constant. This insight provides guidance for designing interfacial hydration structures to optimize solid-liquid-interphase for battery life extension, modulate colloid stability and develop efficient lubricants.         _ Less","","arXiv","https://arxiv.org/abs/2406.18827","0","1","synthetic_biology"
"MeSH Concept Relevance and Knowledge Evolution: A Data-driven Perspective","Abstract:                _algorithm is used to propagate the relevance scores to the parent nodes. We evaluated our approach using changes in the terminology and showed that it effectively captures the evolution of MeSH concepts. At the first level of the hierarchy, the most relevant concept - Chemical and Drugs - had a decreasing trend (\\texti_         _ More           The Medical Subject Headings (MeSH), one of the main knowledge organization systems in the biomedical domain, constantly evolves following the latest scientific discoveries in health and life sciences. Previous research focused on quantifying information in MeSH using its hierarchical structure. In this work, we propose a data-driven approach based on information theory and network analyses to quantify the relevance of MeSH concepts. Our approach leverages article annotations and their citation networks to compute informativeness, usefulness, disruptiveness, and influence of MeSH concepts over time. Using the the citation network and the MeSH hierarchy, different relevance aspects are computed, and an aggregation algorithm is used to propagate the relevance scores to the parent nodes. We evaluated our approach using changes in the terminology and showed that it effectively captures the evolution of MeSH concepts. At the first level of the hierarchy, the most relevant concept - Chemical and Drugs - had a decreasing trend (\\textit{p}-value $< 0.01$), while at the second level, the most relevant concept - Neoplasms - had an increasing trend (\\textit{p}-value $< 0.01$). We show that the mean relevance of evolving concepts is higher for concepts that remained unchanged (2.09E-03 \\textit{vs.} 8.46E-04). Moreover, we validated the ability of our framework to characterize retracted articles and showed that concepts used to annotate retracted articles (mean relevance: 0.17) differ substantially from those used to annotate non-retracted ones (mean relevance: 0.15). The proposed framework provides an effective method to rank concept relevance and can be useful in maintaining evolving knowledge organization systems.         _ Less","","arXiv","https://arxiv.org/abs/2406.18792","1","1","multiple"
"Exploring the Complex Ionization Environment of the Turbulent DM Tau Disk","Abstract:                Ionization drives important chemical and dynamical processes within protoplanetary disks, including the formation of organics and water in the cold midplane and the transportation of material via accretion and magneto-hydrodynamic (MHD) flows. Understanding these ionization-driven processes is crucial for understanding disk_         _ More           Ionization drives important chemical and dynamical processes within protoplanetary disks, including the formation of organics and water in the cold midplane and the transportation of material via accretion and magneto-hydrodynamic (MHD) flows. Understanding these ionization-driven processes is crucial for understanding disk evolution and planet formation. We use new and archival ALMA observations of HCO+, H13CO+, and N2H+ to produce the first forward-modeled 2D ionization constraints for the DM Tau protoplanetary disk. We include ionization from multiple sources and explore the disk chemistry under a range of ionizing conditions. Abundances from our 2D chemical models are post-processed using non-LTE radiative transfer, visibility sampling, and imaging, and are compared directly to the observed radial emission profiles. The observations are best fit by a modestly reduced CR ionization rate ($__{CR}$ ~ 10$^{-18}$ s$^{-1}$) and a hard X-ray spectrum (hardness ratio [HR] = 0.3), which we associate with stellar flaring conditions. Our best-fit model under-produces emission in the inner disk, suggesting that there may be an additional mechanism enhancing ionization in DM Tau's inner disk. Overall, our findings highlight the complexity of ionization in protoplanetary disks and the need for high resolution multi-line studies.         _ Less","","arXiv","https://arxiv.org/abs/2406.18657","1","1","multiple"
"The Pristine Inner Galaxy Survey (PIGS) X. Probing the early chemical evolution of the Sagittarius dwarf galaxy with carbon abundances","Abstract:                We aim to constrain the chemo-dynamical properties of the Sagittarius (Sgr) dwarf galaxy using carbon abundances. Our sample from the \\textit{Pristine} Inner Galaxy Survey (PIGS) includes $\\sim 350$ metal-poor ([Fe/H]~$<-1.5$) stars in the main body of Sgr with good quality spectroscopic observations. Our metal-poor Sgr population has a larger velocity dispersion than metal-rich Sgr from the liter_         _ More           We aim to constrain the chemo-dynamical properties of the Sagittarius (Sgr) dwarf galaxy using carbon abundances. Our sample from the \\textit{Pristine} Inner Galaxy Survey (PIGS) includes $\\sim 350$ metal-poor ([Fe/H]~$<-1.5$) stars in the main body of Sgr with good quality spectroscopic observations. Our metal-poor Sgr population has a larger velocity dispersion than metal-rich Sgr from the literature, which could be explained by outside-in star formation, extreme Galactic tidal perturbations and/or the presence of a metal-rich disc/bar $+$ a metal-poor halo. The average carbon abundance [C/Fe] in Sgr is similar to that of other classical dwarf galaxies (DGs) and consistently lower than in the Milky Way by $\\sim0.2-0.3$~dex at low metallicity. The interstellar medium in DGs, including Sgr, may have retained yields from more energetic Population~III~and~II supernovae (SNe), thereby reducing the average [C/Fe]. Additionally, SNe~Ia, producing more Fe than C, would start to contribute at lower metallicity in DGs/Sgr than in the Galaxy. The presence of a [C/Fe] gradient for Sgr stars with [Fe/H]~$\\gtrsim-2.0$ ($\\sim 6.8\\times 10^{-4}\\ \\rm{dex \\ arcmin^{-1}}$) suggests that SNe~Ia contributed in the system at those metallicities, especially in its inner regions. There is a low frequency of carbon-enhanced metal-poor (CEMP) stars in our Sgr sample. At higher metallicity/carbon abundance (mostly CEMP-s) this may be due to photometric selection effects, but those are less likely to affect CEMP-no stars. We propose that, given the lower average [C/Fe] in DGs, using the same CEMP definition ([C/Fe]~$>+0.7$) as in the Galaxy under-predicts the number of CEMP stars in DGs, and for Sgr a cut at [C/Fe]$~\\sim +0.35$ may be more appropriate, which brings the frequency of CEMP stars in agreement with that in the Galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2406.18636","3","2","origin_of_life"
"Depth Dependence of Coseismic Off-Fault Damage and its Effects on Rupture Dynamics","Abstract:                Faults are complex systems embedded in an evolving medium fractured by seismic ruptures. This off-fault damage zone is shown to be thermo-hydro-mechano-chemically coupled to the main fault plane by a growing number of studies. Yet, off-fault medium is still, for the most part, modelled as a purely elastic -- hence passive -- medium. Using a micromechanical m_         _ More           Faults are complex systems embedded in an evolving medium fractured by seismic ruptures. This off-fault damage zone is shown to be thermo-hydro-mechano-chemically coupled to the main fault plane by a growing number of studies. Yet, off-fault medium is still, for the most part, modelled as a purely elastic -- hence passive -- medium. Using a micromechanical model that accounts for dynamic changes of elastic moduli and inelastic strains related to crack growth, we investigate the depth variation of dynamically triggered off-fault damage and its counter-impact on earthquake slip dynamics. We show that the damage zone, while narrowing with depth, also becomes denser and contrary to prevailing assumptions continues to act as an energy sink, significantly influencing rupture dynamics by stabilizing slip rates. Furthermore, we observe that damage formation markedly reduces rupture velocity and delays, or even prevents, the transition to supershear speeds even for a narrow damage zone. This underscores the critical need to incorporate the complex interplay between the main fault plane and its surrounding medium across the entire seismogenic zone. As a proof of concept, we introduce a 1D spring-slider model that captures bulk elastic variations, by modulating spring stiffness, and normal stress variations that emulate changes in bulk load. This simple model demonstrates the occurrence of slow slip events alongside conventional earthquakes, driven by the dynamic interaction between bulk temporal evolution and fault slip dynamics, without necessitating any changes to frictional properties.         _ Less","","arXiv","https://arxiv.org/abs/2406.18408","1","2","synthetic_biology"
"Exploring the Stellar Rotation of Early-type Stars in the LAMOST Medium-resolution Survey. III. Evolution","Abstract:                Stellar rotation significantly shapes the evolution of massive stars, yet the interplay of mass and metallicity remains elusive, limiting our capacity to construct accurate stellar_         _ More           Stellar rotation significantly shapes the evolution of massive stars, yet the interplay of mass and metallicity remains elusive, limiting our capacity to construct accurate stellar evolution models and to better estimate the impact of rotation in chemical evolution of galaxies. Our goal is to investigate how mass and metallicity influence the rotational evolution of A-type stars on the main sequence (MS). We seek to identify deviations in rotational behaviors that could serve as new constraints to existing stellar models. Using the LAMOST median-resolution survey Data Release 9, we derived stellar parameters for a population of 104,752 A-type stars. Our study focused on the evolution of surface rotational velocities and their dependence on mass and metallicity in 84,683 `normal' stars. Normalized surface rotational revealed a prevailing evolutionary profile from 1.7 to 4.0 $M_\\odot$. This profile features an initial rapid acceleration until $t/t_\\mathrm{ms} = 0.25$, potentially a second acceleration peak near $t/t_\\mathrm{ms} = 0.55$ for stars heavier than 2.5 $M_\\odot$, followed by a steady decline and a `hook' feature at the end. Surpassing theoretical expectations, the initial acceleration likely stems from a concentrated distribution of angular momentum at ZAMS, resulting in a prolonged increase in speed. The inverse circulation becomes more efficient at lower metallicity, explaining the correlation of the slope of this deceleration phase with metallicity from -0.3 dex up to 0.1 dex. The metal-poor subsample suggests a mechanism dependent on metallicity for removing angular momentum during star formation. The proportion of fast rotators decreases with an increase in metallicity, up to $\\log(Z/Z_\\odot)\\sim -0.2$, a trend consistent with observations of OB-type stars found in the Small and Large Magellanic Clouds.         _ Less","","arXiv","https://arxiv.org/abs/2406.18268","3","2","origin_of_life"
"Observation of Dynamic Nuclear Polarization Echoes","Abstract:                It is demonstrated that the time evolution of the electron-nuclear polarization transfer process during pulsed dynamic nuclear polarization (DNP) can be reversed on a microsecond timescale, leading to the observation of DNP echoes. The DNP echoes are induced by consecutive application of two pulse trains that produce effective Hamiltonians that differ only i_         _ More           It is demonstrated that the time evolution of the electron-nuclear polarization transfer process during pulsed dynamic nuclear polarization (DNP) can be reversed on a microsecond timescale, leading to the observation of DNP echoes. The DNP echoes are induced by consecutive application of two pulse trains that produce effective Hamiltonians that differ only in the sign of the effective hyperfine coupling. The experiments have been performed on a frozen solution of trityl radicals in water/glycerol on a home-built X-band EPR/DNP spectrometer at 80 K. We envisage that DNP echoes will play an important role in future development of pulsed DNP for sensitivity-enhanced NMR, hyperfine spectroscopy, and quantum sensing.         _ Less","","arXiv","https://arxiv.org/abs/2406.18246","0","1","synthetic_biology"
"Thermal explosion characteristics of a gelled hypergolic droplet","Abstract:                When a sphere of one reactant is placed in the medium of another reactant with which it is hypergolic, a chemical reaction (modeled here as a zeroth-order one-step irreversible Arrhenius reaction) occurs at the common interface of the two reactants, and the heat generated at the interface then is transmitted away from it by thermal conduction. Depending on t_         _ More           When a sphere of one reactant is placed in the medium of another reactant with which it is hypergolic, a chemical reaction (modeled here as a zeroth-order one-step irreversible Arrhenius reaction) occurs at the common interface of the two reactants, and the heat generated at the interface then is transmitted away from it by thermal conduction. Depending on the nature of the problem, the system may approach an explosive mode, or it may settle into a steady-state mode. The critical condition defining the transition between these two states is determined analytically. In particular, explicit formulas for the ignition delay time for the explosive mode are provided for two limits, one in which an appropriately defined Damk_hler number is large and the other in which it is closer to the critical conditions. This is accomplished here by deriving and solving an integral equation for the time evolution of the interface temperature, employing activation-energy asymptotics.         _ Less","","arXiv","https://arxiv.org/abs/2406.18222","0","1","synthetic_biology"
"Chemical Evolution of Complex Organic Molecules in Turbulent Protoplanetary Disks: Effect of stochastic UV irradiation","Abstract:                We investigate the chemical evolution of complex organic molecules (COMs) in turbulent disks using gas-ice chemical reaction network simulations. We trace trajectories of dust particles considering advection, turbulent diffusion, gas drag, and vertical settling, for 10$^6$ yrs in_         _ More           We investigate the chemical evolution of complex organic molecules (COMs) in turbulent disks using gas-ice chemical reaction network simulations. We trace trajectories of dust particles considering advection, turbulent diffusion, gas drag, and vertical settling, for 10$^6$ yrs in a protoplanetary disk. Then, we solve a gas-ice chemical reaction network along the trajectories and obtain the temporal evolution of molecular abundances. We find that the COM abundances in particles can differ by more than two orders of magnitude even when the UV fluence (i.e., the time integral of UV flux) received by the particles are similar, suggesting that not only the UV fluence but also the time variation of the UV flux does matter for the evolution of COMs in disks. The impact of UV fluence on molecular abundances differs between oxygen-bearing and nitrogen-bearing COMs. While higher UV fluence results in oxygen being locked into CO$_2$, leading to reduced abundances of oxygen-bearing COMs such as CH$_3$OCH$_3$, mild UV exposure can promote their formation by supplying the precursor radicals. On the other hand, nitrogen is not locked up into specific molecules, allowing the formation of nitrogen-bearing COMs, particularly CH$_3$NH$_2$, even for the particle that receives the higher UV fluence. We also find that the final COM abundances are mostly determined by the inherited abundances from the protostellar core when the UV fluence received by dust particles is less than a critical value, while they are set by both the inherited abundances and the chemistry inside the disk at higher UV fluence.         _ Less","","arXiv","https://arxiv.org/abs/2406.17367","2","2","multiple"
"The influence of flame-pressure waves collisions on the development and evolution of tulip flames","Abstract:                The effects of pressure waves-flame collisions and tube aspect ratio on flame evolution and the formation of tulip and distorted tulip flames were investigated using numerical simulations of the fully compressible Navier-Stokes equations coupled with a detailed chemical model for a stoichiometric hydrogen-air mixture._         _ More           The effects of pressure waves-flame collisions and tube aspect ratio on flame evolution and the formation of tulip and distorted tulip flames were investigated using numerical simulations of the fully compressible Navier-Stokes equations coupled with a detailed chemical model for a stoichiometric hydrogen-air mixture. It is shown that: (1) the rarefaction wave generated by the decelerating flame in the unburned gas is the primary physical process leading to the flame front inversion and the tulip flame formation, (2) the flame front instabilities (Darrieus-Landau or Rayleigh-Taylor) do not participate in the formation of the tulip flame, since the time of the flame front inversion due to the rarefaction wave is considerably shorter than the characteristic times of the development of instabilities with wavelengths of the order of the tube width. The first rarefaction wave in the unburned gas mixture is generated after the flame skirt touches the tube walls and the flame is slowed down due to the reduction in flame surface area. The collision of the flame with the pressure waves reflected from the closed end of the tube leads to a faster and more pronounced formation of a tulip-shaped flame. In later stages, flame collisions with pressure waves can lead to the formation of distorted tulip flames due to short-wavelength Rayleigh-Taylor instability of the flame front. Because flame acceleration and deceleration occur much faster in 3D flames than in 2D flames, tulip flame formation also occurs much faster in 3D flames than in 2D flames.         _ Less","","arXiv","https://arxiv.org/abs/2406.16950","1","1","multiple"
"PRODIGE -- Planet-forming disks in Taurus with NOEMA","Abstract:                _emission observed at 0.9 with the IRAM NOrthern Extended Millimeter Array (NOEMA) as part of the MPG-IRAM Observatory Program PRODIGE (PROtostars and DIsks: Global Evolution PIs: P. Caselli & Th. Henning). Our sample consists of Class II disks with no evidence of strong radial substructures. We use thesedata to constrain the thermal and_         _ More           We aim to constrain the gas density and temperature distributions as well as gas masses in several T Tauri protoplanetary disks located in Taurus. We use the 12CO, 13CO, and C18O (2-1) isotopologue emission observed at 0.9 with the IRAM NOrthern Extended Millimeter Array (NOEMA) as part of the MPG-IRAM Observatory Program PRODIGE (PROtostars and DIsks: Global Evolution PIs: P. Caselli & Th. Henning). Our sample consists of Class II disks with no evidence of strong radial substructures. We use thesedata to constrain the thermal and chemical structure of these disks through theoretical models for gas emission. To fit the combined optically thick and thin CO line data in Fourier space, we developed the DiskCheF code, which includes the parameterized disk physical structure, machine-learning (ML) accelerated chemistry, and the RADMC-3D line radiative transfer module. A key novelty of DiskCheF is the fast and feasible ML-based chemistry trained on the extended grid of the disk physical-chemical models precomputed with the ANDES2 code. This ML approach allows complex chemical kinetics models to be included in a time-consuming disk fitting without the need to run a chemical code. We present a novel approach to incorporate chemistry into disk modeling without the need to explicitly calculate a chemical network every time. Using this new disk modeling tool, we successfully fit the 12CO, 13CO, and C18O (2-1) data from the CI, CY, DL, DM, DN, and IQ Tau disks. The combination of optically thin and optically thick CO lines allows us to simultaneously constrain the disk temperature and mass distribution, and derive the CO-based gas masses. These values are in reasonable agreement with the disk dust masses rescaled by a factor of 100 as well as with other indirect gas measurements.         _ Less","","arXiv","https://arxiv.org/abs/2406.16498","0","1","synthetic_biology"
"Black hole thermodynamic potentials for asymptotic observers","Abstract:                _we can define a black hole dynamical free energy using observables defined at future null infinity which decreases on successive cross sections. The proof of this spontaneous evolution law is similar to Wall's derivation of the generalized second law and relies on the monotonicity properties of the relative entropy. I discuss first the simpler case of t_         _ More           The generalized second law states the total entropy of any closed system as the universe cannot decrease if we include black hole entropy. From the point of view of an asymptotic observer, a black hole can be described at late time as an open system at fixed temperature which can radiate energy and entropy to infinity. I argue that for massless free quantum fields propagating on a black hole background, we can define a black hole dynamical free energy using observables defined at future null infinity which decreases on successive cross sections. The proof of this spontaneous evolution law is similar to Wall's derivation of the generalized second law and relies on the monotonicity properties of the relative entropy. I discuss first the simpler case of the Schwarzschild background in which the grey body factor are neglected and show that in this case the free energy only depends on the Bondi mass, the Hawking temperature and the von Neumann entropy of the propagating quantum fields. Then I argue that taking into account the grey body factors adds a new term to the thermodynamic potential involving the number of particles detected at future null infinity conjugated to a chemical potential. Finally, I discuss the case of the Kerr black hole for which an angular momentum piece needs to be added to the free energy.         _ Less","","arXiv","https://arxiv.org/abs/2406.15843","0","1","synthetic_biology"
"Phase-field simulations opening new horizons in corrosion research","Abstract:                This work overviews a new, recent success of phase-field modelling: its application to predicting the evolution of the corrosion front and the associated structural integrity challenges. Despite its important implications for society, predicting corrosion damage has been an elusive goal for scientists and engineers. The application of phase-field modelling t_         _ More           This work overviews a new, recent success of phase-field modelling: its application to predicting the evolution of the corrosion front and the associated structural integrity challenges. Despite its important implications for society, predicting corrosion damage has been an elusive goal for scientists and engineers. The application of phase-field modelling to corrosion not only enables tracking the electrolyte-metal interface but also provides an avenue to explicitly simulate the underlying mesoscale physical processes. This lays the grounds for developing the first generation of mechanistic corrosion models, which can capture key phenomena such as film rupture and repassivation, the transition from activation- to diffusion-controlled corrosion, interactions with mechanical fields, microstructural and electrochemical effects, intergranular corrosion, material biodegradation, and the interplay with other environmentally-assisted damage phenomena such as hydrogen embrittlement.         _ Less","","arXiv","https://arxiv.org/abs/2406.15013","1","2","synthetic_biology"
"Presolar grains","Abstract:                The chemical makeup of our solar system is a reflection of Galactic_         _ More           The chemical makeup of our solar system is a reflection of Galactic chemical evolution in the local interstellar medium (ISM) over the past ~9 Ga before the formation of the solar system. Although the incorporated ISM dust was mostly destroyed during the solar system formation, a small fraction of the ISM dust, known as presolar grains, is preserved in pristine extraterrestrial materials and identified through their exotic isotopic compositions, pointing to their formation in gas outflows or explosions of ancient stars. Since their stellar birth at more than 4.6 Ga, presolar grains have borne witness to a diverse array of astrophysical and cosmochemical processes. In this chapter, I will review recent progress in utilizing the isotopic and structural compositions of presolar grains to constrain physical mixing processes and dust formation in stars, stellar nucleosynthesis, ISM processes, and the origin and evolution of the solar system.         _ Less","","arXiv","https://arxiv.org/abs/2406.14694","3","2","origin_of_life"
"The earliest phases of CNO enrichment in galaxies","Abstract:                Context. The recent detection of nitrogen-enhanced, metal-poor galaxies at high redshift by the James Webb Space Telescope has sparked renewed interest in exploring the chemical_         _ More           Context. The recent detection of nitrogen-enhanced, metal-poor galaxies at high redshift by the James Webb Space Telescope has sparked renewed interest in exploring the chemical evolution of carbon, nitrogen, and oxygen (the CNO elements) at early times, prompting fresh inquiries into their origins. Aims. The main goal of this paper is to shed light onto the early evolution of the main CNO isotopes in our Galaxy and in young distant systems, such as GN-z11 at z=10.6. Methods. To this aim, we incorporate a stochastic star-formation component into a chemical evolution model calibrated with high-quality Milky Way (MW) data, focusing on the contribution of Population III (Pop III) stars to the early chemical enrichment. Results. By comparing the model predictions with CNO abundance measurements from high-resolution spectroscopy of an homogeneous sample of Galactic halo stars, we first demonstrate that the scatter observed in the metallicity range -4.5 < [Fe/H] <-1.5 can be explained by pre-enrichment from Pop III stars that explode as supernovae (SNe) with different initial masses and energies. Then, by exploiting the chemical evolution model, we provide testable predictions for log(C/N), log(N/O), and log(C/O) vs. log(O/H)+12 in MW-like galaxies observed at different cosmic epochs/redshifts. Finally, by calibrating the chemical evolution model to replicate the observed properties of GN-z11, we provide an alternative interpretation of its log(N/O) abundance ratio, demonstrating that its high N content can be reproduced through enrichment from high-mass faint Pop III SNe. Conclusions. Stochastic chemical enrichment from primordial stars explains both the observed scatter in CNO abundances in MW halo stars and the exceptionally high N/O ratios in some distant galaxies. These findings emphasize the critical role of Pop III stars in shaping early chemical evolution.         _ Less","","arXiv","https://arxiv.org/abs/2406.14615","2","1","origin_of_life"
"Nano-Patterned Pt-Based Metallic Glass Electrocatalysts with In-Situ Copper Oxide Foam for Enhanced Hydrogen Evolution","Abstract:                Hydrogen is a promising energy carrier for replacing fossil fuels, and hydrogen production via hydrogen evolution reaction (HER) is an environmentally friendly option if electrocatalysts with low overpotentials and long-term stability are used. In this work, the electrocatalytic performance of $\\mathrm{Pt_{57.5}Cu_{14.7}Ni_{5.3}P_{22.5}}$ bulk metallic glass_         _ More           Hydrogen is a promising energy carrier for replacing fossil fuels, and hydrogen production via hydrogen evolution reaction (HER) is an environmentally friendly option if electrocatalysts with low overpotentials and long-term stability are used. In this work, the electrocatalytic performance of $\\mathrm{Pt_{57.5}Cu_{14.7}Ni_{5.3}P_{22.5}}$ bulk metallic glass (BMG) with flat, micro-patterned, and nano-patterned surfaces for HER in 0.5 M H2SO4 is studied. The nano-patterned Pt-BMG demonstrates outstanding long-term stability and self-improving behavior with a final overpotential of 150 mV and a Tafel slope of 42 $\\mathrm{mV dec^{-1}}$ after 1000 linear sweep voltammetry (LSV) cycles, which is respectively 42% and 37% lower than in the first LSV cycle. X-ray photoelectron spectroscopy (XPS) and Auger electron spectroscopy (AES) indicate the formation of a layer of CuO/Cu2O foam deposited on top of the nano-patterned surface during the stability test of 1000 LSV cycles. A three-step process is proposed to explain the formation of CuxO foam via dynamic hydrogen bubble templating (DHBT) electrodeposition from Cu dissolution of the Pt-BMG without using copper salt. This work provides a method to create CuxO foams that could be used for various applications. Moreover, nano-patterned BMGs with DHBT deposition offer a feasible strategy to synthesize metal or metal-oxide foams.         _ Less","","arXiv","https://arxiv.org/abs/2406.14079","1","1","multiple"
"Stability analysis for a kinetic bacterial chemotaxis model","Abstract:                We perform stability analysis of a kinetic bacterial chemotaxis model of bacterial self-organization, assuming that bacteria respond sharply to chemical signals. The resulting discontinuous tumbling kernel represents the key challenge for the stability analysis as it rules out a direct linearization of the nonlinear terms. To address this challenge we fruitf_         _ More           We perform stability analysis of a kinetic bacterial chemotaxis model of bacterial self-organization, assuming that bacteria respond sharply to chemical signals. The resulting discontinuous tumbling kernel represents the key challenge for the stability analysis as it rules out a direct linearization of the nonlinear terms. To address this challenge we fruitfully separate the evolution of the shape of the cellular profile from its global motion. We provide a full nonlinear stability theorem in a perturbative setting when chemical degradation can be neglected. With chemical degradation we prove stability of the linearized operator. In both cases we obtain exponential relaxation to equilibrium with an explicit rate using hypocoercivity techniques. To apply a hypocoercivity approach in this setting, we develop two novel and specific approaches: i) the use of the $H^1$ norm instead of the $L^2$ norm, and ii) the treatment of nonlinear terms. This work represents an important step forward in bacterial chemotaxis modeling from a kinetic perspective as most results are currently only available for the macroscopic descriptions, which are usually parabolic in nature. Significant difficulty arises due to the lack of regularization of the kinetic transport operator as compared to the parabolic operator in the macroscopic scaling limit.         _ Less","","arXiv","https://arxiv.org/abs/2406.13994","0","2","synthetic_biology"
"Impacts of Black-Hole-Forming Supernova Explosions on the Diffuse Neutrino Background","Abstract:                _to successful supernova (SN) explosion and black hole (BH) formation simultaneously, which are suggested to be a non-negligible population from the perspective of Galactic chemical evolution, is taken into account. If the BH-forming SNe involve the matter fallback onto the protoneutron star for the long term, their tot_         _ More           Flux spectrum, event rate, and experimental sensitivity are investigated for the diffuse supernova neutrino background (DSNB), which originates from past stellar collapses and is also known as a supernova relic neutrino background. For this purpose, the contribution of collapses that lead to successful supernova (SN) explosion and black hole (BH) formation simultaneously, which are suggested to be a non-negligible population from the perspective of Galactic chemical evolution, is taken into account. If the BH-forming SNe involve the matter fallback onto the protoneutron star for the long term, their total emitted neutrino energy becomes much larger than that of ordinary SNe and failed SNe (BH formation without explosion). Then, in the case of the normal mass hierarchy in neutrino oscillations and with half of all core-collapse SNe being BH-forming SNe, the expected event rate according to the current DSNB model is enhanced by up to a factor of two due to the BH-forming SNe. While substantial uncertainties exist regarding the duration of the matter fallback, which determines the total amount of emitted neutrinos, and the fraction of BH-forming SNe, the operation time required to detect the DSNB at Hyper-Kamiokande would be reduced by such contribution in any case.         _ Less","","arXiv","https://arxiv.org/abs/2406.13276","2","1","origin_of_life"
"Hidden Population III Descendants in Ultra-Faint Dwarf Galaxies","Abstract:                _by uncovering their true descendants. To this aim, we exploit our data-calibrated model for the best-studied ultra-faint dwarf (UFD) galaxy, Bo_tes I, which tracks the chemical_         _ More           The elusive properties of the first (Pop III) stars can be indirectly unveiled by uncovering their true descendants. To this aim, we exploit our data-calibrated model for the best-studied ultra-faint dwarf (UFD) galaxy, Bo_tes I, which tracks the chemical evolution (from carbon to zinc) of individual stars from their formation to the present day. We explore the chemical imprint of Pop III supernovae (SNe), with different explosion energies and masses, showing that they leave distinct chemical signatures in their descendants. We find that UFDs are strongly affected by SNe-driven feedback resulting in a very low fraction of metals retained by their gravitational potential well (< 2.5 %). Furthermore, the higher the Pop III SN explosion energy, the lower the fraction of metals retained. Thus, the probability to find descendants of energetic Pair Instability SNe is extremely low in these systems. Conversely, UFDs are ideal cosmic laboratories to identify the fingerprints of less massive and energetic Pop III SNe through their [X/Fe] abundance ratios. Digging into the literature data of Bo_tes I, we uncover three hidden Pop III descendants: one mono-enriched and two multi-enriched. These stars show the chemical signature of Pop III SNe in the mass range $[20-60]\\rm M_{\\odot}$, spanning a wide range in explosion energies $[0.3-5] 10^{51}$ erg. In conclusion, Pop III descendants are hidden in ancient UFDs but those mono-enriched by a single Pop III SN are extremely rare. Thus, self-consistent models such as the one presented here are required to uncover these precious fossils and probe the properties of the first Pop III supernovae.         _ Less","","arXiv","https://arxiv.org/abs/2406.12960","2","1","origin_of_life"
"Human-level molecular optimization driven by mol-gene evolution","Abstract:                De novo molecule generation allows the search for more drug-like hits across a vast chemical space. However, lead optimization is still required, and the process of optimizing molecular structures faces the challenge of balancing structural novelty with pharmacological properties. This study introduces the Deep Genetic Molecular Modification Algorithm (DGMM)_         _ More           De novo molecule generation allows the search for more drug-like hits across a vast chemical space. However, lead optimization is still required, and the process of optimizing molecular structures faces the challenge of balancing structural novelty with pharmacological properties. This study introduces the Deep Genetic Molecular Modification Algorithm (DGMM), which brings structure modification to the level of medicinal chemists. A discrete variational autoencoder (D-VAE) is used in DGMM to encode molecules as quantization code, mol-gene, which incorporates deep learning into genetic algorithms for flexible structural optimization. The mol-gene allows for the discovery of pharmacologically similar but structurally distinct compounds, and reveals the trade-offs of structural optimization in drug discovery. We demonstrate the effectiveness of the DGMM in several applications.         _ Less","","arXiv","https://arxiv.org/abs/2406.12910","0","1","synthetic_biology"
"The Impact of Stellar Radiative Feedback on Formation of Young Massive Clusters via Fast HI Gas Collisions","Abstract:                _remains unknown. In this paper, we study the formation of such massive clumps via fast HI gas collisions (~100 km/s) as suggested by recent observations and their subsequent evolution into YMCs by using three-dimensional magnetohydrodynamics simulations involving self-gravity and detailed thermal/_         _ More           Young massive clusters (YMCs) are dense aggregates of young stars and are often speculated as potential precursors to globular clusters. However, the formation mechanism of massive and compact gas clumps that precede YMCs remains unknown. In this paper, we study the formation of such massive clumps via fast HI gas collisions (~100 km/s) as suggested by recent observations and their subsequent evolution into YMCs by using three-dimensional magnetohydrodynamics simulations involving self-gravity and detailed thermal/chemical processes. In particular, the impact of ionization feedback from stellar radiation is included in an approximate fashion where the temperature within the HII regions is elevated to 10,000 K, while supernova feedback is not included. We examine whether the resulting massive clumps can survive this ionization feedback and evolve into YMCs. Our simulations reveal the emergence of gas clumps that do not only possess substantial mass (~10^5 M_sun) but also sufficient compactness (~5 pc). Notably, these clumps exhibit significantly higher escape velocities compared to the sound speed of the HII region, indicating effective gravitational retention of gas against feedback-induced evaporation. Consequently, these conditions foster efficient star formation within the massive gas clumps, ultimately leading to their evolution into YMCs. We also perform simulations involving lower-velocity gas collisions, approximately 15 km/s, typical shock velocities induced by galactic superbubbles.         _ Less","","arXiv","https://arxiv.org/abs/2406.12682","2","1","origin_of_life"
"Ariel stellar characterisation II. Chemical abundances of carbon, nitrogen, and oxygen for 181 planet-host FGK dwarf stars","Abstract:                One of the ultimate goals of the ESA Ariel space mission is to shed light on the formation pathways and evolution of planetary systems in the Solar neighbourhood. Such an endeavour is only possible by performing a large_         _ More           One of the ultimate goals of the ESA Ariel space mission is to shed light on the formation pathways and evolution of planetary systems in the Solar neighbourhood. Such an endeavour is only possible by performing a large chemical survey of not only the planets, but also their host stars, inasmuch as stellar elemental abundances are the cipher key to decode the planetary compositional signatures. This work aims at providing homogeneous abundances of C, N, and O of a sample of 181 stars belonging to the Tier 1 of the Ariel Mission Candidate Sample. We applied the spectral synthesis and the equivalent width methods to a variety of atomic and molecular indicators (C I lines at 5052 and 5380.3 A, [O I] forbidden line at 6300.3 A, C_2 bands at 5128 and 5165 A, and CN band at 4215 A) using high-resolution and high S/N spectra collected with several spectrographs. We provide carbon abundances for 180 stars, nitrogen abundances for 105 stars, and oxygen abundances for 89 stars. We analyse the results in the light of the Galactic chemical evolution, and in terms of the planetary companions properties. Our sample basically follows the typical trends with metallicity expected for the [C/Fe], [N/Fe], and [O/Fe] abundance ratios. The fraction between C and O abundances, both yields of primary production, is consistent with a constant ratio as [O/H] increases, whereas the abundance of N tends to increase with the increasing of the O abundance, supporting the theoretical assumption of a secondary production of nitrogen. The [C/N], [C/O], and [N/O] ratios are also correlated with [Fe/H], which might introduce biases in the interpretation of the planetary compositions and formation histories if host stars of different metallicity are compared. We provide relations that can be used to qualitatively estimate whether the atmospheric composition of planets is enriched or not with respect to the host stars.         _ Less","","arXiv","https://arxiv.org/abs/2406.12393","3","2","origin_of_life"
"A Trifecta of Modelling Tools: A Bayesian Binary Black Hole Model Selection combining Population Synthesis and Galaxy Formation Models","Abstract:                _between hyper-parameters governing the specific angular momentum (AM) of mass lost during mass transfer, the mass-loss rates of Wolf-Rayet stars via winds and the chemically homogeneous evolution (CHE) formation channel. We conclude that analysing the marginalised and unmarginalised likelihood is a good indicator of wh_         _ More           Gravitational waves (GWs) have revealed surprising properties of binary black hole (BBH) populations, but there is still mystery surrounding how these compact objects evolve. We apply Bayesian inference and an efficient method to calculate the BBH merger rates in the Shark host galaxies, to determine the combination of COMPAS parameters that outputs a population most like the GW sources from the LVK transient catalogue. For our COMPAS models, we calculate the likelihood with and without the dependence on the predicted number of BBH merger events. We find strong correlations between hyper-parameters governing the specific angular momentum (AM) of mass lost during mass transfer, the mass-loss rates of Wolf-Rayet stars via winds and the chemically homogeneous evolution (CHE) formation channel. We conclude that analysing the marginalised and unmarginalised likelihood is a good indicator of whether the population parameters distribution and number of observed events reflect the LVK data. In doing so, we see that the majority of the models preferred in terms of the population-level parameters of the BBHs greatly overpredict the number of events we should have observed to date. Looking at the smaller number of models which perform well with both likelihoods, we find that those with no CHE, AM loss occurring closer to the donor during the first mass-transfer event, and/or higher rates of mass-loss from Wolf-Rayet winds are generally preferred by current data. We find these conclusions to be robust to our choice of selection criteria.         _ Less","","arXiv","https://arxiv.org/abs/2406.11885","1","2","synthetic_biology"
"Four-dimensional QCD equation of state with multiple chemical potentials","Abstract:                We construct a four-dimensional version of the equation of state (EoS) model NEOS, NEOS-4D, as a function of the temperature and chemical potentials of baryon, electric charge, and strangeness for the hot and dense QCD matter created in relativistic nuclear collisions. This EoS enables multiple conserved charge current_         _ More           We construct a four-dimensional version of the equation of state (EoS) model NEOS, NEOS-4D, as a function of the temperature and chemical potentials of baryon, electric charge, and strangeness for the hot and dense QCD matter created in relativistic nuclear collisions. This EoS enables multiple conserved charge current evolution in a relativistic fluid. Input from Lattice QCD simulations and a hadron resonance gas model is considered for constructing the equation of state. We investigate its applicability to the relativistic hydrodynamic description of nuclear collisions and present a method for efficient numerical implementation.         _ Less","","arXiv","https://arxiv.org/abs/2406.11610","0","1","synthetic_biology"
"Disk Assembly of the Milky Way Suggested from the Time-resolved Chemical Abundance","Abstract:                _and in-situ star formation on the disk, known as the leaky accretion disk. This scenario predicts a strong connection between radial distributions of star formation and chemical abundances. The Milky Way, being the sole galaxy where we can reliably measure star formation histories and the corresponding temporally-resolved_         _ More           Both simulations and observations suggest that the disk assembly of galaxies is governed by the interplay between coplanar gas inflow, ex-planar gas outflow and in-situ star formation on the disk, known as the leaky accretion disk. This scenario predicts a strong connection between radial distributions of star formation and chemical abundances. The Milky Way, being the sole galaxy where we can reliably measure star formation histories and the corresponding temporally-resolved chemical abundances with individual stars, provides a unique opportunity to scrutinize this scenario. Based on the recent large spectroscopic and photometric surveys of Milky Way stars, we obtain the radial profiles of magnesium abundance ([Mg/H]) and star formation rate (SFR) surface density at different lookback time. We find the radial profiles of [Mg/H] can be well-reproduced using the leaky accretion disk model with only two free parameters for stars formed within 4 Gyr, as well as the flattening at large radii of metallicity profiles traced by HII regions and Cepheids. Furthermore, the constraint effective yield of the Milky Way and nearby galaxies show broad consistency with the theoretical predictions from stellar chemical evolution model with a mass-loading factor of 0-2. These results support that the recent assembly of the Milky Way adheres to the leaky accretion disk scenario, bridging the disk formation of our home galaxy to the big picture of disk formation in the Universe.         _ Less","","arXiv","https://arxiv.org/abs/2406.11394","3","2","origin_of_life"
"MINDS. A multi-instrument investigation into the molecule-rich JWST-MIRI spectrum of the DF Tau binary system","Abstract:                Most stars form in multiple systems whose properties can significantly impact circumstellar disk evolution. We investigate the physical and chemical properties of the equal-mass, small separation (~66 mas, ~9 au) DF Tau binary system. Previous observations indicated that only DF Tau A has a circumstellar disk. We prese_         _ More           Most stars form in multiple systems whose properties can significantly impact circumstellar disk evolution. We investigate the physical and chemical properties of the equal-mass, small separation (~66 mas, ~9 au) DF Tau binary system. Previous observations indicated that only DF Tau A has a circumstellar disk. We present JWST-MIRI MRS observations of DF Tau. The MIRI spectrum shows a forest of H2O lines and emission from CO, C2H2, HCN, CO2, and OH. LTE slab models are used to determine the properties of the gas, and we analyze high angular spatial and spectral resolution data from ALMA, VLTI-GRAVITY, and IRTF-iSHELL to aid in the interpretation of the JWST data. The 1.3 mm ALMA continuum data show two equal-brightness sources of compact (R<3 au) emission, with separations and movement consistent with astrometry from VLTI-GRAVITY and the known orbit. This is interpreted as a robust detection of a disk around DF Tau B, which we suggest may host a small (~1 au) cavity to reconcile all observations. The disk around DF Tau A is expected to be a full disk, and spatially and spectrally resolved dust and gas emission points to hot, close-in (<0.2 au) material. Hot (~500-1000 K) H2O, HCN, and C2H2 emission in the MIRI data likely originate in the DF Tau A disk, while a cold (<200 K) H2O component with an extended emitting area is consistent with an origin from both disks. Despite the very compact outer disks, the inner disk composition and conditions are similar to isolated systems, suggesting that the close binary nature is not a driving factor in setting the inner disk chemistry. However, constraining the geometry of the disks, for instance, via higher resolution ALMA observations, would provide additional insight into the mid-infrared gas emission. JWST observations of spatially resolved binaries will be important for understanding the impact of binarity on inner disk chemistry more generally.         _ Less","","arXiv","https://arxiv.org/abs/2406.10217","0","1","synthetic_biology"
"The nucleosynthetic fingerprint of the outermost protoplanetary disk and early Solar System dynamics","Abstract:                Knowledge of the nucleosynthetic isotope composition of the outermost protoplanetary disk is critical to understand the formation and early dynamical evolution of the Solar System. We report the discovery of outer disk material preserved in a pristine meteorite based on its chemical composition, organic-rich petrology,_         _ More           Knowledge of the nucleosynthetic isotope composition of the outermost protoplanetary disk is critical to understand the formation and early dynamical evolution of the Solar System. We report the discovery of outer disk material preserved in a pristine meteorite based on its chemical composition, organic-rich petrology, and 15N-rich, deuterium-rich, and 16O-poor isotope signatures. We infer that this outer disk material originated in the comet-forming region. The nucleosynthetic Fe, Mg, Si and Cr compositions of this material reveal that, contrary to current belief, the isotope signature of the comet-forming region is ubiquitous amongst outer Solar System bodies, possibly reflecting an important planetary building block in the outer Solar System. This nucleosynthetic component represents fresh material added to the outer disk by late accretion streamers connected to the ambient molecular cloud. Our results show that most Solar System carbonaceous asteroids accreted material from the comet-forming region, a signature lacking in the terrestrial planet region.         _ Less","","arXiv","https://arxiv.org/abs/2406.09893","1","1","multiple"
"Does the full configuration interaction method based on quantum phase estimation with Trotter decomposition satisfy the size consistency condition?","Abstract:                _energy of a dimer consisting of two monomers separated by a large distance should be equal to twice the energy of a monomer, known as size consistency, is essential in quantum chemical calculations. Recently, we reported that the size consistency condition can be violated by Trotterization in the unitary coupled cluster singles and doubles (UCCSD) ansatz in_         _ More           Electronic structure calculations of atoms and molecules are considered to be a promising application for quantum computers. Two key algorithms, the quantum phase estimation (QPE) and the variational quantum eigensolver (VQE), have been extensively studied. The condition that the energy of a dimer consisting of two monomers separated by a large distance should be equal to twice the energy of a monomer, known as size consistency, is essential in quantum chemical calculations. Recently, we reported that the size consistency condition can be violated by Trotterization in the unitary coupled cluster singles and doubles (UCCSD) ansatz in VQE when employing molecular orbitals delocalized to the dimer (K. Sugisaki {\\it et al.}, {\\it J. Comput. Chem.}, published online; \\href{https://doi.org/10.1002/jcc.27438}{DOI:10.1002/jcc.27438}). It is well known that the full configuration interaction (full-CI) energy is invariant to arbitrary rotations of molecular orbitals, and therefore the QPE-based full-CI should theoretically satisfy the size consistency. However, Trotterization of the time evolution operator can break the size consistency conditions. In this work, we investigated whether the size consistency can be maintained with Trotterization of the time evolution operator in QPE-based full-CI calculations. Our numerical simulations revealed that size consistency in QPE-based full-CI is not automatically violated by using molecular orbitals delocalized to the dimer, but employing an appropriate Trotter decomposition condition is crucial to maintain size consistency. We also report on the acceleration of QPE simulations through the sequential addition of ancillary qubits.         _ Less","","arXiv","https://arxiv.org/abs/2406.09830","0","1","synthetic_biology"
"Interstellar Nitrogen Isotope Ratios: Measurements on tracers of C$^{14}$N and C$^{15}$N","Abstract:                The nitrogen isotope ratio 14N/15N is a powerful tool to trace Galactic stellar nucleosynthesis and constraining Galactic chemical evolution. Previous observations have found lower 14N/15N ratios in the Galactic center and higher values in the Galactic disk. This is consistent with the inside-out formation scenario of_         _ More           The nitrogen isotope ratio 14N/15N is a powerful tool to trace Galactic stellar nucleosynthesis and constraining Galactic chemical evolution. Previous observations have found lower 14N/15N ratios in the Galactic center and higher values in the Galactic disk. This is consistent with the inside-out formation scenario of our Milky Way. However, previous studies mostly utilized double isotope ratios also including 12C/13C, which introduces additional uncertainties. Here we therefore present observations of C14N and its rare isotopologue, C15N, toward a sample of star forming regions, measured by the IRAM 30 m and/or the ARO 12 m telescope at $_$ ~3 mm wavelength. For those 35 sources detected in both isotopologues, physical parameters are determined. Furthermore we have obtained nitrogen isotope ratios using the strongest hyperfine components of CN and C15N. For those sources showing small deviations from Local Thermodynamical Equilibrium and/or self-absorption, the weakest hyperfine component, likely free of the latter effect, was used to obtain reliable 14N/15N values. Our measured 14N/15N isotope ratios from C14N and C15N measurements are compatible with those from our earlier measurements of NH3 and 15NH3 (Paper I), i.e., increasing ratios to a Galacticentric distance of ~9 kpc. The unweighted second order polynomial fit yields $\\frac{{\\rm C^{14}N}}{{\\rm C^{15}N}} = (-4.85 \\pm 1.89)\\;{\\rm kpc^{-2}} \\times R_{\\rm GC}^{2} + (82.11 \\pm 31.93) \\;{\\rm kpc^{-1}} \\times R_{\\rm GC} - (28.12 \\pm 126.62)$. Toward the outer galaxy, the isotope ratio tends to decrease, supporting an earlier finding by H13CN/HC15N. Galactic chemical evolution models are consistent with our measurements of the 14N/15N isotope ratio, i.e. a rising trend from the Galactic center region to approximately 9 kpc, followed by a decreasing trend with increasing $R_{\\rm GC}$ toward the outer Galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2406.09683","2","1","origin_of_life"
"Controlling the Magnetic Properties of the van der Waals Multiferroic Crystals Co$_{1-x}$Ni$_{x}$I$_2$","Abstract:                _are multiferroic van der Waals materials, in which helimagnetic orders exist simultaneously with electric polarization. Here, we report on the evolution of the crystal structure and of the magnetic properties across the solid solution Co$_{1-x}$Ni$_{x}$I$_2$. We have successfully grown crystals of the whole range of the solid solution, i.e. $x = 0-1$, by em_         _ More           The structurally related compounds NiI$_2$ and CoI$_2$ are multiferroic van der Waals materials, in which helimagnetic orders exist simultaneously with electric polarization. Here, we report on the evolution of the crystal structure and of the magnetic properties across the solid solution Co$_{1-x}$Ni$_{x}$I$_2$. We have successfully grown crystals of the whole range of the solid solution, i.e. $x = 0-1$, by employing the self-selecting vapor growth (SSVG) technique and by carefully tuning the synthesis conditions according to the chemical composition. Our structural investigations show that the crystal symmetry changes from $P\\bar{3}m1$ to $R\\bar{3}m$ when Ni substitutes for Co beyond $x = 0.2$. Both the lattice parameters and magnetic properties evolve continuously and smoothly from one end member to the other, showing that they can be finely tuned by the chemical composition. We also observe that the Ni substitution degree in the solid solution affects the metamagnetic transition typical for CoI$_2$ at high magnetic fields. In particular, we find the existence of the metamagnetic transition similar to that for CoI$_2$ in the NiI$_2$ structure. Based on magnetic measurements we construct the phase diagram of the Co$_{1-x}$Ni$_{x}$I$_2$ system. Controlling the magnetic properties by the chemical composition may open new pathways for the fabrication of electronic devices made of two-dimensional (2D) flakes of multiferroic van der Waals materials.         _ Less","","arXiv","https://arxiv.org/abs/2406.09146","0","2","synthetic_biology"
"From Biased to Unbiased Dynamics: An Infinitesimal Generator Approach","Abstract:                We investigate learning the eigenfunctions of evolution operators for time-reversal invariant stochastic processes, a prime example being the Langevin equation used in molecular dynamics. Many physical or chemical processes described by this equation involve transitions between metastable states separated by high poten_         _ More           We investigate learning the eigenfunctions of evolution operators for time-reversal invariant stochastic processes, a prime example being the Langevin equation used in molecular dynamics. Many physical or chemical processes described by this equation involve transitions between metastable states separated by high potential barriers that can hardly be crossed during a simulation. To overcome this bottleneck, data are collected via biased simulations that explore the state space more rapidly. We propose a framework for learning from biased simulations rooted in the infinitesimal generator of the process and the associated resolvent operator. We contrast our approach to more common ones based on the transfer operator, showing that it can provably learn the spectral properties of the unbiased system from biased data. In experiments, we highlight the advantages of our method over transfer operator approaches and recent developments based on generator learning, demonstrating its effectiveness in estimating eigenfunctions and eigenvalues. Importantly, we show that even with datasets containing only a few relevant transitions due to sub-optimal biasing, our approach recovers relevant information about the transition mechanism.         _ Less","","arXiv","https://arxiv.org/abs/2406.09028","1","1","multiple"
"The neutron-star merger delay-time distribution, r-process 'knees', and the metal budget of the Galaxy","Abstract:                _A~10-100, the numbers of DNSs that merge within a Hubble time, and that presumably lead to short gamma-ray bursts and kilonova explosions. With a simple, empirically based, chemical-evolution calculation, we show that the fast/steep kilonova DTD, convolved with the measured star-formation history of the Milky Way's_         _ More           For a sample of 18 recycled millisecond pulsars (rMSPs) that are in double neutron star (DNS) systems, and 42 rMSPs that are not in DNS pairs, we analyze the distributions of the characteristic age, $__c$, and the time until merger of the double systems, $__{\\rm gw}$. Based on the $__c$ distribution of non-DNS rMSPs, we argue that $__c$ is a reasonable estimator of true pulsar age and that rMSPs are active as pulsars for a long (~Hubble) time. Among the DNSs there is an excess of young systems (small $__c$) with short life expectancy (small $__{\\rm gw}$) compared to model expectations for the distributions of $__c$ and $__{\\rm gw}$ if, at birth, DNSs have a delay-time distribution (DTD) of the form $t^{-1}$ (expected generically for close binaries), or for that matter, from expectations from any single power-law DTD. A two-population DNS model solves the problem: the data are best fit by the combination of a 'fast' population with DTD going as $t^{-1.9\\pm0.4}$, and a 'slow' population of DNSs, with DTD proportional to $t^{-1.1\\pm0.15}$. The fast population can be equivalently represented by a DTD with an exponential cutoff beyond t~300 Myr. The fast population completely dominates, by a factor A~10-100, the numbers of DNSs that merge within a Hubble time, and that presumably lead to short gamma-ray bursts and kilonova explosions. With a simple, empirically based, chemical-evolution calculation, we show that the fast/steep kilonova DTD, convolved with the measured star-formation history of the Milky Way's thick-disk population, naturally reproduces the 'knee' structure seen in abundance-ratio diagrams of thick-disk stars, for europium and two other r-process elements. As a corollary we show, based again solely on empirical input, that the Milky Way is nearly a 'closed box' that has retained at least ~70-90% of the metals produced over the Galaxy's lifetime.         _ Less","","arXiv","https://arxiv.org/abs/2406.08630","1","1","multiple"
"Anomalous Enhancement of the Electrocatalytic Hydrogen Evolution Reaction in AuPt Nanoclusters","Abstract:                Energy- and resource-efficient electrocatalytic water splitting is of paramount importance to enable sustainable hydrogen production. The best bulk catalyst for the hydrogen evolution reaction (HER), i.e., platinum, is one of the scarcest elements on Earth. The use of raw material for HER can be dramatically reduced by utilizing nanoclusters. In addition, na_         _ More           Energy- and resource-efficient electrocatalytic water splitting is of paramount importance to enable sustainable hydrogen production. The best bulk catalyst for the hydrogen evolution reaction (HER), i.e., platinum, is one of the scarcest elements on Earth. The use of raw material for HER can be dramatically reduced by utilizing nanoclusters. In addition, nanoalloying can further improve the performance of these nanoclusters. In this paper, we present results for HER on nanometer-sized ligand-free AuPt nanoclusters grafted on carbon nanotubes. These results demonstrate excellent monodispersity and a significant reduction of the overpotential for the electrocatalytic HER. We utilize atomistic machine learning techniques to elucidate the atomic-scale origin of the synergistic effect between Pt and Au. We show that the presence of surface Au atoms, known to be poor HER catalysts, in a Pt(core)/AuPt(shell) nanocluster structure, drives an anomalous enhancement of the inherently high catalytic activity of Pt atoms.         _ Less","","arXiv","https://arxiv.org/abs/2406.08580","0","1","synthetic_biology"
"Detailed chemical abundances of the globular cluster Terzan 6 in the inner bulge","Abstract:                _25,000) to perform the first comprehensive chemical study of the intermediate luminosity bulge globular cluster Terzan~6. We derived detailed abundances and abundance patterns of 27 giant stars, likely members of Terzan~6, based on their accurate Hubble Space Telescope proper motions and line-of-sight radial velocities. From the spectral analysis of these st_         _ More           We used near-infrared spectroscopy at medium-high resolution (R=8,000$-$25,000) to perform the first comprehensive chemical study of the intermediate luminosity bulge globular cluster Terzan~6. We derived detailed abundances and abundance patterns of 27 giant stars, likely members of Terzan~6, based on their accurate Hubble Space Telescope proper motions and line-of-sight radial velocities. From the spectral analysis of these stars, we determined an average heliocentric radial velocity of 143.3$\\pm$1.0 km s$^{-1}$ with a velocity dispersion of 5.1$\\pm$0.7 km s$^{-1}$ and an average [Fe/H]=$-0.65\\pm0.01$ and a low 1$_$ dispersion of 0.03 dex. We also measured some depletion of [Mn/Fe] with respect to the solar-scaled values and enhancement of for [Ca/Fe], [Si/Fe], [Mg/Fe], [Ti/Fe], [O/Fe], [Al/Fe], [Na/Fe], and, to a lower extent, for [K/Fe], consistent with previous measurements of other bulge globular clusters and favoring the scenario of a rapid bulge formation and chemical enrichment. Some spread in the light element abundances suggest the presence of first- and second-generation stars, typical of genuine globulars. Finally, we measured some depletion of carbon and low $\\rm ^{12}C/^{13}C$ isotopic ratios, as in previous studies of field and cluster bulge giants, indicating that extra-mixing mechanisms should be at work during the post main sequence evolution in the high metallicity regime as well.         _ Less","","arXiv","https://arxiv.org/abs/2406.07180","2","2","multiple"
"MPSDynamics.jl: Tensor network simulations for finite-temperature (non-Markovian) open quantum system dynamics","Abstract:                _language, MPSDynamics.jl is a versatile open-source package providing a choice of several variants of the Time-Dependent Variational Principle (TDVP) method for time evolution (including novel bond-adaptive one-site algorithms). The package also provides strong support for the measurement of single and multi-site observables, as well as the storing and loggi_         _ More           The MPSDynamics.jl package provides an easy to use interface for performing open quantum systems simulations at zero and finite temperatures. The package has been developed with the aim of studying non-Markovian open system dynamics using the state-of-the-art numerically exact Thermalized-Time Evolving Density operator with Orthonormal Polynomials Algorithm (T-TEDOPA) based on environment chain mapping. The simulations rely on a tensor network representation of the quantum states as matrix product states (MPS) and tree tensor network (TTN) states. Written in the Julia programming language, MPSDynamics.jl is a versatile open-source package providing a choice of several variants of the Time-Dependent Variational Principle (TDVP) method for time evolution (including novel bond-adaptive one-site algorithms). The package also provides strong support for the measurement of single and multi-site observables, as well as the storing and logging of data, which makes it a useful tool for the study of many-body physics. It currently handles long-range interactions, time-dependent Hamiltonians, multiple environments, bosonic and fermionic environments, and joint system-environment observables.         _ Less","","arXiv","https://arxiv.org/abs/2406.07052","0","1","synthetic_biology"
"Half Heusler alloy CoVSn as self-supported electrocatalyst for hydrogen evolution reaction","Abstract:                _Co and V atoms as pivotal active centers for hydrogen generation was evident, further enhanced by formation of high valance metal sites Co2O3 and V2O3 during the hydrogen evolution reaction. In essence, this study confirms the stability and promise of CoVSn in hydrogen generation, paving the way for exploring additional self-supported ternary intermetallics_         _ More           Despite significant advancements in electrocatalysis for clean hydrogen fuel generation, the transition from concept to commercialization faces challenges due to the instability of electrocatalysts. This study delves into the exploration of a structurally and mechanically robust half-Heusler alloy, CoVSn, as an efficient electrocatalyst for hydrogen production. The synthesis of CoVSn was achieved using the arc-melting technique and optimized successfully into a cubic structure - a previously unattained and highly challenging feat. The resulting electrode, cut from the obtained CoVSn pellet, served as a self-supported electrocatalyst and initially generates a current density of 10 mA cm-2 at an overpotential of 244 mV. Remarkably, this overpotential decreased uniquely over time, reaches 202 mV after a durability testing of 12 hours, while maintaining its crystal structure integrity after the electrocatalysis process. This progressive enhancement in catalytic activity and structural stability underscores the significance of this research. The synergistic effect between Co and V atoms as pivotal active centers for hydrogen generation was evident, further enhanced by formation of high valance metal sites Co2O3 and V2O3 during the hydrogen evolution reaction. In essence, this study confirms the stability and promise of CoVSn in hydrogen generation, paving the way for exploring additional self-supported ternary intermetallics to enhance water-splitting efficiency.         _ Less","","arXiv","https://arxiv.org/abs/2406.06981","1","1","multiple"
"Metal-Poor Stars in the MW Disk: Resonant Cooling of Vertical Oscillations of Halo Stars in Barred Galaxies","Abstract:                _Together with analyzed radial migration of these halo stars, the cooling phenomenon of halo metal-poor stars can explain their current disk population, and has corollaries for chemical evolution of disk galaxies in general.         _ More           Using numerical simulations of barred disk galaxy embedded in nonspinning and spinning dark matter (DM) halos, we present a novel mechanism of `cooling' the vertical oscillations of DM particles, which acquire the disk kinematics. The underlying mechanism consists of resonant interactions between halo particles and the stellar bar, facilitated by chaotic phase space of the system. The cooling mechanism acts both on dynamical and secular timescales, from $\\sim 0.5$\\,Gyr to few Gyr. The stellar bar acts to absorb kinetic energy of the vertical motions. Using Milky Way-type stellar halo, we estimate the population of metal-poor disk stars trapped by the MW disk and analyze its kinematics. We find that population of metal-poor MW disk stars with $|z|\\ltorder 3$\\,kpc detected by the Gaia DR3 and other surveys can have their origin in the stellar halo. The cooled population also migrates radially outwards by exchanging energy and angular momentum with the spinning bar, and prograde-moving stars have a different distribution from the retrograde ones. Next, we have calculated the ratio of the prograde-to-retrograde orbits of the cooled population and found that this ratio varies radially, with the fast-spinning stellar halo resulting in the shallower radial increase of this ratio outside of the corotation. The nonspinning stellar halo shows a monotonic increase of this ratio with radius outside the corotation. Together with analyzed radial migration of these halo stars, the cooling phenomenon of halo metal-poor stars can explain their current disk population, and has corollaries for chemical evolution of disk galaxies in general.         _ Less","","arXiv","https://arxiv.org/abs/2406.06716","2","2","multiple"
"NEATH III: a molecular line survey of a simulated star-forming cloud","Abstract:                We present synthetic line observations of a simulated molecular cloud, utilising a self-consistent treatment of the dynamics and time-dependent chemical evolution. We investigate line emission from the three most common CO isotopologues ($^{12}$CO, $^{13}$CO, C$^{18}$O) and six supposed tracers of dense gas (NH$_3$, HC_         _ More           We present synthetic line observations of a simulated molecular cloud, utilising a self-consistent treatment of the dynamics and time-dependent chemical evolution. We investigate line emission from the three most common CO isotopologues ($^{12}$CO, $^{13}$CO, C$^{18}$O) and six supposed tracers of dense gas (NH$_3$, HCN, N$_2$H$^+$, HCO$^+$, CS, HNC). Our simulation produces a range of line intensities consistent with that observed in real molecular clouds. The HCN-to-CO intensity ratio is relatively invariant with column density, making HCN (and chemically-similar species such as CS) a poor tracer of high-density material in the cloud. The ratio of N$_2$H$^+$ to HCN or CO, on the other hand, is highly selective of regions with densities above $10^{22} \\, {\\rm cm^{-2}}$, and the N$_2$H$^+$ line is a very good tracer of the dynamics of high volume density ($>10^4 \\, {\\rm cm^{-3}}$) material. Focusing on cores formed within the simulated cloud, we find good agreement with the line intensities of an observational sample of prestellar cores, including reproducing observed CS line intensities with an undepleted elemental abundance of sulphur. However, agreement between cores formed in the simulation, and models of isolated cores which have otherwise-comparable properties, is poor. The formation from and interaction with the large-scale environment has a significant impact on the line emission properties of the cores, making isolated models unsuitable for interpreting observational data.         _ Less","","arXiv","https://arxiv.org/abs/2406.06702","3","2","origin_of_life"
"Foam: A Python package for forward asteroseismic modelling of gravity modes","Abstract:                Asteroseismology, the study of stellar pulsations, offers insights into the internal structures and evolution of stars. Analysing the variations in a star's brightness allows the determination of fundamental properties such as mass, radius, age, and chemical composition. Asteroseismology heavily relies on computati_         _ More           Asteroseismology, the study of stellar pulsations, offers insights into the internal structures and evolution of stars. Analysing the variations in a star's brightness allows the determination of fundamental properties such as mass, radius, age, and chemical composition. Asteroseismology heavily relies on computational tools, but a significant number of them are closed-source, thus inaccessible to the broader astronomic community. This manuscript presents Foam, a Python package designed to perform forward asteroseismic modelling of stars exhibiting gravity modes. It automates and streamlines a considerable fraction of the modelling process, comparing grids of theoretical stellar models and their oscillation frequencies to observed frequency sets in stars. Foam offers the flexibility to employ diverse modelling approaches, allowing users to choose different methodologies for matching theoretically predicted oscillations to observations. It provides options to utilise various sets of observables for comparison with their theoretical counterparts, employ different merit functions for assessing goodness of fit, and to incorporate nested subgrids in a statistically rigorous manner. For applications of these methodologies in modelling observed gravity modes, refer to Michielsen et al. (2021) and Michielsen et al. (2023).         _ Less","","arXiv","https://arxiv.org/abs/2406.06692","0","1","synthetic_biology"
"High-resolution spectroscopy of the variable hot post-AGB star LS 4331 (IRAS 17381-1616)","Abstract:                _and emission features in the wavelength range 3700-9200 _ is carried out for the first time. From non-LTE analysis of absorption lines the atmospheric parameters and chemical composition of the star are derived. We estimate $T_{\\rm eff}=20~900\\pm500$ K, $\\log g=2.57\\pm0.08$, $V_r=-51.7\\pm0.8$ km s$^{-1}$, $__{\\rm t}=24\\pm4$ km s$^{-1}$ and $v \\sin i=30\\pm5$_         _ More           An analysis of high-resolution ($R\\sim48\\,000$) optical spectrum of hot (B1Ibe) post-AGB star LS 4331 (IRAS 17381-1616) is presented. The detailed identification of the observed absorption and emission features in the wavelength range 3700-9200 _ is carried out for the first time. From non-LTE analysis of absorption lines the atmospheric parameters and chemical composition of the star are derived. We estimate $T_{\\rm eff}=20~900\\pm500$ K, $\\log g=2.57\\pm0.08$, $V_r=-51.7\\pm0.8$ km s$^{-1}$, $__{\\rm t}=24\\pm4$ km s$^{-1}$ and $v \\sin i=30\\pm5$ km s$^{-1}$. A abundance analysis for C, N, O, Mg, Al, S and Si reveals that the N and O abundance is close to solar while metal underabundances relative to the solar value (i.e. [Mg/H] = -1.04 dex, [Al/H] = -1.20 dex, [Si/H] = -0.46 dex) are found. We conclude that LS 4331 is a high galactic latitude metal-poor and carbon deficient hot post-AGB star. The underabundance of carbon ([C/H]= -0.64 dex) is similar to that found in other hot post-AGB stars and indicates that the star's AGB phase of evolution was terminated before the third dredge up. From the nebular emission lines the plasma diagnostics are derived. The presence of nebular emission lines in the spectrum of LS 4331 indicates that the photoionization of circumstellar envelope has already started. The nebular parameters and expansion velocity of the nebula is derived. Using the Gaia DR3 distance the absolute luminosity of the star is derived and the star's position on the post-AGB evolutionary tracks suggests that its initial main sequence mass is about 1.2$M_{\\odot}$. It is also reported that fast irregular brightness variations with an amplitude of up to 0.3 mag in $V$ band have been found in the star, typical of hot post-AGB objects.         _ Less","","arXiv","https://arxiv.org/abs/2406.06240","0","1","synthetic_biology"
"Tuning the water intrinsic permeability of PEGDA hydrogel membranes by adding free PEG chains of varying molar masses","Abstract:                _critical overlap concentration C^* of PEG chains, for the highest PEG molar mass studied. Furthermore, we note that the maximum intrinsic permeability follows a non-monotonic evolution with respect to the PEG molar mass and reaches its peak at 35 000 g.mol-1. Besides our results show that a significant fraction of PEG chains is irreversibly trapped within th_         _ More           We explore the effect of poly (ethylene glycol) (PEG) molar mass on the intrinsic permeability and structural characteristics of poly (ethylene glycol) diacrylate PEGDA/PEG composite hydrogel membranes. We observe that by varying the PEG content and molar mass, we can finely adjust the water intrinsic permeability over several orders of magnitude. Notably, we show the existence of a maximum water intrinsic permeability, already identified in a previous study to be located at the critical overlap concentration C^* of PEG chains, for the highest PEG molar mass studied. Furthermore, we note that the maximum intrinsic permeability follows a non-monotonic evolution with respect to the PEG molar mass and reaches its peak at 35 000 g.mol-1. Besides our results show that a significant fraction of PEG chains is irreversibly trapped within the PEGDA matrix even for the shortest molar masses down to 600 g.mol-1. This observation suggests the possibility of covalent grafting of PEG chains to the PEGDA matrix. CryoSEM and AFM measurements demonstrate the presence of large micron-sized cavities separated by PEGDA-rich walls whose nanometric structure strongly depends on the PEG content. By combining our permeability and structural measurements, we suggest that the PEG chains trapped inside the PEGDA rich walls induce nanoscale defects in the cross linking density, resulting in an increased permeability below C^*. Conversely, above C^*, we speculate that partially-trapped PEG chains may form a brush-like arrangement on the surface of the PEGDA-rich walls, leading to a reduction in permeability. These two opposing effects are anticipated to exhibit molar-mass-dependent trends, contributing to the non-monotonic variation of the maximum intrinsic permeability at C^*. Overall, our results demonstrate the potential to fine-tune the properties of hydrogel membranes, offering new opportunities in separation applications.         _ Less","","arXiv","https://arxiv.org/abs/2406.06190","0","1","synthetic_biology"
"Exact Entanglement correlation complements the chemical bond description","Abstract:                We analyze the properties of the exact solution obtained by us recently for the extended Hetiler-London model for chemical bonding which has an analytic form. The emphasis is put on defining two-particle entanglement correlation as the complementary characterization of the_         _ More           We analyze the properties of the exact solution obtained by us recently for the extended Hetiler-London model for chemical bonding which has an analytic form. The emphasis is put on defining two-particle entanglement correlation as the complementary characterization of the chemical bond and relating it to the partial atomicity and the so-called true covalency. The newly introduced characteristics remove the deficiency of the standard definition of covalency which now vanishes in the limit of the separated atoms. In effect, a gradual evolution of the system of two indistinguishable electrons in a bound state into their distinguishable correspondents can be traced systematically. The present analysis has a universal meaning and may also be applied to more complex systems.         _ Less","","arXiv","https://arxiv.org/abs/2406.06171","0","1","synthetic_biology"
"Quantum nuclear dynamics on a distributed set of ion-trap quantum computing systems","Abstract:                Quantum nuclear dynamics with wavepacket time-evolution is classically intractable and viewed as a promising avenue for quantum information processing. Here, we use an IonQ 11-qubit trapped-ion quantum computer, Harmony, to study the quantum wavepacket dynamics of a shared-proton within a short-strong hydrogen-bonded system. We also provide the first applica_         _ More           Quantum nuclear dynamics with wavepacket time-evolution is classically intractable and viewed as a promising avenue for quantum information processing. Here, we use an IonQ 11-qubit trapped-ion quantum computer, Harmony, to study the quantum wavepacket dynamics of a shared-proton within a short-strong hydrogen-bonded system. We also provide the first application of distributed quantum computing for chemical dynamics problems, where the distributed set of quantum processes is constructed using a tensor network formalism. For a range of initial states, we experimentally drive the ion-trap system to emulate the quantum nuclear wavepacket as it evolves along the potential surface generated from electronic structure. Following the experimental creation of the nuclear wavepacket, we extract measurement observables such as its time-dependent spatial projection and its characteristic vibrational frequencies to good agreement with classical results. Vibrational eigenenergies obtained from quantum computational are in agreement with those obtained from classical simulations to within a fraction of a kcal/mol, thus suggesting chemical accuracy. Our approach opens a new paradigm for studying the quantum chemical dynamics and vibrational spectra of molecules and also provides the first demonstration for parallel quantum computation on a distributed set of ion-trap quantum computers.         _ Less","","arXiv","https://arxiv.org/abs/2406.05197","1","2","synthetic_biology"
"Effect of time-varying X-ray emission from stellar flares on the ionization of protoplanetary disks","Abstract:                X-rays have significant impacts on cold, weakly ionized protoplanetary disks by increasing the ionization rate and driving chemical reactions. Stellar flares are explosions that emit intense X-rays and are the unique source of hard X-rays with an energy of $\\gtrsim10$ keV in the protoplanetary disk systems. Hard X-rays should be carefully taken into account_         _ More           X-rays have significant impacts on cold, weakly ionized protoplanetary disks by increasing the ionization rate and driving chemical reactions. Stellar flares are explosions that emit intense X-rays and are the unique source of hard X-rays with an energy of $\\gtrsim10$ keV in the protoplanetary disk systems. Hard X-rays should be carefully taken into account in models as they can reach the disk midplane as a result of scattering in the disk atmospheres. However, previous models are insufficient to predict the hard X-ray spectra because of simplifications in flare models. We develop a model of X-ray spectra of stellar flares based on observations and flare theories. The flare temperature and nonthermal electron emissions are modeled as functions of flare energy, which allows us to better predict the hard X-ray photon flux than before. Using our X-ray model, we conduct radiative transfer calculations to investigate the impact of flare hard X-rays on disk ionization, with a particular focus on the protoplanetary disk around a T Tauri star. We demonstrate that for a flare with an energy of $ 10^{35}$ erg, X-ray photons with $\\gtrsim 5$ keV increase the ionization rates more than galactic cosmic rays down to $z \\approx 0.1R$. The contribution of flare X-rays to the ionization at the midplane depends on the disk parameters such as disk mass and dust settling. We also find that the 10-year-averaged X-rays from multiple flares could certainly contribute to the ionization. These results emphasize the importance of stellar flares on the disk evolution.         _ Less","","arXiv","https://arxiv.org/abs/2406.04946","0","1","synthetic_biology"
"Star Formation by Supernova Implosion","Abstract:                Recent hydrodynamical simulations of the late stages of supernova remnant (SNR) evolution have revealed that as they merge with the ambient medium, SNRs implode, leading to the formation of dense clouds in their center. While being highly_         _ More           Recent hydrodynamical simulations of the late stages of supernova remnant (SNR) evolution have revealed that as they merge with the ambient medium, SNRs implode, leading to the formation of dense clouds in their center. While being highly chemically enriched by their host SNR, these clouds appear to have similar properties as giant molecular clouds, which are believed to be the main site of star formation. Here, we develop a simple model, in order to estimate the efficiency of the star formation that might be triggered by the implosion of SNRs. We separately consider two cases, cyclic star formation, maintained by the episodic driving of feedback from new generations of stars; and a single burst of star formation, triggered by a single explosion. We find that in the cyclic case, star formation is inefficient, with implosion-triggered star-formation contributing a few percent of the observed star-formation efficiency per free-fall timescale. In the single-burst case, higher star-formation efficiencies can be obtained. However, while the implosion-triggered process might not contribute much to the overall star-formation, due to the high chemical enrichment of the birth clouds, it can explain the formation of a significant fraction of metal-rich stars.         _ Less","","arXiv","https://arxiv.org/abs/2406.04792","1","1","multiple"
"\\texttt{Simba}-\\texttt{C}: the evolution of the thermal and chemical properties in the intragroup medium","Abstract:                The newly updated \\texttt{GIZMO} and \\texttt{Simba} based simulation, \\texttt{Simba-C}, with its new stellar feedback, chemical enrichment, and recalibrated AGN feedback, allows for a detailed study of the intragroup medium X-ray properties. We discuss the impact of various physical mechanisms, e.g. stellar and AGN feedback, and_         _ More           The newly updated \\texttt{GIZMO} and \\texttt{Simba} based simulation, \\texttt{Simba-C}, with its new stellar feedback, chemical enrichment, and recalibrated AGN feedback, allows for a detailed study of the intragroup medium X-ray properties. We discuss the impact of various physical mechanisms, e.g. stellar and AGN feedback, and chemical enrichment, on the composition and the global scaling relations of nearby galaxy groups. We also study the evolution ($z=2$ to $0$) of the global properties for the $1\\,\\mathrm{keV}$ temperature groups. \\texttt{Simba-C} shows improved consistent matching with the observations of all X-ray scaling relations compared to \\texttt{Simba}. It is well known that AGN feedback has a significant influence on $L_{X,0.5-2.0}-T_{spec,corr}$, $S_{500/2500}-T_{spec,corr}$, and gas mass fractions, with our \\texttt{Simba-C} results consistent with it. Our recalibrated AGN feedback strength also showed an additional improvement in gas entropy, which now aligns with CLoGS observations. The updated stellar feedback and chemical enrichment model is shown to play an important role in our understanding of the chemical abundance ratios and their evolution within galaxy groups. In particular, we find that \\texttt{Simba-C} produces an increase in the amount of heavier elements (specifically Si and Fe) relative to O, compared to \\texttt{Simba}.         _ Less","","arXiv","https://arxiv.org/abs/2406.04761","0","1","synthetic_biology"
"Large-scale geometry and topology of gas fields: Effects of AGN and stellar feedback","Abstract:                Feedback from stars and active galactic nuclei (AGNs) primarily affects the formation and evolution of galaxies and the circumgalactic medium, leaving some kind of imprint on larger scales. Based on the {\\sc Simba} hydrodynamical simulation suite and using the full set of Minkowski functionals (MFs), this study systematically analyses the time_         _ More           Feedback from stars and active galactic nuclei (AGNs) primarily affects the formation and evolution of galaxies and the circumgalactic medium, leaving some kind of imprint on larger scales. Based on the {\\sc Simba} hydrodynamical simulation suite and using the full set of Minkowski functionals (MFs), this study systematically analyses the time evolution of the global geometry and topology of the gas temperature, pressure, density (total, HI, and H$_2$), and the metallicity fields between redshifts $z=5$ and $z=0$. The MFs show that small-scale astrophysical processes are persistent and manifest on larger, up to tens of Mpc scales, highlighting the specific morphological signatures of the relevant feedback mechanisms on these scales in the last $\\sim12$~Gyr. In qualitative terms, we were able establish a ranking that varies according to the field considered: stellar feedback mostly determines the morphology of the pressure and density fields and AGN jets are the primary origin of the morphology of the temperature and metallicity fields, while X-ray heating and AGN winds play the second most important role in shaping the geometry and topology of all the gaseous fields, except metallicity. Hence, the cosmic evolution of the geometry and topology of fields characterising the thermodynamical and chemical properties of the cosmic web offers complementary, larger scale constraints to galaxy formation models.         _ Less","","arXiv","https://arxiv.org/abs/2406.04430","1","1","multiple"
"Chemical Abundances of Early Quiescent Galaxies: New Observations and Modelling Impacts","Abstract:                Recent stellar chemical abundance measurements of a handful of $z\\sim2$ quiescent galaxies have suggested these galaxies exhibit a remarkably strong $_$-enhancement compared to their local and intermediate redshift counterparts. This apparent chemical evolution following quenchin_         _ More           Recent stellar chemical abundance measurements of a handful of $z\\sim2$ quiescent galaxies have suggested these galaxies exhibit a remarkably strong $_$-enhancement compared to their local and intermediate redshift counterparts. This apparent chemical evolution following quenching suggests that even the innermost regions of massive early-type galaxies may have experienced substantial mixing of stars in mergers, challenging a purely inside-out growth model. However, larger samples are needed to determine whether a high $_$-enhancement ([Mg/Fe] $\\approx 0.5$) is common in $z \\sim 2$ quiescent galaxies, and a comparative analysis is needed to determine whether it is consistently inferred using different stellar population synthesis models. We report age and stellar chemical abundance measurements for a sample of four gravitationally lensed quiescent galaxies at $z\\sim2.1-2.65$ based on Magellan/FIRE spectroscopy. For three of these galaxies we constrain the $_$-enhancement, and in two cases we measure high values comparable to earlier results when the spectra are analyzed consistently. We also find that the choice of modeling approach can exert a significant effect on the measured abundances. This model dependence can be partly, but not entirely, explained by the complex abundance patterns of $_$ elements in galaxies, which has been observed at lower redshifts and in one $z \\sim 2$ quiescent galaxy. Our investigation highlights the importance of independently varying abundance of $_$ elements when fitting the spectra of such galaxies. Observations with JWST will soon deliver precise and spatially resolved abundances of these and other quiescent galaxies at cosmic noon, opening a new window into their evolution.         _ Less","","arXiv","https://arxiv.org/abs/2406.03549","1","2","synthetic_biology"
"Simultaneous retrieval of orbital phase resolved JWST/MIRI emission spectra of the hot Jupiter WASP-43b: evidence of water, ammonia and carbon monoxide","Abstract:                _thus enabling detailed characterisation of their atmospheres. Precise constraints on the atmospheric composition of these exoplanets offer insights into their formation and evolution. We analyse four phase-resolved emission spectra of the hot Jupiter WASP-43b, generated from a phase curve observed with the MIRI/LRS onboard the JWST, to retrieve its atmosphe_         _ More           Spectroscopic phase curves of hot Jupiters measure their emission spectra at multiple orbital phases, thus enabling detailed characterisation of their atmospheres. Precise constraints on the atmospheric composition of these exoplanets offer insights into their formation and evolution. We analyse four phase-resolved emission spectra of the hot Jupiter WASP-43b, generated from a phase curve observed with the MIRI/LRS onboard the JWST, to retrieve its atmospheric properties. Using a parametric 2D temperature model and assuming a chemically homogeneous atmosphere within the observed pressure region, we simultaneously fit the four spectra to constrain the abundances of atmospheric constituents, thereby yielding more precise constraints than previous work that analysed each spectrum independently. Our analysis reveals statistically significant evidence of NH3 (4$_$) in a hot Jupiter's emission spectra for the first time, along with evidence of H2O (6.5$_$), CO (3.1$_$), and a non-detection of CH4. With our abundance constraints, we tentatively estimate the metallicity of WASP-43b at 0.6-6.5$\\times$solar and its C/O ratio at 0.6-0.9. Our findings offer vital insights into the atmospheric conditions and formation history of WASP-43b by simultaneously constraining the abundances of carbon, oxygen, and nitrogen-bearing species.         _ Less","","arXiv","https://arxiv.org/abs/2406.03490","1","1","multiple"
"Fluorine Abundances in Local Stellar Populations","Abstract:                _disk than the thin. The thin and thick disk average [F/Fe] for our sample of stars combined with the literature differ by 0.03 dex. The observations are compared to available chemical evolution models.         _ More           We present the first fluorine measurements in 12 normal giants belonging to the Galactic thin and thick disks using spectra obtained with the Phoenix infrared spectrometer on the 2.1m telescope at Kitt Peak. Abundances are determined from the (1-0) R9 2.3358 micron feature of the molecule HF. Additionally, sodium abundances are derived in 25 giants in the thin disk, thick disk, and halo using the Na I line at 2.3379 microns. We report fluorine abundances for thin and thick disk stars in the metallicity range -0.7 < [Fe/H] < 0. We add two abundance measurements for stars with [Fe/H] < 0.5 dex which are at a critical metallicity range to constrain models. We find a larger dispersion in fluorine abundances than sodium abundances despite both species having similar overall uncertainties due to atmospheric parameters, suggesting this dispersion is real and not observational. The dispersion is slightly larger in the thick disk than the thin. The thin and thick disk average [F/Fe] for our sample of stars combined with the literature differ by 0.03 dex. The observations are compared to available chemical evolution models.         _ Less","","arXiv","https://arxiv.org/abs/2406.02855","1","1","multiple"
"Spatiotemporal Predictions of Toxic Urban Plumes Using Deep Learning","Abstract:                Industrial accidents, chemical spills, and structural fires can release large amounts of harmful materials that disperse into urban atmospheres and impact populated areas. Computer models are typically used to predict the transport of toxic plumes by solving fluid dynamical equations. However, these models can be computationally expensive due to the need for_         _ More           Industrial accidents, chemical spills, and structural fires can release large amounts of harmful materials that disperse into urban atmospheres and impact populated areas. Computer models are typically used to predict the transport of toxic plumes by solving fluid dynamical equations. However, these models can be computationally expensive due to the need for many grid cells to simulate turbulent flow and resolve individual buildings and streets. In emergency response situations, alternative methods are needed that can run quickly and adequately capture important spatiotemporal features. Here, we present a novel deep learning model called ST-GasNet that was inspired by the mathematical equations that govern the behavior of plumes as they disperse through the atmosphere. ST-GasNet learns the spatiotemporal dependencies from a limited set of temporal sequences of ground-level toxic urban plumes generated by a high-resolution large eddy simulation model. On independent sequences, ST-GasNet accurately predicts the late-time spatiotemporal evolution, given the early-time behavior as an input, even for cases when a building splits a large plume into smaller plumes. By incorporating large-scale wind boundary condition information, ST-GasNet achieves a prediction accuracy of at least 90% on test data for the entire prediction period.         _ Less","","arXiv","https://arxiv.org/abs/2406.02582","1","1","multiple"
"Universal limiting behaviour of reaction-diffusion systems with conservation laws","Abstract:                _been largely studied as two separate paradigms. Here we show that in reaction-diffusion systems composed of many species, the presence of a conservation law constrains the evolution of the conserved quantity to be governed by a Cahn-Hilliard-like equation. This establishes a direct link with the paradigm of coexistence and recent 'active' field theor_         _ More           Making sense of complex inhomogeneous systems composed of many interacting species is a grand challenge that pervades basically all natural sciences. Phase separation and pattern formation in reaction-diffusion systems have been largely studied as two separate paradigms. Here we show that in reaction-diffusion systems composed of many species, the presence of a conservation law constrains the evolution of the conserved quantity to be governed by a Cahn-Hilliard-like equation. This establishes a direct link with the paradigm of coexistence and recent 'active' field theories. Hence, even for complex many-species systems a dramatically simplified but accurate description emerges over coarse spatio-temporal scales. Using the nullcline (the line of homogeneous steady states) as the central motif, we develop a geometrical framework which endows chemical space with a basis and suitable coordinates. This framework allows us to capture and understand the effect of eliminating fast non-conserved degrees of freedom, and to explicitly construct coefficients of the coarse field theory. We expect that the theory we develop here will be particularly relevant to advance our understanding of biomolecular condensates.         _ Less","","arXiv","https://arxiv.org/abs/2406.02409","1","1","multiple"
"Interplay between thermal and compositional gradients decides the microstructure during thermomigration: a phase-field study","Abstract:                _To investigate such microstructural changes, we present a phase-field model that incorporates coupling between concentration and thermal gradients. First, we simulated the evolution of non-uniform concentration profiles in the single-phase regions of Fe-C and Fe-N alloy systems due to imposed thermal gradients. To validate our model with the classical exper_         _ More           The presence of thermal gradients in alloys often leads to non-uniformity in concentration profiles, which can induce the thermomigration of microstructural features such as precipitates. To investigate such microstructural changes, we present a phase-field model that incorporates coupling between concentration and thermal gradients. First, we simulated the evolution of non-uniform concentration profiles in the single-phase regions of Fe-C and Fe-N alloy systems due to imposed thermal gradients. To validate our model with the classical experiments performed by Darken and Oriani, we studied the evolution of spatially varying concentration profiles where thermal gradients encompass single-phase and two-phase regions. We developed a parameterized thermodynamic description of the two-phase region of a binary alloy to systematically study the effect of interactions between chemically-driven and thermal gradient-driven diffusion of solute on the evolution of precipitates. Our simulations show how thermal gradient, precipitate size, and interparticle distance influence the migration and associated morphological changes of precipitates. The composition profiles and migration rates obtained from single-particle simulations show an exact match with our analytical model. We use twoparticle simulations to show conditions under which thermomigration induces the growth of the smaller particle and shrinkage of the larger one in contrast to the isothermal Ostwald ripening behavior. Our multiparticle simulations show similar behavior during coarsening. Moreover, in the presence of a thermal gradient, there is a shift in the center of mass of the precipitates towards the high-temperature region. Thus, our study offers new insights into the phenomena of microstructure evolution in the presence of thermal gradient.         _ Less","","arXiv","https://arxiv.org/abs/2406.00649","0","2","synthetic_biology"
"Nexus: A framework for conrolled simulations of idealised galaxies","Abstract:                _our needs. In addition, we make use of a proprietary module to account for galaxy formation physics, including gas cooling and heating, star formation, stellar feedback, and chemical enrichment. NEXUS' basic functionality consists in the generation of bespoke initial conditions (ICs) for a diversity of galaxy models, which are advanced in time to simulat_         _ More           Motivated by the need for realistic, dynamically self-consistent, evolving galaxy models that avoid the complexity of full, and zoom-in, cosmological simulations, we have developed NEXUS, an integral framework to create and evolve synthetic galaxies made of collisionless and gaseous components. NEXUS leverages the power of publicly available, tried-and-tested packages: the stellar-dynamics, action-based library AGAMA; and the adaptive mesh refinement, N-body/hydrodynamical code RAMSES, modified to meet our needs. In addition, we make use of a proprietary module to account for galaxy formation physics, including gas cooling and heating, star formation, stellar feedback, and chemical enrichment. NEXUS' basic functionality consists in the generation of bespoke initial conditions (ICs) for a diversity of galaxy models, which are advanced in time to simulate the galaxy's evolution. The fully self-consistent ICs are generated with a distribution-function based approach, as implemented in the galaxy modelling module of AGAMA -- up to now restricted to collisionless components, extended in this work to treat two types of gaseous configurations: hot halos and gas discs. NEXUS allows constructing equilibrium models with disc gas fractions $0~\\leq~f_{\\rm gas}~\\leq~1$, appropriate to model both low- and high-redshift galaxies. Similarly, the framework is ideally suited to the study of galactic ecology, i.e. the dynamical interplay between stars and gas over billions of years. As a validation and illustration of our framework, we reproduce several isolated galaxy model setups reported in earlier studies, and present a new, `nested bar' galaxy simulation. Future upgrades of NEXUS will include magneto-hydrodynamics and highly energetic particle (`cosmic ray') heating.         _ Less","","arXiv","https://arxiv.org/abs/2406.00342","1","1","multiple"
"Non-destructive Degradation Pattern Decoupling for Ultra-early Battery Prototype Verification Using Physics-informed Machine Learning","Abstract:                _from material prototypes to commercial batteries, making prototype verification critical to quality assessment. A fundamental challenge involves deciphering intertwined chemical processes to characterize degradation patterns and their quantitative relationship with battery performance. Here we show that a physics-informed machine learning approach can quanti_         _ More           Manufacturing complexities and uncertainties have impeded the transition from material prototypes to commercial batteries, making prototype verification critical to quality assessment. A fundamental challenge involves deciphering intertwined chemical processes to characterize degradation patterns and their quantitative relationship with battery performance. Here we show that a physics-informed machine learning approach can quantify and visualize temporally resolved losses concerning thermodynamics and kinetics only using electric signals. Our method enables non-destructive degradation pattern characterization, expediting temperature-adaptable predictions of entire lifetime trajectories, rather than end-of-life points. The verification speed is 25 times faster yet maintaining 95.1% accuracy across temperatures. Such advances facilitate more sustainable management of defective prototypes before massive production, establishing a 19.76 billion USD scrap material recycling market by 2060 in China. By incorporating stepwise charge acceptance as a measure of the initial manufacturing variability of normally identical batteries, we can immediately identify long-term degradation variations. We attribute the predictive power to interpreting machine learning insights using material-agnostic featurization taxonomy for degradation pattern decoupling. Our findings offer new possibilities for dynamic system analysis, such as battery prototype degradation, demonstrating that complex pattern evolutions can be accurately predicted in a non-destructive and data-driven fashion by integrating physics-informed machine learning.         _ Less","","arXiv","https://arxiv.org/abs/2406.00276","0","1","synthetic_biology"
"Generalized Inverse Optimal Control and its Application in Biology","Abstract:                _organisms exhibit remarkable adaptations across all scales, from molecules to ecosystems. We believe that many of these adaptations correspond to optimal solutions driven by evolution, training, and underlying physical and chemical laws and constraints. While some argue against such optimality principles due to their p_         _ More           Living organisms exhibit remarkable adaptations across all scales, from molecules to ecosystems. We believe that many of these adaptations correspond to optimal solutions driven by evolution, training, and underlying physical and chemical laws and constraints. While some argue against such optimality principles due to their potential ambiguity, we propose generalized inverse optimal control to infer them directly from data. This novel approach incorporates multi-criteria optimality, nestedness of objective functions on different scales, the presence of active constraints, the possibility of switches of optimality principles during the observed time horizon, maximization of robustness, and minimization of time as important special cases, as well as uncertainties involved with the mathematical modeling of biological systems. This data-driven approach ensures that optimality principles are not merely theoretical constructs but are firmly rooted in experimental observations. Furthermore, the inferred principles can be used in forward optimal control to predict and manipulate biological systems, with possible applications in bio-medicine, biotechnology, and agriculture. As discussed and illustrated, the well-posed problem formulation and the inference are challenging and require a substantial interdisciplinary effort in the development of theory and robust numerical methods.         _ Less","","arXiv","https://arxiv.org/abs/2405.20747","0","2","synthetic_biology"
"Enhanced formation of interstellar complex organic molecules on carbon monoxide ice","Abstract:                We investigate the role of carbon monoxide ice in the chemical evolution of prestellar cores using astrochemical rate equation models. We constrain the ratios of the binding energies on CO ice and H$_{2}$O ice for a series of adsorbates deemed important in diffusive chemistry on H$_{2}$O ices. We later include these ra_         _ More           We investigate the role of carbon monoxide ice in the chemical evolution of prestellar cores using astrochemical rate equation models. We constrain the ratios of the binding energies on CO ice and H$_{2}$O ice for a series of adsorbates deemed important in diffusive chemistry on H$_{2}$O ices. We later include these ratios in our chemical reaction network model, where the binding and diffusion energies of icy species vary as a function of the surface composition. When the surface coverage of CO increases, the model shows an enhancement of O-bearing complex organic molecules, especially those formed from the intermediate products of CO hydrogenation (e.g. HCO) and CH$_{3}$/CH$_{2}$. Because the binding energy of CH$_{3}$/CH$_{2}$ is in the right range, its diffusion rate increases significantly with CO coverage. At $T>$14 K and with less influence, enhanced diffusion of HCO also contributes to the increase of the abundances of COM. We find, however, that chemistry is not always enhanced on CO ice and that the temperature and cosmic ray ionization rate of each astronomical object is crucial for this particular chemistry, revealing a highly non-trivial behavior that needs to be addressed on a per-case basis. Our results are highly relevant in the context of interstellar ice observations with JWST.         _ Less","","arXiv","https://arxiv.org/abs/2405.20707","2","2","multiple"
"Space-time first-order correlations of an open Bose-Hubbard model with incoherent pump and loss","Abstract:                _chain and with spatially homogeneous one-body loss and pump within the Markovian approximation. The steady state corresponds to an infinite temperature state at finite chemical potential with diagonal spatial correlations. Nonetheless, we observe a nontrivial behaviour of the space-time two-point correlation function in the steady state, obtained by exact di_         _ More           We investigate the correlation properties in the steady state of driven-dissipative interacting bosonic systems in the quantum regime, as for example non-linear photonic cavities. Specifically, we consider the Bose-Hubbard model on a periodic chain and with spatially homogeneous one-body loss and pump within the Markovian approximation. The steady state corresponds to an infinite temperature state at finite chemical potential with diagonal spatial correlations. Nonetheless, we observe a nontrivial behaviour of the space-time two-point correlation function in the steady state, obtained by exact diagonalisation. In particular, we find that the decay width of the propagator is not only renormalised at increasing interactions, as it is the case of a single non-linear resonator, but also at increasing hopping strength. We then compute the full spectral function, finding that it contains both a dispersive free-particle like dispersion at low energy and a doublon branch at energy corresponding to the on-site interactions. We compare with the corresponding calculation for the ground state of a closed quantum system and show that the driven-dissipative nature - determining both the steady state and the dynamical evolution - changes the low-lying part of the spectrum, where noticeably, the dispersion is quadratic instead of linear at small wavevectors.         _ Less","","arXiv","https://arxiv.org/abs/2405.19972","0","1","synthetic_biology"
"Hybrid Quantum Algorithm for Simulating Real-Time Thermal Correlation Functions","Abstract:                _speed-up over the classical algorithm by computing short-time matrix elements of the quantum propagator on a quantum computer. We show that the component of imaginary-time evolution can be performed accurately using the recently developed Probabilistic Imaginary-Time_         _ More           We present a hybrid Path Integral Monte Carlo (hPIMC) algorithm to calculate real-time quantum thermal correlation functions and demonstrate its application to open quantum systems. The hPIMC algorithm leverages the successes of classical PIMC as a computational tool for high-dimensional system studies by exactly simulating dissipation using the Feynman-Vernon influence functional on a classical computer. We achieve a quantum speed-up over the classical algorithm by computing short-time matrix elements of the quantum propagator on a quantum computer. We show that the component of imaginary-time evolution can be performed accurately using the recently developed Probabilistic Imaginary-Time Evolution (PITE) algorithm, and we introduce a novel low-depth circuit for approximate real-time evolution under the kinetic energy operator using a Discrete Variable Representation (DVR). We test the accuracy of the approximation by computing the position-position thermal correlation function of a proton transfer reaction.         _ Less","","arXiv","https://arxiv.org/abs/2405.19599","0","1","synthetic_biology"
"Effective phase diffusion for spin phase evolution under random nonlinear magnetic field","Abstract:                _which extends the effective phase diffusion method for linear gradient field. Based on the phase diffusion, the proposed method reveals the general features of phase evolutions in non-nonlinear gradient fields. There are three types of phase_         _ More           The general theoretical description of spin self-diffusion under nonlinear gradient is proposed, which extends the effective phase diffusion method for linear gradient field. Based on the phase diffusion, the proposed method reveals the general features of phase evolutions in non-nonlinear gradient fields. There are three types of phase evolutions: phase diffusion, float phase evolution, and shift based on the starting position. For spin diffusion near the origin of the nonlinear field, these three phase evolutions significantly affect the NMR signal. The traditional methods have difficulties in handling these three-phase evolutions. Notably, the phase from float phase evolution is missed or misplaced in traditional methods, which leads to incorrect NMR signal attenuation or phase shift. The method here shows that the diffusing and float phase evolutions come from the first and second derivatives of the gradient field. Based on these three phase evolutions, the phase variance and corresponding NMR signal attenuation are obtained, demonstrated by calculating the phase diffusions under the parabolic and cubic fields. The results indicate that signal attenuation obeys Gaussian attenuation for a short time, then changes to Lorentzian or Mittag Leffler function attenuations when time increases, significantly different from Gaussian attenuation. For spins starting diffusion far away from the origin, the signal attenuation is Gaussian, but the float phase still has an important effect on the total phase shift of even-order gradient fields, which could be used to measure the diffusion coefficient directly. Random walk simulations are performed, which support the obtained theoretical results. The obtained general theoretical expressions can handle random order nonlinear gradient field. The results could help develop advanced experimental techniques for NMR and MRI.         _ Less","","arXiv","https://arxiv.org/abs/2405.18514","0","1","synthetic_biology"
"A path towards constraining the evolution of the interstellar medium and outflows in the Milky Way using APOGEE","Abstract:                _data. However, it remains disjoint from recent advancements in understanding the physics of the Galactic interstellar medium (ISM). This paper introduces a new model for the chemical_         _ More           In recent years, the study of the Milky Way has significantly advanced due to extensive spectroscopic surveys of its stars, complemented by astroseismic and astrometric data. However, it remains disjoint from recent advancements in understanding the physics of the Galactic interstellar medium (ISM). This paper introduces a new model for the chemical evolution of the Milky Way that can be constrained on stellar data, because it combines a state-of-the-art ISM model with a Milky Way stellar disc model. Utilizing a dataset of red clump stars from APOGEE, known for their precise ages and metallicities, we concentrate on the last 6 billion years -- a period marked by Milky Way's secular evolution. We examine the oxygen abundance in the low-$_$ disc stars relative to their ages and birth radii, validating or constraining critical ISM parameters that remain largely unexplored in extragalactic observations. The models that successfully reproduce the radius -- metallicity distribution and the age -- metallicity distribution of stars without violating existing ISM observations indicate a need for modest differential oxygen enrichment in Galactic outflows, meaning that the oxygen abundance of outflows is higher than the local ISM abundance, irrespective of outflow mass loading. The models also suggest somewhat elevated ISM gas velocity dispersion levels over the past 6 billion years compared to galaxies of similar mass. The extra turbulence necessary could result from energy from gas accretion onto the Galaxy, supernovae clustering in the ISM, or increased star formation efficiency per freefall time. This work provides a novel approach to constraining the Galactic ISM and outflows, leveraging the detailed insights available from contemporary Milky Way surveys.         _ Less","","arXiv","https://arxiv.org/abs/2405.18223","3","2","origin_of_life"
"Extraction of Physical Properties of Interstellar Medium from the Observed Line Profiles","Abstract:                _molecules are ubiquitous in space, the study of the 'Molecular Universe' could unfold the mystery of the existing Interstellar medium. Star formation is linked to the chemical_         _ More           Since molecules are ubiquitous in space, the study of the 'Molecular Universe' could unfold the mystery of the existing Interstellar medium. Star formation is linked to the chemical evolution processes. Thus, an analysis of the formation of stars coupled with the chemical evolution would give a clear insight into the entire process. For example, various evolutionary stages of star formation could be probed by observing various molecules. Chemical diagnostics of these regions could be used to extract the physical properties (e.g., density, temperature, ionization degree, etc.) of these regions. Radiative transfer calculations are worthwhile in estimating physical parameters of the region where molecules are detected. However, the radiative transfer calculations are limited due to insufficient molecular data, such as spectroscopic information or collisional excitation probabilities of many interstellar species. Complex organic molecules are detected in various environments ranging from the cold gas in prestellar cores to the warm gas on solar system scales close to individual protostars. A comparative study of the relative abundances of molecules could provide insights into the beginning of chemical complexity and the link to our solar system. In my thesis, I would mainly investigate the physical properties and kinematics of different star-forming regions using radiative transfer modeling. The observed spatial differentiation between various key molecules is used to explain their physical structure or evolution and various microphysical effects. In addition, some key molecules are used to study the various evolutionary phases. This simulated data is useful for interpreting the observed data of different telescopes like IRAM 30m, GBT, ALMA, Herschel, SOFIA, etc.         _ Less","","arXiv","https://arxiv.org/abs/2405.17989","2","1","origin_of_life"
"Global existence, fast signal diffusion limit, and $L^\\infty$-in-time convergence rates in a competitive chemotaxis system","Abstract:                We study a chemotaxis system that includes two competitive prey and one predator species in a two-dimensional domain, where the movement of prey (resp. predators) is driven by chemicals secreted by predators (resp. prey), called mutually repulsive (resp. mutually attractive) chemotaxis effect. The kinetics for all species are chosen according to the competit_         _ More           We study a chemotaxis system that includes two competitive prey and one predator species in a two-dimensional domain, where the movement of prey (resp. predators) is driven by chemicals secreted by predators (resp. prey), called mutually repulsive (resp. mutually attractive) chemotaxis effect. The kinetics for all species are chosen according to the competitive Lotka-Volterra equations for prey and to a Holling type functional response for the predator. Under the biologically relevant scenario that the chemicals diffuse much faster than the individual diffusion of all species and a suitable re-scaling, equations for chemical concentrations are parabolic with slow evolution of coefficient $0<\\varepsilon\\ll 1$. In the first main result, we show the global existence of a unique classical solution to the system for each $\\varepsilon$. Secondly, we study rigorously the so-called fast signal diffusion limit, passing from the system including parabolic equations with the slow evolution to the one with all elliptic equations for chemical concentrations, i.e. the limit as $\\varepsilon \\to 0$. This explains why elliptic equations can be proposed for chemical concentration instead of parabolic ones with slow evolution. Thirdly, the $L^\\infty$-in-time convergence rates for the fast signal diffusion limit are estimated, where the effect of the initial layer is carefully treated. Finally, the differences between the systems with and without the slow evolution, and between the systems with one or two preys are discussed due to numerical simulations.         _ Less","","arXiv","https://arxiv.org/abs/2405.17392","0","1","synthetic_biology"
"Gas-phase hydrogenation of large, astronomically relevant PAH cations","Abstract:                _is confirmed. From the theoretical calculation, the bonding ability plays an important role in the gas-phase hydrogenation processes. The factors that affect the hydrogenation chemical reactivity are discussed, including the effect of carbon skeleton structure, the side-edged structure, the molecular size, the five- and six-membered C-ring structure, the bay_         _ More           To investigate the gas-phase hydrogenation processes of large, astronomically relevant cationic polycyclic aromatic hydrocarbon (PAH) molecules under the interstellar environments, the ion-molecule collision reaction between six PAH cations and H-atoms is studied. The experimental results show that the hydrogenated PAH cations are efficiently formed, and no even-odd hydrogenated mass patterns are observed in the hydrogenation processes. The structure of newly formed hydrogenated PAH cations and the bonding energy for the hydrogenation reaction pathways are investigated with quantum theoretical calculations. The exothermic energy for each reaction pathway is relatively high, and the competition between hydrogenation and dehydrogenation is confirmed. From the theoretical calculation, the bonding ability plays an important role in the gas-phase hydrogenation processes. The factors that affect the hydrogenation chemical reactivity are discussed, including the effect of carbon skeleton structure, the side-edged structure, the molecular size, the five- and six-membered C-ring structure, the bay region structure, and the neighboring hydrogenation. The IR spectra of hydrogenated PAH cations are also calculated. These results we obtain once again validate the complexity of hydrogenated PAH molecules, and provide the direction for the simulations and observations under the coevolution interstellar chemistry network. We infer that if we do not consider other chemical evolution processes (e.g., photo-evolution), then the hydrogenation states and forms of PAH compounds are intricate and complex in the interstellar medium (ISM).         _ Less","","arXiv","https://arxiv.org/abs/2405.16811","1","1","multiple"
"He-enriched STAREVOL models for globular cluster multiple populations. Self-consistent isochrones from ZAMS to the TP-AGB phase","Abstract:                A common property of globular clusters (GC) is to host multiple populations characterized by peculiar chemical abundances. Recent photometric studies suggest that the He content could vary between the populations of a GC by up to $_$He $\\sim$ 0.13, in mass fraction. The initial He content impacts the_         _ More           A common property of globular clusters (GC) is to host multiple populations characterized by peculiar chemical abundances. Recent photometric studies suggest that the He content could vary between the populations of a GC by up to $_$He $\\sim$ 0.13, in mass fraction. The initial He content impacts the evolution of low-mass stars by ultimately modifying their lifetimes, luminosity, temperatures, and, more generally, the morphology of post-RGB evolutionary tracks in the Hertzsprung-Russell diagram. We present new physically accurate isochrones with different initial He-enrichments and metallicities, with a focus on the methods implemented to deal with the post-RGB phases. The isochrones are based on tracks computed with the stellar evolution code STAREVOL for different metallicities (Z = 0.0002, 0.0009, 0.002, and 0.008) and with different He-enrichment (from 0.25 to 0.6 in mass fraction). We describe the effect of He-enrichment on the morphology of the isochrones and test these by comparing the predicted number counts of HB and AGB stars with those of selected GCs. Comparing the number ratios, we find that our new theoretical ones agree with the observed values within $1_$ in most cases. The work presented here sets the ground for future studies on stellar populations in globular clusters, in which the abundances of light elements in He-enhanced models will rely on different assumptions for the causes of this enrichment. The developed methodology permits the computation of isochrones from new stellar tracks with non-canonical stellar processes. The checked number counts ensure that, at least in this reference set, the contribution of the luminous late stages of stellar evolution to the integrated light of a GC is represented adequately.         _ Less","","arXiv","https://arxiv.org/abs/2405.16505","0","1","synthetic_biology"
"X-ray Coulomb explosion imaging reveals role of molecular structure in internal conversion","Abstract:                _the molecular rearrangement using Coulomb explosion imaging. Our measurement links the extracted deplanarization of the molecular geometry to the previously studied temporal evolution of the electronic properties of the system. In particular, the protons of the exploded molecule are well-suited messengers carrying rich information on the molecule's geome_         _ More           Molecular photoabsorption results in an electronic excitation/ionization which couples to the rearrangement of the nuclei. The resulting intertwined change of nuclear and electronic degrees of freedom determines the conversion of photoenergy into other molecular energy forms. Nucleobases are excellent candidates for studying such dynamics, and great effort has been taken in the past to observe the electronic changes induced by the initial excitation in a time-resolved manner using ultrafast electron spectroscopy. The linked geometrical changes during nucleobase photorelaxation have so far not been observed directly in time-resolved experiments. Here, we present a study on a thionucleobase, where we extract comprehensive information on the molecular rearrangement using Coulomb explosion imaging. Our measurement links the extracted deplanarization of the molecular geometry to the previously studied temporal evolution of the electronic properties of the system. In particular, the protons of the exploded molecule are well-suited messengers carrying rich information on the molecule's geometry at distinct times after the initial electronic excitation. The combination of ultrashort laser pulses to trigger molecular dynamics, intense X-ray free-electron laser pulses for the explosion of the molecule, and multi-particle coincidence detection opens new avenues for time-resolved studies of complex molecules in the gas phase.         _ Less","","arXiv","https://arxiv.org/abs/2405.15367","2","2","multiple"
"Quadrupolar resonance spectroscopy of individual nuclei using a room-temperature quantum sensor","Abstract:                Nuclear quadrupolar resonance (NQR) spectroscopy reveals chemical bonding patterns in materials and molecules through the unique coupling between nuclear spins and local fields. However, traditional NQR techniques require macroscopic ensembles of nuclei to yield a detectable signal, which precludes the study of individual molecules and obscures molecule-to-m_         _ More           Nuclear quadrupolar resonance (NQR) spectroscopy reveals chemical bonding patterns in materials and molecules through the unique coupling between nuclear spins and local fields. However, traditional NQR techniques require macroscopic ensembles of nuclei to yield a detectable signal, which precludes the study of individual molecules and obscures molecule-to-molecule variations due to local perturbations or deformations. Optically active electronic spin qubits, such as the nitrogen-vacancy (NV) center in diamond, facilitate the detection and control of individual nuclei through their local magnetic couplings. Here, we use NV centers to perform NQR spectroscopy on their associated nitrogen-14 ($^{14}$N) nuclei at room temperature. In mapping the nuclear quadrupolar Hamiltonian, we resolve minute variations between individual nuclei. The measurements further reveal correlations between the parameters in the NV center's electronic spin Hamiltonian and the $^{14}$N quadropolar Hamiltonian, as well as a previously unreported Hamiltonian term that results from symmetry breaking. We further design pulse sequences to initialize, readout, and control the quantum evolution of the $^{14}$N nuclear state using the nuclear quadrupolar Hamiltonian.         _ Less","","arXiv","https://arxiv.org/abs/2405.14859","1","1","multiple"
"Bifunctional Noble Metal-free Ternary Chalcogenide Electrocatalysts for Overall Water Splitting","Abstract:                _the presence of the stoichiometric ratio of elements in these compounds. X-ray photoelectron spectroscopy (XPS) and X-ray absorption spectroscopy (XAS) were used to study the chemical states on the surface and in bulk, respectively. These materials exhibit bifunctional catalytic activity towards the two half-reactions of the water-splitting process, with LaN_         _ More           Hydrogen has been identified as a clean, zero carbon, sustainable, and promising energy source for the future, and electrochemical water splitting for hydrogen production is an emission-free, efficient energy conversion technology. A major limitation of this approach is the unavailability of efficient, abundant, inexpensive catalysts, which prompts the need for new catalytic materials. Here, we report the synthesis and electrocatalytic properties of a novel transition metal-based ternary chalcogenide family, LaMS$_3$ (M = Mn, Fe, Co, Ni). Powder X-ray diffraction confirms the phase purity of these materials, while composition analysis using energy dispersive spectroscopy (EDS) confirms the presence of the stoichiometric ratio of elements in these compounds. X-ray photoelectron spectroscopy (XPS) and X-ray absorption spectroscopy (XAS) were used to study the chemical states on the surface and in bulk, respectively. These materials exhibit bifunctional catalytic activity towards the two half-reactions of the water-splitting process, with LaNiS$_3$ being the most active material for both hydrogen evolution reaction (HER) and oxygen evolution reaction (OER). The LaMS$_3$ compounds show long-term stability with negligible change in the overpotential at a constant current density of 10 mA cm$^{-2}$ over 18 hours of measurements. As compared to the corresponding ternary oxides, the LaMS$_3$ materials exhibit higher activity and significantly lower Tafel slopes. The ability to catalyze both half-reactions of water electrolysis makes these materials promising candidates for bifunctional catalysts and presents a new avenue to search for high-efficiency electrocatalysts for water splitting.         _ Less","","arXiv","https://arxiv.org/abs/2405.14187","0","2","synthetic_biology"
"Mechanistic Insights into Non-Adiabatic Interband Transitions on a Semiconductor Surface Induced by Hydrogen Atom Collisions","Abstract:                _hyperthermal H atom scattering from a semiconductor surface, Ge(111)c(2*8), we present a mixed quantum-classical non-adiabatic molecular dynamics model based on time-dependent evolution of Kohn-Sham orbitals and a classical path approximation. Our results suggest that facile non-adiabatic transitions occur selectively at the rest atom site, featuring excitat_         _ More           To understand the recently observed mysterious non-adiabatic energy transfer for hyperthermal H atom scattering from a semiconductor surface, Ge(111)c(2*8), we present a mixed quantum-classical non-adiabatic molecular dynamics model based on time-dependent evolution of Kohn-Sham orbitals and a classical path approximation. Our results suggest that facile non-adiabatic transitions occur selectively at the rest atom site, featuring excitation of valance band electrons to the conduction band, but not at the adatom site. This drastic site specificity can be attributed to the changes of the local band structure upon energetic H collisions at different surface sites, leading to transient near-degeneracies and significant couplings between occupied and unoccupied orbitals at the rest atom, but not at the adatom. These insights shed valuable light on the collisional induced non-adiabatic dynamics at semiconductor surfaces.         _ Less","","arXiv","https://arxiv.org/abs/2405.13361","0","2","synthetic_biology"
"Theia 456: Tidally Shredding an Open Cluster","Abstract:                _We focus on one such structure, Theia 456 (COIN-Gaia-13), a loosely bound collection of ~320 stars spanning ~120 pc that has previously been shown to exhibit kinematic, chemical, and gyrochronal coherency, indicating a common origin. We obtain follow-up radial velocities and supplement these with Gaia astrometry to perform an in-depth dynamical analysis of_         _ More           The application of clustering algorithms to the Gaia astrometric catalog has revolutionized our census of stellar populations in the Milky Way, including the discovery of many new, dispersed structures. We focus on one such structure, Theia 456 (COIN-Gaia-13), a loosely bound collection of ~320 stars spanning ~120 pc that has previously been shown to exhibit kinematic, chemical, and gyrochronal coherency, indicating a common origin. We obtain follow-up radial velocities and supplement these with Gaia astrometry to perform an in-depth dynamical analysis of Theia 456. By integrating stellar orbits through a Milky Way potential, we find the currently dispersed structure coalesced into a small cluster in the past. Via Bayesian modeling, we derive a kinematic age of 245 +/- 3 Myr (statistical), a half-mass radius of 9 +/- 2 pc, and an initial one-dimensional velocity dispersion of 0.14 +/- 0.02 km/s. Our results are entirely independent of model isochrones, details of stellar evolution, and internal cluster dynamics, and the statistical precision in our age derivation rivals that of the most precise age-dating techniques known today, though our imperfect knowledge of the Milky Way potential and simple spherical model for Theia 456 at birth add additional uncertainties. Using posterior predictive checking, we confirm these results are robust under reasonable variations to the Milky Way potential. Such low density structures that are disrupted by the Galactic tides before virializing may be ubiquitous, signifying that Theia 456 is a valuable benchmark for studying the dynamical history of stellar populations in the Milky Way.         _ Less","","arXiv","https://arxiv.org/abs/2405.13133","0","1","synthetic_biology"
"Multiple chemical tracers finally unveil the intricate NGC\\,1333 IRAS\\,4A outflow system. FAUST XVI","Abstract:                _exploration of outflows in protobinary systems presents a challenging yet crucial endeavour, offering valuable insights into the dynamic interplay between protostars and their evolution. In this study, we examine the morphology and dynamics of jets and outflows within the IRAS\\,4A protobinary system. This analysis is based on ALMA observations of SiO(5--4),_         _ More           The exploration of outflows in protobinary systems presents a challenging yet crucial endeavour, offering valuable insights into the dynamic interplay between protostars and their evolution. In this study, we examine the morphology and dynamics of jets and outflows within the IRAS\\,4A protobinary system. This analysis is based on ALMA observations of SiO(5--4), H$_2$CO(3$_{0,3}$--2$_{0,3}$), and HDCO(4$_{1,4}$--3$_{1,3}$) with a spatial resolution of $\\sim$150\\,au. Leveraging an astrochemical approach involving the use of diverse tracers beyond traditional ones has enabled the identification of novel features and a comprehensive understanding of the broader outflow dynamics. Our analysis reveals the presence of two jets in the redshifted emission, emanating from IRAS\\,4A1 and IRAS\\,4A2, respectively. Furthermore, we identify four distinct outflows in the region for the first time, with each protostar, 4A1 and 4A2, contributing to two of them. We characterise the morphology and orientation of each outflow, challenging previous suggestions of bends in their trajectories. The outflow cavities of IRAS\\,4A1 exhibit extensions of 10$''$ and 13$''$ with position angles (PA) of 0$^{\\circ}$ and -12$^{\\circ}$, respectively, while those of IRAS\\,4A2 are more extended, spanning 18$''$ and 25$''$ with PAs of 29$^{\\circ}$ and 26$^{\\circ}$. We propose that the misalignment of the cavities is due to a jet precession in each protostar, a notion supported by the observation that the more extended cavities of the same source exhibit lower velocities, indicating they may stem from older ejection events.         _ Less","","arXiv","https://arxiv.org/abs/2405.12735","1","2","synthetic_biology"
"Chemical evolution of the Galactic bulge with different stellar populations","Abstract:                _an intense star formation burst, while the metal-rich stars formed during a second burst and/or were accreted from the inner Galactic disk due to a growing bar. We used a chemical evolution model that tracks various chemical species with detailed nucleosynthesis, focusing on Fe p_         _ More           The metallicity distribution function (MDF) of the Galactic bulge features a multi-peak shape, with a metal-poor peak at [Fe/H]=-0.3 dex and a metal-rich peak at [Fe/H]=+0.3 dex. This bimodality is also seen in [alpha/Fe] versus [Fe/H] ratios, indicating different stellar populations in the bulge. We aim to replicate the observed MDF by proposing a scenario where the metal-poor bulge stars formed in situ during an intense star formation burst, while the metal-rich stars formed during a second burst and/or were accreted from the inner Galactic disk due to a growing bar. We used a chemical evolution model that tracks various chemical species with detailed nucleosynthesis, focusing on Fe production from both Type Ia supernovae and massive stars, including rotating massive stars with varying velocities. Our model also accounts for gas infall, outflow, and the effect of stellar migration. Results are compared to 13,000 stars from the SDSS/APOGEE survey within 3.5 kpc of the Galactic center. Our model successfully reproduces the double-peak shape of the bulge MDF and the alpha-element abundance trends relative to Fe by assuming (i) a multi-burst star formation history with a 250 Myr quenching of the first burst and (ii) stellar migration from the inner disk due to a growing bar. We estimate that about 40% of the bulge-bar's stellar mass originates from the inner disk. Nucleosynthesis models that assume either no rotation for massive stars or a rotational velocity distribution favoring slow rotation at high metallicities best match the observed MDF and [alpha/Fe] and [Ce/Fe] versus [Fe/H] abundance patterns.         _ Less","","arXiv","https://arxiv.org/abs/2405.12585","3","2","origin_of_life"
"(Re)mind the gap: a hiatus in star formation history unveiled by APOGEE DR17","Abstract:                _/H], thus confirming previous suggestions by Gratton et al. (1996) and Fuhrmann (1998). Then we try to interpret the data by means of detailed chemical models. We compare the APOGEE DR17 red giant stars with the predictions of a detailed chemical evolution model based on the two-_         _ More           The analysis of several spectroscopic surveys indicates the presence of a bimodality between the disc stars in the abundance ratio space of [$_$/Fe] versus [Fe/H]. The two stellar groups are commonly referred to as the high-$_$ and low-$_$ sequences. Some models capable of reproducing such a bimodality, invoke the presence of a hiatus in the star formation history in our Galaxy, whereas other models explain the two sequences by means of stellar migration. Our aim is to show that the existence of the gap in the star formation rate between high-$_$ and low-$_$ is evident in the stars of APOGEE DR17, if one plots [Fe/$_$] versus [$_$/H], thus confirming previous suggestions by Gratton et al. (1996) and Fuhrmann (1998). Then we try to interpret the data by means of detailed chemical models. We compare the APOGEE DR17 red giant stars with the predictions of a detailed chemical evolution model based on the two-infall paradigm, taking also into account possible accretion of dwarf satellites. The APOGEE DR17 abundance ratios [Fe/$_$] versus [$_$/H] exhibit a sharp increase of [Fe/$_$] at a nearly constant [$_$/H] (where $_$ elements considered are Mg, Si, O) during the transition between the two disc phases. This observation strongly supports the hypothesis that a hiatus in star formation occurred during this evolutionary phase. Notably, the most pronounced growth in the [Fe/$_$] versus [$_$/H] relation is observed for oxygen, as this element is exclusively synthesised in core-collapse supernovae. A chemical model predicting a stop in the star formation of a duration of roughly 3.5 Gyr, and where the high-$_$ disc starts forming from pre-enriched gas by a previous encounter with a dwarf galaxy can well explain the observations.         _ Less","","arXiv","https://arxiv.org/abs/2405.11025","3","3","multiple"
"The ESO SupJup Survey I: Chemical and isotopic characterisation of the late L-dwarf DENIS J0255-4700 with CRIRES$^+$","Abstract:                It has been proposed that the distinct formation and evolution of exoplanets and brown dwarfs may affect the chemical and isotopic content of their atmospheres. Recent work has indeed shown differences in the $^{12}$C/$^{13}$C isotope ratio, provisionally attributed to the top-down formation of brown dwarfs and the cor_         _ More           It has been proposed that the distinct formation and evolution of exoplanets and brown dwarfs may affect the chemical and isotopic content of their atmospheres. Recent work has indeed shown differences in the $^{12}$C/$^{13}$C isotope ratio, provisionally attributed to the top-down formation of brown dwarfs and the core accretion pathway of super-Jupiters. The ESO SupJup Survey aims to disentangle the formation pathways of isolated brown dwarfs and planetary-mass companions using chemical and isotopic tracers. The survey uses high-resolution spectroscopy with the recently upgraded VLT/CRIRES$^+$ spectrograph, covering a total of 49 targets. Here, we present the first results: an atmospheric characterisation of DENIS J0255-4700, an isolated brown dwarf near the L-T transition. We analyse its K-band spectrum using a retrieval framework where the radiative transfer code petitRADTRANS is coupled to PyMultiNest. Gaussian Processes are employed to model inter-pixel correlations and we adopt an updated parameterisation of the PT-profile. Abundances of CO, H$_2$O, CH$_4$, and NH$_3$ are retrieved for this fast-rotating L-dwarf. The ExoMol H$_2$O line list provides a significantly better fit than that of HITEMP. A free-chemistry retrieval is strongly favoured over equilibrium chemistry, caused by an under-abundance of CH$_4$. The free-chemistry retrieval constrains a super-solar C/O-ratio of $\\sim0.68$ and a solar metallicity. We find tentative evidence ($\\sim3_$) for the presence of $^{13}$CO, with a constraint on the isotope ratio of $\\mathrm{^{12}C/^{13}C}=184^{+61}_{-40}$ and a lower limit of $\\gtrsim97$, suggesting a depletion of $^{13}$C compared to the interstellar medium ($\\sim68$). High-resolution, high signal-to-noise K-band spectra provide an excellent means to constrain the chemistry and isotopic content of sub-stellar objects, as is the main objective of the ESO SupJup Survey.         _ Less","","arXiv","https://arxiv.org/abs/2405.10841","2","2","multiple"
"Experimental investigations of diacetylene ice photochemistry in Titan's atmospheric conditions","Abstract:                _. The evolution of the ice's composition was monitored using spectroscopic techniques. Our results reveal that diacetylene ice is reactive through singlet-triplet absorption, similar to the photochemistry of other organic ices of Titan (such as dicyanoacetylene C$_4$N$_2$ ice) that we investigated previously. Several_         _ More           A large fraction of the organic species produced photochemically in the atmosphere of Titan can condense to form ice particles in the stratosphere and in the troposphere. According to various studies, diacetylene (C$_4$H$_2$) condenses below 100 km where it can be exposed to ultraviolet radiation. We studied experimentally the photochemistry of diacetylene ice (C$_4$H$_2$) to evaluate its potential role in the lower altitude photochemistry of Titan's atmospheric ices. Methods. C$_4$H$_2$ ice films were irradiated with near-ultraviolet (near-UV) photons ( _ > 300 nm) with different UV sources to assess the impact of the wavelengths of photons on the photochemistry of C$_4$H$_2$. The evolution of the ice's composition was monitored using spectroscopic techniques. Our results reveal that diacetylene ice is reactive through singlet-triplet absorption, similar to the photochemistry of other organic ices of Titan (such as dicyanoacetylene C$_4$N$_2$ ice) that we investigated previously. Several chemical processes occurred during the photolysis: the hydrogenation of C$_4$H$_2$ to form other C$_4$ hydrocarbons (vinylacetylene C$_4$H$_4$ to butane C$_4$H$_{10}$); the formation of larger and highly polymerizable hydrocarbons, such as triacetylene (C$_6$H$_2$); and the formation of an organic polymer that is stable at room temperature. The nondetection of diacetylene ice in Titan's atmosphere or surface could be rationalized based on our experimental results that C$_4$H$_2$ is photochemically highly reactive in the solid phase when exposed to near-UV radiation that reaches Titan's lower altitudes and surface. C$_4$H$_2$ may be one of the key molecules promoting the chemistry in the ices and aerosols of Titan's haze layers, especially in the case of co-condensation with other organic volatiles, with which it could initiate more complex solid-phase chemistry.         _ Less","","arXiv","https://arxiv.org/abs/2405.10760","1","1","multiple"
"Interacting chiral fermions on the lattice with matrix product operator norms","Abstract:                _code to demonstrate that the ground state for large system sizes can be determined efficiently. As our tensor network approach does not exhibit any sign problem, we can add a chemical potential and study real-time evolution.         _ More           We develop a Hamiltonian formalism for simulating interacting chiral fermions on the lattice while preserving unitarity and locality and without breaking the chiral symmetry. The fermion doubling problem is circumvented by constructing a Fock space endowed with a semi-definite norm. When projecting our theory on the the single-particle sector, we recover the framework of Stacey fermions, and we demonstrate that the scaling limit of the free model recovers the chiral fermion field. Technically, we make use of a matrix product operator norm to mimick the boundary of a higher dimensional topological theory. As a proof of principle, we consider a single Weyl fermion on a periodic ring with Hubbard-type nearest-neighbor interactions and construct a variational generalized DMRG code to demonstrate that the ground state for large system sizes can be determined efficiently. As our tensor network approach does not exhibit any sign problem, we can add a chemical potential and study real-time evolution.         _ Less","","arXiv","https://arxiv.org/abs/2405.10285","0","1","synthetic_biology"
"First star formation in extremely early epochs","Abstract:                First stars play crucial roles in development of the universe, influencing events like cosmic reionization and the chemical enrichment. While first stars are conventionally thought to form at around $z \\sim 20-30$ in the standard $_$ Cold Dark Matter ($_$CDM) cosmology, observational constraints on small-scale density fluctuations remain limited, possibly di_         _ More           First stars play crucial roles in development of the universe, influencing events like cosmic reionization and the chemical enrichment. While first stars are conventionally thought to form at around $z \\sim 20-30$ in the standard $_$ Cold Dark Matter ($_$CDM) cosmology, observational constraints on small-scale density fluctuations remain limited, possibly differing significantly from the scale-invariant fluctuations assumed in the $_$CDM model. Should this be the case, the formation of first stars could occur much earlier than typically predicted. In this study, we investigate the formation process of first stars in the extremely early epochs of $z \\gtrsim 100$ in the post-recombination universe. At such early times, the effects of the warm cosmic microwave background (CMB) become significant. We calculate the collapse of primordial star-forming clouds using a one-zone thermo-chemical model that accounts for CMB influences on radiative heating, Compton cooling, and photodissociation reactions. We found that the impact of the CMB on the evolution is limited at $z \\lesssim 100$, with the temperature evolution closely resembling the conventional model. However, within the range $100 \\lesssim z \\lesssim 400$, the formation of H$_2$ via the H$^-$ channel is impeded by H$^-$ photodetachment induced by the CMB, leading to higher temperatures compared to standard one. Consequently, first stars with masses exceeding $1000 ~\\mathrm{M}_\\odot$ can emerge at $z \\gtrsim 100$. Furthermore, at $z \\gtrsim 500$, the temperature evolution becomes nearly isothermal solely due to atomic cooling, as H$_2$ formation is entirely suppressed. In such cases, supermassive stars with masses around $\\sim 10^5 ~\\mathrm{M}_\\odot$ are expected to form solely via atomic cooling. These findings emphasize the significant variation in the typical mass of the first stars depending on the epoch of formation.         _ Less","","arXiv","https://arxiv.org/abs/2405.10073","1","1","multiple"
"The metallicity and carbon-to-oxygen ratio of the ultra-hot Jupiter WASP-76b from Gemini-S/IGRINS","Abstract:                Measurements of the carbon-to-oxygen (C/O) ratios of exoplanet atmospheres can reveal details about their formation and evolution. Recently, high-resolution cross-correlation analysis has emerged as a method of precisely constraining the C/O ratios of hot Jupiter atmospheres. We present two transits of the ultra-hot Jupiter WASP-76b observed between 1.4-2.4_         _ More           Measurements of the carbon-to-oxygen (C/O) ratios of exoplanet atmospheres can reveal details about their formation and evolution. Recently, high-resolution cross-correlation analysis has emerged as a method of precisely constraining the C/O ratios of hot Jupiter atmospheres. We present two transits of the ultra-hot Jupiter WASP-76b observed between 1.4-2.4 $_$m with Gemini-S/IGRINS. We detected the presence of H$_{2}$O, CO, and OH at signal-to-noise ratios of 6.93, 6.47, and 3.90, respectively. We performed two retrievals on this data set. A free retrieval for abundances of these three species retrieved a volatile metallicity of $\\left[\\frac{\\mathrm{C}+\\mathrm{O}} {\\mathrm{H}}\\right]=-0.70^{+1.27}_{-0.93}$, consistent with the stellar value, and a super-solar carbon-to-oxygen ratio of C/O$=0.80^{+0.07}_{-0.11}$. We also ran a chemically self-consistent grid retrieval, which agreed with the free retrieval within $1_$ but favored a slightly more sub-stellar metallicity and solar C/O ratio ($\\left[\\frac{\\mathrm{C}+\\mathrm{O}} {\\mathrm{H}}\\right]=-0.74^{+0.23}_{-0.17}$ and C/O$=0.59^{+0.13}_{-0.14}$). A variety of formation pathways may explain the composition of WASP-76b. Additionally, we found systemic ($V_{sys}$) and Keplerian ($K_{p}$) velocity offsets which were broadly consistent with expectations from 3D general circulation models of WASP-76b, with the exception of a redshifted $V_{sys}$ for H$_{2}$O. Future observations to measure the phase-dependent velocity offsets and limb differences at high resolution on WASP-76b will be necessary to understand the H$_{2}$O velocity shift. Finally, we find that the population of exoplanets with precisely constrained C/O ratios generally trends toward super-solar C/O ratios. More results from high-resolution observations or JWST will serve to further elucidate any population-level trends.         _ Less","","arXiv","https://arxiv.org/abs/2405.09769","1","1","multiple"
"BSQ Conserved Charges in Relativistic Viscous Hydrodynamics solved with Smoothed Particle Hydrodynamics","Abstract:                _anti-quark pairs to generate the initial BSQ charge distributions. We study correlations between the BSQ charges and find that local BSQ fluctuations remain finite during the evolution, with corresponding chemical potentials of ($\\sim100$--$200 \\,\\rm MeV$) at freeze-out. We find that our framework produces reasonable m_         _ More           Conservation laws play a crucial role in the modeling of heavy-ion collisions, including the those for charges such as baryon number (B), strangeness (S), and electric charge (Q). In this study, we present a new 2+1 relativistic viscous hydrodynamic code called CCAKE which uses the Smoothed Particle Hydrodynamics (SPH) formalism to locally conserve BSQ charges, together with an extended description of the multi-dimensional equation of state (EoS) obtained from lattice Quantum Chromodynamics. Initial conditions for CCAKE are supplied by the ICCING model, which samples gluon splittings into quark anti-quark pairs to generate the initial BSQ charge distributions. We study correlations between the BSQ charges and find that local BSQ fluctuations remain finite during the evolution, with corresponding chemical potentials of ($\\sim100$--$200 \\,\\rm MeV$) at freeze-out. We find that our framework produces reasonable multiplicities of identified particles and that ICCING has no significant effect on the collective flow of all charged particles nor of identified particles when only one particle of interest is considered. However, we show specifically for Pb+Pb collisions at the LHC $\\sqrt{s_{NN}}=5.02$ TeV that ICCING does have an effect on collective flow of identified particles if two particles of interest are considered.         _ Less","","arXiv","https://arxiv.org/abs/2405.09648","0","1","synthetic_biology"
"Volatile atmospheres of lava worlds","Abstract:                A magma ocean (MO) is thought to be a ubiquitous stage in the early evolution of rocky planets and exoplanets. During the lifetime of the MO, exchanges between the interior and exterior envelopes of the planet are very efficient. In particular, volatile elements that initially are contained in the solid part of the planet can be released and form a secondary_         _ More           A magma ocean (MO) is thought to be a ubiquitous stage in the early evolution of rocky planets and exoplanets. During the lifetime of the MO, exchanges between the interior and exterior envelopes of the planet are very efficient. In particular, volatile elements that initially are contained in the solid part of the planet can be released and form a secondary outgassed atmosphere. We determine trends in the H-C-N-O-S composition and thickness of these secondary atmospheres for varying planetary sizes and MO extents, and the oxygen fugacity of MOs, which provides the main control for the atmospheric chemistry. We used a model with coupled chemical gas-gas and silicate melt-gas equilibria and mass conservation to predict the composition of an atmosphere at equilibrium with the MO depending on the planet size and the extent and redox state of the MO. We used a self-consistent mass-radius model for the rocky core to inform the structure of the planet, which we combined with an atmosphere model to predict the transit radius of lava worlds. We find that MOs (especially the shallow ones) on small planets are generally more reduced, and are thus dominated by H2-rich atmospheres (whose outgassing is strengthened at low planetary mass), while larger planets and deeper MOs vary from CO to CO2-N2-SO2 atmospheres, with increasing fO2 . In the former case, the low molecular mass of the atmosphere combined with the low gravity of the planets yields a large vertical extension of the atmosphere, while in the latter cases, secondary outgassed atmospheres on super-Earths are likely significantly shrunk. Both N and C are largely outgassed regardless of the conditions, while the S and H outgassing is strongly dependent on the fO2 , as well as on the planetary mass and MO extent for the latter.         _ Less","","arXiv","https://arxiv.org/abs/2405.09284","0","1","synthetic_biology"
"The ratio of [Eu/$_$] differentiates accreted/in-situ Milky Way stars across metallicities, as indicated by both field stars and globular clusters","Abstract:                _-process elements, GCs trace the star formation history of their hosts, motivating their use as sub-Gyr timers of galactic evolution. Furthermore, fitting the trends in [Eu/Si] using a simple galactic_         _ More           We combine stellar orbits with the abundances of the heavy, $r$-process element europium and the light, $_$-element, silicon to separate in-situ and accreted populations in the Milky Way across all metallicities. At high orbital energy, the accretion-dominated halo shows elevated values of [Eu/Si], while at lower energies, where many of the stars were born in-situ, the levels of [Eu/Si] are lower. These systematically different levels of [Eu/Si] in the MW and the accreted halo imply that the scatter in [Eu/$_$] within a single galaxy is smaller than previously thought. At the lowest metallicities, we find that both accreted and in-situ populations trend down in [Eu/Si], consistent with enrichment via neutron star mergers. Through compiling a large dataset of abundances for 46 globular clusters (GCs), we show that differences in [Eu/Si] extend to populations of in-situ/accreted GCs. We interpret this consistency as evidence that in $r$-process elements, GCs trace the star formation history of their hosts, motivating their use as sub-Gyr timers of galactic evolution. Furthermore, fitting the trends in [Eu/Si] using a simple galactic chemical evolution model, we find that differences in [Eu/Si] between accreted and in-situ MW field stars cannot be explained through star formation efficiency alone. Finally, we show that the use of [Eu/Si] as a chemical tag between GCs and their host galaxies extends beyond the Local Group, to the halo of M31 - potentially offering the opportunity to do Galactic Archaeology in an external galaxy.         _ Less","","arXiv","https://arxiv.org/abs/2405.08963","2","1","origin_of_life"
"Hydrodynamical simulations of proton ingestion flashes in Type I X-ray Bursts","Abstract:                _that accrete from a hydrogen-rich companion. Using the low Mach number fluid code MAESTROeX, we investigate the growth of the convection zone due to nuclear burning, and the evolution of the_         _ More           We perform the first multidimensional fluid simulations of thermonuclear helium ignition underneath a hydrogen-rich shell. This situation is relevant to Type I X-ray bursts on neutron stars that accrete from a hydrogen-rich companion. Using the low Mach number fluid code MAESTROeX, we investigate the growth of the convection zone due to nuclear burning, and the evolution of the chemical abundances in the atmosphere of the star. We also examine the convective boundary mixing processes that cause the evolution to differ significantly from previous one-dimensional simulations that rely on mixing-length theory. We find that the convection zone grows outwards as penetrating fluid elements cool the overlying radiative layer, rather than directly from the increasing entropy of the convection zone itself. Simultaneously, these flows efficiently mix composition, carrying carbon out of, and protons into the convection zone even before contact with the hydrogen shell. We discuss the implications of these effects for future modeling of these events and observations.         _ Less","","arXiv","https://arxiv.org/abs/2405.08952","0","2","synthetic_biology"
"Chemically peculiar stars on the pre-main sequence","Abstract:                Context. The chemically peculiar (CP) stars of the upper main sequence are defined by spectral peculiarities that indicate unusual elemental abundance patterns in the presence of diffusion in the calm, stellar atmospheres. Some of them have a stable local magnetic field of up to several kiloGauss. The pre-main-sequence_         _ More           Context. The chemically peculiar (CP) stars of the upper main sequence are defined by spectral peculiarities that indicate unusual elemental abundance patterns in the presence of diffusion in the calm, stellar atmospheres. Some of them have a stable local magnetic field of up to several kiloGauss. The pre-main-sequence evolution of these objects is still a mystery and contains many open questions. Aims. We identify CP stars on the pre-main sequence to determine possible mechanisms that lead to the occurrence of chemical peculiarities in the (very) early stages of stellar evolution. Methods. We identified likely pre-main-sequence stars by fitting the spectral energy distributions. The subsequent analysis using stellar spectra and photometric time series helped us to distinguish between CP and non-CP stars. Additionally, we compared our results to the literature to provide the best possible quality assessment. Results. Out of 45 candidates, about 70 % seem to be true CP stars or CP candidates. Furthermore, 9 sources appear to be CP stars on the pre-main sequence, and all are magnetic. We finally report a possible CP2 star that is also a pre-main-sequence star and was not previously in the literature. Conclusions. The evolution of the peculiarities seems to be related to the (strong) magnetic fields in these CP2 stars.         _ Less","","arXiv","https://arxiv.org/abs/2405.08946","0","1","synthetic_biology"
"Rotation and Abundances of the Benchmark Brown Dwarf HD 33632 Ab from Keck/KPIC High-resolution Spectroscopy","Abstract:                _exoplanets, similar to previous findings. A larger sample of close-in gas giant exoplanets and brown dwarfs will critically examine our understanding of their formation and evolution through rotation and chemical abundance measurements.         _ More           We present the projected rotational velocity and molecular abundances for HD 33632 Ab obtained via Keck Planet Imager and Characterizer high-resolution spectroscopy. HD 33632 Ab is a nearby benchmark brown dwarf companion at a separation of $\\sim$20 au that straddles the L/T transition. Using a forward-modeling framework with on-axis host star spectra, self-consistent substellar atmospheric and retrieval models for HD 33632 Ab, we derive a projected rotational velocity of 53 $\\pm$ 3 km/s and carbon/water mass fractions of log CO = $-$2.3 $\\pm$ 0.3 and log H$_2$O = $-$2.7 $\\pm$ 0.2. The inferred carbon-to-oxygen ratio (C/O = 0.58 $\\pm$ 0.14), molecular abundances, and metallicity ([C/H] = 0.0 $\\pm$ 0.2 dex) of HD 33632 Ab are consistent with its host star. Although detectable methane opacities are expected in L/T transition objects, we did not recover methane in our KPIC spectra, partly due to the high $v\\sin{i}$ and to disequilibrium chemistry at the pressures we are sensitive to. We parameterize the spin as the ratio of rotation over break-up velocity, and compare HD 33632 Ab to a compilation of >200 very low-mass objects (M$\\lesssim$0.1 M$_{\\odot}$) that have spin measurements in the literature. There appears to be no clear trend for the isolated field low-mass objects versus mass, but a tentative trend is identified for low-mass companions and directly imaged exoplanets, similar to previous findings. A larger sample of close-in gas giant exoplanets and brown dwarfs will critically examine our understanding of their formation and evolution through rotation and chemical abundance measurements.         _ Less","","arXiv","https://arxiv.org/abs/2405.08312","1","1","multiple"
"The $_$-process nucleosynthesis in core-collapse supernovae II. Effect of the explosive recipe","Abstract:                _production of p-nuclei in C-O shell mergers is a robust result, independently from the subsequent explosive nucleosynthesis. A realistic range of variations in the evolution of stellar progenitors and in the CCSN explosions might boost the CCSN contribution to the galactic_         _ More           The $_$-process in core-collapse supernovae (CCSNe) can produce a number of neutron-deficient stable isotopes heavier than iron (p-nuclei). However, current model predictions do to not fully reproduce the solar abundances. We investigate the impact of different explosion energies and parameters on the nucleosynthesis of p-nuclei, by studying stellar models with different initial masses and CCSN explosions. We find that the total p-nuclei yields are only marginally affected by the CCSN explosion prescriptions if the $_$-process production is already efficient in the stellar progenitors due to a C-O shell merger. In most of CCSN explosions from progenitors without C-O shell merger, the $_$-process yields increase with the explosion energy up to an order of magnitude, depending on the progenitor structure and the CCSN prescriptions. The trend of the p-nuclei production with the explosion energy is more complicated if we look at the production of single p-nuclei. The light p-nuclei tend to be the most enhanced with increasing the explosion energy. In particular, for the CCSN models where the $_$-rich freeze-out component is ejected, the yields of the lightest p-nuclei increase by up to three orders of magnitude. We provide the first extensive study using different sets of massive stars of the impact of varying CCSN explosion prescriptions on the production of the p-nuclei. Unlike previous expectations and recent results in the literature, we find that the average production of p-nuclei tends to increase with the explosion energy. We also confirm that the pre-explosive production of p-nuclei in C-O shell mergers is a robust result, independently from the subsequent explosive nucleosynthesis. A realistic range of variations in the evolution of stellar progenitors and in the CCSN explosions might boost the CCSN contribution to the galactic chemical evolution of p-nuclei.         _ Less","","arXiv","https://arxiv.org/abs/2405.07783","1","1","multiple"
"High-frequency Optimally Windowed Chirp rheometry for rapidly evolving viscoelastic materials: application to a crosslinking thermoset","Abstract:                Abstract   Knowledge of the evolution of mechanical properties of the curing matrix is of great importance in composite parts or structure fabrication. Conventional rheometry, based on small amplitude oscillatory shear is limited by long interrogation times. In rapidly evolving materials, time sweeps can provide a meaningful measurement albeit at a single fr_         _ More           Abstract   Knowledge of the evolution of mechanical properties of the curing matrix is of great importance in composite parts or structure fabrication. Conventional rheometry, based on small amplitude oscillatory shear is limited by long interrogation times. In rapidly evolving materials, time sweeps can provide a meaningful measurement albeit at a single frequency. To overcome this constraint we utilize a combined frequency and amplitude-modulated chirped strain waveform in conjunction with a home-made sliding plate piezo-operated (PZR) and a dual-head commercial rotational rheometer (Anton Paar MCR 702) to probe the linear viscoelasticity of these time-evolving materials. The direct controllability of the PZR resulting from the absence of any kind of firmware and the microsecond actuator-sensor response renders this device ideal for exploring the advantages of this technique. The high frequency capability allows us to extend the upper limits of the accessible linear viscoelastic spectrum and most importantly, to shorten the length of the interrogating strain signal (OWCh-PZR) to sub-second scales, while retaining a high time-bandwidth product. This short duration ensures that the mutation number (NMu) is kept sufficiently low, even in fast curing resins. The method is validated via calibration tests in both instruments and the corresponding limitations are discussed. As a proof of concept the technique is applied to a curing vinylester resin. The linear viscoelastic (LVE) spectrum is assessed every 20 seconds to monitor the rapid evolution of the time- and frequency-dependence of the complex modulus. Finally, FTIR spectroscopy is utilized to gain insights on the evolution of the chemical network while the gap-dependence of the evolving material properties in these heterogeneous systems is also investigated.         _ Less","","arXiv","https://arxiv.org/abs/2405.07721","0","1","synthetic_biology"
"Super-concentrated alkali hydroxide electrolytes for rechargeable Zn batteries","Abstract:                _batteries, they are plagued by parasitic reactions at the Zn anodes. We apply super-concentrated alkaline electrolytes to suppress two key parasitic reactions, hydrogen evolution and ZnO passivation. An electrolyte with 15 M KOH displays a broad electrochemical window (>2.5 V on Au), a high ZnO solubility (>1.5 M), and an exceptionally high ionic condu_         _ More           Rechargeable Zn batteries offer safe, inexpensive energy storage, but when deeply discharged to compete with lithium-ion batteries, they are plagued by parasitic reactions at the Zn anodes. We apply super-concentrated alkaline electrolytes to suppress two key parasitic reactions, hydrogen evolution and ZnO passivation. An electrolyte with 15 M KOH displays a broad electrochemical window (>2.5 V on Au), a high ZnO solubility (>1.5 M), and an exceptionally high ionic conductivity (>0.27 S/cm at 25 C). Spectroscopies and ab-initio molecular dynamics simulation suggest K+-OH- pairs and a tightened water network to underpin the stability. The simulation further reveals unique triggered proton hopping that offsets the lack of water wires to sustain the conductivity. Low hydrogen evolution, confirmed via online mass spectroscopy, and slow passivation enable a NiOOH||Zn battery to deliver a cumulative capacity of 8.4 Ah cm-2 and a Zn-air battery to last for over 110 hours.         _ Less","","arXiv","https://arxiv.org/abs/2405.07675","0","1","synthetic_biology"
"Local topology and perestroikas in protein structure and folding dynamics","Abstract:                _to a progressive disintegration of the modular structures. The folding and unfolding processes are quantitatively characterized by a correlation function that describes the evolution of perestroikas under temperature changes. The approach provides a comprehensive framework for understanding the Physics of protein folding and unfolding transitions, contributi_         _ More           Methods of local topology are introduced to the field of protein physics. This is achieved by explaining how the folding and unfolding processes of a globular protein alter the local topology of the protein's C-alpha backbone through conformational bifurcations. The mathematical formulation builds on the concept of Arnol'd's perestroikas, by extending it to piecewise linear chains using the discrete Frenet frame formalism. In the low-temperature folded phase, the backbone geometry generalizes the concept of a Peano curve, with its modular building blocks modeled by soliton solutions of a discretized nonlinear Schroedinger equation. The onset of thermal unfolding begins when perestroikas change the flattening and branch points that determine the centers of solitons. When temperature increases, the perestroikas cascade, which leads to a progressive disintegration of the modular structures. The folding and unfolding processes are quantitatively characterized by a correlation function that describes the evolution of perestroikas under temperature changes. The approach provides a comprehensive framework for understanding the Physics of protein folding and unfolding transitions, contributing to the broader field of protein structure and dynamics.         _ Less","","arXiv","https://arxiv.org/abs/2405.06348","2","3","synthetic_biology"
"Abundances in eight bulge stars from the optical and near-infrared","Abstract:                _-elements are key for understanding the early chemical enrichment of the Galactic bulge. The elements of interest present lines in different wavelength regions, and some of them show lines only in part of the spectra. In the present work, the CNO trio, the alpha-elements Mg, Si, Ca, and Ti, and odd-Z Na and Al are examined as measured from optical and H-band_         _ More           Context: The abundances of the $_$-elements are key for understanding the early chemical enrichment of the Galactic bulge. The elements of interest present lines in different wavelength regions, and some of them show lines only in part of the spectra. In the present work, the CNO trio, the alpha-elements Mg, Si, Ca, and Ti, and odd-Z Na and Al are examined as measured from optical and H-band lines.   Aims: The aim of this work is to carry out a detailed comparison of stellar parameters and abundances derived in the optical and near-infrared (H-band). We also inspect the best available lines for a list of bulge stars previously analyzed by the Apache Point Observatory Galactic Evolution Experiment (APOGEE) team in the H-band and by our group in the optical. This work is mainly of interest to spectroscopists.   Methods: In the present work, we compared the stellar parameters and abundance results derived from APOGEE H-band spectra with optical analyses based on Ultraviolet and Visual Echelle Spectrograph at the Very Large Telescope (VLT/UVES) data for eight bulge stars.   Results:We point out the most suitable wavelength region for each of the studied elements, and highlight difficulties in the derivation of stellar parameters both in the optical and H-band. The near-infrared will allow observations of a large number of stars in the near future given new instruments soon to be available. The identification of spectral lines in this spectral region and the investigation of their reliability are ongoing efforts worldwide. New instruments will also allow simultaneous observation of H-band and optical.         _ Less","","arXiv","https://arxiv.org/abs/2405.06153","0","1","synthetic_biology"
"Binary black hole mergers from Population III star clusters","Abstract:                Binary black holes (BBHs) born from the evolution of Population III (Pop. III) stars are one of the main high-redshift targets for next-generation ground-based gravitational-wave (GW) detectors. Their predicted initial mass function and lack of metals make them the ideal progenitors of black holes above the upper edge of the pair-instability mass gap, i.e. w_         _ More           Binary black holes (BBHs) born from the evolution of Population III (Pop. III) stars are one of the main high-redshift targets for next-generation ground-based gravitational-wave (GW) detectors. Their predicted initial mass function and lack of metals make them the ideal progenitors of black holes above the upper edge of the pair-instability mass gap, i.e. with a mass higher than $\\approx{}134$ (241) M$_\\odot$ for stars that become (do not become) chemically homogeneous during their evolution. Here, we investigate the effects of cluster dynamics on the mass function of BBHs born from Pop. III stars, by considering the main uncertainties on Pop. III star mass function, orbital properties of binary systems, star cluster's mass and disruption time. In our dynamical models, at least $\\sim$5% and up to 100% BBH mergers in Pop. III star clusters have primary mass $m_1$ above the upper edge of the pair-instability mass gap. In contrast, only $\\lesssim {} 3$% isolated BBH mergers have primary mass above the gap, unless their progenitors evolved as chemically homogeneous stars. The lack of systems with primary and/or secondary mass inside the gap defines a zone of avoidance with sharp boundaries in the primary mass - mass ratio plane. Finally, we estimate the merger rate density of BBHs and, in the most optimistic case, we find a maximum of $\\mathcal{R}\\approx200\\,{\\rm Gpc^{-3}\\,yr^{-1}}$ at $z\\sim15$ for BBHs formed via dynamical capture. For comparison, the merger rate density of isolated Pop. III BBHs is $\\mathcal{R}\\leq{}10\\,{\\rm Gpc^{-3}\\,yr^{-1}}$, for the same model of Pop. III star formation history.         _ Less","","arXiv","https://arxiv.org/abs/2405.06037","1","1","multiple"
"Massive interacting binaries as an enrichment source for multiple populations in star clusters","Abstract:                We present a suite of binary evolution models with massive primaries (10 $\\leq$ M$_1$ $\\leq$ 40 M$_\\odot$) and periods and mass ratios chosen such that the systems undergo non-conservative mass transfer while the primaries have helium cores. We track the total mass and chemical composition of the ejecta from these syst_         _ More           We present a suite of binary evolution models with massive primaries (10 $\\leq$ M$_1$ $\\leq$ 40 M$_\\odot$) and periods and mass ratios chosen such that the systems undergo non-conservative mass transfer while the primaries have helium cores. We track the total mass and chemical composition of the ejecta from these systems. This material shows the abundance signatures of hot hydrogen burning which are needed to explain the abundance patterns seen in multiple populations in massive star clusters. We then calculate the total yield of a population of binary stars with masses, mass ratios, and periods consistent with their distribution in a field population. We show that the overall abundance of this material is enriched in helium, nitrogen, sodium, and aluminum, and depleted in carbon, oxygen, and magnesium, by amounts that are consistent with observations. We also show that such a population of binaries will return approximately 25% of its mass in this ejecta (compared to 4% if all the stars were single), over a characteristic timescale of about 12 Myr. We argue that massive binaries must be seriously considered as a contributor to the source of enriched material needed to explain the multiple populations in massive clusters, since essentially all massive stars are formed in binaries or higher order multiples, massive binaries are primarily formed in clusters, and massive binaries naturally produce material of the right composition.         _ Less","","arXiv","https://arxiv.org/abs/2405.05687","0","1","synthetic_biology"
"Chemo-dynamical Evolution of Simulated Satellites for a Milky Way-like Galaxy","Abstract:                The chemical abundances of Milky Way's satellites reflect their star formation histories (SFHs), yet, due to the difficulty of determining the ages of old stars, the SFHs of most satellites are poorly measured. Ongoing and upcoming surveys will obtain around ten times more medium-resolution spectra for stars in satellites than are currently available. To_         _ More           The chemical abundances of Milky Way's satellites reflect their star formation histories (SFHs), yet, due to the difficulty of determining the ages of old stars, the SFHs of most satellites are poorly measured. Ongoing and upcoming surveys will obtain around ten times more medium-resolution spectra for stars in satellites than are currently available. To correctly extract SFHs from large samples of chemical abundances, the relationship between chemical abundances and SFHs needs to be clarified. Here, we perform a high-resolution cosmological zoom-in simulation of a Milky Way-like galaxy with detailed models of star formation, supernova feedback, and metal diffusion. We quantify SFHs, metallicity distribution functions, and the $_$-element (Mg, Ca, and Si) abundances in satellites of the host galaxy. We find that star formation in most simulated satellites is quenched before infalling to their host. Star formation episodes in simulated satellites are separated by a few hundred Myr owing to supernova feedback; each star formation event produces groups of stars with similar [$_$/Fe] and [Fe/H]. We then perform a mock observation of the upcoming Subaru Prime Focus Spectrograph (PFS) observations. We find that Subaru PFS will be able to detect distinct groups of stars in [$_$/Fe] vs. [Fe/H] space, produced by episodic star formation. This result means that episodic SFHs can be estimated from the chemical abundances of $\\gtrsim$ 1,000 stars determined with medium-resolution spectroscopy.         _ Less","","arXiv","https://arxiv.org/abs/2405.05330","2","2","multiple"
"First detection of CO isotopologues in a high-redshift main-sequence galaxy: evidence of a top-heavy stellar initial mass function","Abstract:                _, is significantly lower than that of local main-sequence galaxies. We estimate the isotope ratio, oxygen abundance and stellar mass using a series of chemical evolution models with varying star-formation histories and IMFs. All models favour an IMF that is more top-heavy than that of the Milky Way. Thus, as with starb_         _ More           Recent observations and theories have presented a strong challenge to the universality of the stellar initial mass function (IMF) in extreme environments. A notable example has been found for starburst conditions, where evidence favours a top-heavy IMF, i.e. there is a bias toward massive stars compared to the IMF that is responsible for the stellar mass function and elemental abundances observed in the Milky Way. Local starburst galaxies have star-formation rates similar to those in high-redshift main-sequence galaxies, which appear to dominate the stellar mass budget at early epochs. However, the IMF of high-redshift main-sequence galaxies is yet to be probed. Since $^{13}$CO and C$^{18}$O isotopologues are sensitive to the IMF, we have observed these lines towards four strongly-lensed high-redshift main-sequence galaxies using the Atacama Large Millimeter/sub-millimeter Array. Of our four targets, SDSS J0901+1814, at $z \\approx 2.26$, is seen clearly in $^{13}$CO and C$^{18}$O, the first detection of CO isotopologues in the high-redshift main-sequence galaxy population. The observed $^{13}$C/$^{18}$O ratio, $2.4 \\pm 0.8$, is significantly lower than that of local main-sequence galaxies. We estimate the isotope ratio, oxygen abundance and stellar mass using a series of chemical evolution models with varying star-formation histories and IMFs. All models favour an IMF that is more top-heavy than that of the Milky Way. Thus, as with starburst galaxies, main-sequence galaxies in the high-redshift Universe have a greater fraction of massive stars than a Milky-Way IMF would imply.         _ Less","","arXiv","https://arxiv.org/abs/2405.05317","2","1","origin_of_life"
"The effect of the environment-dependent stellar initial mass function on the photometric properties of star-forming galaxies","Abstract:                _proposed by the integrated-galactic IMF (IGIMF) theory and supported by empirical evidence. We incorporate PARSEC and COLIBRI stellar isochrones into the GalIMF code, a galaxy chemical evolution (GCE) model featuring real-time updates of environment-dependent gwIMFs. This newly developed photometric GalIMF (photGalIMF)_         _ More           (Abridged) Observational estimates of galaxy properties rely on the inherent galaxy-wide initial mass function (gwIMF), which systematically varies with the global SFR and metallicity, as proposed by the integrated-galactic IMF (IGIMF) theory and supported by empirical evidence. We incorporate PARSEC and COLIBRI stellar isochrones into the GalIMF code, a galaxy chemical evolution (GCE) model featuring real-time updates of environment-dependent gwIMFs. This newly developed photometric GalIMF (photGalIMF) code allows the calculation of photometric properties for galaxies with diverse stellar populations. Subsequently, we analyze observed luminosities and metallicities of local star-forming galaxies to deduce their stellar masses assuming that they have constant SFRs over 13.6 Gyr. We also compute SFR$-$H$_$ luminosity relations for varying stellar metallicities using a separate stellar population synthesis code based on PEGASE. Comparing the IGIMF theory to the canonical universal IMF, our analysis reveals that estimates of the stellar masses and SFRs for local star-forming galaxies differ by factors of $\\approx 2$ and 10, respectively. The computed gas-depletion timescale increases with gas mass, implying lower star formation efficiencies in more massive galaxies, possibly due to stronger feedback regulation, aligning with theoretical expectations. Additionally, the characteristic stellar mass buildup timescale increases with stellar mass, indicating that massive disk galaxies initiate star formation earlier than their low-mass counterparts. The photGalIMF code enables self-consistent computations of galactic photometry, self-consistently with GCE modelling within the context of an environment-dependent gwIMF. Utilizing Ks-band and H$_$ luminosities of galaxies, the outcomes include galaxy mass, SFR, and fitting functions for the SFR correction factor.         _ Less","","arXiv","https://arxiv.org/abs/2405.05313","2","1","origin_of_life"
"The GALAH survey: Tracing the Milky Way's formation and evolution through RR Lyrae stars","Abstract:                Stellar mergers and accretion events have been crucial in shaping the evolution of the Milky Way (MW). These events have been dynamically identified and chemically characterised using red giants and main-sequence stars. RR Lyrae (RRL) variables can play a crucial role in tracing the early formation of the MW since they_         _ More           Stellar mergers and accretion events have been crucial in shaping the evolution of the Milky Way (MW). These events have been dynamically identified and chemically characterised using red giants and main-sequence stars. RR Lyrae (RRL) variables can play a crucial role in tracing the early formation of the MW since they are ubiquitous, old (t$\\ge$10 Gyr) low-mass stars and accurate distance indicators. We exploited Data Release 3 of the GALAH survey to identify 78 field RRLs suitable for chemical analysis. Using synthetic spectra calculations, we determined atmospheric parameters and abundances of Fe, Mg, Ca, Y, and Ba. Most of our stars exhibit halo-like chemical compositions, with an iron peak around [Fe/H]$\\approx -$1.40, and enhanced Ca and Mg content. Notably, we discovered a metal-rich tail, with [Fe/H] values ranging from $-$1 to approximately solar metallicity. This sub-group includes almost ~1/4 of the sample, it is characterised by thin disc kinematics and displays sub-solar $_$-element abundances, marginally consistent with the majority of the MW stars. Surprisingly, they differ distinctly from typical MW disc stars in terms of the s-process elements Y and Ba. We took advantage of similar data available in the literature and built a total sample of 535 field RRLs for which we estimated kinematical and dynamical properties. We found that metal-rich RRLs (1/3 of the sample) likely represent an old component of the MW thin disc. We also detected RRLs with retrograde orbits and provided preliminary associations with the Gaia-Sausage-Enceladus, Helmi, Sequoia, Sagittarius, and Thamnos stellar streams.         _ Less","","arXiv","https://arxiv.org/abs/2405.04580","2","2","multiple"
"ChemPlasKin: a general-purpose program for unified gas and plasma kinetics simulations","Abstract:                This work introduces ChemPlasKin, a freely accessible solver optimized for zero-dimensional (0D) simulations of chemical kinetics of neutral gas in non-equilibrium plasma environments. By integrating the electron Boltzmann equation solver, CppBOLOS, with the open-source combustion library, Cantera, at the source code level, ChemPlasKin computes time-resolved_         _ More           This work introduces ChemPlasKin, a freely accessible solver optimized for zero-dimensional (0D) simulations of chemical kinetics of neutral gas in non-equilibrium plasma environments. By integrating the electron Boltzmann equation solver, CppBOLOS, with the open-source combustion library, Cantera, at the source code level, ChemPlasKin computes time-resolved evolution of species concentration and gas temperature in a unified gas-plasma kinetics framework. The model allows high fidelity predictions of both chemical thermal effects and plasma-induced heating, including fast gas heating and slower vibrational-translational relaxation processes. Additionally, a new heat loss model is developed for nanosecond pulsed discharges, specifically within pin-pin electrode configurations. With its versatility, ChemPlasKin is well-suited for a wide range of applications, from plasma-assisted combustion (PAC) to fuel reforming. In this paper, the reliability, accuracy and efficiency of ChemPlasKin are validated through a number of test problems, demonstrating its utility in advancing gas-plasma kinetic studies.         _ Less","","arXiv","https://arxiv.org/abs/2405.04224","0","1","synthetic_biology"
"Planetary Nebulae of the Large Magellanic Cloud I: A multiwavelength analysis","Abstract:                Planetary nebulae (PNe) have three main components: a central star (CS), ionised gas and dust in the nebula. Each of them contains critical chemical fingerprints of their_         _ More           Planetary nebulae (PNe) have three main components: a central star (CS), ionised gas and dust in the nebula. Each of them contains critical chemical fingerprints of their evolution, serving as tracers of the evolution, nucleosynthesis and dust production that occurred during the preceding asymptotic giant branch (AGB) phase. We aim to build a bridge to link the PN phase to the evolution of their progenitors, trying to better understand the dust production and mass-loss mechanism during the final AGB phase. Here, we present a comprehensive study of nine Large Magellanic Cloud (LMC) spherical or elliptical PNe whose observations from the ultraviolet (UV) through the infrared (IR) are available in the literature. We characterize nebulae and CSs, finding information as the amount of gas that makes up the nebula and the dust that surrounds the CS, necessary to reconstruct the evolutionary history of mass-loss and dust production. We compare the observed energy distribution of the selected PNe to that obtained from photoionization modeling, taking into account the presence of dust. The physical and chemical parameters of the central stars are then compared with the predictions from the evolutionary tracks. We characterized the source, assigning to each CS a progenitor, early-AGB mass. We estimated the mass of the nebula and the dust-to-gas ratio. For 5 objects, we find evidence for the presence of a near-IR bump, which would be connected to the presence of hot dust.         _ Less","","arXiv","https://arxiv.org/abs/2405.03640","2","2","multiple"
"MACE: A Machine learning Approach to Chemistry Emulation","Abstract:                _environment is closely coupled to its dynamics, the latter often found to be complex. Hence, to properly model these environments a 3D context is necessary. However, solving chemical kinetics within a 3D hydro simulation is computationally infeasible for a even a modest parameter study. In order to develop a feasible 3D hydro-_         _ More           The chemistry of an astrophysical environment is closely coupled to its dynamics, the latter often found to be complex. Hence, to properly model these environments a 3D context is necessary. However, solving chemical kinetics within a 3D hydro simulation is computationally infeasible for a even a modest parameter study. In order to develop a feasible 3D hydro-chemical simulation, the classical chemical approach needs to be replaced by a faster alternative. We present mace, a Machine learning Approach to Chemistry Emulation, as a proof-of-concept work on emulating chemistry in a dynamical environment. Using the context of AGB outflows, we have developed an architecture that combines the use of an autoencoder (to reduce the dimensionality of the chemical network) and a set of latent ordinary differential equations (that are solved to perform the temporal evolution of the reduced features). Training this architecture with an integrated scheme makes it possible to successfully reproduce a full chemical pathway in a dynamical environment. mace outperforms its classical analogue on average by a factor 26. Furthermore, its efficient implementation in PyTorch results in a sub-linear scaling with respect to the number of hydrodynamical simulation particles.         _ Less","","arXiv","https://arxiv.org/abs/2405.03274","0","1","synthetic_biology"
"A Dynamical Simulation Model of a Cement Clinker Rotary Kiln","Abstract:                _systematic description and results of a dynamical simulation model of a rotary kiln for clinker, based on first engineering principles. The model is built upon thermophysical, chemical, and transportation models for both the formation of clinker phases and fuel combustion in the kiln. The model is presented as a 1D model with counter-flow between gas and cli_         _ More           This study provides a systematic description and results of a dynamical simulation model of a rotary kiln for clinker, based on first engineering principles. The model is built upon thermophysical, chemical, and transportation models for both the formation of clinker phases and fuel combustion in the kiln. The model is presented as a 1D model with counter-flow between gas and clinker phases and is demonstrated by a simulation using industrially relevant input. An advantage of the proposed model is that it provides the evolution of the individual compounds for both the fuel and clinker. As such, the model comprises a stepping stone for evaluating the development of process control systems for existing cement plants.         _ Less","","arXiv","https://arxiv.org/abs/2405.03200","1","1","multiple"
"Four-hundred Very Metal-poor Stars Studied with LAMOST and Subaru. III. Dynamically Tagged Groups and Chemodynamical Properties","Abstract:                _galaxies, making them essential tools for unraveling the early stages of Galaxy formation. Understanding the origin of VMP stars requires comprehensive studies of their chemical compositions and kinematics, which are currently lacking. Hence, we conduct a chemodynamical analysis of 352 VMP stars selected from one of the largest uniform high-resolution VMP st_         _ More           Very metal-poor (VMP) stars record the signatures of early accreted galaxies, making them essential tools for unraveling the early stages of Galaxy formation. Understanding the origin of VMP stars requires comprehensive studies of their chemical compositions and kinematics, which are currently lacking. Hence, we conduct a chemodynamical analysis of 352 VMP stars selected from one of the largest uniform high-resolution VMP star samples, jointly obtained from LAMOST and Subaru. We apply a friends-of-friends clustering algorithm to the master catalog of this high-resolution sample, which consists of 5778 VMP stars. It results in 131 dynamically tagged groups with 89 associated with known substructures in the Milky Way, including Gaia-Sausage-Enceladus (GSE), Thamnos, Helmi streams, Sequoia, Wukong, Pontus, and the very metal-poor disk (VMPD). Our findings are: (i) the VMPD shows lower Zn abundances than the rest, which indicates that it could be a relic of small stellar systems; (ii) Sequoia shows moderately high r-process abundances; (iii) Helmi streams show deficiencies in carbon and light neutron-capture elements; (iv) the fraction of carbon-enhanced metal-poor stars with no enhancement in heavy elements (CEMP-no stars) seems low in the VMPD and the Helmi streams; and (v) a subgroup in GSE exhibits a very high fraction of r-process enhanced stars, with four out of five showing [Eu/Fe]> +1.0. The abundance patterns of other elements in VMP substructures largely match the whole VMP sample. We also study large-scale correlations between abundance ratios and kinematics without classifying stars into substructures, but it does not yield significant correlations once the overall chemical evolution is considered for most elements.         _ Less","","arXiv","https://arxiv.org/abs/2405.02978","3","2","origin_of_life"
"Morphokinematical study of the planetary nebula Me2-1: Unveiling its point-symmetric and unusual physical structure","Abstract:                _images in several emission lines, and high- and intermediate-resolution long-slit spectra of Me2-1 to investigate its morphology and 3D structure, its physical parameters and chemical abundances. We identified in Me2-1: an elliptical ring; two elongated, curved structures (caps) that contain three pairs of bright point-symmetric (PS) knots; a shell interior_         _ More           (Abridged) We present narrow-band images in several emission lines, and high- and intermediate-resolution long-slit spectra of Me2-1 to investigate its morphology and 3D structure, its physical parameters and chemical abundances. We identified in Me2-1: an elliptical ring; two elongated, curved structures (caps) that contain three pairs of bright point-symmetric (PS) knots; a shell interior of the ring; and a faint halo or attached shell. The caps are observed in all images, the PS knots only in the low-excitation emission line ones. These structures are also identified in the high-resolution long-slit spectra. The 3D reconstruction shows that Me2-1 consists of a ring seen almost pole-on, and a virtually spherical shell, to which the caps and PS knots are attached. Caps and PS knots most probably trace the sites where high-velocity collimated bipolar outflows, ejected along a wobbling axis, collide with the spherical shell, are slowed down, and remain attached to it. Although the main excitation mechanism in Me2-1 is found to be photoionization, a contribution of shocks in the PS knots is suggested by their emission line ratios. The combination of collimated outflows and a ring with a spherical shell is unusual among planetary nebulae. We speculate that two planets, each with less than one Jupiter mass, could be involved in the formation of Me2-1 if both enter a common envelope evolution during the asymptotic giant branch phase of the progenitor. One planet is tidally disrupted, forming an accretion disk around the central star, from which collimated bipolar outflows are ejected; the other planet survives, causing wobbling of the accretion disk. The derived physical parameters and chemical abundances are similar to those obtained in previous analyses, with the abundances also pointing to a low-mass progenitor of Me2-1.         _ Less","","arXiv","https://arxiv.org/abs/2405.02938","1","1","multiple"
"Predicting the impact of water transport on carbonation-induced corrosion in variably saturated reinforced concrete","Abstract:                _of cracked and uncracked concrete, revealing a very good agreement with independent experiments from a set of consistent parameters. In addition, insight is gained into the evolution of carbonation penetration and corrosion current density under periodic wetting and drying conditions. Among others, we find that cyclic wetting periods significantly speed up t_         _ More           A modelling framework for predicting carbonation-induced corrosion in reinforced concrete is presented. The framework constituents include a new model for water transport in cracked concrete, a link between corrosion current density and water saturation, and a theory for characterising concrete carbonation. The theoretical framework is numerically implemented using the finite element method and model predictions are extensively benchmarked against experimental data. The results show that the model is capable of accurately predicting carbonation progress, as well as wetting and drying of cracked and uncracked concrete, revealing a very good agreement with independent experiments from a set of consistent parameters. In addition, insight is gained into the evolution of carbonation penetration and corrosion current density under periodic wetting and drying conditions. Among others, we find that cyclic wetting periods significantly speed up the carbonation progress and that the induced corrosion current density is very sensitive to concrete saturation.         _ Less","","arXiv","https://arxiv.org/abs/2405.02611","0","1","synthetic_biology"
"Observations of Titan's Stratosphere During Northern Summer: Temperatures, CH3CN and CH3D Abundances","Abstract:                _stratospheric measurements remain sparse during Titan's northern summer and fall. The lack of seasonal symmetry in observations of Titan's temperature field and chemical abundances raises questions about the nature of the middle atmosphere's meridional circulation and evolution over Titan's 29-yr seaso_         _ More           Titan's atmospheric composition and dynamical state have previously been studied over numerous epochs by both ground- and space-based facilities. However, stratospheric measurements remain sparse during Titan's northern summer and fall. The lack of seasonal symmetry in observations of Titan's temperature field and chemical abundances raises questions about the nature of the middle atmosphere's meridional circulation and evolution over Titan's 29-yr seasonal cycle that can only be answered through long-term monitoring campaigns. Here, we present maps of Titan's stratospheric temperature, acetonitrile (or methyl cyanide; CH$_3$CN), and monodeuterated methane (CH$_3$D) abundances following Titan's northern summer solstice obtained with Band 9 ($\\sim0.43$ mm) ALMA observations. We find that increasing temperatures towards high-southern latitudes, currently in winter, resemble those observed during Titan's northern winter by the Cassini mission. Acetonitrile abundances have changed significantly since previous (sub)millimeter observations, and we find that the species is now highly concentrated at high-southern latitudes. The stratospheric CH$_3$D content is found to range between 4-8 ppm in these observations, and we infer the CH$_4$ abundance to vary between $\\sim0.9-1.6\\%$ through conversion with previously measured D/H values. A global value of CH$_4=1.15\\%$ was retrieved, lending further evidence to the temporal and spatial variability of Titan's stratospheric methane when compared with previous measurements. Additional observations are required to determine the cause and magnitude of stratospheric enhancements in methane during these poorly understood seasons on Titan.         _ Less","","arXiv","https://arxiv.org/abs/2405.02535","0","1","synthetic_biology"
"The Role of Acetylene in the Chemical Evolution of Carbon Complexity","Abstract:                _by its unique balance of stability and reactivity, acetylene is the simplest unsaturated organic molecule known to have a triple bond. In addition to its inherent chemical properties, acetylene is one of the most prevalent organic molecules found across the Universe, spanning from the icy surfaces of planets and satellites and the cold interstellar medium wi_         _ More           Acetylene, among the multitude of organic molecules discovered in space, plays a distinct role in the genesis of organic matter. Characterized by its unique balance of stability and reactivity, acetylene is the simplest unsaturated organic molecule known to have a triple bond. In addition to its inherent chemical properties, acetylene is one of the most prevalent organic molecules found across the Universe, spanning from the icy surfaces of planets and satellites and the cold interstellar medium with low temperatures to hot circumstellar envelopes where temperatures surge to several thousand kelvins. These factors collectively position acetylene as a crucial building block in the molecular diversification of organic molecules and solids present in space. This review comprehensively discusses the formation and expansion of carbon skeletons involving acetylene, ranging from the formation of simple molecules to the origination of the first aromatic ring and ultimately to the formation of nanosized carbon particles. Mechanisms pertinent to both hot environments, such as circumstellar envelopes, and cold environments, including molecular clouds and planetary atmospheres, are explored. In addition, this review contemplates the role of acetylene in the synthesis of prebiotic molecules. A distinct focus is accorded to the recent advancements and future prospects of research into catalytic processes involving acetylene molecules, which is a significant instrument in driving the evolution of carbon complexity in the Universe. The insights garnered from this review underline the significance of acetylene in astrochemistry and potentially contribute to our understanding of the chemical evolution of the Universe.         _ Less","","arXiv","https://arxiv.org/abs/2405.01866","5","3","origin_of_life"
"JWST Imaging of the Closest Globular Clusters -- II. Discovery of Brown Dwarfs in NGC 6397 and Measurement of Age from the Brown Dwarf Cooling Sequence, using SANDee - a New Grid of Model Isochrones across the Hydrogen-Burning Limit","Abstract:                _clusters contain vast repositories of metal-poor stars that represent some of the oldest stellar generations in the Universe. The archaeological footprint of early Galactic evolution may be retained in the measurable properties of globular clusters, such as their ages, mass functions and_         _ More           Globular clusters contain vast repositories of metal-poor stars that represent some of the oldest stellar generations in the Universe. The archaeological footprint of early Galactic evolution may be retained in the measurable properties of globular clusters, such as their ages, mass functions and chemical abundances. Until recently, all photometric studies of globular clusters were restricted to stellar members. Now, the sensitivity of JWST can extend this analysis to the substellar regime. If detected in sufficient numbers, brown dwarf members can provide tight constraints on the properties of their parent population. We present SANDee - a new grid of stellar models that accurately represent the color-magnitude diagrams of globular clusters across the hydrogen-burning limit at a wide range of metallicities. Using JWST NIRCam photometry and the new models, we identify three brown dwarfs in the globular cluster NGC 6397 with effective temperatures of 1300-1800 K, confirmed by both proper motion and model fitting. We use the observed luminosities of discovered brown dwarfs to obtain the first age estimate of a globular cluster from its substellar cooling sequence: 13.4 +/- 3.3 Gyr. We also derive the local mass function of the cluster across the hydrogen-burning limit and find it to be top-heavy, suggesting extensive dynamical evolution. We expect that the constraints on both age and mass function of NGC 6397 derived in this work can be greatly improved by a second epoch of NIRCam imaging in the same field.         _ Less","","arXiv","https://arxiv.org/abs/2405.01634","0","1","synthetic_biology"
"The spectral evolution of white dwarfs: where do we stand?","Abstract:                _However, observations reveal a much more complex situation, as the surface of a white dwarf (1) can be dominated by helium rather than hydrogen, (2) can be polluted by trace chemical species, and (3) can undergo significant composition changes with time. This indicates that various mechanisms of element transport effectively compete against gravitational se_         _ More           White dwarfs are the dense, burnt-out remnants of the vast majority of stars, condemned to cool over billions of years as they steadily radiate away their residual thermal energy. To first order, their atmosphere is expected to be made purely of hydrogen due to the efficient gravitational settling of heavier elements. However, observations reveal a much more complex situation, as the surface of a white dwarf (1) can be dominated by helium rather than hydrogen, (2) can be polluted by trace chemical species, and (3) can undergo significant composition changes with time. This indicates that various mechanisms of element transport effectively compete against gravitational settling in the stellar envelope. This phenomenon is known as the spectral evolution of white dwarfs and has important implications for Galactic, stellar, and planetary astrophysics. This invited review provides a comprehensive picture of our current understanding of white dwarf spectral evolution. We first describe the latest observational constraints on the variations in atmospheric composition along the cooling sequence, covering both the dominant and trace constituents. We then summarise the predictions of state-of-the-art models of element transport in white dwarfs and assess their ability to explain the observed spectral evolution. Finally, we highlight remaining open questions and suggest avenues for future work.         _ Less","","arXiv","https://arxiv.org/abs/2405.01268","2","3","synthetic_biology"
"A Low Temperature Kinetic Study of the C(3P) + CH3OCH3 Reaction. Rate constants, H-atom Product Yields and Astrochemical Implications","Abstract:                Atomic carbon in its ground electronic state, C(3P), is expected to be present at high abundances during the evolution of dense molecular clouds. Consequently, its reactions with other interstellar species could have a strong influence on the_         _ More           Atomic carbon in its ground electronic state, C(3P), is expected to be present at high abundances during the evolution of dense molecular clouds. Consequently, its reactions with other interstellar species could have a strong influence on the chemical composition of these regions. Here, we report the results of an investigation of the reaction between C(3P) and dimethylether, CH3OCH3, which was recently detected in dark cloud TMC-1. Experiments were performed to study the kinetics of this reaction using a continuous supersonic flow reactor employing pulsed laser photolysis and pulsed laser induced fluorescence for atomic radical generation and detection respectively. Rate constants for this process were measured between 50 K and 296 K, while additional measurements of the product atomic hydrogen yields were also performed over the 75-296 K range. To better understand the experimental results, statistical rate theory was used to calculate rate constants over the same temperature range and to provide insight on the major product channels. These simulations, based on quantum chemical calculations of the ground triplet state of the C3H6O molecule, allowed us to obtain the most important features of the underlying potential energy surface. The measured rate constant increases as the temperature falls, reaching a value of k_(C+CH_3 OCH_3 )= 7.5 x 10-11 cm3 s-1 at 50 K, while the low measured H-atom yields support the theoretical prediction that the major reaction products are CH3 + CH3 + CO. The effects of this reaction on the abundances of interstellar CH3OCH3 and related species were tested using a gas-grain dense cloud model, employing an expression for the rate constant, k(T) = alpha(T/300)^beta, with alpha = 1.27 x 10-11 and beta = -1.01. These simulations predict that the C(3P) + CH3OCH3 reaction decreases gas-phase CH3OCH3 abundances by more than an order of magnitude at early times.         _ Less","","arXiv","https://arxiv.org/abs/2405.01068","0","1","synthetic_biology"
"The impact of stellar metallicity on rotation and activity evolution in the Kepler field using gyro-kinematic ages","Abstract:                In recent years, there has been a push to understand how chemical composition affects the magnetic activity levels of main sequence low-mass stars. Results indicate that more metal-rich stars are more magnetically active for a given stellar mass and rotation period. This metallicity dependence has implications for how the rotation periods and activity levels_         _ More           In recent years, there has been a push to understand how chemical composition affects the magnetic activity levels of main sequence low-mass stars. Results indicate that more metal-rich stars are more magnetically active for a given stellar mass and rotation period. This metallicity dependence has implications for how the rotation periods and activity levels of low-mass stars evolve over their lifetimes. Numerical modelling suggests that at late ages more metal-rich stars should be rotating more slowly and be more magnetically active. In this work, we study the rotation and activity evolution of low-mass stars using a sample of Kepler field stars. We use the gyro-kinematic age dating technique to estimate ages for our sample and use the photometric activity index as our proxy for magnetic activity. We find clear evidence that, at late ages, more metal-rich stars have spun down to slower rotation in agreement with the theoretical modeling. However, further investigation is required to definitively determine whether the magnetic activity evolution occurs in a metallicity dependent way.         _ Less","","arXiv","https://arxiv.org/abs/2405.00779","0","1","synthetic_biology"
"The NIRVANDELS Survey: the stellar and gas-phase mass-metallicity relations of star-forming galaxies at z = 3.5","Abstract:                _. We employ analytic chemical evolution models to place a constraint on the strength of galactic-level outflows via the mass-outflow factor ($_$). We show that outflow efficiencies that scale as $_\\propto M_{\\star}^{-0.32}$ can simultaneously explain the functional form of of the stellar and gas-phase MZR, as well as t_         _ More           We present determinations of the gas-phase and stellar metallicities of a sample of 65 star-forming galaxies at $z \\simeq 3.5$ using rest-frame far-ultraviolet (FUV) spectroscopy from the VANDELS survey in combination with follow-up rest-frame optical spectroscopy from VLT/KMOS and Keck/MOSFIRE. We infer gas-phase oxygen abundances ($Z_{\\mathrm{g}}$; tracing O/H) via strong optical nebular lines and stellar iron abundances ($Z_{\\star}$; tracing Fe/H) from full spectral fitting to the FUV continuum. Our sample spans the stellar mass range $8.5 < \\mathrm{log}(M_{\\star}/\\mathrm{M}_{\\odot}) < 10.5$ and shows clear evidence for both a stellar and gas-phase mass-metallicity relation (MZR). We find that our O and Fe abundance estimates both exhibit a similar mass-dependence, such that $\\mathrm{Fe/H}\\propto M_{\\star}^{0.30\\pm0.11}$ and $\\mathrm{O/H}\\propto M_{\\star}^{0.32\\pm0.09}$. At fixed $M_{\\star}$ we find that, relative to their solar values, O abundances are systematically larger than Fe abundances (i.e., $_$-enhancement).We estimate an average enhancement of $\\mathrm{(O/Fe)} = 2.65 \\pm 0.16 \\times \\mathrm{(O/Fe)_\\odot}$ which appears to be independent of $M_{\\star}$. We employ analytic chemical evolution models to place a constraint on the strength of galactic-level outflows via the mass-outflow factor ($_$). We show that outflow efficiencies that scale as $_\\propto M_{\\star}^{-0.32}$ can simultaneously explain the functional form of of the stellar and gas-phase MZR, as well as the degree of $_$-enhancement at fixed Fe/H. Our results add further evidence to support a picture in which $_$-enhanced abundance ratios are ubiquitous in high-redshift star-forming galaxies, as expected for young systems whose interstellar medium is primarily enriched by core-collapse supernovae.         _ Less","","arXiv","https://arxiv.org/abs/2405.00774","2","2","multiple"
"Vorticity Suppression by Particle Lag Effects in Shock-Driven Multiphase Instability","Abstract:                Shock-driven multiphase mixing occurs in many physical systems such as explosive dispersal of chemical or biological agents, in the_         _ More           Shock-driven multiphase mixing occurs in many physical systems such as explosive dispersal of chemical or biological agents, in the evolution of supernova remnants, and in supersonic and detonative combustion engines. This mixing process is driven by the Shock Driven Multiphase Instability (SDMI), a derivative of the canonical Richtmyer-Meshkov Instability (RMI). The SDMI deviates from the RMI as particle lag effects become significant, where a higher momentum deficit leads to longer equilibration times and a reduction in hydrodynamic mixing. In this work, the effect of particle lag (rate of momentum transfer) on the SDMI evolution was isolated and investigated utilizing solid nondeforming and nonevaporating particles of differing sizes while holding the effective density ratio (mass of particles in the interface) constant. Three particle sizes were selected with increasing velocity relaxation times. Experiments were conducted by accelerating a cylindrical interface comprised of air and seeded particles surrounded by clean (particle-free) air with a Mach 1.35 shock wave. The development of the multiphase interface was measured using particle imaging velocimetry (PIV). Circulation measurements showed a decrease in mixing with increasing particle size. Finally, a new model, derived from theory, is proposed to predict circulation deposition, mixing energy, in the SDMI based on shock strength, effective density ratio, and particle response times.         _ Less","","arXiv","https://arxiv.org/abs/2405.00111","0","1","synthetic_biology"
"OCCASO V. Chemical-abundance trends with Galactocentric distance and age","Abstract:                Context. Open clusters provide valuable information on stellar nucleosynthesis and the chemical_         _ More           Context. Open clusters provide valuable information on stellar nucleosynthesis and the chemical evolution of the Galactic disc, as their age and distances can be measured more precisely with photometry than for field stars. Aims. Our aim is to study the chemical distribution of the Galactic disc using open clusters by analysing the existence of gradients with Galactocentric distance, azimuth or height from the plane and dependency with age. Methods. High-resolution spectra (R>60 000) of 194 stars belonging to 36 open clusters are used to determine atmospheric parameters and chemical abundances with two independent methods: equivalent widths and spectral synthesis. The sample has been complemented with 63 clusters with high-resolution spectroscopy from literature. Results. We measure local thermodynamic equilibrium abundances for 21 elements: _ (Mg, Si, Ca, and Ti), odd-Z (Na and Al), Fe-peak (Fe, Sc, V, Cr, Mn, Co, Ni, Cu, and Zn), and neutron-capture (Sr, Y, Zr, Ba, Ce, and Nd). We also provide non-local thermodynamic equilibrium abundances for elements when corrections are available. We find inner disc young clusters enhanced in [Mg/Fe] and [Si/Fe] compared to other clusters of their age. For [Ba/Fe] we report an age trend flattening for older clusters (age<2.5 Ga). The studied elements follow the expected radial gradients as a function of their nucleosynthesis groups, which are significantly steeper for the oldest systems. For the first time, we investigate the existence of an azimuthal gradient, finding some hints of its existence among the old clusters (age>2 Ga).         _ Less","","arXiv","https://arxiv.org/abs/2405.00110","2","1","origin_of_life"
"Testing the accuracy of SED modeling techniques using the NIHAO-SKIRT-Catalog","Abstract:                _tool for inferring star-formation histories from nearby galaxy observations, but is fraught with difficulty due to our incomplete understanding of stellar populations, chemical enrichment processes, and the nonlinear, geometry-dependent effects of dust on our observations. The NIHAO-SKIRT-Catalog uses hydrodynamic simulations and radiative transfer to produc_         _ More           We use simulated galaxy observations from the NIHAO-SKIRT-Catalog to test the accuracy of Spectral Energy Distribution (SED) modeling techniques. SED modeling is an essential tool for inferring star-formation histories from nearby galaxy observations, but is fraught with difficulty due to our incomplete understanding of stellar populations, chemical enrichment processes, and the nonlinear, geometry-dependent effects of dust on our observations. The NIHAO-SKIRT-Catalog uses hydrodynamic simulations and radiative transfer to produce SEDs from the ultraviolet (UV) through the infrared (IR), accounting for the effects of dust. We use the commonly used Prospector software to perform inference on these SEDs, and compare the inferred stellar masses and star-formation rates (SFRs) to the known values in the simulation. We match the stellar population models to isolate the effects of differences in the star-formation history, the chemical evolution history, and the dust. We find that the combined effect of model mismatches for high mass ($> 10^{9.5} M_{\\odot}$) galaxies leads to inferred SFRs that are on average underestimated by a factor of 2 when fit to UV through IR photometry, and a factor of 3 when fit to UV through optical photometry. These biases lead to significant inaccuracies in the resulting sSFR-mass relations, with UV through optical fits showing particularly strong deviations from the true relation of the simulated galaxies. In the context of massive existing and upcoming photometric surveys, these results highlight that star-formation history inference from photometry remains imprecise and inaccurate, and that there is a pressing need for more realistic testing of existing techniques.         _ Less","","arXiv","https://arxiv.org/abs/2404.19742","3","2","origin_of_life"
"A Wide Metallicity Range for Gyr-old Stars in the Nuclear Star Cluster","Abstract:                _, and ages assuming single-star evolution. The oldest of these stars is 1.5 Gyr while the youngest and most metal-rich is only 100 Myr. The wide range in metallicity poses interesting questions concerning the chemical evolution and enrichment of the NSC and adds to the evidence f_         _ More           We report metallicities for three $\\sim$Gyr-old stars in the Milky Way nuclear star cluster (NSC) using high-resolution near-infrared spectroscopy. We derive effective temperatures from a calibration with Sc line strength, which yields results in good agreement with other methods, and metallicities from spectral fits to Fe I lines. Our derived metallicities range from -1.2 < [Fe/H] < +0.5, a span of 1.7 dex. In addition we use isochrone projection to obtain masses of 1.6 to 4.3 M$_\\odot$, and ages assuming single-star evolution. The oldest of these stars is 1.5 Gyr while the youngest and most metal-rich is only 100 Myr. The wide range in metallicity poses interesting questions concerning the chemical evolution and enrichment of the NSC and adds to the evidence for the presence of a young, metal-rich population in the NSC. We suggest that the candidate intermediate-age, metal-poor ([Fe/H] = -1.2) star may be best explained as a blue straggler from an underlying old population.         _ Less","","arXiv","https://arxiv.org/abs/2404.19628","1","1","multiple"
"Massive stars evolution with new C12+C12 nuclear reaction rate -- the core carbon-burning phase","Abstract:                Nuclear reactions drive the stellar evolution and contribute to the stellar and galactic_         _ More           Nuclear reactions drive the stellar evolution and contribute to the stellar and galactic chemicals abundances. New determinations of the nuclear reaction rates for key fusion reactions of stellar evolution are now available, paving the way to improved stellar model predictions. We explore the impact of new C12+C12 reaction rates for massive stars evolution, structure, and nucleosynthesis during core carbon-burning phase. We analyse the consequences for stars of different masses including rotation-induced mixing. We computed a grid of massive stars at solar metallicity using the stellar evolution code GENEC. We explored the results using three different references for the rates, with or without rotation. We study the effect in terms of evolution, structure, and critical mass limit between intermediate and massive stars. We explored the consequences for nucleosynthesis during the core C-burning phase by means of a one-zone nucleosynthesis code. We confirm the significant impact of using the recent nuclear reaction rates following the hindrance hypothesis as well as the mass-dependent effect of a resonance at 2.14 MeV. This impacts the characteristics of the core of stars from the C-ignition and during all the core C-burning phase. The change of rates modifies the central nucleosynthesis during the core C-burning phase, resulting in an underproduction of s-process elements. The correct and accurate determination of the nuclear reaction rates, with especially the existence and location of resonances, impacts stellar evolution in many aspects affecting the model predictions. The choice of the nuclear reaction rates reference for the C12+C12 fusion reaction changes significantly the behaviour of the core during the C-burning phase. This choice is then to be taken carefully in order to interpret stellar evolution and fate of massive stars.         _ Less","","arXiv","https://arxiv.org/abs/2404.18662","0","1","synthetic_biology"
"Excitation mechanisms of C II optical permitted lines in ionized nebulae","Abstract:                Context. Carbon is the fourth most abundant element in the universe and its distribution is critical to understanding stellar evolution and nucleosynthesis. In optical studies of ionized nebulae, the only way to determine the C/H abundance is by using faint CII recombination lines (RLs). However, these lines give systematically higher abundances than their c_         _ More           Context. Carbon is the fourth most abundant element in the universe and its distribution is critical to understanding stellar evolution and nucleosynthesis. In optical studies of ionized nebulae, the only way to determine the C/H abundance is by using faint CII recombination lines (RLs). However, these lines give systematically higher abundances than their collisionally excited counterparts, observable at ultraviolet (UV) wavelengths. Therefore, a proper understanding of the excitation mechanisms of the faint permitted lines is crucial for addressing this long-standing abundance discrepancy (AD) problem. Aims. In this study, we investigate the excitation mechanisms of CII lines _3918, 3920, 4267, 5342, 6151, 6462, 7231, 7236, 7237 and 9903. Methods. We use the DEep Spectra of Ionized REgions Database (DESIRED) that contains spectra of HII regions, planetary nebulae and other objects to analyze the fluorescence contributions to these lines and the accuracy of the atomic recombination data used to model the C+ ion. Results. We find that CII _4267, 5342, 6151, 6462 and 9903 arise exclusively from recombinations with no fluorescent contributions. In addition, the recombination theory for these lines is consistent with the observations. Our findings show that the AD problem for C2+ is not due to fluorescence in the widely used CII lines or errors in their atomic parameters, but to other phenomena like temperature variations or chemical inhomogeneities. On the other hand, CII _3918, 3920, 6578, 7231, 7236, 7237 have important fluorescent contributions, which are inadvisable for tracing the C2+ abundances. We also discuss the effects of possible inconsistencies in the atomic effective recombination coefficients of CII _6578, 7231, 7236 and 7237.         _ Less","","arXiv","https://arxiv.org/abs/2404.18581","0","1","synthetic_biology"
"Simultaneous measurement of extensional stress and flow birefringence field for uniaxially extending worm-like micellar solutions","Abstract:                _method with a high-speed polarization camera to measure the extensional stress and flow-induced birefringence field simultaneously. In the liquid dripping method, temporal evolution images of the liquid filament diameter for fluids dripping from a nozzle are measured to obtain the extensional stress loading on the liquid filament. These images are captured w_         _ More           The present study proposes a novel and simple rheo-optical technique to investigate the relation between the rheology of complex fluids and their internal structural deformation under uniaxial extensional flow. The macroscale results of viscoelasticity from rheological measurements and microscale results of birefringence from optical measurements are combined to evaluate the microstructural deformation and orientation state inside the fluids under extensional stress. The proposed technique combines a liquid dripping method with a high-speed polarization camera to measure the extensional stress and flow-induced birefringence field simultaneously. In the liquid dripping method, temporal evolution images of the liquid filament diameter for fluids dripping from a nozzle are measured to obtain the extensional stress loading on the liquid filament. These images are captured with a high-speed polarization camera connected to a micro polarization element alley, enabling high-speed imaging of the birefringent field. Worm-like micellar solutions of cetyltrimethylammonium bromide (CTAB) and sodium salicylate (NaSal) with varying concentrations of CTAB and NaSal are employed as the measurement targets. Consequently, we successfully visualized temporally developing images of the birefringence field of uniaxially extending worm-like micellar solutions induced by the orientation of micelles toward the extensional direction. Furthermore, the proposed technique supports investigating the conditions for establishing the stress-optical rule, which is the linear relation between stress and birefringence for complex fluids. The stress-optical coefficient, a proportionality constant indicating the sensitivity of birefringence to stress, is analyzed from these measurements. The stress-optical coefficient under uniaxial extensional flow is confirmed to be comparable to that under shear flow.         _ Less","","arXiv","https://arxiv.org/abs/2404.17643","1","1","multiple"
"Rapidly rotating Population III stellar models as a source of primary nitrogen","Abstract:                The first stars might have been fast rotators. This would have important consequences for their radiative, mechanical and chemical feedback. We discuss the impact of fast initial rotation on the_         _ More           The first stars might have been fast rotators. This would have important consequences for their radiative, mechanical and chemical feedback. We discuss the impact of fast initial rotation on the evolution of massive Population III models and on their nitrogen and oxygen stellar yields. We explore the evolution of Population III stars with initial masses in the range of 9Msol < Mini < 120Msol starting with an initial rotation on the Zero Age Main Sequence equal to 70% of the critical one. We find that with the physics of rotation considered here, our rapidly-rotating Population III stellar models do not follow a homogeneous evolution. They lose very little mass in case mechanical winds are switched on when the surface rotation becomes equal or larger than the critical velocity. Impact on the ionising flux appears modest when compared to moderately-rotating models. Fast rotation favours, in models with initial masses above ~20Msol, the appearance of a very extended intermediate convective zone around the H-burning shell during the core He-burning phase. This shell has important consequences on the sizes of the He- and CO-cores and thus impacts the final fate of stars. Moreover, it has a strong impact on nucleosynthesis boosting the production of primary 14N. Fast initial rotation impacts significantly the chemical feedback of Population III stars. Observations of extremely metal-poor stars and/or starbursting regions are essential to provide constraints on the properties of the first stars.         _ Less","","arXiv","https://arxiv.org/abs/2404.16512","0","1","synthetic_biology"
"A finite-time quantum Otto engine with tunnel coupled one-dimensional Bose gases","Abstract:                _strokes. More specifically, the interaction-induced work strokes are modelled by treating the working fluid as an isolated quantum many-body system undergoing unitary evolution. The equilibration strokes, on the other hand, are modelled by treating the working fluid as an open quantum system tunnel-coupled to another quasicondensate which acts as either the_         _ More           We undertake a theoretical study of a finite-time quantum Otto engine cycle driven by inter-particle interactions in a weakly interacting one-dimensional Bose gas in the quasicondensate regime. Utilizing a $c$-field approach, we simulate the entire Otto cycle, i.e. the two work strokes and the two equilibration strokes. More specifically, the interaction-induced work strokes are modelled by treating the working fluid as an isolated quantum many-body system undergoing unitary evolution. The equilibration strokes, on the other hand, are modelled by treating the working fluid as an open quantum system tunnel-coupled to another quasicondensate which acts as either the hot or cold reservoir, albeit of finite size. We find that, unlike a uniform 1D Bose gas, a harmonically trapped quasicondensate cannot operate purely as a \\emph{heat} engine; instead, the engine operation is enabled by additional \\emph{chemical} work performed on the working fluid, facilitated by the inflow of particles from the hot reservoir. The microscopic treatment of dynamics during equilibration strokes enables us to evaluate the characteristic operational time scales of this Otto chemical engine, crucial for characterizing its power output, without any \\emph{ad hoc} assumptions about typical thermalization timescales. We analyse the performance and quantify the figures of merit of the proposed Otto chemical engine, finding that it offers a favourable trade-off between efficiency and power output, particularly when the interaction-induced work strokes are implemented via a sudden quench. We further demonstrate that in the sudden quench regime, the engine operates with an efficiency close to the near-adiabatic (near maximum efficiency) limit, while concurrently achieving maximum power output.         _ Less","","arXiv","https://arxiv.org/abs/2404.16470","0","1","synthetic_biology"
"The separate effect of halo mass and stellar mass on the evolution of massive disk galaxies","Abstract:                We analyse a sample of massive disk galaxies selected from the SDSS-IV/MaNGA survey to investigate how the evolution of these galaxies depends on their stellar and halo masses. We applied a semi-analytic spectral fitting approach to the data from different regions in the galaxies to derive several of their key physical properties. From the best-fit model res_         _ More           We analyse a sample of massive disk galaxies selected from the SDSS-IV/MaNGA survey to investigate how the evolution of these galaxies depends on their stellar and halo masses. We applied a semi-analytic spectral fitting approach to the data from different regions in the galaxies to derive several of their key physical properties. From the best-fit model results, together with direct observables such as morphology, colour, and the Mgb/$\\langle$Fe$\\rangle$ index ratio measured within $1 R_{\\rm e}$, we find that for central galaxies both their stellar and halo masses have a significant influence in their evolution. For a given halo mass, galaxies with higher stellar mass accumulate their stellar mass and become chemically enriched earlier than those with smaller stellar mass. Furthermore, at a given stellar mass, galaxies living in more massive halos have longer star-formation timescales and are delayed in becoming chemically enriched. In contrast, the evolution of massive satellite galaxies is mostly determined by their stellar mass. The results indicate that both the assembled halo mass and the halo assembly history impact the evolution of central galaxies. Our spatially resolved analysis indicates that only the galaxy properties in the central region ($0.0$--$0.5 R_{\\rm e}$) show the dependencies described above. This fact supports a halo-driven formation scenario since the galaxies' central regions are more likely to contain old stars formed along with the halo itself, keeping a memory of the halo formation process.         _ Less","","arXiv","https://arxiv.org/abs/2404.16181","2","2","multiple"
"Quasi-equilibrium chemical evolution in starless cores","Abstract:                The chemistry of H2O, CO and other small molecular species in an isolated pre-stellar core, L1544, has been assessed in the context of a comprehensive gas-grain chemical model, coupled to an empirically constrained physical/dynamical model. Our main findings are (i) that the_         _ More           The chemistry of H2O, CO and other small molecular species in an isolated pre-stellar core, L1544, has been assessed in the context of a comprehensive gas-grain chemical model, coupled to an empirically constrained physical/dynamical model. Our main findings are (i) that the chemical network remains in near equilibrium as the core evolves towards star formation and the molecular abundances change in response to the evolving physical conditions. The gas-phase abundances at any time can be calculated accurately with equilibrium chemistry, and the concept of chemical clocks is meaningless in molecular clouds with similar conditions and dynamical time scales, and (ii) A comparison of the results of complex and simple chemical networks indicates that the abundances of the dominant oxygen and carbon species, H2O, CO, C, and C+ are reasonably approximated by simple networks. In chemical equilibrium, the time-dependent differential terms vanish and a simple network reduces to a few algebraic equations. This allows rapid calculation of the abundances most responsible for spectral line radiative cooling in molecular clouds with long dynamical time scales. The dust ice mantles are highly structured and the ice layers retain a memory of the gas-phase abundances at the time of their deposition. A complex (gas-phase and gas-grain) chemical structure therefore exists, with cosmic-ray induced processes dominating in the inner regions. The inferred H2O abundance profiles for L1544 require that the outer parts of the core and also any medium exterior to the core are essentially transparent to the interstellar radiation field.         _ Less","","arXiv","https://arxiv.org/abs/2404.15876","3","2","origin_of_life"
"CAI formation in the early Solar System","Abstract:                _system, found as light-coloured crystalline ingredients in meteorites. Their formation time is commonly associated with age zero of the Solar System. Yet, the physical and chemical processes that once led to the formation of these sub-millimetre to centimetre-sized mineral particles in the early solar nebula are still a matter of debate. This paper proposes_         _ More           Ca-Al-rich inclusions (CAIs) are the oldest dated solid materials in the solar system, found as light-coloured crystalline ingredients in meteorites. Their formation time is commonly associated with age zero of the Solar System. Yet, the physical and chemical processes that once led to the formation of these sub-millimetre to centimetre-sized mineral particles in the early solar nebula are still a matter of debate. This paper proposes a pathway to form such inclusions during the earliest phases of disc evolution. We combine 1D viscous disc evolutionary models with 2D radiative transfer, equilibrium condensation, and new dust opacity calculations. We show that the viscous heating associated with the high accretion rates in the earliest evolutionary phases causes the midplane inside of about 0.5 au to heat up to limiting temperatures of about 1500-1700 K, but no further. These high temperatures force all refractory material components of the inherited interstellar dust grains to sublimate - except for a few Al-Ca-Ti oxides such as Al2O3, Ca2Al2SiO7, and CaTiO3. Once the Mg-Fe silicates are gone, the dust becomes more transparent and the heat is more efficiently transported to the disc surface, which prevents any further warm-up. This thermostat mechanism keeps these minerals above their annealing temperature for hundreds of thousands of years, which creates large, pure and crystalline particles. These particles are dragged out by the viscously spreading disc. Beyond about 0.5 au, the silicates re-condense on the Ca-Al-rich particles, adding an amorphous silicate matrix. We estimate that this mechanism to produce CAIs works during the first 50000 years of disc evolution. These particles then continue to move outward and populate the entire disc up to radii of about 50 au, before, eventually, the accretion rate subsides, the disc cools, and the particles start to drift inwards.         _ Less","","arXiv","https://arxiv.org/abs/2404.15715","1","1","multiple"
"Order evolution from a high-entropy matrix: understanding and predicting paths to low temperature equilibrium","Abstract:                _trends. The highest-entropy homogeneous and random solid-solution is a parent structure from which a continuum of lower-entropy offspring can originate by adopting chemical and/or structural order. This report demonstrates how synthesis conditions, thermal history, and elastic and chemical boundary conditions conspire_         _ More           Interest in high-entropy inorganic compounds originates from their ability to stabilize cations and anions in local environments that rarely occur at standard temperature and pressure. This leads to new crystalline phases in many-cation formulations with structures and properties that depart from conventional trends. The highest-entropy homogeneous and random solid-solution is a parent structure from which a continuum of lower-entropy offspring can originate by adopting chemical and/or structural order. This report demonstrates how synthesis conditions, thermal history, and elastic and chemical boundary conditions conspire to regulate this process in Mg0.2Co0.2Ni0.2Cu0.2Zn0.2O, during which coherent CuO nano-tweeds and spinel nano-cuboids evolve. We do so by combining structured synthesis routes, atomic-resolution microscopy and spectroscopy, density functional theory, and a phase field modeling framework that accurately predicts the emergent structure and local chemistry. This establishes a framework to appreciate, understand, and predict the macrostate spectrum available to a high-entropy system that is critical to rationalize property engineering opportunities.         _ Less","","arXiv","https://arxiv.org/abs/2404.15708","0","1","synthetic_biology"
"NGC1856: Using machine learning techniques to uncover detailed stellar abundances from MUSE data","Abstract:                _to derive [Si/Fe] and [C/Fe] abundances for this cluster. The revolutionary combination of integral-field spectroscopy and data-driven modeling will allow us to understand the chemical enrichment of star clusters and their host galaxies in greater detail expanding our understanding of galaxy evolution.         _ More           We present the first application of the novel approach based on data-driven machine learning methods applied to Multi-Unit Spectroscopic Explorer (MUSE) field data to derive stellar abundances of star clusters. MUSE has been used to target more than 10,000 fields, and it is unique in its ability to study dense stellar fields such as stellar clusters providing spectra for each individual star. We use MUSE data of the extragalactic young stellar cluster NGC 1856, located in the Large Magellanic Cloud (LMC). We present the individual stellar [Fe/H] abundance of 327 cluster members in addition to [Mg/Fe], [Si/Fe], [Ti/Fe], [C/Fe], [Ni/Fe], and [Cr/Fe] abundances of subsample sets. Our results match the LMC abundances obtained in the literature for [Mg/Fe], [Ti/Fe], [Ni/Fe], and [Cr/Fe]. This study is the first to derive [Si/Fe] and [C/Fe] abundances for this cluster. The revolutionary combination of integral-field spectroscopy and data-driven modeling will allow us to understand the chemical enrichment of star clusters and their host galaxies in greater detail expanding our understanding of galaxy evolution.         _ Less","","arXiv","https://arxiv.org/abs/2404.15527","0","1","synthetic_biology"
"The chemistry of extra-solar materials from white dwarf planetary systems","Abstract:                White dwarf planetary systems provide a unique way to measure the bulk composition of exoplanetary material. Extrasolar asteroids/comets/moons which have survived the evolution of their host star can end up in the atmosphere of the white dwarf. Asteroids and boulders appear to be the most common pollutants, where we use the term 'asteroids' to refer_         _ More           White dwarf planetary systems provide a unique way to measure the bulk composition of exoplanetary material. Extrasolar asteroids/comets/moons which have survived the evolution of their host star can end up in the atmosphere of the white dwarf. Asteroids and boulders appear to be the most common pollutants, where we use the term 'asteroids' to refer to the parent body that is polluting the atmosphere. The presence of the planetary material is detected via absorption lines of heavy elements. White dwarfs with these absorption features are called 'polluted' white dwarfs. Polluted white dwarfs were expected to be rare objects because white dwarfs have high surface gravities, therefore, these heavy elements will settle out of the white dwarf's atmospheres in a short amount of time (Paquette et al. 1986). However, high-resolution spectroscopic surveys found that 25-50% of white dwarfs are polluted (Zuckerman et al. 2003, 2010; Koester et al. 2014). The mechanism responsible for making a polluted white dwarf must be common and efficient. There is strong theoretical and observational evidence that white dwarfs are accreting from planetary material. There are different mechanisms that can deliver exoplanetary material into the Roche lobe of the white dwarf. Debris disks, transits from disintegrating bodies, and intact planets have all been detected around white dwarfs (e.g., Jura et al. 2007; Vanderburg et al. 2015, 2020). This chapter will describe how the chemical autopsies are conducted, and what is learnt about exoplanetary material from polluted white dwarfs.         _ Less","","arXiv","https://arxiv.org/abs/2404.15425","1","2","synthetic_biology"
"Meteorites and Planet Formation","Abstract:                _character of being pieces of other worlds. Scientifically, they are critical to interpreting the early stages of formation of the Solar System, as well as the geological evolution of asteroids, the Moon, and Mars, and they are vital to understanding planetary formation processes. With the burgeoning exploration of extrasolar planetary systems, knowledge of t_         _ More           Meteorites are a remarkable resource. They capture the imagination of people worldwide with their spectacular entry through Earth's atmosphere as fireballs, and their exotic character of being pieces of other worlds. Scientifically, they are critical to interpreting the early stages of formation of the Solar System, as well as the geological evolution of asteroids, the Moon, and Mars, and they are vital to understanding planetary formation processes. With the burgeoning exploration of extrasolar planetary systems, knowledge of the fundamental process of planetary growth from protoplanetary disks has taken on a new significance. Meteorites provide essential and detailed insight into the formation of planetary systems, although we must bear in mind that they only represent one reference point (our own Solar System) in what is clearly a wide spectrum of possible chemical and physical parameters governing the diverse realm of extrasolar planets. This chapter summarises the nature of our meteorite collections, and the ways in which meteorites contribute to our understanding of the formation and evolution of our own Solar System, with broader implications for planetary systems in general.         _ Less","","arXiv","https://arxiv.org/abs/2404.15424","1","2","synthetic_biology"
"Impact of main-sequence mass loss on the appearance, structure and evolution of Wolf-Rayet stars","Abstract:                Stellar winds are one of the most important drivers of massive star evolution and a vital source of_         _ More           Stellar winds are one of the most important drivers of massive star evolution and a vital source of chemical, mechanical, and radiative feedback. Despite its significance, mass loss remains a major uncertainty in stellar evolution models. Particularly the interdependencies of different approaches with subsequent evolutionary stages and predicted observable phenomena are far from being systematically understood. In this study, we examine the impact of main sequence mass loss on the structure of massive stars throughout their evolution. A particular focus is placed on the consequences for entering the Wolf-Rayet (WR) regime and the subsequent evolution. Using the Geneva stellar evolution code, we compute grids of single, non-rotating stellar models at solar and Large Magellanic Cloud (LMC) metallicity of initial masses between 20 and 120 solar masses, with two representative prescriptions for high and low main sequence mass loss. We obtain detailed numerical predictions regarding the structure and evolution of massive stars, and infer the role of main sequence mass loss by comparison of the mass-loss rate prescriptions. We present implications for the overall evolutionary trajectory, including the evolution of WR stars, as well as the effect on stellar yields and stellar populations. Mass loss during the main sequence plays an important role due to its ability to affect the sequence and duration of all subsequent phases. We identify several distinct evolutionary paths for massive stars which are significantly influenced by the chosen main sequence mass-loss description. We also discuss the impact of uncertainties other than mass loss on the evolution, in particular those relating to convection. We further demonstrate that not just the total mass loss, but the specific mass-loss history throughout a star's life is a crucial determinant of many aspects, such as the resulting stellar yields.         _ Less","","arXiv","https://arxiv.org/abs/2404.14488","0","1","synthetic_biology"
"Preserving linear invariants in ensemble filtering methods","Abstract:                Formulating dynamical models for physical phenomena is essential for understanding the interplay between the different mechanisms and predicting the evolution of physical states. However, a dynamical model alone is often insufficient to address these fundamental tasks, as it suffers from model errors and uncertainties. One common remedy is to rely on data as_         _ More           Formulating dynamical models for physical phenomena is essential for understanding the interplay between the different mechanisms and predicting the evolution of physical states. However, a dynamical model alone is often insufficient to address these fundamental tasks, as it suffers from model errors and uncertainties. One common remedy is to rely on data assimilation, where the state estimate is updated with observations of the true system. Ensemble filters sequentially assimilate observations by updating a set of samples over time. They operate in two steps: a forecast step that propagates each sample through the dynamical model and an analysis step that updates the samples with incoming observations. For accurate and robust predictions of dynamical systems, discrete solutions must preserve their critical invariants. While modern numerical solvers satisfy these invariants, existing invariant-preserving analysis steps are limited to Gaussian settings and are often not compatible with classical regularization techniques of ensemble filters, e.g., inflation and covariance tapering. The present work focuses on preserving linear invariants, such as mass, stoichiometric balance of chemical species, and electrical charges. Using tools from measure transport theory (Spantini et al., 2022, SIAM Review), we introduce a generic class of nonlinear ensemble filters that automatically preserve desired linear invariants in non-Gaussian filtering problems. By specializing this framework to the Gaussian setting, we recover a constrained formulation of the Kalman filter. Then, we show how to combine existing regularization techniques for the ensemble Kalman filter (Evensen, 1994, J. Geophys. Res.) with the preservation of the linear invariants. Finally, we assess the benefits of preserving linear invariants for the ensemble Kalman filter and nonlinear ensemble filters.         _ Less","","arXiv","https://arxiv.org/abs/2404.14328","1","2","synthetic_biology"
"X-shooter spectroscopy of Liller1 giant stars","Abstract:                We present the first comprehensive chemical study of a representative sample of 27 luminous red giant branch (RGB) stars belonging to Liller 1, a complex stellar system in the Galactic bulge. This study is based on medium-resolution near-infrared spectra acquired with X-shooter at the Very Large Telescope. We found a subpopulation counting 22 stars with subs_         _ More           We present the first comprehensive chemical study of a representative sample of 27 luminous red giant branch (RGB) stars belonging to Liller 1, a complex stellar system in the Galactic bulge. This study is based on medium-resolution near-infrared spectra acquired with X-shooter at the Very Large Telescope. We found a subpopulation counting 22 stars with subsolar metallicity ($<$[Fe/H]$>=-0.31\\pm0.02$ and 1$_$ dispersion of 0.08 dex) and with enhanced [$_$/Fe], [Al/Fe], and [K/Fe] that likely formed early and quickly from gas that was mainly enriched by type II supernovae, and a metal-rich population counting 5 stars with supersolar metallicity ($<$[Fe/H]$>$=+0.22$\\pm$0.03 and 1$_$ dispersion of 0.06 dex) and roughly solar-scaled [$_$/Fe], [Al/Fe], and [K/Fe] that formed at later epochs from gas that was also enriched by type Ia supernovae. Moreover, both subpopulations show enhanced [Na/Fe], as in the bulge field, about solar-scaled [V/Fe], and depletion of [C/Fe] and $^{12}$C/$^{13}$C with respect to the solar values. This indicates that mixing and extra-mixing processes during the RGB evolution also occur at very high metallicities. Notably, no evidence of a Na-O anticorrelation, which is considered the fingerprint of genuine globular clusters, has been found. This challenges any formation scenarios that invoke the accretion of a molecular cloud or an additional stellar system onto a genuine globular cluster. The results of this study underline the strong chemical similarity between Liller 1 and Terzan 5 and support the hypothesis that these complex stellar systems might be fossil fragments of the epoch of Galactic bulge formation.         _ Less","","arXiv","https://arxiv.org/abs/2404.14130","2","2","multiple"
"Structural modulation driven Curie temperature enhancement in Cr-doped SrRuO3","Abstract:                _correlated system with competing ground states are often poised close to the quantum critical point. External perturbations such as pressure, strain, electric field, and chemical doping can stabilise its ground state with exotic physical properties. Cr-doping is the lone exception which enhances the Curie-temperature in one of such correlated system SrRuO_         _ More           Strongly correlated system with competing ground states are often poised close to the quantum critical point. External perturbations such as pressure, strain, electric field, and chemical doping can stabilise its ground state with exotic physical properties. Cr-doping is the lone exception which enhances the Curie-temperature in one of such correlated system SrRuO$_3$. To find the origin of $T_C$ enhancement, we investigate temperature-dependent structure, spectroscopic, magnetic and magnetotransport properties in SrRu$_{1-x}$Cr$_x$O$_3$. Cr-doping squeezes the unit cell volume which effectively enhances the stretching octahedral distortion by nearly five times than pure SrRuO$_3$. The Curie temperature increment by $\\sim$ 22 K for x = 0.15 is found to be intertwined with the structural-modulation. Temperature-dependent Neutron diffraction analysis indicate that the unit cell volume minima coincide exactly with the enhanced ferromagnetic ordering ($\\sim$ 190 K). Further analysis reveals that the effect of Cr-doping not only freezes the octahedral tilt below 100 K but also suppresses the complex magnetism responsible for exchange bias and topological hall effect in SrRuO$_3$. The spectroscopic measurements find a reduction of itinerancy of d-electrons with Cr-doping. The magnetotransport measurements portray an evolution from itinerant to localised ferromagnetism.         _ Less","","arXiv","https://arxiv.org/abs/2404.13593","0","1","synthetic_biology"
"New Evidence of Binarity in Young _-Rich Turn-off and Subgiant Stars: Fast Rotation and Strong Magnetic Activity","Abstract:                _with asteroseismology and abundance enhancement in _ elements measured from high-resolution spectroscopy. The youth origin of YAR stars has been proposed to be binary evolution via mass transfer or stellar mergers. If that is the case, YAR stars should spin rapidly and thus be magnetically active, because they are mass and angular momentum gainers. In this s_         _ More           Young _-rich (YAR) stars within the old Galactic thick disk exhibit a dual characteristic of relative youth determined with asteroseismology and abundance enhancement in _ elements measured from high-resolution spectroscopy. The youth origin of YAR stars has been proposed to be binary evolution via mass transfer or stellar mergers. If that is the case, YAR stars should spin rapidly and thus be magnetically active, because they are mass and angular momentum gainers. In this study, to seek this binary footprint we select YAR stars on the main-sequence turn-off or the subgiant branch (MSTO-SGB) from APOGEE DR17, whose ages and projected rotation velocities (vsini) can be precisely measured. With APOGEE vsini and LAMOST spectra, we find that YAR stars are indeed fast rotators and magnetically active. In addition, we observe low [C/N] ratios and high Gaia RUWE in some YAR stars, suggesting that these MSTO-SGB stars probably have experienced mass transfer from red-giant companions. Our findings underscore that magnetic activity can serve as a valuable tool for probing the binary evolution for other chemically peculiar stars, such as red giants with lithium anomalies and carbon-enhanced metal-poor stars.         _ Less","","arXiv","https://arxiv.org/abs/2404.13562","0","1","synthetic_biology"
"Age analysis of extrasolar planets: Insight from stellar isochrone models","Abstract:                There is growing evidence from stellar kinematics and galactic chemical evolution (GCE) suggesting that giant planets (M$_{P}\\geq$0.3$M_{J}$) are relatively young compared to the most commonly occurring population of small planets (M$_{P} <$0.3$M_{J}$). To further test the validity of these results, we analyzed the_         _ More           There is growing evidence from stellar kinematics and galactic chemical evolution (GCE) suggesting that giant planets (M$_{P}\\geq$0.3$M_{J}$) are relatively young compared to the most commonly occurring population of small planets (M$_{P} <$0.3$M_{J}$). To further test the validity of these results, we analyzed the ages for a large number of 2336 exoplanet hosting stars determined using three different but well-established isochrone fitting models, namely, PARSEC, MIST, and Yonsei Yale (YY). As input parameters, we used Gaia DR3 parallaxes, magnitudes, and photometric temperature, as well as spectroscopically determined more accurate temperatures and metallicities from the Sweet Catalog. Our analysis suggests that $\\sim$~50$\\%$ to 70$\\%$ of stars with planets are younger than the sun. We also find that, among the confirmed exoplanetary systems, stars hosting giant planets are even younger compared to small planet hosts. The median age of $\\sim$~2.61 to 3.48~Gyr estimated for the giant planet-hosting stars (depending on the model input parameters) suggests that the later chemical enrichment of the galaxy by the iron-peak elements, largely produced from Type Ia supernovae, may have paved the way for the formation of gas giants. Furthermore, within the giant planet population itself, stars hosting hot Jupiters (orbital period $\\le$10 days) are found to be younger compared to the stellar hosts of cool and warm Jupiters (orbital period $>$10 days), implying that hot Jupiters could be the youngest systems to emerge in the progression of planet formation.         _ Less","","arXiv","https://arxiv.org/abs/2404.13398","2","1","origin_of_life"
"Shock waves in Interstellar Cloud-Cloud and Wind-Cloud Collisions","Abstract:                The interstellar medium (ISM) is a key ingredient of galaxies and their evolution, consisting of multiphase, turbulent dust and gas. Some of the star-forming regions in our Galaxy originate from cloud-cloud and wind-cloud collisions, which generate shock waves that change the physical and_         _ More           The interstellar medium (ISM) is a key ingredient of galaxies and their evolution, consisting of multiphase, turbulent dust and gas. Some of the star-forming regions in our Galaxy originate from cloud-cloud and wind-cloud collisions, which generate shock waves that change the physical and chemical properties of the gas. We utilise our own python-based shock-finding algorithm to study the properties and distribution of shocks in interstellar collisions. Such interactions are studied via 3D numerical simulations with different initial conditions: Cloud-cloud collisions (CCc): We identify four stages of evolution: pre-collision, compression, pass-through, and dissipation. We also vary the size of one of the colliding clouds. Larger clouds facilitate cloud erosion and the formation of more and stronger shocks at early stages. Shock distributions are also time-dependent, as strong shocks are only produced during the early stages. As the collisions evolve, turbulent kinetic energy is rapidly dissipated, so most perturbations become subsonic waves at late times. Wind-cloud collisions (WCc): we identify four stages: compression, stripping, expansion, and break-up. We study the evolution of several diagnostics in these clouds: energies (thermal and kinetic), temperature, displacement of the centre of mass, and mass-weighted averages of the cloud density and acceleration. We show, that the geometry of the cloud impact the diagnostic parameters, for example, smoothing the edges of the cloud leads to enhanced mass losses and dispersion, but has little impact on the shock distribution.         _ Less","","arXiv","https://arxiv.org/abs/2404.13250","1","1","multiple"
"Dynamical formation of Gaia BH3 in the progenitor globular cluster of the ED-2 stream","Abstract:                Context. The star-black hole (S-BH) binary known as Gaia BH3, discovered by the Gaia Collaboration is chemically and kinematically associated with the metal-poor ED-2 stream in the Milky Way halo.   Aims. We explore the possibility that Gaia BH3 was assembled dynamically in the progenitor globular cluster (GC) of the ED-2 stream.   Methods. We used a public_         _ More           Context. The star-black hole (S-BH) binary known as Gaia BH3, discovered by the Gaia Collaboration is chemically and kinematically associated with the metal-poor ED-2 stream in the Milky Way halo.   Aims. We explore the possibility that Gaia BH3 was assembled dynamically in the progenitor globular cluster (GC) of the ED-2 stream.   Methods. We used a public suite of star-by-star dynamical Monte Carlo models to identify S-BH binaries in GCs with different initial masses and (half-mass) radii.   Results. We show that a likely progenitor of the ED-2 stream was a relatively low-mass ($\\lesssim10^5M_\\odot$) GC with an initial half-mass radius of ~4 pc. Such a GC can dynamically retain a large fraction of its BH population and dissolve on the orbit of ED-2. From the suite of models we find that GCs produce ~ 3 - 30 S-BH binaries, approximately independent of initial GC mass and inversely correlated with initial cluster radius. Scaling the results to the Milky Way GC population, we find that ~75% of the S-BH binaries formed in GCs are ejected from their host GC, all in the early phases of evolution ($\\lesssim1$ Gyr); these are expected to no longer be close to streams. The ~25% of S-BH binaries retained until dissolution are expected to form part of streams, such that for an initial mass of the progenitor of ED-2 of a few $10^4M_\\odot$, we expect ~2-3 S-BH to end up in the stream. GC models with metallicities similar to Gaia BH3 ($\\lesssim1\\%$ solar) include S-BH binaries with similar BH masses ($\\gtrsim30M_\\odot$), orbital periods, and eccentricities.   Conclusions. We predict the Galactic halo contains of order $10^5$ S-BH binaries that formed dynamically in GCs, a fraction of which may readily be detected in Gaia DR4. The detection of these sources provides valuable tests of BH dynamics in clusters and the possible role in formation of gravitational wave sources.         _ Less","","arXiv","https://arxiv.org/abs/2404.13036","1","1","multiple"
"The JWST-SUSPENSE Ultradeep Spectroscopic Program: Survey Overview and Star-Formation Histories of Quiescent Galaxies at 1 < z < 3","Abstract:                _Survey Probing Extragalactic Near-infrared Stellar Emission (SUSPENSE), executed with NIRSpec on JWST. The primary goal of the SUSPENSE program is to characterize the stellar, chemical, and kinematic properties of massive quiescent galaxies at cosmic noon. In a single deep NIRSpec/MSA configuration, we target 20 distant quiescent galaxy candidates ($z=1-3$,_         _ More           We present an overview and first results from the Spectroscopic Ultradeep Survey Probing Extragalactic Near-infrared Stellar Emission (SUSPENSE), executed with NIRSpec on JWST. The primary goal of the SUSPENSE program is to characterize the stellar, chemical, and kinematic properties of massive quiescent galaxies at cosmic noon. In a single deep NIRSpec/MSA configuration, we target 20 distant quiescent galaxy candidates ($z=1-3$, $H_{AB}\\le23$), as well as 53 star-forming galaxies at $z=1-4$. With 16~hr of integration and the G140M-F100LP dispersion-filter combination, we observe numerous Balmer and metal absorption lines for all quiescent candidates. We derive stellar masses (log$M_*/M_{\\odot}\\sim10.2-11.5$) and detailed star-formation histories (SFHs) and show that all 20 candidate quiescent galaxies indeed have quenched stellar populations. These galaxies show a variety of mass-weighted ages ($0.8-3.3$~Gyr) and star formation timescales ($\\sim0.5-4$~Gyr), and four out of 20 galaxies were already quiescent by $z=3$. On average, the $z>1.75$ $[z<1.75]$ galaxies formed 50\\% of their stellar mass before $z=4$ $[z=3]$. Furthermore, the typical SFHs of galaxies in these two redshift bins ($z_{\\text{mean}}=2.2~[1.3]$) indicate that galaxies at higher redshift formed earlier and over shorter star-formation timescales compared to lower redshifts. Although this evolution is naturally explained by the growth of the quiescent galaxy population over cosmic time, number density calculations imply that mergers and/or late-time star formation also contribute to the evolution. In future work, we will further unravel the early formation, quenching, and late-time evolution of these galaxies by extending this work with studies on their chemical abundances, resolved stellar populations and kinematics.         _ Less","","arXiv","https://arxiv.org/abs/2404.12432","3","4","synthetic_biology"
"Alloyed Re$_x$Mo$_{1-x}$S$_2$ Nanoflakes with Enlarged Interlayer Distances for Hydrogen Evolution","Abstract:                _) has attracted significant attention due to its great potential as a low-cost and efficient catalyst for the hydrogen evolution reaction. Developing a facile, easily upscalable, and inexpensive approach to produce catalytically active nanostructured MoS$_2$ with a high yield would significantly advance its practical application. Colloidal synthesis offers s_         _ More           Molybdenum sulfide (MoS$_2$) has attracted significant attention due to its great potential as a low-cost and efficient catalyst for the hydrogen evolution reaction. Developing a facile, easily upscalable, and inexpensive approach to produce catalytically active nanostructured MoS$_2$ with a high yield would significantly advance its practical application. Colloidal synthesis offers several advantages over other preparation techniques to overcome the low reaction yield of exfoliation and drawbacks of expensive equipment and processes used in chemical vapor deposition. In this work, we report an efficient synthesis of alloyed Re$_x$Mo$_{1-x}$S$_2$ nanoflakes with an enlarged interlayer distance, among which the composition Re$_{0.55}$Mo$_{0.45}$S$_2$ exhibits excellent catalytic performance with overpotentials as low as 79 mV at 10 mA/cm2 and a small Tafel slope of 42 mV/dec. Density functional theory calculations prove that enlarging the distance between layers in the Re$_x$Mo$_{1-x}$S$_2$alloy can greatly improve its catalytic performance due to a significantly reduced free energy of hydrogen adsorption. The developed approach paves the way to design advanced transition metal dichalcogenide-based catalysts for hydrogen evolution and to promote their large-scale practical application.         _ Less","","arXiv","https://arxiv.org/abs/2404.12412","0","1","synthetic_biology"
"Kinematics and metallicity of the dwarf spheroidal galaxy Andromeda XVIII","Abstract:                _), parameters for the simplest chemical evolution models were estimated using the maximum likelihood coupled with a Markov Chain Monte Carlo (MCMC) method. The metallicity distribution is inconsistent with these models, due to a sharp metal-rich cutoff. We estimated Andromeda XVIII's mean heliocentric velocity, rot_         _ More           Andromeda XVIII is an isolated dwarf galaxy 579 kpc away from the nearest large galaxy, M31. It is a candidate 'backsplash galaxy' that might have been affected by a close passage to M31. We present new Keck/DEIMOS spectroscopy of Andromeda XVIII to assess the likelihood that it is a backsplash galaxy. We estimated the velocities, metallicities ([Fe/H]), and $_$-enhancements ([$_$/Fe]) for 56 probable members. Based on the abundances of 38 stars with low errors ($_[Fe/H] < 0.3$), parameters for the simplest chemical evolution models were estimated using the maximum likelihood coupled with a Markov Chain Monte Carlo (MCMC) method. The metallicity distribution is inconsistent with these models, due to a sharp metal-rich cutoff. We estimated Andromeda XVIII's mean heliocentric velocity, rotation velocity, position angle of the rotation axis, and velocity dispersion using the maximum likelihood coupled with an MCMC. There is no evidence for bulk rotation, though subpopulations might be rotating. The mean heliocentric velocity is -337.2 km s$^{-1}$, such that the line-of-sight velocity relative to M31 is lower than the escape velocity from M31. Together, the metallicity distribution and the mean velocity are consistent with a sudden interruption of star formation. For possible causes of this quenching, we considered gas loss due to ram pressure stripping during a close passage by M31 or due to a past major merger. However, we cannot rule out internal feedback (i.e., a terminal wind).         _ Less","","arXiv","https://arxiv.org/abs/2404.11804","2","1","origin_of_life"
"Effective one-dimension reduction of multi-compartment complex systems dynamics","Abstract:                _broad class of systems, including ecological, epidemiological, and sociological ones, are characterized by populations of individuals assigned to specific categories, e.g., a chemical species, an opinion or an epidemic state, that are modeled as compartments. Due to interactions and intrinsic dynamics, individuals are allowed to change category, leading to c_         _ More           A broad class of systems, including ecological, epidemiological, and sociological ones, are characterized by populations of individuals assigned to specific categories, e.g., a chemical species, an opinion or an epidemic state, that are modeled as compartments. Due to interactions and intrinsic dynamics, individuals are allowed to change category, leading to concentrations varying over time with complex behavior, typical of reaction-diffusion systems. While compartmental modeling provides a powerful framework for studying the dynamics of such populations and describe the spatiotemporal evolution of a system, it mostly relies on deterministic mean-field descriptions to deal with systems with many degrees of freedom. Here, we propose a method to alleviate some of the limitations of compartmental models by capitalizing on tools originating from quantum physics to systematically reduce multi-dimensional systems to an effective one-dimensional representation. Using this reduced system, we are able to not only investigate the mean-field dynamics and their critical behavior, but we can additionally study stochastic representations that capture fundamental features of the system. We demonstrate the validity of our formalism by studying the critical behavior of models widely adopted to study epidemic, ecological and economic systems.         _ Less","","arXiv","https://arxiv.org/abs/2404.11366","0","1","synthetic_biology"
"Quantum Simulation of Open Quantum Dynamics via Non-Markovian Quantum State Diffusion","Abstract:                Quantum simulation of non-Markovian open quantum dynamics is essential but challenging for standard quantum computers due to their non-Hermitian nature, leading to non-unitary evolution, and the limitations of available quantum resources. Here we introduce a hybrid quantum-classical algorithm designed for simulating dissipative dynamics in system with non-Ma_         _ More           Quantum simulation of non-Markovian open quantum dynamics is essential but challenging for standard quantum computers due to their non-Hermitian nature, leading to non-unitary evolution, and the limitations of available quantum resources. Here we introduce a hybrid quantum-classical algorithm designed for simulating dissipative dynamics in system with non-Markovian environment. Our approach includes formulating a non-Markovian Stochastic Schr_dinger equation with complex frequency modes (cNMSSE) where the non-Markovianity is characterized by the mode excitation. Following this, we utilize variational quantum simulation to capture the non-unitary evolution within the cNMSSE framework, leading to a substantial reduction in qubit requirements. To demonstrate our approach, we investigated the spin-boson model and dynamic quantum phase transitions (DQPT) within transverse field Ising model (TFIM). Significantly, our findings reveal the enhanced DQPT in TFIM due to non-Markovian behavior.         _ Less","","arXiv","https://arxiv.org/abs/2404.10655","0","1","synthetic_biology"
"High-resolution atmospheric retrievals of WASP-76b transmission spectroscopy with ESPRESSO: Monitoring limb asymmetries across multiple transits","Abstract:                _as the varying vertical temperature structure and dynamics between the limbs of WASP-76b, across multiple transits, we aim to enhance our understanding of the 3D nature and chemical/dynamical evolution of such objects over the timescales of months/years. We present retrievals of three VLT/ESPRESSO observations of the u_         _ More           Direct atmospheric retrievals of exoplanets at high-resolution have recently allowed for a more detailed characterisation of their chemistry and dynamics from the ground. By monitoring the longitudinal distribution of species, as well as the varying vertical temperature structure and dynamics between the limbs of WASP-76b, across multiple transits, we aim to enhance our understanding of the 3D nature and chemical/dynamical evolution of such objects over the timescales of months/years. We present retrievals of three VLT/ESPRESSO observations of the ultra-hot Jupiter WASP-76b, including one not yet reported in the literature, from which we constrain the atmospheric abundances, vertical temperature structure, and atmospheric dynamics for both the leading and trailing limbs of the atmosphere separately, via novel rotational broadening kernels. We confirm the presence of VO recently reported in the atmosphere of WASP-76b. We find a uniform longitudinal distribution of Fe and Mg across the limbs of the atmosphere, for each of our transits, consistent with previous works as well as with stellar values. We constrain substellar Na/Fe and Cr/Fe ratios across each of our transits, consistent with previous studies of WASP-76b. Where constrained, V/Fe and VO/Fe ratios were also found to be broadly consistent between the limbs of the atmosphere for each of the transits, as well as with previous studies. However, for two of the transits, both V and VO were unconstrained in the leading limb, suggesting possible depletion due to recombination and condensation. The consistency of our constraints across multiple high-resolution observations, as well as with previous studies using varying modelling/retrieval frameworks and/or instruments, affirms the efficacy of high-resolution ground-based retrievals of exoplanetary atmospheres.         _ Less","","arXiv","https://arxiv.org/abs/2404.10463","0","1","synthetic_biology"
"The Rise of the $R$-Process in the Gaia-Sausage/Enceladus Dwarf Galaxy","Abstract:                _. For the first time, we find a clear rise in [Eu/Mg] with increasing [Mg/H] within one galaxy. We use a chemical evolution model to study how such a rise can result from the interplay of prompt and delayed r-process enrichment events. Delayed r-process sources are required to explain the rise and subsequent leveling o_         _ More           Neutron star mergers (NSMs) produce copious amounts of heavy r-process elements after a time delayed inspiral process. Once NSMs are present in a galaxy, r-process elements, such as Eu, are expected to significantly increase with time. Yet, there has been limited observational data in support of Eu increasing within Local Group galaxies. We have obtained high-resolution Magellan/MIKE observations of 43 metal-poor stars in the Gaia-Sausage/Enceladus tidally disrupted galaxy with $-2.5 < \\rm{[Fe/H]} < -1$. For the first time, we find a clear rise in [Eu/Mg] with increasing [Mg/H] within one galaxy. We use a chemical evolution model to study how such a rise can result from the interplay of prompt and delayed r-process enrichment events. Delayed r-process sources are required to explain the rise and subsequent leveling off of [Eu/Mg] in this disrupted galaxy. However, the rise may be explained by delayed r-process sources with either short ($\\sim 10$ Myr) or long ($\\sim 500$ Myr) minimum delay times. Future studies on the nature of r-process sources and their enrichment processes in the GSE will require additional stars in the GSE at even lower metallicities than the present study.         _ Less","","arXiv","https://arxiv.org/abs/2404.10067","1","1","multiple"
"Stellar population astrophysics (SPA) with the TNG: Measurement of the He I 10830_ line in the open cluster Stock 2","Abstract:                The precise measurement of stellar abundances plays a pivotal role in providing constraints on the chemical evolution of the Galaxy. However, before spectral lines can be employed as reliable abundance indicators, particularly for challenging elements such as helium, they must undergo thorough scrutiny. Galactic open c_         _ More           The precise measurement of stellar abundances plays a pivotal role in providing constraints on the chemical evolution of the Galaxy. However, before spectral lines can be employed as reliable abundance indicators, particularly for challenging elements such as helium, they must undergo thorough scrutiny. Galactic open clusters, representing well-defined single stellar populations, offer an ideal setting for unfolding the information stored in the helium spectral line feature. In this study, we characterize the profile and strength of the helium transition at around 10830_ (He 10830) in nine giant stars in the Galactic open cluster Stock 2. To remove the influence of weak blending lines near the helium feature, we calibrated their oscillator strengths ($\\log gf$) by employing corresponding abundances obtained from simultaneously observed optical spectra. Our observations reveal that He 10830 in all the targets is observed in absorption, with line strengths categorized into two groups. Three stars exhibit strong absorption, including a discernible secondary component, while the remaining stars exhibit weaker absorption. The lines are in symmetry and align with or around their rest wavelengths, suggesting a stable upper chromosphere without a significant systematic mass motion. We found a correlation between He 10830 strength and Ca II $\\log{R'_\\mathrm{HK}}$ index, with a slope similar to that reported in previous studies on dwarf stars. This correlation underscores the necessity of accounting for stellar chromosphere structure when employing He 10830 as a probe for stellar helium abundance. The procedure of measuring the He 10830 we developed in this study is applicable not only to other Galactic open clusters but also to field stars, with the aim of mapping helium abundance across various types of stars in the future.         _ Less","","arXiv","https://arxiv.org/abs/2404.09975","2","1","origin_of_life"
"Disentanglement of the chemodynamical assembly: mapping the Milky Way disks","Abstract:                The formation and structure of the Milky Way has a fundamental role in our understanding of the universe and its evolution, and thanks to the Gaia mission and large spectroscopic surveys, we live an exceptional moment of data availability, allowing us to trace the building blocks of the Galactic disk and their relations. In this sense, we propose here the ex_         _ More           The formation and structure of the Milky Way has a fundamental role in our understanding of the universe and its evolution, and thanks to the Gaia mission and large spectroscopic surveys, we live an exceptional moment of data availability, allowing us to trace the building blocks of the Galactic disk and their relations. In this sense, we propose here the exploration of a large dataset in a top-down fashion, elaborating a similarity map of the local Galactic volume in order to segregate and characterise its main components, searching for hints about their relations. We have used the t-SNE algorithm with chemical, orbital and kinematic properties of the stars to produce 2D manifolds and dissect their structure by isolating populations to further analyse their behaviour. The young thin disk could be clearly separated from the older thick disk, also showing a puzzling transition zone with hints about the aftermath of the Gaia-Sausage-Enceladus merger. Moving groups and resonant features also appear prominently in the maps, splitting the disk into inner and outer portions as consequence of the resonances produced by the Galactic bar. The dynamical halo appears as an extreme end related to the heated portion of the thick disk, showing sub-structures corresponding to known accreted populations. Open and globular clusters also appear in their chemical/evolutionary context. We present details of the developed strategy, an overview of the different populations and their relations, as well as a discussion and insights of our results in the scenario of Galactic evolution.         _ Less","","arXiv","https://arxiv.org/abs/2404.09968","3","3","multiple"
"Large bulk photovoltaic effect and Fermi surface mediated its enhancement with chemical potential in ZnGeP$_2$","Abstract:                _5 eV at the chemical potential of E$_f$ = 0 eV which increase about 38\\% and 81\\% respectively at a chemical potential of E$_f$ = 1.52 eV. The systematic_         _ More           Bulk photovoltaic effect is a non-linear response in noncentrosymmetric materials that converts light into DC current. In this work, we investigate the optical linear and non-linear responses in a chalcopyrite semiconductor ZnGeP$_2$. We report large bulk photovoltaics namely shift and circular photogalvanic current conductivities which are 4.46 $_$A/V$^2$ and -5.49 $_$A/V$^2$ respectively with the incident photo energy around $\\sim$ 5 eV at the chemical potential of E$_f$ = 0 eV which increase about 38\\% and 81\\% respectively at a chemical potential of E$_f$ = 1.52 eV. The systematic evolution of the bulk Fermi surface along with the high symmetry points in three dimensional Brillouin zone reveals the enhancement of bulk photovoltaics with the chemical potential in ZnGeP$_2$. To verify our findings, we further explore the distribution of bulk projected bands and surface Fermi surface distribution in the energy landscape using tight binding Hamiltonian within semi infinite slab geometry. This shows that the augmentation of bulk photovoltaics with the chemical potential is due to the surface Fermi surface states along the high symmetry $_-Z$ direction in Brillouin zone. Our thorough and detailed study not only provides a deeper understanding about the role of Fermi surface contribution to the bulk photovoltaic responses with chemical potential, but also suggests ZnGeP$_2$ as an ideal candidate for optoelectronics and bulk photovoltaics.         _ Less","","arXiv","https://arxiv.org/abs/2404.09913","0","1","synthetic_biology"
"Strong coupling electron-photon dynamics: a real-time investigation of energy redistribution in molecular polaritons","Abstract:                _using a real-time quantum electrodynamics coupled cluster (RT-QED-CC) model, which allows for spatial and temporal visualization of transport processes. We compute the time evolution of photonic and molecular observables, such as the dipole moment and the photon coordinate, following the excitation of the system induced by short laser pulses. Our simulation_         _ More           We analyze the real-time electron-photon dynamics in long-range polariton-mediated energy transfer using a real-time quantum electrodynamics coupled cluster (RT-QED-CC) model, which allows for spatial and temporal visualization of transport processes. We compute the time evolution of photonic and molecular observables, such as the dipole moment and the photon coordinate, following the excitation of the system induced by short laser pulses. Our simulation highlights the different time scales of electrons and photons under light-matter strong coupling, the role of dark states, and the differences with the electronic (F_rster and Dexter) energy exchange mechanisms. The developed method can simulate multiple high-intensity laser pulses while explicitly retaining electronic and electron-photon correlation and is thus suited for nonlinear optics and transient absorption spectroscopies of molecular polaritons.         _ Less","","arXiv","https://arxiv.org/abs/2404.09762","0","2","synthetic_biology"
"Modeling the Galactic Chemical Evolution of Helium","Abstract:                We examine the galactic chemical evolution (GCE) of $^4$He in one-zone and multi-zone models, with particular attention to theoretical predictions and empirical constraints on IMF-averaged yields. Published models of massive star winds and core collapse supernovae span a factor of 2 -- 3 in the IMF-averaged $^4$He yiel_         _ More           We examine the galactic chemical evolution (GCE) of $^4$He in one-zone and multi-zone models, with particular attention to theoretical predictions and empirical constraints on IMF-averaged yields. Published models of massive star winds and core collapse supernovae span a factor of 2 -- 3 in the IMF-averaged $^4$He yield, $y\\mathrm{_{He}^{CC}}$. Published models of intermediate mass, asymptotic giant branch (AGB) stars show better agreement on the IMF-averaged yield, $y\\mathrm{_{He}^{AGB}}$, and they predict that more than half of this yield comes from stars with $M=4-8 M_\\odot$, making AGB $^4$He enrichment rapid compared to Fe enrichment from Type Ia supernovae. Although our GCE models include many potentially complicating effects, the short enrichment time delay and mild metallicity dependence of the predicted yields makes the results quite simple: across a wide range of metallicity and age, the non-primordial $^4$He mass fraction $_Y = Y-Y_{\\mathrm{P}}$ is proportional to the abundance of promptly produced $_$-elements, like oxygen, with $_Y/Z_{\\mathrm{O}} \\approx (y\\mathrm{_{He}^{CC}}+y\\mathrm{_{He}^{AGB}})/y\\mathrm{_{O}^{CC}}$. Reproducing solar abundances with our fiducial choice of the oxygen yield $y\\mathrm{_{O}^{CC}}=0.0071$ implies $y\\mathrm{_{He}^{CC}}+y\\mathrm{_{He}^{AGB}} \\approx 0.022$, i.e., $0.022M_\\odot$ of net $^4$He production per solar mass of star formation. Our GCE models with this yield normalization are consistent with most available observations, though the implied $y\\mathrm{_{He}^{CC}}$ is low compared to most of the published massive star models. More precise measurements of $_Y$ in stars and gas across a wide range of metallicity and [$_$/Fe] ratio could test our models more stringently, either confirming the simple picture suggested by our calculations or revealing surprises in the evolution of the second most abundant element.         _ Less","","arXiv","https://arxiv.org/abs/2404.08765","2","1","origin_of_life"
"21cm signal from Dark Ages collapsing halos with detailed molecular cooling treatment","Abstract:                _Results. We present the CHEMFAST code, that we developed to compute the cosmological 21cm neutral hydrogen line inside collapsing matter overdensity. We precisely track evolution in the abundances of ions, atoms and molecules through a network of chemical reactions. Computing the molecular thermal function due to th_         _ More           Context. In order to understand the formation of the first stars, which set the transition between the Dark Ages and Cosmic Dawn epochs, it is necessary to provide a detailed description of the physics at work within the first clouds of gas which, during their gravitational collapse, will set the conditions for stars to be form through the mechanism of thermal instability.   Aims. Our objective is to study in detail the molecular cooling of gas in the halos preceding the formation of the first stars. We are furthermore assessing the sensitivity of the 21cm hydrogen line to this cooling channel.   Results. We present the CHEMFAST code, that we developed to compute the cosmological 21cm neutral hydrogen line inside collapsing matter overdensity. We precisely track evolution in the abundances of ions, atoms and molecules through a network of chemical reactions. Computing the molecular thermal function due to the excitation of the rotational levels of the H2 molecule, we find it strongly affects the gas temperature inside collapsing clouds of $10^8$ M$_\\odot$. The gas temperature falls at the end of the collapse, when the molecular cooling takes over the heating due to gravitation.   Conclusions. We find that the 21cm brightness temperature inside the collapsing cloud presents an emission feature, different from the one predicted in expansion scenario. It moreover follows the same behavior as the gas temperature, as it is also strongly affected by the molecular cooling. This makes it a promising probe in order to map the collapsing halos and thermal processes at work inside them.         _ Less","","arXiv","https://arxiv.org/abs/2404.08479","1","1","multiple"
"MINCE II. Neutron capture elements","Abstract:                _neutron-capture elements but also of light elements and iron peak elements in a large sample of giant stars in this metallicity range. T The aim of this work is to study the chemical_         _ More           The MINCE (Measuring at Intermediate metallicity Neutron-Capture Elements) project aims to gather the abundances of neutron-capture elements but also of light elements and iron peak elements in a large sample of giant stars in this metallicity range. T The aim of this work is to study the chemical evolution of galactic sub-components recently identified (i.e. Gaia Sausage Enceladus (GSE), Sequoia). We used high signal-to-noise ratios, high-resolution spectra and standard 1D LTE spectrum synthesis to determine the detailed abundances. We could determine the abundances for up to 10 neutron-capture elements (Sr, Y, Zr, Ba, La, Ce, Pr, Nd, Sm and Eu) in 33 stars. The general trends of abundance ratios [n-capture element/Fe] versus [Fe/H] are in agreement with the results found in the literature. When our sample is divided in sub-groups depending on their kinematics, we found that the run of [Sr/Ba] vs [Ba/H] for the stars belonging to the GSE accretion event shows a tight anti-correlation. The results for the Sequoia stars, although based on a very limited sample, shows a [Sr/Ba] systematically higher than the [Sr/Ba] found in the GSE stars at a given [Ba/H] hinting at a different nucleosynthetic history. Stochastic chemical evolution models have been computed to understand the evolution of the GSE chemical composition of Sr and Ba. The first conclusions are that the GSE chemical evolution is similar to the evolution of a dwarf galaxy with galactic winds and inefficient star formation.   Detailed abundances of neutron-capture elements have been measured in high-resolution, high signal-to-noise spectra of intermediate metal-poor stars, the metallicity range covered by the MINCE project. These abundances have been compared to detailed stochastic models of galactic chemical evolution.         _ Less","","arXiv","https://arxiv.org/abs/2404.08418","2","1","origin_of_life"
"Galactic Chemical Evolution Models Favor an Extended Type Ia Supernova Delay-Time Distribution","Abstract:                Type Ia supernovae (SNe Ia) produce most of the Fe-peak elements in the Universe and therefore are a crucial ingredient in galactic chemical evolution models. SNe Ia do not explode immediately after star formation, and the delay-time distribution (DTD) has not been definitively determined by supernova surveys or theore_         _ More           Type Ia supernovae (SNe Ia) produce most of the Fe-peak elements in the Universe and therefore are a crucial ingredient in galactic chemical evolution models. SNe Ia do not explode immediately after star formation, and the delay-time distribution (DTD) has not been definitively determined by supernova surveys or theoretical models. Because the DTD also affects the relationship among age, [Fe/H], and [$_$/Fe] in chemical evolution models, comparison with observations of stars in the Milky Way is an important consistency check for any proposed DTD. We implement several popular forms of the DTD in combination with multiple star formation histories for the Milky Way in multi-zone chemical evolution models which include radial stellar migration. We compare our predicted interstellar medium abundance tracks, stellar abundance distributions, and stellar age distributions to the final data release of the Apache Point Observatory Galactic Evolution Experiment (APOGEE). We find that the DTD has the largest effect on the [$_$/Fe] distribution: a DTD with more prompt SNe Ia produces a stellar abundance distribution that is skewed toward a lower [$_$/Fe] ratio. While the DTD alone cannot explain the observed bimodality in the [$_$/Fe] distribution, in combination with an appropriate star formation history it affects the goodness of fit between the predicted and observed high-$_$ sequence. Our model results favor an extended DTD with fewer prompt SNe Ia than the fiducial $t^{-1}$ power law.         _ Less","","arXiv","https://arxiv.org/abs/2404.08059","3","2","origin_of_life"
"Time evolution as an optimization problem: The hydrogen atom in strong laser fields in a basis of time-dependent Gaussian wave packets","Abstract:                Recent advances in attosecond science have made it increasingly important to develop stable, reliable and accurate algorithms and methods to model the time evolution of atoms and molecules in intense laser fields. A key process in attosecond science is high-harmonic generation, which is challenging to model with fixed Gaussian basis sets, as it produces high_         _ More           Recent advances in attosecond science have made it increasingly important to develop stable, reliable and accurate algorithms and methods to model the time evolution of atoms and molecules in intense laser fields. A key process in attosecond science is high-harmonic generation, which is challenging to model with fixed Gaussian basis sets, as it produces high-energy electrons, with a resulting rapidly varying and highly oscillatory wave function that extends over dozens of _ngstr_m. Recently, Rothe's method, where time evolution is rephrased as an optimization problem, has been applied to the one-dimensional Schr_dinger equation. Here, we apply Rothe's method to the hydrogen wave function and demonstrate that complex-valued Gaussian wave packets with time-dependent width, center, and momentum parameters are able to reproduce spectra obtained from essentially exact grid calculations for high-harmonic generation with only 50-181 Gaussians for field strengths up to $5\\times 10^{14}$W/cm$^2$. This paves the way for the inclusion of continuum contributions into real-time, time-dependent electronic-structure theory with Gaussian basis sets for strong fields, and eventually accurate simulations of the time evolution of molecules without the Born-Oppenheimer approximation.         _ Less","","arXiv","https://arxiv.org/abs/2404.07699","0","1","synthetic_biology"
"Open-Source Protein Language Models for Function Prediction and Protein Design","Abstract:                _requires significant computational resources, limiting their accessibility. To address this, we integrate a PLM into DeepChem, an open-source framework for computational biology and chemistry, to provide a more accessible platform for protein-related tasks.   We evaluate the performance of the integrated model on various protein prediction tasks, showing tha_         _ More           Protein language models (PLMs) have shown promise in improving the understanding of protein sequences, contributing to advances in areas such as function prediction and protein engineering. However, training these models from scratch requires significant computational resources, limiting their accessibility. To address this, we integrate a PLM into DeepChem, an open-source framework for computational biology and chemistry, to provide a more accessible platform for protein-related tasks.   We evaluate the performance of the integrated model on various protein prediction tasks, showing that it achieves reasonable results across benchmarks. Additionally, we present an exploration of generating plastic-degrading enzyme candidates using the model's embeddings and latent space manipulation techniques. While the results suggest that further refinement is needed, this approach provides a foundation for future work in enzyme design. This study aims to facilitate the use of PLMs in research fields like synthetic biology and environmental sustainability, even for those with limited computational resources.         _ Less","","arXiv","https://arxiv.org/abs/2412.13519","0","2","synthetic_biology"
"Modeling therapy sequence for advanced cancer: A microsimulation approach leveraging Electronic Health Record data","Abstract:                _to estimate transition probabilities, and one using observed patient trajectories through the health states. We use bootstrap resampling to estimate standard errors. We create synthetic EHR-like datasets to evaluate these methods where within-patient transition times depend on covariates and a copula generator, and compare with Markov cohort models. We demon_         _ More           Many patients with advanced cancers undergo multiple lines of treatment. We develop methods for estimating quality-adjusted outcomes and cost-effectiveness of therapy sequences, informed by patient-level longitudinal data from Electronic Health Records (EHRs). We develop microsimulation models with a discrete-time health-state transition framework and propose two methods: one using multi-state models to estimate transition probabilities, and one using observed patient trajectories through the health states. We use bootstrap resampling to estimate standard errors. We create synthetic EHR-like datasets to evaluate these methods where within-patient transition times depend on covariates and a copula generator, and compare with Markov cohort models. We demonstrate these methods in two treatment sequences for advanced bladder cancer (cisplatin or carboplatin-based therapy followed by immunotherapy), incorporating external information on costs, utilities, and expected adverse event. Both methods produced well-calibrated overall survivals, although the trajectory approach was often superior. The multi-state model approach generated lower standard errors but was biased when compared to known results from the synthetic datasets. The observed trajectory approach mostly produced confidence intervals that covered known values. In the bladder cancer example, both methods result in a Net Monetary Benefit (NMB)>0 for the cisplatin-based treatment sequence with a willingness to pay of $100,000 per quality-adjusted life year. Both microsimulation methods produce well-calibrated results and offer superior performance to a homogeneous Markov cohort approach when studying therapy sequence. Where available, patient level EHR-based data should be considered to inform cost-effectiveness models.         _ Less","","arXiv","https://arxiv.org/abs/2412.13234","1","0","origin_of_life"
"Interplay of damage and repair in the control of epithelial tissue integrity in response to cyclic loading","Abstract:                _(ii) strain-regulated remodelling and damage accumulation, and (iii) repair mechanisms in epithelial tissues. We discuss how fatigue in biological tissues differs from synthetic materials, in that damage can be partially or fully reversed by repair mechanisms acting on timescales shorter than cyclic loading. We highlight that timescales are critical to unde_         _ More           Epithelial tissues are continuously exposed to cyclic stretch. Physiological stretching has been found to regulate soft tissue function at the molecular, cellular, and tissue scales, allowing tissues to preserve their homeostasis and adapt to challenges. In contrast, dysregulated or pathological stretching can induce damage and tissue fragilisation. Many mechanisms have been described for the repair of epithelial tissues across a range of time-scales. In this review, we present the timescales of (i) physiological cyclic loading regimes, (ii) strain-regulated remodelling and damage accumulation, and (iii) repair mechanisms in epithelial tissues. We discuss how fatigue in biological tissues differs from synthetic materials, in that damage can be partially or fully reversed by repair mechanisms acting on timescales shorter than cyclic loading. We highlight that timescales are critical to understanding the interplay between damage and repair in tissues that experience cyclic loading, opening up new avenues for exploring soft tissue homeostasis.         _ Less","","arXiv","https://arxiv.org/abs/2412.13040","1","2","synthetic_biology"
"Convolution goes higher-order: a biologically inspired mechanism empowers image classification","Abstract:                _convolution operator, capturing multiplicative interactions akin to those observed in early and advanced stages of biological visual processing. We evaluated this approach on synthetic datasets by measuring sensitivity to testing higher-order correlations and performance in standard benchmarks (MNIST, FashionMNIST, CIFAR10, CIFAR100 and Imagenette). Our arch_         _ More           We propose a novel approach to image classification inspired by complex nonlinear biological visual processing, whereby classical convolutional neural networks (CNNs) are equipped with learnable higher-order convolutions. Our model incorporates a Volterra-like expansion of the convolution operator, capturing multiplicative interactions akin to those observed in early and advanced stages of biological visual processing. We evaluated this approach on synthetic datasets by measuring sensitivity to testing higher-order correlations and performance in standard benchmarks (MNIST, FashionMNIST, CIFAR10, CIFAR100 and Imagenette). Our architecture outperforms traditional CNN baselines, and achieves optimal performance with expansions up to 3rd/4th order, aligning remarkably well with the distribution of pixel intensities in natural images. Through systematic perturbation analysis, we validate this alignment by isolating the contributions of specific image statistics to model performance, demonstrating how different orders of convolution process distinct aspects of visual information. Furthermore, Representational Similarity Analysis reveals distinct geometries across network layers, indicating qualitatively different modes of visual information processing. Our work bridges neuroscience and deep learning, offering a path towards more effective, biologically inspired computer vision models. It provides insights into visual information processing and lays the groundwork for neural networks that better capture complex visual patterns, particularly in resource-constrained scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2412.06740","1","1","multiple"
"The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications","Abstract:                _across many scientific disciplines. However, its real-world applications remain limited. Current methods often rely on unrealistic assumptions and are evaluated only on simple synthetic toy datasets, often with inadequate evaluation metrics. In this paper, we substantiate these claims by performing a systematic review of the recent causal discovery literatur_         _ More           Causal discovery aims to automatically uncover causal relationships from data, a capability with significant potential across many scientific disciplines. However, its real-world applications remain limited. Current methods often rely on unrealistic assumptions and are evaluated only on simple synthetic toy datasets, often with inadequate evaluation metrics. In this paper, we substantiate these claims by performing a systematic review of the recent causal discovery literature. We present applications in biology, neuroscience, and Earth sciences - fields where causal discovery holds promise for addressing key challenges. We highlight available simulated and real-world datasets from these domains and discuss common assumption violations that have spurred the development of new methods. Our goal is to encourage the community to adopt better evaluation practices by utilizing realistic datasets and more adequate metrics.         _ Less","","arXiv","https://arxiv.org/abs/2412.01953","1","1","multiple"
"The matter/life nexus in biological cells","Abstract:                _of life's heredity, evolution, and reproduction led to formation of the Central Dogma. With startling speed, technological development then gave rise to structural biology, systems biology, and synthetic biology - and a search to replic_         _ More           The search for what differentiates inanimate matter from living things began in antiquity as a search for a 'fundamental life force' embedded deep within living things - a special material unit owned only by life - later transforming to more circumspect search for unique gains in function that transform nonliving matter to that which can reproduce, adapt, and survive. Aristotelian thinking about the matter/life distinction and Vitalistic philosophy's 'vital force' persisted well into the Scientific Revolution, only to be debunked by Pasteur and Brown in the 19th century. Acceptance of the atomic reality and understanding of the uniqueness of life's heredity, evolution, and reproduction led to formation of the Central Dogma. With startling speed, technological development then gave rise to structural biology, systems biology, and synthetic biology - and a search to replicate and synthesize that 'gain in function' that transforms matter to life. Yet one still cannot build a living cell de novo from its atomic and molecular constituents, and 'that which I cannot create, I do not understand'. In the last two decades, new recognition of old ideas - spatial organization and compartmentalization - have renewed focus on Brownian and flow physics. In this Review, we explore how experimental and computational advances in the last decade have embraced the deep coupling between physics and cellular biochemistry to shed light on the matter/life nexus. Whole-cell modeling and synthesis are offering promising new insights that may shed light on this nexus in the cell's watery, crowded milieu.         _ Less","","arXiv","https://arxiv.org/abs/2412.01743","2","5","synthetic_biology"
"Differential learning kinetics govern the transition from memorization to generalization during in-context learning","Abstract:                _a network's limited capacity to memorize favors generalization. Here, we examine the mechanistic underpinnings of this transition using a small transformer applied to a synthetic ICL task. Using theory and experiment, we show that the sub-circuits that memorize and generalize can be viewed as largely independent. The relative rates at which these sub-cir_         _ More           Transformers exhibit in-context learning (ICL): the ability to use novel information presented in the context without additional weight updates. Recent work shows that ICL emerges when models are trained on a sufficiently diverse set of tasks and the transition from memorization to generalization is sharp with increasing task diversity. One interpretation is that a network's limited capacity to memorize favors generalization. Here, we examine the mechanistic underpinnings of this transition using a small transformer applied to a synthetic ICL task. Using theory and experiment, we show that the sub-circuits that memorize and generalize can be viewed as largely independent. The relative rates at which these sub-circuits learn explains the transition from memorization to generalization, rather than capacity constraints. We uncover a memorization scaling law, which determines the task diversity threshold at which the network generalizes. The theory quantitatively explains a variety of other ICL-related phenomena, including the long-tailed distribution of when ICL is acquired, the bimodal behavior of solutions close to the task diversity threshold, the influence of contextual and data distributional statistics on ICL, and the transient nature of ICL.         _ Less","","arXiv","https://arxiv.org/abs/2412.00104","1","0","origin_of_life"
"The 2024 Motile Active Matter Roadmap","Abstract:                _agents covers a wide range, from nanomotors, cytoskeleton, and cells, to insects, fish, birds, and people. Inspired by biological active systems, various types of autonomous synthetic nano- and micromachines have been designed, which provide the basis for multifunctional, highly responsive, intelligent active materials. A major challenge for understanding an_         _ More           Activity and autonomous motion are fundamental aspects of many living and engineering systems. Here, the scale of biological agents covers a wide range, from nanomotors, cytoskeleton, and cells, to insects, fish, birds, and people. Inspired by biological active systems, various types of autonomous synthetic nano- and micromachines have been designed, which provide the basis for multifunctional, highly responsive, intelligent active materials. A major challenge for understanding and designing active matter is their inherent non-equilibrium nature due to persistent energy consumption, which invalidates equilibrium concepts such as free energy, detailed balance, and time-reversal symmetry. Furthermore, interactions in ensembles of active agents are often non-additive and non-reciprocal. An important aspect of biological agents is their ability to sense the environment, process this information, and adjust their motion accordingly. It is an important goal for the engineering of micro-robotic systems to achieve similar functionality. With many fundamental properties of motile active matter now reasonably well understood and under control, the ground is prepared for the study of physical aspects and mechanisms of motion in complex environments, of the behavior of systems with new physical features like chirality, of the development of novel micromachines and microbots, of the emergent collective behavior and swarming of intelligent self-propelled particles, and of particular features of microbial systems. The vast complexity of phenomena and mechanisms involved in the self-organization and dynamics of motile active matter poses major challenges, which can only be addressed by a truly interdisciplinary effort involving scientists from biology, chemistry, ecology, engineering, mathematics, and physics.         _ Less","","arXiv","https://arxiv.org/abs/2411.19783","1","1","multiple"
"Synthetic frequency-controlled gene circuits unlock expanded cellular states","Abstract:                _of frequency-encoded signals in natural systems, fundamental challenges in designing and implementing frequency-responsive gene circuits have limited their development in synthetic_         _ More           Natural biological systems process environmental information through both amplitude and frequency-modulated signals, yet engineered biological circuits have largely relied on amplitude-based regulation alone. Despite the prevalence of frequency-encoded signals in natural systems, fundamental challenges in designing and implementing frequency-responsive gene circuits have limited their development in synthetic biology. Here we present a Time-Resolved Gene Circuit (TRGC) architecture that enables frequency-to-amplitude signal conversion in engineered biological systems. Through systematic analysis, we establish a theoretical framework that guides the design of synthetic circuits capable of distinct frequency-dependent responses, implementing both high-pass and low-pass filtering behaviors. To enable rigorous characterization of these dynamic circuits, we developed a high-throughput automated platform that ensures stable and reproducible measurements of frequency-dependent r esponses across diverse conditions. Using this platform, we demonstrate that these frequency-modulated circuits can access cellular states unreachable through conventional amplitude modulation, significantly expanding the controllable gene expression space in multi-gene systems. Our results show that frequency modulation expands the range of achievable expression patterns when controlling multiple genes through a single input, demonstrating a new paradigm for engineering cellular behaviors. This work establishes frequency modulation as a powerful strategy for expanding the capabilities of engineered biological systems and enhancing cellular response to dynamic signals.         _ Less","","arXiv","https://arxiv.org/abs/2411.17158","1","2","synthetic_biology"
"An improved, high yield method for isolating nuclei from individual zebrafish embryos for single-nucleus RNA sequencing","Abstract:                Zebrafish are an ideal system to study the effect(s) of chemical, genetic, and environmental perturbations on development due to their high fecundity and fast growth. Recently, single cell sequencing has emerged as a powerful tool to measure the effect of these perturbations at a whole embryo scale. These types of experiments rely on the ability to isolate nuclei from a large number of individuall_         _ More           Zebrafish are an ideal system to study the effect(s) of chemical, genetic, and environmental perturbations on development due to their high fecundity and fast growth. Recently, single cell sequencing has emerged as a powerful tool to measure the effect of these perturbations at a whole embryo scale. These types of experiments rely on the ability to isolate nuclei from a large number of individually barcoded zebrafish embryos in parallel. Here we report a method for efficiently isolating high-quality nuclei from zebrafish embryos in a 96-well plate format by bead homogenization in a lysis buffer. Through head-to-head sciPlex-RNA-seq experiments, we demonstrate that this method represents a substantial improvement over enzymatic dissociation and that it is compatible with a wide range of developmental stages.         _ Less","","arXiv","https://arxiv.org/abs/2411.15309","0","1","synthetic_biology"
"Computational and Experimental Exploration of Protein Fitness Landscapes: Navigating Smooth and Rugged Terrains","Abstract:                Proteins evolve through complex sequence spaces, with fitness landscapes serving as a conceptual framework that links sequence to function. Fitness landscapes can be smooth, where multiple similarly accessible evolutionary paths are available, or rugged, where the presence of multiple local fitness optima complicate evolution and prediction. Indeed, many proteins, especially those with complex fun_         _ More           Proteins evolve through complex sequence spaces, with fitness landscapes serving as a conceptual framework that links sequence to function. Fitness landscapes can be smooth, where multiple similarly accessible evolutionary paths are available, or rugged, where the presence of multiple local fitness optima complicate evolution and prediction. Indeed, many proteins, especially those with complex functions or under multiple selection pressures, exist on rugged fitness landscapes. Here we discuss the theoretical framework that underpins our understanding of fitness landscapes, alongside recent work that has advanced our understanding - particularly the biophysical basis for smoothness versus ruggedness. Finally, we address the rapid advances that have been made in computational and experimental exploration and exploitation of fitness landscapes, and how these can identify efficient routes to protein optimization.         _ Less","","arXiv","https://arxiv.org/abs/2411.12957","0","1","synthetic_biology"
"MolParser: End-to-end Visual Recognition of Molecule Structures in the Wild","Abstract:                _information is embedded in molecular structure figures, complicating large-scale literature searches and limiting the application of large language models in fields such as biology, chemistry, and pharmaceuticals. The automatic extraction of precise chemical structures is of critical importance. However, the presence of numerous Markush structures in real-wo_         _ More           In recent decades, chemistry publications and patents have increased rapidly. A significant portion of key information is embedded in molecular structure figures, complicating large-scale literature searches and limiting the application of large language models in fields such as biology, chemistry, and pharmaceuticals. The automatic extraction of precise chemical structures is of critical importance. However, the presence of numerous Markush structures in real-world documents, along with variations in molecular image quality, drawing styles, and noise, significantly limits the performance of existing optical chemical structure recognition (OCSR) methods. We present MolParser, a novel end-to-end OCSR method that efficiently and accurately recognizes chemical structures from real-world documents, including difficult Markush structure. We use a extended SMILES encoding rule to annotate our training dataset. Under this rule, we build MolParser-7M, the largest annotated molecular image dataset to our knowledge. While utilizing a large amount of synthetic data, we employed active learning methods to incorporate substantial in-the-wild data, specifically samples cropped from real patents and scientific literature, into the training process. We trained an end-to-end molecular image captioning model, MolParser, using a curriculum learning approach. MolParser significantly outperforms classical and learning-based methods across most scenarios, with potential for broader downstream applications. The dataset is publicly available.         _ Less","","arXiv","https://arxiv.org/abs/2411.11098","1","0","origin_of_life"
"SDDBench: A Benchmark for Synthesizable Drug Design","Abstract:                _As a result, evaluating the synthesizability of molecules in general drug design scenarios remains a significant challenge in the field of drug discovery. The commonly used synthetic accessibility (SA) score aims to evaluate the ease of synthesizing generated molecules, but it falls short of guaranteeing that_         _ More           A significant challenge in wet lab experiments with current drug design generative models is the trade-off between pharmacological properties and synthesizability. Molecules predicted to have highly desirable properties are often difficult to synthesize, while those that are easily synthesizable tend to exhibit less favorable properties. As a result, evaluating the synthesizability of molecules in general drug design scenarios remains a significant challenge in the field of drug discovery. The commonly used synthetic accessibility (SA) score aims to evaluate the ease of synthesizing generated molecules, but it falls short of guaranteeing that synthetic routes can actually be found. Inspired by recent advances in top-down synthetic route generation, we propose a new, data-driven metric to evaluate molecule synthesizability. Our approach directly assesses the feasibility of synthetic routes for a given molecule through our proposed round-trip score. This novel metric leverages the synergistic duality between retrosynthetic planners and reaction predictors, both of which are trained on extensive reaction datasets. To demonstrate the efficacy of our method, we conduct a comprehensive evaluation of round-trip scores alongside search success rate across a range of representative molecule generative models. Code is available at https://github.com/SongtaoLiu0823/SDDBench.         _ Less","","arXiv","https://arxiv.org/abs/2411.08306","1","1","multiple"
"SynapsNet: Enhancing Neuronal Population Dynamics Modeling via Learning Functional Connectivity","Abstract:                _three distinct tasks, demonstrate that SynapsNet consistently outperforms existing models in forecasting population activity. Additionally, our experiments on both real and synthetic data showed that SynapsNet accurately learns functional connectivity that reveals predictive interactions between neurons.         _ More           The availability of large-scale neuronal population datasets necessitates new methods to model population dynamics and extract interpretable, scientifically translatable insights. Existing deep learning methods often overlook the biological mechanisms underlying population activity and thus exhibit suboptimal performance with neuronal data and provide little to no interpretable information about neurons and their interactions. In response, we introduce SynapsNet, a novel deep-learning framework that effectively models population dynamics and functional interactions between neurons. Within this biologically realistic framework, each neuron, characterized by a latent embedding, sends and receives currents through directed connections. A shared decoder uses the input current, previous neuronal activity, neuron embedding, and behavioral data to predict the population activity in the next time step. Unlike common sequential models that treat population activity as a multichannel time series, SynapsNet applies its decoder to each neuron (channel) individually, with the learnable functional connectivity serving as the sole pathway for information flow between neurons. Our experiments, conducted on mouse cortical activity from publicly available datasets and recorded using the two most common population recording modalities (Ca imaging and Neuropixels) across three distinct tasks, demonstrate that SynapsNet consistently outperforms existing models in forecasting population activity. Additionally, our experiments on both real and synthetic data showed that SynapsNet accurately learns functional connectivity that reveals predictive interactions between neurons.         _ Less","","arXiv","https://arxiv.org/abs/2411.08221","1","0","origin_of_life"
"Control-Oriented Models Inform Synthetic Biology Strategies in CAR T Cell Immunotherapy","Abstract:                _theoretical development of new therapeutic strategies. {Following this rationale, we propose the use of control-oriented models to guide the augmentation of CAR T therapy with synthetic gene circuitry. Here we present an initial investigation where we adapt a previously developed CAR T model for control-oriented purposes. We then explore the impact of realis_         _ More           Chimeric antigen receptor (CAR) T cell therapy is revolutionizing the treatment of blood cancers. Mathematical models that can predict the effectiveness of immunotherapies such as CAR T are of increasing interest due to their ability to reduce the number of experiments performed and to guide the theoretical development of new therapeutic strategies. {Following this rationale, we propose the use of control-oriented models to guide the augmentation of CAR T therapy with synthetic gene circuitry. Here we present an initial investigation where we adapt a previously developed CAR T model for control-oriented purposes. We then explore the impact of realistic alternative activation methods as control inputs to ensure effective tumor clearance.         _ Less","","arXiv","https://arxiv.org/abs/2411.07927","0","3","synthetic_biology"
"Neuropsychology and Explainability of AI: A Distributional Approach to the Relationship Between Activation Similarity of Neural Categories in Synthetic Cognition","Abstract:                _approach to the explainability of artificial neural networks, which involves using concepts from human cognitive psychology as relevant heuristic references for developing synthetic explanatory frameworks that align with human modes of thought. The analogical concepts mobilized here, which are intended to create such an epistemological bridge, are those of c_         _ More           We propose a neuropsychological approach to the explainability of artificial neural networks, which involves using concepts from human cognitive psychology as relevant heuristic references for developing synthetic explanatory frameworks that align with human modes of thought. The analogical concepts mobilized here, which are intended to create such an epistemological bridge, are those of categorization and similarity, as these notions are particularly suited to the categorical 'nature' of the reconstructive information processing performed by artificial neural networks. Our study aims to reveal a unique process of synthetic cognition, that of the categorical convergence of highly activated tokens. We attempt to explain this process with the idea that the categorical segment created by a neuron is actually the result of a superposition of categorical sub-dimensions within its input vector space.         _ Less","","arXiv","https://arxiv.org/abs/2411.07243","1","1","multiple"
"Analysing control-theoretic properties of nonlinear synthetic biology circuits","Abstract:        Synthetic_         _ More   Synthetic biology is a recent area of biological engineering, whose aim is to provide cells with novel functionalities. A number of important results regarding the development of control circuits in synthetic biology have been achieved during the last decade. A differential geometry approach can be used for the analysis of said systems, which are often nonlinear. Here we demonstrate the application of such tools to analyse the structural identifiability, observability, accessibility, and controllability of several biomolecular systems. We focus on a set of synthetic circuits of current interest, which can perform several tasks, both in open loop and closed loop settings. We analyse their properties with our own methods and tools; further, we describe a new open-source implementation of the techniques.         _ Less","","arXiv","https://arxiv.org/abs/2411.05450","0","1","synthetic_biology"
"Automated Classification of Cell Shapes: A Comparative Evaluation of Shape Descriptors","Abstract:                _of various features for shape classification, including Elliptical Fourier Descriptors, curvature features, and lower dimensional representations. Using an annotated synthetic dataset of noisy contours, we identify the most suitable shape descriptors and apply them to a set of real images for qualitative analysis. Our aim is to provide a comprehensive evalua_         _ More           This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images. We assess the performance of various features for shape classification, including Elliptical Fourier Descriptors, curvature features, and lower dimensional representations. Using an annotated synthetic dataset of noisy contours, we identify the most suitable shape descriptors and apply them to a set of real images for qualitative analysis. Our aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization-critical tasks in both biological research and histopathological assessments.         _ Less","","arXiv","https://arxiv.org/abs/2411.00561","1","1","multiple"
"Absorb & Escape: Overcoming Single Model Limitations in Generating Genomic Sequences","Abstract:                Abstract Recent advances in immunology and synthetic biology have accelerated the development of deep generative methods for DNA sequence design. Two dominant approaches in this field are AutoRegressive (AR) models and Diffusion Models (DMs). However, genomic sequences are functionally heterogeneous, consisting of mult_         _ More           Abstract Recent advances in immunology and synthetic biology have accelerated the development of deep generative methods for DNA sequence design. Two dominant approaches in this field are AutoRegressive (AR) models and Diffusion Models (DMs). However, genomic sequences are functionally heterogeneous, consisting of multiple connected regions (e.g., Promoter Regions, Exons, and Introns) where elements within each region come from the same probability distribution, but the overall sequence is non-homogeneous. This heterogeneous nature presents challenges for a single model to accurately generate genomic sequences. In this paper, we analyze the properties of AR models and DMs in heterogeneous genomic sequence generation, pointing out crucial limitations in both methods: (i) AR models capture the underlying distribution of data by factorizing and learning the transition probability but fail to capture the global property of DNA sequences. (ii) DMs learn to recover the global distribution but tend to produce errors at the base pair level. To overcome the limitations of both approaches, we propose a post-training sampling method, termed Absorb & Escape (A&E) to perform compositional generation from AR models and DMs. This approach starts with samples generated by DMs and refines the sample quality using an AR model through the alternation of the Absorb and Escape steps. To assess the quality of generated sequences, we conduct extensive experiments on 15 species for conditional and unconditional DNA generation. The experiment results from motif distribution, diversity checks, and genome integration tests unequivocally show that A&E outperforms state-of-the-art AR models and DMs in genomic sequence generation.         _ Less","","arXiv","https://arxiv.org/abs/2410.21345","0","1","synthetic_biology"
"Push-Forward Signed Distance Functions enable interpretable and robust continuous shape quantification","Abstract:                _Procrustes Analysis, such as coefficient correlations and landmark choices. We present the PF-SDM theory, provide a practically computable algorithm, and benchmark it on synthetic data.         _ More           We introduce the Push-Forward Signed Distance Morphometric (PF-SDM), a novel method for shape quantification in biomedical imaging that is continuous, interpretable, and invariant to shape-preserving transformations. PF-SDM effectively captures the geometric properties of shapes, including their topological skeletons and radial symmetries. This results in a robust and interpretable shape descriptor that generalizes to capture temporal shape dynamics. Importantly, PF-SDM avoids certain issues of previous geometric morphometrics, like Elliptical Fourier Analysis and Generalized Procrustes Analysis, such as coefficient correlations and landmark choices. We present the PF-SDM theory, provide a practically computable algorithm, and benchmark it on synthetic data.         _ Less","","arXiv","https://arxiv.org/abs/2410.21004","1","0","origin_of_life"
"Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision","Abstract:                _of PeptideGPT in de novo protein design and underscore the potential of leveraging NLP-based approaches for paving the way for future innovations and breakthroughs in synthetic biology and bioinformatics. Codes, models, and data used in this study are freely available at: https://github.com/aayush-shah14/PeptideGPT.         _ More           In recent years, natural language processing (NLP) models have demonstrated remarkable capabilities in various domains beyond traditional text generation. In this work, we introduce PeptideGPT, a protein language model tailored to generate protein sequences with distinct properties: hemolytic activity, solubility, and non-fouling characteristics. To facilitate a rigorous evaluation of these generated sequences, we established a comprehensive evaluation pipeline consisting of ideas from bioinformatics to retain valid proteins with ordered structures. First, we rank the generated sequences based on their perplexity scores, then we filter out those lying outside the permissible convex hull of proteins. Finally, we predict the structure using ESMFold and select the proteins with pLDDT values greater than 70 to ensure ordered structure. The properties of generated sequences are evaluated using task-specific classifiers - PeptideBERT and HAPPENN. We achieved an accuracy of 76.26% in hemolytic, 72.46% in non-hemolytic, 78.84% in non-fouling, and 68.06% in solubility protein generation. Our experimental results demonstrate the effectiveness of PeptideGPT in de novo protein design and underscore the potential of leveraging NLP-based approaches for paving the way for future innovations and breakthroughs in synthetic biology and bioinformatics. Codes, models, and data used in this study are freely available at: https://github.com/aayush-shah14/PeptideGPT.         _ Less","","arXiv","https://arxiv.org/abs/2410.19222","1","2","synthetic_biology"
"Tipping points in fitness landscape of heterogeneous populations","Abstract:                _to quantify fitness dynamics and predict critical transitions in heterogeneous populations. The results can be extended further to model fitness landscapes of natural and synthetic multi-species consortia exposed to environmental fluctuations mimicking climatic shifts and immunopathological settings.         _ More           Predicting fitness of biologically-active populations, communities or systems in fluctuating environments is a long-standing challenge. Phenotypic plasticity and bet-hedging strategy, two key evolutionary traits living systems harness to optimize fitness in dynamic environments, have been widely reported yet how interplays therein could mediate fitness landscapes of heterogeneous populations remain unknown. Leveraging the financial asset pricing model, here we provide a dynamical framework for fitness of heterogeneous populations, underpinned by the interrelations between sub-populations exhibiting phenotypic plasticity and bet-hedgeding. Our framework, independent of the definition of fitness, employs a nonlinear difference equation to present fitness dynamics, and capture the emergence of tipping points, marking the onset of critical state transitions which lead to catastrophic shifts. This study identifies limits on the selective advantage conferred by bet-hedging through reduction in the temporal variance of fitness, with far-reaching ramifications on our current understanding of hedging-mediated fitness enhancement of a population. The lower bound of the effective fitness variance is set by a maximum number of bet-hedgers, beyond which the fitness landscape approaches critical transition, as confirmed by critical slowing down in the vicinity of tipping points. We estimate the scaling law for the critical slowing down numerically and derive the characteristic recovery time for heterogeneous populations. Taken together, our work provides a generic theoretical framework to quantify fitness dynamics and predict critical transitions in heterogeneous populations. The results can be extended further to model fitness landscapes of natural and synthetic multi-species consortia exposed to environmental fluctuations mimicking climatic shifts and immunopathological settings.         _ Less","","arXiv","https://arxiv.org/abs/2410.17791","1","1","multiple"
"The Interplay Between Physical Activity, Protein Consumption, and Sleep Quality in Muscle Protein Synthesis","Abstract:                _stimulates MPS post-resistance training. It is observed that physically frail individuals aged 76 to 92 and middle-aged adults aged 62 to 74 have lower mixed muscle protein synthetic rates than individuals aged 20 to 32. High-whey protein and leucine-enriched supplements enhance MPS more efficiently than standard dairy products in older adults engaged in res_         _ More           This systematic review examines the synergistic and individual influences of resistance exercise, dietary protein supplementation, and sleep/recovery on muscle protein synthesis (MPS). Electronic databases such as Scopus, Google Scholar, and Web of Science were extensively used. Studies were selected based on relevance to the criteria and were ensured to be directly applicable to the objectives. Research indicates that a protein dose of 20 to 25 grams maximally stimulates MPS post-resistance training. It is observed that physically frail individuals aged 76 to 92 and middle-aged adults aged 62 to 74 have lower mixed muscle protein synthetic rates than individuals aged 20 to 32. High-whey protein and leucine-enriched supplements enhance MPS more efficiently than standard dairy products in older adults engaged in resistance programs. Similarly, protein intake before sleep boosts overnight MPS rates, which helps prevent muscle loss associated with sleep debt, exercise-induced damage, and muscle-wasting conditions like sarcopenia and cachexia. Resistance exercise is a functional intervention to achieve muscular adaptation and improve function. Future research should focus on variables such as fluctuating fitness levels, age groups, genetics, and lifestyle factors to generate more accurate and beneficial results.         _ Less","","arXiv","https://arxiv.org/abs/2410.16169","1","3","synthetic_biology"
"Molecular Signal Reception in Complex Vessel Networks: The Role of the Network Topology","Abstract:                The notion of synthetic molecular communication (MC) refers to the transmission of information via molecules and is largely foreseen for use within the human body, where traditional electromagnetic wave (EM)-based communication is impractical. MC is anticipated to enable innovative medical applications, such as early-stage tumor detection, targeted drug deli_         _ More           The notion of synthetic molecular communication (MC) refers to the transmission of information via molecules and is largely foreseen for use within the human body, where traditional electromagnetic wave (EM)-based communication is impractical. MC is anticipated to enable innovative medical applications, such as early-stage tumor detection, targeted drug delivery, and holistic approaches like the Internet of Bio-Nano Things (IoBNT). Many of these applications involve parts of the human cardiovascular system (CVS), here referred to as networks, posing challenges for MC due to their complex, highly branched vessel structures. To gain a better understanding of how the topology of such branched vessel networks affects the reception of a molecular signal at a target location, e.g., the network outlet, we present a generic analytical end-to-end model that characterizes molecule propagation and reception in linear branched vessel networks (LBVNs). We specialize this generic model to any MC system employing superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules and a planar coil as receiver (RX). By considering components that have been previously established in testbeds, we effectively isolate the impact of the network topology and validate our theoretical model with testbed data. Additionally, we propose two metrics, namely the molecule delay and the multi-path spread, that relate the LBVN topology to the molecule dispersion induced by the network, thereby linking the network structure to the signal-to-noise ratio (SNR) at the target location. This allows the characterization of the SNR at any point in the network solely based on the network topology. Consequently, our framework can, e.g., be exploited for optimal sensor placement in the CVS or identification of suitable testbed topologies for given SNR requirements.         _ Less","","arXiv","https://arxiv.org/abs/2410.15943","1","0","origin_of_life"
"Learning to refine domain knowledge for biological network inference","Abstract:                _systems. Alternatively, amortized causal structure learning algorithms encode inductive biases through data simulation and train supervised models to recapitulate these synthetic graphs. However, realistically simulating_         _ More           Perturbation experiments allow biologists to discover causal relationships between variables of interest, but the sparsity and high dimensionality of these data pose significant challenges for causal structure learning algorithms. Biological knowledge graphs can bootstrap the inference of causal structures in these situations, but since they compile vastly diverse information, they can bias predictions towards well-studied systems. Alternatively, amortized causal structure learning algorithms encode inductive biases through data simulation and train supervised models to recapitulate these synthetic graphs. However, realistically simulating biology is arguably even harder than understanding a specific system. In this work, we take inspiration from both strategies and propose an amortized algorithm for refining domain knowledge, based on data observations. On real and synthetic datasets, we show that our approach outperforms baselines in recovering ground truth causal graphs and identifying errors in the prior knowledge with limited interventional data.         _ Less","","arXiv","https://arxiv.org/abs/2410.14436","1","0","origin_of_life"
"DPLM-2: A Multimodal Diffusion Protein Language Model","Abstract:                _with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer. By training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals. We also implement an efficient warm-up strategy to explo_         _ More           Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities. In this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures. To enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer. By training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals. We also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models. Empirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach. Moreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs, as well as providing structure-aware representations for predictive tasks.         _ Less","","arXiv","https://arxiv.org/abs/2410.13782","0","1","synthetic_biology"
"Optimal network sizes for most robust Turing patterns","Abstract:                _in large networks. Furthermore, we find that with multiple immobile nodes, differential diffusion ceases to be important for Turing patterns. Our findings may inform future synthetic biology approaches and provide insights into bridging the gap to complex developmental pathways.         _ More           Many cellular patterns exhibit a reaction-diffusion component, suggesting that Turing instability may contribute to pattern formation. However, biological gene-regulatory pathways are more complex than simple Turing activator-inhibitor models and generally do not require fine-tuning of parameters as dictated by the Turing conditions. To address these issues, we employ random matrix theory to analyze the Jacobian matrices of larger networks with robust statistical properties. Our analysis reveals that Turing patterns are more likely to occur by chance than previously thought and that the most robust Turing networks have an optimal size, surprisingly consisting only of a handful of molecular species, thus significantly increasing their identifiability in biological systems. This optimal size emerges from a tradeoff between the highest stability in small networks and the greatest instability with diffusion in large networks. Furthermore, we find that with multiple immobile nodes, differential diffusion ceases to be important for Turing patterns. Our findings may inform future synthetic biology approaches and provide insights into bridging the gap to complex developmental pathways.         _ Less","","arXiv","https://arxiv.org/abs/2410.11513","1","1","multiple"
"Unbiased estimation of second-order parameter sensitivities for stochastic reaction networks","Abstract:                Stochastic models for chemical reaction networks are increasingly popular in systems and synthetic biology. These models formulate the reaction dynamics as Continuous-Time Markov Chains (CTMCs) whose propensities are parameterized by a vector $_$ and parameter sensitivities are introduced as derivatives of their expect_         _ More           Stochastic models for chemical reaction networks are increasingly popular in systems and synthetic biology. These models formulate the reaction dynamics as Continuous-Time Markov Chains (CTMCs) whose propensities are parameterized by a vector $_$ and parameter sensitivities are introduced as derivatives of their expected outputs with respect to components of the parameter vector. Sensitivities characterise key properties of the output like robustness and are also at the heart of numerically efficient optimisation routines like Newton-type algorithms used in parameter inference and the design of of control mechanisms. Currently the only unbiased estimator for second-order sensitivities is based on the Girsanov transform and it often suffers from high estimator variance. We develop a novel estimator for second-order sensitivities by first rigorously deriving an integral representation of these sensitivities. We call the resulting method the Double Bernoulli Path Algorithm and illustrate its efficiency through numerical examples.         _ Less","","arXiv","https://arxiv.org/abs/2410.11471","0","2","synthetic_biology"
"Filtering coupled Wright-Fisher diffusions","Abstract:                _in closed form. We lay out pseudo codes for the implementation of the algorithms, discuss how to handle the unavailable quantities, and briefly illustrate the procedure with synthetic data.         _ More           Coupled Wright-Fisher diffusions have been recently introduced to model the temporal evolution of finitely-many allele frequencies at several loci. These are vectors of multidimensional diffusions whose dynamics are weakly coupled among loci through interaction coefficients, which make the reproductive rates for each allele depend on its frequencies at several loci. Here we consider the problem of filtering a coupled Wright-Fisher diffusion with parent-independent mutation, when this is seen as an unobserved signal in a hidden Markov model. We assume individuals are sampled multinomially at discrete times from the underlying population, whose type configuration at the loci is described by the diffusion states, and adapt recently introduced duality methods to derive the filtering and smoothing distributions. These respectively provide the conditional distribution of the diffusion states given past data, and that conditional on the entire dataset, and are key to be able to perform parameter inference on models of this type. We show that for this model these distributions are countable mixtures of tilted products of Dirichlet kernels, and describe their mixing weights and how these can be updated sequentially. The evaluation of the weights involves the transition probabilities of the dual process, which are not available in closed form. We lay out pseudo codes for the implementation of the algorithms, discuss how to handle the unavailable quantities, and briefly illustrate the procedure with synthetic data.         _ Less","","arXiv","https://arxiv.org/abs/2410.11429","0","1","synthetic_biology"
"CoTCoNet: An Optimized Coupled Transformer-Convolutional Network with an Adaptive Graph Reconstruction for Leukemia Detection","Abstract:                _features of leukocyte cells and employs a Population-based Meta-Heuristic Algorithm for feature selection and optimization. To mitigate data imbalance issues, we employ a synthetic leukocyte generator. In the evaluation phase, we initially assess CoTCoNet on a dataset containing 16,982 annotated cells, and it achieves remarkable accuracy and F1-Score rates o_         _ More           Swift and accurate blood smear analysis is an effective diagnostic method for leukemia and other hematological malignancies. However, manual leukocyte count and morphological evaluation using a microscope is time-consuming and prone to errors. Conventional image processing methods also exhibit limitations in differentiating cells due to the visual similarity between malignant and benign cell morphology. This limitation is further compounded by the skewed training data that hinders the extraction of reliable and pertinent features. In response to these challenges, we propose an optimized Coupled Transformer Convolutional Network (CoTCoNet) framework for the classification of leukemia, which employs a well-designed transformer integrated with a deep convolutional network to effectively capture comprehensive global features and scalable spatial patterns, enabling the identification of complex and large-scale hematological features. Further, the framework incorporates a graph-based feature reconstruction module to reveal the hidden or unobserved hard-to-see biological features of leukocyte cells and employs a Population-based Meta-Heuristic Algorithm for feature selection and optimization. To mitigate data imbalance issues, we employ a synthetic leukocyte generator. In the evaluation phase, we initially assess CoTCoNet on a dataset containing 16,982 annotated cells, and it achieves remarkable accuracy and F1-Score rates of 0.9894 and 0.9893, respectively. To broaden the generalizability of our model, we evaluate it across four publicly available diverse datasets, which include the aforementioned dataset. This evaluation demonstrates that our method outperforms current state-of-the-art approaches. We also incorporate an explainability approach in the form of feature visualization closely aligned with cell annotations to provide a deeper understanding of the framework.         _ Less","","arXiv","https://arxiv.org/abs/2410.08797","1","1","multiple"
"Synth-SONAR: Sonar Image Synthesis with Enhanced Diversity and Realism via Dual Diffusion Models and GPT Prompting","Abstract:                Sonar image synthesis is crucial for advancing applications in underwater exploration, marine biology, and defence. Traditional methods often rely on extensive and costly data collection using sonar sensors, jeopardizing data quality and diversity. To overcome these limitations, this study proposes a new sonar image synthesis framework, Synth-SONAR leveragin_         _ More           Sonar image synthesis is crucial for advancing applications in underwater exploration, marine biology, and defence. Traditional methods often rely on extensive and costly data collection using sonar sensors, jeopardizing data quality and diversity. To overcome these limitations, this study proposes a new sonar image synthesis framework, Synth-SONAR leveraging diffusion models and GPT prompting. The key novelties of Synth-SONAR are threefold: First, by integrating Generative AI-based style injection techniques along with publicly available real/simulated data, thereby producing one of the largest sonar data corpus for sonar research. Second, a dual text-conditioning sonar diffusion model hierarchy synthesizes coarse and fine-grained sonar images with enhanced quality and diversity. Third, high-level (coarse) and low-level (detailed) text-based sonar generation methods leverage advanced semantic information available in visual language models (VLMs) and GPT-prompting. During inference, the method generates diverse and realistic sonar images from textual prompts, bridging the gap between textual descriptions and sonar image generation. This marks the application of GPT-prompting in sonar imagery for the first time, to the best of our knowledge. Synth-SONAR achieves state-of-the-art results in producing high-quality synthetic sonar datasets, significantly enhancing their diversity and realism.         _ Less","","arXiv","https://arxiv.org/abs/2410.08612","1","0","origin_of_life"
"InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions","Abstract:                Understanding and designing biomolecules, such as proteins and small molecules, is central to advancing drug discovery, synthetic biology, and enzyme engineering. Recent breakthroughs in Artificial Intelligence (AI) have revolutionized biomolecular research, achieving remarkable accuracy in biomolecular prediction and_         _ More           Understanding and designing biomolecules, such as proteins and small molecules, is central to advancing drug discovery, synthetic biology, and enzyme engineering. Recent breakthroughs in Artificial Intelligence (AI) have revolutionized biomolecular research, achieving remarkable accuracy in biomolecular prediction and design. However, a critical gap remains between AI's computational power and researchers' intuition, using natural language to align molecular complexity with human intentions. Large Language Models (LLMs) have shown potential to interpret human intentions, yet their application to biomolecular research remains nascent due to challenges including specialized knowledge requirements, multimodal data integration, and semantic alignment between natural language and biomolecules. To address these limitations, we present InstructBioMol, a novel LLM designed to bridge natural language and biomolecules through a comprehensive any-to-any alignment of natural language, molecules, and proteins. This model can integrate multimodal biomolecules as input, and enable researchers to articulate design goals in natural language, providing biomolecular outputs that meet precise biological needs. Experimental results demonstrate InstructBioMol can understand and design biomolecules following human instructions. Notably, it can generate drug molecules with a 10% improvement in binding affinity and design enzymes that achieve an ESP Score of 70.4, making it the only method to surpass the enzyme-substrate interaction threshold of 60.0 recommended by the ESP developer. This highlights its potential to transform real-world biomolecular research.         _ Less","","arXiv","https://arxiv.org/abs/2410.07919","1","4","synthetic_biology"
"Siamese networks for Poincar_ embeddings and the reconstruction of evolutionary trees","Abstract:                _Unlike previous work, we employ Siamese networks to learn embeddings from only leaf node samples of the latent tree. We demonstrate our method's effectiveness on both synthetic data and spectrograms from six species of finches.         _ More           We present a method for reconstructing evolutionary trees from high-dimensional data, with a specific application to bird song spectrograms. We address the challenge of inferring phylogenetic relationships from phenotypic traits, like vocalizations, without predefined acoustic properties. Our approach combines two main components: Poincar_ embeddings for dimensionality reduction and distance computation, and the neighbor joining algorithm for tree reconstruction. Unlike previous work, we employ Siamese networks to learn embeddings from only leaf node samples of the latent tree. We demonstrate our method's effectiveness on both synthetic data and spectrograms from six species of finches.         _ Less","","arXiv","https://arxiv.org/abs/2410.07387","0","1","synthetic_biology"
"How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension","Abstract:                _and node features. However, the potential of LLMs in graph pattern mining remains largely unexplored. This is a key component in fields such as computational chemistry, biology, and social network analysis. To bridge this gap, this work introduces a comprehensive benchmark to assess LLMs' capabilities in graph pattern tasks. We have developed a benchmark_         _ More           Benchmarking the capabilities and limitations of large language models (LLMs) in graph-related tasks is becoming an increasingly popular and crucial area of research. Recent studies have shown that LLMs exhibit a preliminary ability to understand graph structures and node features. However, the potential of LLMs in graph pattern mining remains largely unexplored. This is a key component in fields such as computational chemistry, biology, and social network analysis. To bridge this gap, this work introduces a comprehensive benchmark to assess LLMs' capabilities in graph pattern tasks. We have developed a benchmark that evaluates whether LLMs can understand graph patterns based on either terminological or topological descriptions. Additionally, our benchmark tests the LLMs' capacity to autonomously discover graph patterns from data. The benchmark encompasses both synthetic and real datasets, and a variety of models, with a total of 11 tasks and 7 models. Our experimental framework is designed for easy expansion to accommodate new models and datasets. Our findings reveal that: (1) LLMs have preliminary abilities to understand graph patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting input data to align with the knowledge acquired during pretraining can enhance performance; (3) The strategies employed by LLMs may differ from those used in conventional algorithms.         _ Less","","arXiv","https://arxiv.org/abs/2410.05298","1","1","multiple"
"Generating Seamless Virtual Immunohistochemical Whole Slide Images with Content and Color Consistency","Abstract:                _clinical assessment and diagnoses. To address this limitation, we propose a novel consistent WSI synthesis network, CC-WSI-Net, that extends GAN models to produce seamless synthetic whole slide images. Our CC-WSI-Net integrates a content- and color-consistency supervisor, ensuring consistency across tiles and facilitating the generation of seamless_         _ More           Immunohistochemical (IHC) stains play a vital role in a pathologist's analysis of medical images, providing crucial diagnostic information for various diseases. Virtual staining from hematoxylin and eosin (H&E)-stained whole slide images (WSIs) allows the automatic production of other useful IHC stains without the expensive physical staining process. However, current virtual WSI generation methods based on tile-wise processing often suffer from inconsistencies in content, texture, and color at tile boundaries. These inconsistencies lead to artifacts that compromise image quality and potentially hinder accurate clinical assessment and diagnoses. To address this limitation, we propose a novel consistent WSI synthesis network, CC-WSI-Net, that extends GAN models to produce seamless synthetic whole slide images. Our CC-WSI-Net integrates a content- and color-consistency supervisor, ensuring consistency across tiles and facilitating the generation of seamless synthetic WSIs while ensuring Sox10 immunohistochemistry accuracy in melanocyte detection. We validate our method through extensive image-quality analyses, objective detection assessments, and a subjective survey with pathologists. By generating high-quality synthetic WSIs, our method opens doors for advanced virtual staining techniques with broader applications in research and clinical care.         _ Less","","arXiv","https://arxiv.org/abs/2410.01072","2","1","origin_of_life"
"Learning Stochastic Dynamics from Snapshots through Regularized Unbalanced Optimal Transport","Abstract:                _the connections between the RUOT and Schr_dinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddi_         _ More           Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learnt directly from data. Theoretically, we explore the connections between the RUOT and Schr_dinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape.         _ Less","","arXiv","https://arxiv.org/abs/2410.00844","1","1","multiple"
"Geometric shape matching for recovering protein conformations from single-particle Cryo-EM data","Abstract:                _group. By selecting a deformation energy, the optimality conditions are obtained, which lead to computational algorithms for optimal deformations. We showcase our approach on synthetic data, for which we recover the three-dimensional structure of the backbone.         _ More           We address recovery of the three-dimensional backbone structure of single polypeptide proteins from single-particle cryo-electron microscopy (Cryo-SPA) data. Cryo-SPA produces noisy tomographic projections of electrostatic potentials of macromolecules. From these projections, we use methods from shape analysis to recover the three-dimensional backbone structure. Thus, we view the reconstruction problem as an indirect matching problem, where a point cloud representation of the protein backbone is deformed to match 2D tomography data. The deformations are obtained via the action of a matrix Lie group. By selecting a deformation energy, the optimality conditions are obtained, which lead to computational algorithms for optimal deformations. We showcase our approach on synthetic data, for which we recover the three-dimensional structure of the backbone.         _ Less","","arXiv","https://arxiv.org/abs/2410.00833","1","0","origin_of_life"
"EnzymeFlow: Generating Reaction-specific Enzyme Catalytic Pockets through Flow Matching and Co-Evolutionary Dynamics","Abstract:                Enzyme design is a critical area in biotechnology, with applications ranging from drug development to synthetic biology. Traditional methods for enzyme function prediction or protein binding pocket design often fall short in capturing the dynamic and complex nature of enzyme-substrate interactions, particularly in cata_         _ More           Enzyme design is a critical area in biotechnology, with applications ranging from drug development to synthetic biology. Traditional methods for enzyme function prediction or protein binding pocket design often fall short in capturing the dynamic and complex nature of enzyme-substrate interactions, particularly in catalytic processes. To address the challenges, we introduce EnzymeFlow, a generative model that employs flow matching with hierarchical pre-training and enzyme-reaction co-evolution to generate catalytic pockets for specific substrates and catalytic reactions. Additionally, we introduce a large-scale, curated, and validated dataset of enzyme-reaction pairs, specifically designed for the catalytic pocket generation task, comprising a total of $328,192$ pairs. By incorporating evolutionary dynamics and reaction-specific adaptations, EnzymeFlow becomes a powerful model for designing enzyme pockets, which is capable of catalyzing a wide range of biochemical reactions. Experiments on the new dataset demonstrate the model's effectiveness in designing high-quality, functional enzyme catalytic pockets, paving the way for advancements in enzyme engineering and synthetic biology. We provide EnzymeFlow code at https://github.com/WillHua127/EnzymeFlow with notebook demonstration at https://github.com/WillHua127/EnzymeFlow/blob/main/enzymeflow_demo.ipynb.         _ Less","","arXiv","https://arxiv.org/abs/2410.00327","0","4","synthetic_biology"
"Single-shot reconstruction of three-dimensional morphology of biological cells in digital holographic microscopy using a physics-driven neural network","Abstract:                _phase-shifted holograms or angle scanning. The performance of the proposed MorpHoloNet is validated by reconstructing 3D morphologies and refractive index distributions from synthetic holograms of ellipsoids and experimental holograms of biological cells. The proposed deep learning model is utilized to reconstruct spatiotemporal variations in 3D translationa_         _ More           Recent advances in deep learning-based image reconstruction techniques have led to significant progress in phase retrieval using digital in-line holographic microscopy (DIHM). However, existing deep learning-based phase retrieval methods have technical limitations in generalization performance and three-dimensional (3D) morphology reconstruction from a single-shot hologram of biological cells. In this study, we propose a novel deep learning model, named MorpHoloNet, for single-shot reconstruction of 3D morphology by integrating physics-driven and coordinate-based neural networks. By simulating the optical diffraction of coherent light through a 3D phase shift distribution, the proposed MorpHoloNet is optimized by minimizing the loss between the simulated and input holograms on the sensor plane. Compared to existing DIHM methods that face challenges with twin image and phase retrieval problems, MorpHoloNet enables direct reconstruction of 3D complex light field and 3D morphology of a test sample from its single-shot hologram without requiring multiple phase-shifted holograms or angle scanning. The performance of the proposed MorpHoloNet is validated by reconstructing 3D morphologies and refractive index distributions from synthetic holograms of ellipsoids and experimental holograms of biological cells. The proposed deep learning model is utilized to reconstruct spatiotemporal variations in 3D translational and rotational behaviors and morphological deformations of biological cells from consecutive single-shot holograms captured using DIHM. MorpHoloNet would pave the way for advancing label-free, real-time 3D imaging and dynamic analysis of biological cells under various cellular microenvironments in biomedical and engineering fields.         _ Less","","arXiv","https://arxiv.org/abs/2409.20013","1","0","origin_of_life"
"ECG-Image-Database: A Dataset of ECG Images with Real-World Imaging and Scanning Artifacts; A Foundation for Computerized ECG Image Digitization and Analysis","Abstract:                _generated both digitally and physically. The toolkit was applied to 977 12-lead ECG records from the PTB-XL database and 1,000 from Emory Healthcare to create high-fidelity synthetic ECG images. These unique images were subjected to both programmatic distortions using ECG-Image-Kit and physical effects like soaking, staining, and mold growth, followed by sc_         _ More           We introduce the ECG-Image-Database, a large and diverse collection of electrocardiogram (ECG) images generated from ECG time-series data, with real-world scanning, imaging, and physical artifacts. We used ECG-Image-Kit, an open-source Python toolkit, to generate realistic images of 12-lead ECG printouts from raw ECG time-series. The images include realistic distortions such as noise, wrinkles, stains, and perspective shifts, generated both digitally and physically. The toolkit was applied to 977 12-lead ECG records from the PTB-XL database and 1,000 from Emory Healthcare to create high-fidelity synthetic ECG images. These unique images were subjected to both programmatic distortions using ECG-Image-Kit and physical effects like soaking, staining, and mold growth, followed by scanning and photography under various lighting conditions to create real-world artifacts.   The resulting dataset includes 35,595 software-labeled ECG images with a wide range of imaging artifacts and distortions. The dataset provides ground truth time-series data alongside the images, offering a reference for developing machine and deep learning models for ECG digitization and classification. The images vary in quality, from clear scans of clean papers to noisy photographs of degraded papers, enabling the development of more generalizable digitization algorithms.   ECG-Image-Database addresses a critical need for digitizing paper-based and non-digital ECGs for computerized analysis, providing a foundation for developing robust machine and deep learning models capable of converting ECG images into time-series. The dataset aims to serve as a reference for ECG digitization and computerized annotation efforts. ECG-Image-Database was used in the PhysioNet Challenge 2024 on ECG image digitization and classification.         _ Less","","arXiv","https://arxiv.org/abs/2409.16612","0","1","synthetic_biology"
"Iterative algorithms for the reconstruction of early states of prostate cancer growth","Abstract:                _cancer, we describe tumour dynamics using a phase-field model coupled with two reaction-diffusion equations for a nutrient and the local prostate-specific antigen. We generate synthetic data using a discretisation based on Isogeometric Analysis. Then, building on our previous analytical work (Beretta et al., SIAP (2024)), we propose an iterative reconstructi_         _ More           The development of mathematical models of cancer informed by time-resolved measurements has enabled personalised predictions of tumour growth and treatment response. However, frequent cancer monitoring is rare, and many tumours are treated soon after diagnosis with limited data. To improve the predictive capabilities of cancer models, we investigate the problem of recovering earlier tumour states from a single spatial measurement at a later time. Focusing on prostate cancer, we describe tumour dynamics using a phase-field model coupled with two reaction-diffusion equations for a nutrient and the local prostate-specific antigen. We generate synthetic data using a discretisation based on Isogeometric Analysis. Then, building on our previous analytical work (Beretta et al., SIAP (2024)), we propose an iterative reconstruction algorithm based on the Landweber scheme, showing local convergence with quantitative rates and exploring an adaptive step size that leads to faster reconstruction algorithms. Finally, we run simulations demonstrating high-quality reconstructions even with long time horizons and noisy data.         _ Less","","arXiv","https://arxiv.org/abs/2409.12844","0","1","synthetic_biology"
"EEG-based Decoding of Selective Visual Attention in Superimposed Videos","Abstract:                _information. Locating visual attention is a fundamental problem in neuroscience with potential applications in brain-computer interfaces. Conventional paradigms often use synthetic stimuli or static images, but visual stimuli in real life contain smooth and highly irregular dynamics. In this study, we show that these irregular dynamics in natural videos can_         _ More           Selective attention enables humans to efficiently process visual stimuli by enhancing important locations or objects and filtering out irrelevant information. Locating visual attention is a fundamental problem in neuroscience with potential applications in brain-computer interfaces. Conventional paradigms often use synthetic stimuli or static images, but visual stimuli in real life contain smooth and highly irregular dynamics. In this study, we show that these irregular dynamics in natural videos can be decoded from electroencephalography (EEG) signals to perform selective visual attention decoding. To this end, we propose an experimental paradigm in which participants attend to one of two superimposed videos, each showing a center-aligned person performing a stage act. We then train a stimulus-informed decoder to extract EEG signal components that are correlated with the motion patterns of the attended object, and show that this decoder can be used on unseen data to detect which of both objects is attended. Eye movements are also found to be correlated to the motion patterns in the attended video, despite the spatial overlap between the target and the distractor. We further show that these eye movements do not dominantly drive the EEG-based decoding and that complementary information exists in EEG and gaze data. Moreover, our results indicate that EEG also captures information about unattended objects. To our knowledge, this study is the first to explore EEG-based selective visual attention decoding on natural videos, opening new possibilities for experiment design in related fields.         _ Less","","arXiv","https://arxiv.org/abs/2409.12562","1","0","origin_of_life"
"A computational framework for optimal and Model Predictive Control of stochastic gene regulatory networks","Abstract:                Engineering biology requires precise control of biomolecular circuits, and Cybergenetics is the field dedicated to achieving this goal. A significant challenge in developing controllers for cellular functions is designing systems that can effectively manage molecular noise. To address this, there has been increasing effort to develop model-based controllers_         _ More           Engineering biology requires precise control of biomolecular circuits, and Cybergenetics is the field dedicated to achieving this goal. A significant challenge in developing controllers for cellular functions is designing systems that can effectively manage molecular noise. To address this, there has been increasing effort to develop model-based controllers for stochastic biomolecular systems, where a major difficulty lies in accurately solving the chemical master equation. In this work we develop a framework for optimal and Model Predictive Control of stochastic gene regulatory networks with three key advantageous features: high computational efficiency, the capacity to control the overall probability density function enabling the fine-tuning of the cell population to obtain complex shapes and behaviors (including bimodality and other emergent properties), and the capacity to handle high levels of intrinsic molecular noise. Our method exploits an efficient approximation of the Chemical Master Equation using Partial Integro-Differential Equations, which additionally enables the development of an effective adjoint-based optimization. We illustrate the performance of the methods presented through two relevant studies in Synthetic Biology: shaping bimodal cell populations and tracking moving target distributions via inducible gene regulatory circuits.         _ Less","","arXiv","https://arxiv.org/abs/2409.11036","0","1","synthetic_biology"
"GFlowNet Pretraining with Inexpensive Rewards","Abstract:                _offline drug-like molecule datasets, which conditions A-GFNs on inexpensive yet informative molecular descriptors such as drug-likeliness, topological polar surface area, and synthetic accessibility scores. These properties serve as proxy rewards, guiding A-GFNs towards regions of chemical space that exhibit desirable pharmacological properties. We further o_         _ More           Generative Flow Networks (GFlowNets), a class of generative models have recently emerged as a suitable framework for generating diverse and high-quality molecular structures by learning from unnormalized reward distributions. Previous works in this direction often restrict exploration by using predefined molecular fragments as building blocks, limiting the chemical space that can be accessed. In this work, we introduce Atomic GFlowNets (A-GFNs), a foundational generative model leveraging individual atoms as building blocks to explore drug-like chemical space more comprehensively. We propose an unsupervised pre-training approach using offline drug-like molecule datasets, which conditions A-GFNs on inexpensive yet informative molecular descriptors such as drug-likeliness, topological polar surface area, and synthetic accessibility scores. These properties serve as proxy rewards, guiding A-GFNs towards regions of chemical space that exhibit desirable pharmacological properties. We further our method by implementing a goal-conditioned fine-tuning process, which adapts A-GFNs to optimize for specific target properties. In this work, we pretrain A-GFN on the ZINC15 offline dataset and employ robust evaluation metrics to show the effectiveness of our approach when compared to other relevant baseline methods in drug design.         _ Less","","arXiv","https://arxiv.org/abs/2409.09702","1","1","multiple"
"The Future of Decoding Non-Standard Nucleotides: Leveraging Nanopore Sequencing for Expanded Genetic Codes","Abstract:                Expanding genetic codes from natural standard nucleotides to artificial non-standard nucleotides marks a significant advancement in synthetic_         _ More           Expanding genetic codes from natural standard nucleotides to artificial non-standard nucleotides marks a significant advancement in synthetic biology, with profound implications for biotechnology and medicine. Decoding the biological information encoded in these non-standard nucleotides presents new challenges, as traditional sequencing technologies are unable to recognize or interpret novel base pairings. In this perspective, we explore the potential of nanopore sequencing, which is uniquely suited to decipher both standard and non-standard nucleotides by directly measuring the biophysical properties of nucleic acids. Nanopore technology offers real-time, long-read sequencing without the need for amplification or synthesis, making it particularly advantageous for expanded genetic systems like Artificially Expanded Genetic Information Systems (AEGIS). We discuss how the adaptability of nanopore sequencing and advancements in data processing can unlock the potential of these synthetic genomes and open new frontiers in understanding and utilizing expanded genetic codes.         _ Less","","arXiv","https://arxiv.org/abs/2409.09314","1","1","multiple"
"Exploring Biological Neuronal Correlations with Quantum Generative Models","Abstract:                _through quantum machine learning, which can achieve efficient training with fewer parameters. In this work, we introduce a quantum generative model framework for generating synthetic data that captures the spatial and temporal correlations of biological neuronal activity. Our model demonstrates the ability to achieve reliable outcomes with fewer trainable pa_         _ More           Understanding of how biological neural networks process information is one of the biggest open scientific questions of our time. Advances in machine learning and artificial neural networks have enabled the modeling of neuronal behavior, but classical models often require a large number of parameters, complicating interpretability. Quantum computing offers an alternative approach through quantum machine learning, which can achieve efficient training with fewer parameters. In this work, we introduce a quantum generative model framework for generating synthetic data that captures the spatial and temporal correlations of biological neuronal activity. Our model demonstrates the ability to achieve reliable outcomes with fewer trainable parameters compared to classical methods. These findings highlight the potential of quantum generative models to provide new tools for modeling and understanding neuronal behavior, offering a promising avenue for future research in neuroscience.         _ Less","","arXiv","https://arxiv.org/abs/2409.09125","1","0","origin_of_life"
"Syntax-Guided Procedural Synthesis of Molecules","Abstract:                Designing synthetically accessible molecules and recommending analogs to unsynthesizable molecules are important problems for accelerating molecular discovery. We reconceptualize both problems using ideas from program synthesis. Drawing inspiration from syntax-guided synthesis approaches, we decouple the syntactic skeleton from the semantics of a_         _ More           Designing synthetically accessible molecules and recommending analogs to unsynthesizable molecules are important problems for accelerating molecular discovery. We reconceptualize both problems using ideas from program synthesis. Drawing inspiration from syntax-guided synthesis approaches, we decouple the syntactic skeleton from the semantics of a synthetic tree to create a bilevel framework for reasoning about the combinatorial space of synthesis pathways. Given a molecule we aim to generate analogs for, we iteratively refine its skeletal characteristics via Markov Chain Monte Carlo simulations over the space of syntactic skeletons. Given a black-box oracle to optimize, we formulate a joint design space over syntactic templates and molecular descriptors and introduce evolutionary algorithms that optimize both syntactic and semantic dimensions synergistically. Our key insight is that once the syntactic skeleton is set, we can amortize over the search complexity of deriving the program's semantics by training policies to fully utilize the fixed horizon Markov Decision Process imposed by the syntactic template. We demonstrate performance advantages of our bilevel framework for synthesizable analog generation and synthesizable molecule design. Notably, our approach offers the user explicit control over the resources required to perform synthesis and biases the design space towards simpler solutions, making it particularly promising for autonomous synthesis platforms.         _ Less","","arXiv","https://arxiv.org/abs/2409.05873","0","1","synthetic_biology"
"Limits on the computational expressivity of non-equilibrium biophysical processes","Abstract:                _and a creased 'energy landscape' with multiple basins. Our findings have implications for understanding and designing physical computing systems in both biological and synthetic chemical settings.         _ More           Many biological decision-making processes can be viewed as performing a classification task over a set of inputs, using various chemical and physical processes as 'biological hardware.' In this context, it is important to understand the inherent limitations on the computational expressivity of classification functions instantiated in biophysical media. Here, we model biochemical networks as Markov jump processes and train them to perform classification tasks, allowing us to investigate their computational expressivity. We reveal several unanticipated limitations on the input-output functions of these systems, which we further show can be lifted using biochemical mechanisms like promiscuous binding. We analyze the flexibility and sharpness of decision boundaries as well as the classification capacity of these networks. Additionally, we identify distinctive signatures of networks trained for classification, including the emergence of correlated subsets of spanning trees and a creased 'energy landscape' with multiple basins. Our findings have implications for understanding and designing physical computing systems in both biological and synthetic chemical settings.         _ Less","","arXiv","https://arxiv.org/abs/2409.05827","1","0","origin_of_life"
"Non-explosivity of endotactic stochastic reaction systems","Abstract:                Reaction networks have been widely used as generic models in diverse areas of applied science, such as biology, chemistry, ecology, epidemiology, and computer science. Reaction networks incorporating noisy effect are modelled as continuous time Markov chains (CTMC), and are called stochastic reaction systems. Non-explosivity is a concept that characterizes r_         _ More           Reaction networks have been widely used as generic models in diverse areas of applied science, such as biology, chemistry, ecology, epidemiology, and computer science. Reaction networks incorporating noisy effect are modelled as continuous time Markov chains (CTMC), and are called stochastic reaction systems. Non-explosivity is a concept that characterizes regularity of CTMCs. In this paper, we study non-explosivity of stochastic reaction systems, in the sense of their underlying CTMCs. By constructing a simple linear Lyapunov function, we obtain non-explosivity for a class of endotactic stochastic reaction systems containing second-order endotactic stochastic mass-action systems as a subset. As a consequence, we prove that every bimolecular weakly reversible stochastic mass-action system is non-explosive. We apply our results to diverse models in biochemistry, epidemiology, ecology, and synthetic biology in the literature.         _ Less","","arXiv","https://arxiv.org/abs/2409.05340","0","2","synthetic_biology"
"NeuralCRNs: A Natural Implementation of Learning in Chemical Reaction Networks","Abstract:                _to sense and react to the dynamic changes in their environment is a testament to the adaptive capabilities of their internal biochemical circuitry. One of the goals of synthetic_         _ More           The remarkable ability of single-celled organisms to sense and react to the dynamic changes in their environment is a testament to the adaptive capabilities of their internal biochemical circuitry. One of the goals of synthetic biology is to develop biochemical analogues of such systems to autonomously monitor and control biochemical processes. Such systems may have impactful applications in fields such as molecular diagnostics, smart therapeutics, and in vivo nanomedicine. So far, the attempts to create such systems have been focused on functionally replicating the behavior of traditional feedforward networks in abstract and DNA-based synthetic chemistries. However, the inherent incompatibility between digital and chemical modes of computation introduces several nonidealities into these implementations, making it challenging to realize them in practice. In this work, we present NeuralCRNs, a novel supervised learning framework constructed as a collection of deterministic chemical reaction networks (CRNs). Unlike prior works, the NeuralCRNs framework is founded on dynamical system-based learning implementations and, thus, results in chemically compatible computations. First, we show the construction and training of a supervised learning classifier for linear classification. We then extend this framework to support nonlinear classification. We then demonstrate the validity of our constructions by training and evaluating them first on several binary and multi-class classification datasets with complex class separation boundaries. Finally, we detail several considerations regarding the NeuralCRNs framework and elaborate on the pros and cons of our methodology compared to the existing works.         _ Less","","arXiv","https://arxiv.org/abs/2409.00034","0","2","synthetic_biology"
"A review of sequential Monte Carlo methods for real-time disease modeling","Abstract:                _demonstrating the algorithm's effectiveness in monitoring time-varying parameters such as the effective reproduction number. Case studies, including simulations with synthetic data and analysis of real-world COVID-19 data from Ireland, demonstrate the practical applicability of this approach for informing timely public health interventions.         _ More           Sequential Monte Carlo methods are a powerful framework for approximating the posterior distribution of a state variable in a sequential manner. They provide an attractive way of analyzing dynamic systems in real-time, taking into account the limitations of traditional approaches such as Markov Chain Monte Carlo methods, which are not well suited to data that arrives incrementally. This paper reviews and explores the application of Sequential Monte Carlo in dynamic disease modeling, highlighting its capacity for online inference and real-time adaptation to evolving disease dynamics. The integration of kernel density approximation techniques within the stochastic Susceptible-Exposed-Infectious-Recovered (SEIR) compartment model is examined, demonstrating the algorithm's effectiveness in monitoring time-varying parameters such as the effective reproduction number. Case studies, including simulations with synthetic data and analysis of real-world COVID-19 data from Ireland, demonstrate the practical applicability of this approach for informing timely public health interventions.         _ Less","","arXiv","https://arxiv.org/abs/2408.15739","1","3","synthetic_biology"
"Imaging mitochondrial calcium dynamics in the central nervous system","Abstract:                _In the last few decades, a panel of techniques have been developed to measure mitochondrial calcium dynamics, relying mostly on photonic microscopy, and including synthetic sensors, hybrid sensors and genetically encoded calcium sensors. The goal of this review is to endow the reader with a deep knowledge of the historical and latest tools to monitor mitocho_         _ More           Mitochondrial calcium handling is a particularly active research area in the neuroscience field, as it plays key roles in the regulation of several functions of the central nervous system, such as synaptic transmission and plasticity, astrocyte calcium signaling, neuronal activity{\\ldots} In the last few decades, a panel of techniques have been developed to measure mitochondrial calcium dynamics, relying mostly on photonic microscopy, and including synthetic sensors, hybrid sensors and genetically encoded calcium sensors. The goal of this review is to endow the reader with a deep knowledge of the historical and latest tools to monitor mitochondrial calcium events in the brain, as well as a comprehensive overview of the current state of the art in brain mitochondrial calcium signaling. We will discuss the main calcium probes used in the field, their mitochondrial targeting strategies, their key properties and major drawbacks. In addition, we will detail the main roles of mitochondrial calcium handling in neuronal tissues through an extended report of the recent studies using mitochondrial targeted calcium sensors in neuronal and astroglial cells, in vitro and in vivo.         _ Less","","arXiv","https://arxiv.org/abs/2408.12202","4","4","multiple"
"Robust Approximate Characterization of Single-Cell Heterogeneity in Microbial Growth","Abstract:                _possible without performing tracking, even at low temporal resolution. To this end, we infer the parameters of a stochastic multi-stage birth process model using the Bayesian Synthetic Likelihood method at varying temporal resolutions by subsampling microscopy sequences, for which ground truth tracking is available. Our results indicate, that the proposed ap_         _ More           Live-cell microscopy allows to go beyond measuring average features of cellular populations to observe, quantify and explain biological heterogeneity. Deep Learning-based instance segmentation and cell tracking form the gold standard analysis tools to process the microscopy data collected, but tracking in particular suffers severely from low temporal resolution. In this work, we show that approximating cell cycle time distributions in microbial colonies of C. glutamicum is possible without performing tracking, even at low temporal resolution. To this end, we infer the parameters of a stochastic multi-stage birth process model using the Bayesian Synthetic Likelihood method at varying temporal resolutions by subsampling microscopy sequences, for which ground truth tracking is available. Our results indicate, that the proposed approach yields high quality approximations even at very low temporal resolution, where tracking fails to yield reasonable results.         _ Less","","arXiv","https://arxiv.org/abs/2408.04501","0","2","synthetic_biology"
"Modeling Latent Neural Dynamics with Gaussian Process Switching Linear Dynamical Systems","Abstract:                _leverage a modified learning objective which improves the estimation accuracy of kernel hyperparameters compared to previous GP-SDE fitting approaches. We apply our method to synthetic data and data recorded in two neuroscience experiments and demonstrate favorable performance in comparison to the rSLDS.         _ More           Understanding how the collective activity of neural populations relates to computation and ultimately behavior is a key goal in neuroscience. To this end, statistical methods which describe high-dimensional neural time series in terms of low-dimensional latent dynamics have played a fundamental role in characterizing neural systems. Yet, what constitutes a successful method involves two opposing criteria: (1) methods should be expressive enough to capture complex nonlinear dynamics, and (2) they should maintain a notion of interpretability often only warranted by simpler linear models. In this paper, we develop an approach that balances these two objectives: the Gaussian Process Switching Linear Dynamical System (gpSLDS). Our method builds on previous work modeling the latent state evolution via a stochastic differential equation whose nonlinear dynamics are described by a Gaussian process (GP-SDEs). We propose a novel kernel function which enforces smoothly interpolated locally linear dynamics, and therefore expresses flexible -- yet interpretable -- dynamics akin to those of recurrent switching linear dynamical systems (rSLDS). Our approach resolves key limitations of the rSLDS such as artifactual oscillations in dynamics near discrete state boundaries, while also providing posterior uncertainty estimates of the dynamics. To fit our models, we leverage a modified learning objective which improves the estimation accuracy of kernel hyperparameters compared to previous GP-SDE fitting approaches. We apply our method to synthetic data and data recorded in two neuroscience experiments and demonstrate favorable performance in comparison to the rSLDS.         _ Less","","arXiv","https://arxiv.org/abs/2408.03330","0","1","synthetic_biology"
"Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis","Abstract:                _Our algorithm leverages pruning to provide an integrated estimation of channel importance, and ensembles to achieve better accuracy and provide a label probability. Using a synthetic multivariate time series classification dataset in which we control the amount of information carried by each of the channels, we first show that our algorithm is able to corre_         _ More           Multivariate Time Series Classification (MTSC) is a ubiquitous problem in science and engineering, particularly in neuroscience, where most data acquisition modalities involve the simultaneous time-dependent recording of brain activity in multiple brain regions. In recent years, Random Convolutional Kernel models such as ROCKET and MiniRocket have emerged as highly effective time series classification algorithms, capable of achieving state-of-the-art accuracy results with low computational load. Despite their success, these types of models face two major challenges when employed in neuroscience: 1) they struggle to deal with high-dimensional data such as EEG and MEG, and 2) they are difficult to interpret. In this work, we present a novel ROCKET-based algorithm, named Detach-Rocket Ensemble, that is specifically designed to address these two problems in MTSC. Our algorithm leverages pruning to provide an integrated estimation of channel importance, and ensembles to achieve better accuracy and provide a label probability. Using a synthetic multivariate time series classification dataset in which we control the amount of information carried by each of the channels, we first show that our algorithm is able to correctly recover the channel importance for classification. Then, using two real-world datasets, a MEG dataset and an EEG dataset, we show that Detach-Rocket Ensemble is able to provide both interpretable channel relevance and competitive classification accuracy, even when applied directly to the raw brain data, without the need for feature engineering.         _ Less","","arXiv","https://arxiv.org/abs/2408.02760","1","0","origin_of_life"
"GNUMAP: A Parameter-Free Approach to Unsupervised Dimensionality Reduction via Graph Neural Networks","Abstract:                _Network (GNN) methods stemming from contrastive learning, unsupervised node representation learning for graph data is rapidly gaining traction across various fields, from biology to molecular dynamics, where it is often used as a dimensionality reduction tool. However, there remains a significant gap in understanding the quality of the low-dimensional node r_         _ More           With the proliferation of Graph Neural Network (GNN) methods stemming from contrastive learning, unsupervised node representation learning for graph data is rapidly gaining traction across various fields, from biology to molecular dynamics, where it is often used as a dimensionality reduction tool. However, there remains a significant gap in understanding the quality of the low-dimensional node representations these methods produce, particularly beyond well-curated academic datasets. To address this gap, we propose here the first comprehensive benchmarking of various unsupervised node embedding techniques tailored for dimensionality reduction, encompassing a range of manifold learning tasks, along with various performance metrics. We emphasize the sensitivity of current methods to hyperparameter choices -- highlighting a fundamental issue as to their applicability in real-world settings where there is no established methodology for rigorous hyperparameter selection. Addressing this issue, we introduce GNUMAP, a robust and parameter-free method for unsupervised node representation learning that merges the traditional UMAP approach with the expressivity of the GNN framework. We show that GNUMAP consistently outperforms existing state-of-the-art GNN embedding methods in a variety of contexts, including synthetic geometric datasets, citation networks, and real-world biomedical data -- making it a simple but reliable dimensionality reduction tool.         _ Less","","arXiv","https://arxiv.org/abs/2407.21236","1","1","multiple"
"Diffusion-Based Generation of Neural Activity from Disentangled Latent Codes","Abstract:                _data. We apply our model, called Generating Neural Observations Conditioned on Codes with High Information (GNOCCHI), to time series neural data and test its application to synthetic and biological recordings of neural activity during reaching. In comparison to a VAE-based sequential autoencoder, GNOCCHI learns higher-quality latent spaces that are more clea_         _ More           Recent advances in recording technology have allowed neuroscientists to monitor activity from thousands of neurons simultaneously. Latent variable models are increasingly valuable for distilling these recordings into compact and interpretable representations. Here we propose a new approach to neural data analysis that leverages advances in conditional generative modeling to enable the unsupervised inference of disentangled behavioral variables from recorded neural activity. Our approach builds on InfoDiffusion, which augments diffusion models with a set of latent variables that capture important factors of variation in the data. We apply our model, called Generating Neural Observations Conditioned on Codes with High Information (GNOCCHI), to time series neural data and test its application to synthetic and biological recordings of neural activity during reaching. In comparison to a VAE-based sequential autoencoder, GNOCCHI learns higher-quality latent spaces that are more clearly structured and more disentangled with respect to key behavioral variables. These properties enable accurate generation of novel samples (unseen behavioral conditions) through simple linear traversal of the latent spaces produced by GNOCCHI. Our work demonstrates the potential of unsupervised, information-based models for the discovery of interpretable latent spaces from neural data, enabling researchers to generate high-quality samples from unseen conditions.         _ Less","","arXiv","https://arxiv.org/abs/2407.21195","1","0","origin_of_life"
"Statistical Survey of Chemical and Geometric Patterns on Protein Surfaces as a Blueprint for Protein-mimicking Nanoparticles","Abstract:                _niches similar to those observed in proteins), although there are also significant differences. Looking forward, this work provides a blueprint for the rational design of synthetic nanoobjects with further enhanced mimicry of proteins' surface properties.         _ More           Despite recent breakthroughs in understanding how protein sequence relates to structure and function, considerably less attention has been paid to the general features of protein surfaces beyond those regions involved in binding and catalysis. This paper provides a systematic survey of the universe of protein surfaces and quantifies the sizes, shapes, and curvatures of the positively/negatively charged and hydrophobic/hydrophilic surface patches as well as correlations between such patches. It then compares these statistics with the metrics characterizing nanoparticles functionalized with ligands terminated with positively and negatively charged ligands. These particles are of particular interest because they are also surface-patchy and have been shown to exhibit both antibiotic and anticancer activities - via selective interactions against various cellular structures - prompting loose analogies to proteins. Our analyses support such analogies in several respects (e.g., patterns of charged protrusions and hydrophobic niches similar to those observed in proteins), although there are also significant differences. Looking forward, this work provides a blueprint for the rational design of synthetic nanoobjects with further enhanced mimicry of proteins' surface properties.         _ Less","","arXiv","https://arxiv.org/abs/2407.14063","1","1","multiple"
"Differentiable Optimization of Similarity Scores Between Models and Brains","Abstract:                _cross-validated and regularized linear regression. We find no consistent threshold for a good similarity score - it depends on both the measure and the dataset. In addition, synthetic datasets optimized to maximize similarity scores initially learn the highest variance principal component of the target dataset, but some methods like angular Procrustes captur_         _ More           How do we know if two systems - biological or artificial - process information in a similar way? Similarity measures such as linear regression, Centered Kernel Alignment (CKA), Normalized Bures Similarity (NBS), and angular Procrustes distance, are often used to quantify this similarity. However, it is currently unclear what drives high similarity scores and even what constitutes a 'good' score. Here, we introduce a novel tool to investigate these questions by differentiating through similarity measures to directly maximize the score. Surprisingly, we find that high similarity scores do not guarantee encoding task-relevant information in a manner consistent with neural data; and this is particularly acute for CKA and even some variations of cross-validated and regularized linear regression. We find no consistent threshold for a good similarity score - it depends on both the measure and the dataset. In addition, synthetic datasets optimized to maximize similarity scores initially learn the highest variance principal component of the target dataset, but some methods like angular Procrustes capture lower variance dimensions much earlier than methods like CKA. To shed light on this, we mathematically derive the sensitivity of CKA, angular Procrustes, and NBS to the variance of principal component dimensions, and explain the emphasis CKA places on high variance components. Finally, by jointly optimizing multiple similarity measures, we characterize their allowable ranges and reveal that some similarity measures are more constraining than others. While current measures offer a seemingly straightforward way to quantify the similarity between neural systems, our work underscores the need for careful interpretation. We hope the tools we developed will be used by practitioners to better understand current and future similarity measures.         _ Less","","arXiv","https://arxiv.org/abs/2407.07059","1","0","origin_of_life"
"Synthetic data: How could it be used for infectious disease research?","Abstract:                Over the last three to five years, it has become possible to generate machine learning synthetic data for healthcare-related uses. However, concerns have been raised about potential negative factors associated with the possibilities of artificial dataset generation. These include the potential misuse of generative artificial intelligence (AI) in fields such_         _ More           Over the last three to five years, it has become possible to generate machine learning synthetic data for healthcare-related uses. However, concerns have been raised about potential negative factors associated with the possibilities of artificial dataset generation. These include the potential misuse of generative artificial intelligence (AI) in fields such as cybercrime, the use of deepfakes and fake news to deceive or manipulate, and displacement of human jobs across various market sectors.   Here, we consider both current and future positive advances and possibilities with synthetic datasets. Synthetic data offers significant benefits, particularly in data privacy, research, in balancing datasets and reducing bias in machine learning models. Generative AI is an artificial intelligence genre capable of creating text, images, video or other data using generative models. The recent explosion of interest in GenAI was heralded by the invention and speedy move to use of large language models (LLM). These computational models are able to achieve general-purpose language generation and other natural language processing tasks and are based on transformer architectures, which made an evolutionary leap from previous neural network architectures.   Fuelled by the advent of improved GenAI techniques and wide scale usage, this is surely the time to consider how synthetic data can be used to advance infectious disease research. In this commentary we aim to create an overview of the current and future position of synthetic data in infectious disease research.         _ Less","","arXiv","https://arxiv.org/abs/2407.06211","1","2","synthetic_biology"
"Synthetic Data for Discriminating Serotonergic Neurons using Convolutional Neural Networks","Abstract:                _serotonergic neurons is an interesting one, but the key challenge is often given by the limited experimental data available for training. This study presents a procedure for synthetic data generation that combines smoothed spike waveforms with heterogeneous noise masks from real recordings. This approach expanded the training set while mitigating overfitting_         _ More           Serotonergic neurons in the raphe nuclei exhibit diverse electrophysiological properties and functional roles, yet conventional identification methods rely on restrictive criteria that likely overlook atypical serotonergic cells. The use of convolutional neural network (CNN) for comprehensive classification of both typical and atypical serotonergic neurons is an interesting one, but the key challenge is often given by the limited experimental data available for training. This study presents a procedure for synthetic data generation that combines smoothed spike waveforms with heterogeneous noise masks from real recordings. This approach expanded the training set while mitigating overfitting of background noise signatures. CNN models trained on the augmented dataset achieved high accuracy (96.2% true positive rate, 88.8% true negative rate) on non-homogeneous test data collected under different experimental conditions than the training, validation and testing data.         _ Less","","arXiv","https://arxiv.org/abs/2407.05701","1","1","multiple"
"A differentiable Gillespie algorithm for simulating chemical kinetics, parameter estimation, and designing synthetic biological circuits","Abstract:                _input-output relationships. These examples illustrate the utility of the DGA for analyzing stochastic chemical kinetics, including a wide variety of problems of interest to synthetic and systems biology.         _ More           The Gillespie algorithm is commonly used to simulate and analyze complex chemical reaction networks. Here, we leverage recent breakthroughs in deep learning to develop a fully differentiable variant of the Gillespie algorithm. The differentiable Gillespie algorithm (DGA) approximates discontinuous operations in the exact Gillespie algorithm using smooth functions, allowing for the calculation of gradients using backpropagation. The DGA can be used to quickly and accurately learn kinetic parameters using gradient descent and design biochemical networks with desired properties. As an illustration, we apply the DGA to study stochastic models of gene promoters. We show that the DGA can be used to: (i) successfully learn kinetic parameters from experimental measurements of mRNA expression levels from two distinct $\\textit{E. coli}$ promoters and (ii) design nonequilibrium promoter architectures with desired input-output relationships. These examples illustrate the utility of the DGA for analyzing stochastic chemical kinetics, including a wide variety of problems of interest to synthetic and systems biology.         _ Less","","arXiv","https://arxiv.org/abs/2407.04865","0","1","synthetic_biology"
"A data-driven approach to modeling brain activity using differential equations","Abstract:                _data and prior domain knowledge to recover differential equations. The algorithm's practicality in real-world scenarios is demonstrated through its application on both synthetic and real datasets.         _ More           This research focuses on an innovative task of extracting equations from incomplete data, moving away from traditional methods used for complete solutions. The study addresses the challenge of extracting equations from data, particularly in the study of brain activity using electrophysiological data, which is often limited by insufficient information. The study provides a brief review of existing open-source equation derivation approaches in the context of modeling brain activity. The section below introduces a novel algorithm that employs incomplete data and prior domain knowledge to recover differential equations. The algorithm's practicality in real-world scenarios is demonstrated through its application on both synthetic and real datasets.         _ Less","","arXiv","https://arxiv.org/abs/2407.00824","2","1","origin_of_life"
"WENDY: Covariance Dynamics Based Gene Regulatory Network Inference","Abstract:                Determining gene regulatory network (GRN) structure is a central problem in biology, with a variety of inference methods available for different types of data. For a widely prevalent and challenging use case, namely single-cell gene expression data measured after intervention at multiple time points with unknown joint distributions, there is only one known s_         _ More           Determining gene regulatory network (GRN) structure is a central problem in biology, with a variety of inference methods available for different types of data. For a widely prevalent and challenging use case, namely single-cell gene expression data measured after intervention at multiple time points with unknown joint distributions, there is only one known specifically developed method, which does not fully utilize the rich information contained in this data type. We develop an inference method for the GRN in this case, netWork infErence by covariaNce DYnamics, dubbed WENDY. The core idea of WENDY is to model the dynamics of the covariance matrix, and solve this dynamics as an optimization problem to determine the regulatory relationships. To evaluate its effectiveness, we compare WENDY with other inference methods using synthetic data and experimental data. Our results demonstrate that WENDY performs well across different data sets.         _ Less","","arXiv","https://arxiv.org/abs/2407.00754","1","0","origin_of_life"
"High Throughput Parameter Estimation and Uncertainty Analysis Applied to the Production of Mycoprotein from Synthetic Lignocellulosic Hydrolysates","Abstract:                The current global food system produces substantial waste and carbon emissions while exacerbating the effects of global hunger and protein deficiency. This study aims to address these challenges by exploring the use of lignocellulosic agricultural residues as feedstocks for microbial protein fermentation, focusing on Fusarium venenatum A3/5, a mycelial strain known for its high protein yield and q_         _ More           The current global food system produces substantial waste and carbon emissions while exacerbating the effects of global hunger and protein deficiency. This study aims to address these challenges by exploring the use of lignocellulosic agricultural residues as feedstocks for microbial protein fermentation, focusing on Fusarium venenatum A3/5, a mycelial strain known for its high protein yield and quality. We propose a high throughput microlitre batch fermentation system paired with analytical chemistry to generate time-series data of microbial growth and substrate utilisation. An unstructured biokinetic model was developed using a bootstrap sampling approach to quantify uncertainty in the parameter estimates. The model was validated against an independent dataset of a different glucose-xylose composition to assess the predictive performance. Our results indicate a robust model fit with high coefficients of determination and low root mean squared errors for biomass, glucose, and xylose concentrations. Estimated parameter values provided insights into the resource utilisation strategies of Fusarium venenatum A3/5 in mixed substrate cultures, aligning well with previous research findings. Significant correlations between estimated parameters were observed, highlighting challenges in parameter identifiability. This work provides a foundational model for optimising the production of microbial protein from lignocellulosic waste, contributing to a more sustainable global food system.         _ Less","","arXiv","https://arxiv.org/abs/2407.00209","0","1","synthetic_biology"
"Moment-based parameter inference with error guarantees for stochastic reaction networks","Abstract:                _or computationally expensive simulations. We demonstrate its use for uncertainty quantification, data integration and prediction of latent species statistics through synthetic data from common nonlinear biochemical models including the Schl_gl model, the toggle switch and post-transcriptional regulation.         _ More           Inferring parameters of models of biochemical kinetics from single-cell data remains challenging because of the uncertainty arising from the intractability of the likelihood function of stochastic reaction networks. Such uncertainty falls beyond current error quantification measures, which focus on the effects of finite sample size and identifiability but lack theoretical guarantees when likelihood approximations are needed. Here, we propose an inference method for stochastic reaction networks with nonlinear and rational propensities at steady state that provides bounds on the parameters via convex optimisation over sets constrained by moment equations and moment matrices. Our approach takes observations from the stochastic reaction network and forms moment intervals, which are then used to constrain parameters through convex sets. The bounds on the parameters contain the true parameters under the condition that the moment intervals contain the true stationary moments, thus providing uncertainty quantification and error guarantees. Our approach does not need to predict moments and distributions for given parameters (i.e., it avoids solving or simulating the forward problem), and hence circumvents intractable likelihood computations or computationally expensive simulations. We demonstrate its use for uncertainty quantification, data integration and prediction of latent species statistics through synthetic data from common nonlinear biochemical models including the Schl_gl model, the toggle switch and post-transcriptional regulation.         _ Less","","arXiv","https://arxiv.org/abs/2406.17434","0","1","synthetic_biology"
"A synthetic T-cell receptor-like protein behaves as a Janus particle in solution","Abstract:                Protein engineering enables the creation of tailor-made proteins for an array of applications. ImmTACs stand out as promising therapeutics for cancer and other treatments, while also presenting unique challenges for stability, formulation and delivery. We have shown that ImmTACs behave as Janus particles in solution, leading to self-association at low concentrations, even when the averaged protein_         _ More           Protein engineering enables the creation of tailor-made proteins for an array of applications. ImmTACs stand out as promising therapeutics for cancer and other treatments, while also presenting unique challenges for stability, formulation and delivery. We have shown that ImmTACs behave as Janus particles in solution, leading to self-association at low concentrations, even when the averaged protein-protein interactions suggest that the molecule should be stable. The formation of small but stable oligomers has been confirmed by static and dynamic light scattering and analytical ultracentrifugation. Modelling of the structure using Alphafold leads to a rational explanation for this behaviour, consistent with the Janus particle assembly observed for inverse patchy particles.         _ Less","","arXiv","https://arxiv.org/abs/2406.16610","1","0","origin_of_life"
"Social learning with complex contagion","Abstract:                _of selection that biases imitation towards more successful types. Our analysis intercalates the fields of evolutionary game theory with complex contagions, and it provides a synthetic framework that describes more realistic forms of behavioral change in social systems.         _ More           We introduce a mathematical model that combines the concepts of complex contagion with payoff-biased imitation, to describe how social behaviors spread through a population. Traditional models of social learning by imitation are based on simple contagion -- where an individual may imitate a more successful neighbor following a single interaction. Our framework generalizes this process to incorporate complex contagion, which requires multiple exposures before an individual considers adopting a different behavior. We formulate this as a discrete time and state stochastic process in a finite population, and we derive its continuum limit as an ordinary differential equation that generalizes the replicator equation, the most widely used dynamical model in evolutionary game theory. When applied to linear frequency-dependent games, our social learning with complex contagion produces qualitatively different outcomes than traditional imitation dynamics: it can shift the Prisoner's Dilemma from a unique all-defector equilibrium to either a stable mixture of cooperators and defectors in the population, or a bistable system; it changes the Snowdrift game from a single to a bistable equilibrium; and it can alter the Coordination game from bistability at the boundaries to two internal equilibria. The long-term outcome depends on the balance between the complexity of the contagion process and the strength of selection that biases imitation towards more successful types. Our analysis intercalates the fields of evolutionary game theory with complex contagions, and it provides a synthetic framework that describes more realistic forms of behavioral change in social systems.         _ Less","","arXiv","https://arxiv.org/abs/2406.14922","0","1","synthetic_biology"
"Flight-Scope: microscopy with microfluidics in microgravity","Abstract:                _conditions on biological organisms. These include astronauts but also useful micro-organisms they may bring with them to produce food, medicine, and other useful compounds by synthetic biology. Parabolic flights are one of the most accessible microgravity research platforms but present their own challenges: relatively_         _ More           With the European Space Agency (ESA) and NASA working to return humans to the moon and onwards to Mars, it has never been more important to study the impact of altered gravity conditions on biological organisms. These include astronauts but also useful micro-organisms they may bring with them to produce food, medicine, and other useful compounds by synthetic biology. Parabolic flights are one of the most accessible microgravity research platforms but present their own challenges: relatively short periods of altered gravity (~20s) and aircraft vibration. Live-imaging is necessary in these altered-gravity conditions to readout any real-time phenotypes. Here we present Flight-Scope, a new microscopy and microfluidics platform to study dynamic cellular processes during the short, altered gravity periods on parabolic flights. We demonstrated Flight-Scopes capability by performing live and dynamic imaging of fluorescent glucose uptake by yeast, S. cerevisiae, on board an ESA parabolic flight. Flight-Scope operated well in this challenging environment, opening the way for future microgravity experiments on biological organisms.         _ Less","","arXiv","https://arxiv.org/abs/2406.09902","0","1","synthetic_biology"
"Foundations for reconstructing early microbial life","Abstract:                _deep time. This review critically examines our current understanding of early microbial life and describes the foundations of an emerging area in microbiology and evolutionary synthetic biology to reconstruct the earliest microbial innovations.         _ More           For more than 3.5 billion years, life experienced dramatic environmental extremes on Earth. These include shifts from oxygen-less to over-oxygenated atmospheres and cycling between hothouse conditions and global glaciations. Meanwhile, an ecological revolution took place. The planet evolved from one dominated by microbial life to one containing the plants and animals that are most familiar today. The activities of many key cellular inventions evolved early in the history of life, collectively defining the nature of our biosphere and underpinning human survival. There is a critical need for a new disciplinary synthesis to reveal how microbes and their molecular systems survived ever changing global conditions over deep time. This review critically examines our current understanding of early microbial life and describes the foundations of an emerging area in microbiology and evolutionary synthetic biology to reconstruct the earliest microbial innovations.         _ Less","","arXiv","https://arxiv.org/abs/2406.09354","1","3","synthetic_biology"
"Projecting Molecules into Synthesizable Chemical Spaces","Abstract:                _recently been introduced to accelerate the drug discovery process, but their progression to experimental validation remains limited, largely due to a lack of consideration for synthetic accessibility in practical settings. In this work, we introduce a novel framework that is capable of generating new chemical structures while ensuring_         _ More           Discovering new drug molecules is a pivotal yet challenging process due to the near-infinitely large chemical space and notorious demands on time and resources. Numerous generative models have recently been introduced to accelerate the drug discovery process, but their progression to experimental validation remains limited, largely due to a lack of consideration for synthetic accessibility in practical settings. In this work, we introduce a novel framework that is capable of generating new chemical structures while ensuring synthetic accessibility. Specifically, we introduce a postfix notation of synthetic pathways to represent molecules in chemical space. Then, we design a transformer-based model to translate molecular graphs into postfix notations of synthesis. We highlight the model's ability to: (a) perform bottom-up synthesis planning more accurately, (b) generate structurally similar, synthesizable analogs for unsynthesizable molecules proposed by generative models with their properties preserved, and (c) explore the local synthesizable chemical space around hit molecules.         _ Less","","arXiv","https://arxiv.org/abs/2406.04628","0","1","synthetic_biology"
"SynAsk: Unleashing the Power of Large Language Models in Organic Synthesis","Abstract:                _specialized domains enhances their capabilities for domain-specific applications. Notably, NLP has made significant strides in organic chemistry, particularly in predicting synthetic tasks, paving the way for the development of LLMs tailored to the organic chemistry field. In this work, we introduce SynAsk, a comprehensive organic chemistry domain-specific L_         _ More           The field of natural language processing (NLP) has witnessed a transformative shift with the emergence of large language models (LLMs), revolutionizing various language tasks and applications, and the integration of LLM into specialized domains enhances their capabilities for domain-specific applications. Notably, NLP has made significant strides in organic chemistry, particularly in predicting synthetic tasks, paving the way for the development of LLMs tailored to the organic chemistry field. In this work, we introduce SynAsk, a comprehensive organic chemistry domain-specific LLM platform developed by AIChemEco Inc. By finetuning an LLM with domain-specific data and integrating it with a chain of thought approach, SynAsk seamlessly accesses our knowledge base and advanced chemistry tools in a question-and-answer format. This includes functionalities such as a basic chemistry knowledge base, molecular information retrieval, reaction performance prediction, retrosynthesis prediction, chemical literature acquisition, and more. This novel methodology synergizes fine-tuning techniques with external resource integration, resulting in an organic chemistry-specific model poised to facilitate research and discovery in the field. Accessible via http://synask.aichemeco.com, SynAsk represents a significant advancement in leveraging NLP for synthetic applications.         _ Less","","arXiv","https://arxiv.org/abs/2406.04593","3","2","origin_of_life"
"GNNAnatomy: Systematic Generation and Evaluation of Multi-Level Explanations for Graph Neural Networks","Abstract:                _we measure the change in classification confidence after removing each graphlet from the original graph. We demonstrate the effectiveness of GNNAnatomy through case studies on synthetic and real-world graph datasets from sociology and biology domains. Additionally, we compare GNNAnatomy with state-of-the-art explainabl_         _ More           Graph Neural Networks (GNNs) excel in machine learning tasks involving graphs, such as node classification, graph classification, and link prediction. However, explaining their decision-making process is challenging due to the complex transformations GNNs perform by aggregating relational information from graph topology. Existing methods for explaining GNNs face key limitations: (1) lack of flexibility in generating explanations at varying levels, (2) difficulty in identifying unique substructures relevant to class differentiation, and (3) little support to ensure the trustworthiness of explanations. To address these challenges, we introduce GNNAnatomy, a visual analytics system designed to generate and evaluate multi-level GNN explanations for graph classification tasks. GNNAnatomy uses graphlets, primitive graph substructures, to identify the most critical substructures in a graph class by analyzing the correlation between GNN predictions and graphlet frequencies. These correlations are presented interactively for user-selected group of graphs through our visual analytics system. To further validate top-ranked graphlets, we measure the change in classification confidence after removing each graphlet from the original graph. We demonstrate the effectiveness of GNNAnatomy through case studies on synthetic and real-world graph datasets from sociology and biology domains. Additionally, we compare GNNAnatomy with state-of-the-art explainable GNN methods to showcase its utility and versatility.         _ Less","","arXiv","https://arxiv.org/abs/2406.04548","1","0","origin_of_life"
"Mapping dynamical systems into chemical reactions","Abstract:                _processes. A special subset of these DSs that can model chemical reactions under mass-action kinetics is called chemical dynamical systems (CDSs). A central problem in synthetic biology is to map polynomial DSs into dynamically similar CDSs. In this paper, we introduce the quasi-chemical map (QCM) that can systematical_         _ More           Polynomial dynamical systems (DSs) can model a wide range of physical processes. A special subset of these DSs that can model chemical reactions under mass-action kinetics is called chemical dynamical systems (CDSs). A central problem in synthetic biology is to map polynomial DSs into dynamically similar CDSs. In this paper, we introduce the quasi-chemical map (QCM) that can systematically solve this problem. The QCM introduces suitable state-dependent perturbations into any given polynomial DS which then becomes a CDS under sufficiently large translations of variables. This map preserves robust features, such as generic equilibria and limit cycles, as well as temporal properties, such as periods of oscillations. Furthermore, the resulting CDSs are at most one degree higher than the original DSs. We demonstrate the QCM by designing relatively simple CDSs with exotic dynamics and bifurcations, and addressing Hilbert's 16th problem in chemistry.         _ Less","","arXiv","https://arxiv.org/abs/2406.03473","0","1","synthetic_biology"
"Recurrent neural chemical reaction networks that approximate arbitrary dynamics","Abstract:                Many important phenomena in chemistry and biology are realized via dynamical features such as multi-stability, oscillations, and chaos. Construction of novel chemical systems with such finely-tuned dynamics is a challenging problem central to the growing field of_         _ More           Many important phenomena in chemistry and biology are realized via dynamical features such as multi-stability, oscillations, and chaos. Construction of novel chemical systems with such finely-tuned dynamics is a challenging problem central to the growing field of synthetic biology. In this paper, we address this problem by putting forward a molecular version of a recurrent artificial neural network, which we call a recurrent neural chemical reaction network (RNCRN). We prove that the RNCRN, with sufficiently many auxiliary chemical species and suitable fast reactions, can be systematically trained to achieve any dynamics. This approximation ability is shown to hold independent of the initial conditions for the auxiliary species, making the RNCRN more experimentally feasible. To demonstrate the results, we present a number of relatively simple RNCRNs trained to display a variety of biologically-important dynamical features.         _ Less","","arXiv","https://arxiv.org/abs/2406.03456","0","2","synthetic_biology"
"Transient infrared nanoscopy resolves the millisecond photoswitching dynamics of single lipid vesicles in water","Abstract:                _nanocarriers under physiological conditions and with minimal interference is crucial for advancing nanomedicine, photopharmacology, drug delivery, nanotheranostics and synthetic biology. Yet, analytical methods struggle to combine precise chemical imaging and measurements without perturbative labeling. This challenge i_         _ More           Understanding the biophysical and biochemical properties of molecular nanocarriers under physiological conditions and with minimal interference is crucial for advancing nanomedicine, photopharmacology, drug delivery, nanotheranostics and synthetic biology. Yet, analytical methods struggle to combine precise chemical imaging and measurements without perturbative labeling. This challenge is exemplified for azobenzene-based photoswitchable lipids, which are intriguing reagents for controlling nanocarrier properties on fast timescales, enabling, e.g., precise light-induced drug release processes. Here, we leverage the chemical recognition and high spatio-temporal resolution of scattering-type scanning near-field optical microscopy (s-SNOM) to demonstrate non-destructive, label-free mid-infrared (MIR) imaging and spectroscopy of photoswitchable liposomes below the diffraction limit and the tracking of their dynamics down to 50 ms resolution. The vesicles are adsorbed on an ultrathin 10-nm SiN membrane, which separates the sample space from the tip space for stable and hour-long observations. By implementing a transient nanoscopy approach, we accurately resolve, for the first time, photoinduced changes in both the shape and the MIR spectral signature of individual vesicles and reveal abrupt change dynamics of the underlying photoisomerization process. Our findings highlight the methods potential for future studies on the complex dynamics of unlabeled nanoscale soft matter, as well as, in a broader context, for host-guest systems, energy materials or drugs.         _ Less","","arXiv","https://arxiv.org/abs/2406.02513","1","3","synthetic_biology"
"Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Backbone Generation","Abstract:                _-- we train FoldFlow-2 at scale on a new dataset that is an order of magnitude larger than PDB datasets of prior works, containing both known proteins in PDB and high-quality synthetic structures achieved through filtering. We further demonstrate the ability to align FoldFlow-2 to arbitrary rewards, e.g. increasing secondary structures diversity, by introduc_         _ More           Proteins are essential for almost all biological processes and derive their diverse functions from complex 3D structures, which are in turn determined by their amino acid sequences. In this paper, we exploit the rich biological inductive bias of amino acid sequences and introduce FoldFlow-2, a novel sequence-conditioned SE(3)-equivariant flow matching model for protein structure generation. FoldFlow-2 presents substantial new architectural features over the previous FoldFlow family of models including a protein large language model to encode sequence, a new multi-modal fusion trunk that combines structure and sequence representations, and a geometric transformer based decoder. To increase diversity and novelty of generated samples -- crucial for de-novo drug design -- we train FoldFlow-2 at scale on a new dataset that is an order of magnitude larger than PDB datasets of prior works, containing both known proteins in PDB and high-quality synthetic structures achieved through filtering. We further demonstrate the ability to align FoldFlow-2 to arbitrary rewards, e.g. increasing secondary structures diversity, by introducing a Reinforced Finetuning (ReFT) objective. We empirically observe that FoldFlow-2 outperforms previous state-of-the-art protein structure-based generative models, improving over RFDiffusion in terms of unconditional generation across all metrics including designability, diversity, and novelty across all protein lengths, as well as exhibiting generalization on the task of equilibrium conformation sampling. Finally, we demonstrate that a fine-tuned FoldFlow-2 makes progress on challenging conditional design tasks such as designing scaffolds for the VHH nanobody.         _ Less","","arXiv","https://arxiv.org/abs/2405.20313","1","0","origin_of_life"
"Bayesian Uncertainty Quantification for Anaerobic Digestion models","Abstract:                Uncertainty quantification is critical for ensuring adequate predictive power of computational models used in biology. Focusing on two anaerobic digestion models, this article introduces a novel generalized Bayesian procedure, called VarBUQ, ensuring a correct tradeoff between flexibility and computational cost. A benchmark against three existing methods (Fi_         _ More           Uncertainty quantification is critical for ensuring adequate predictive power of computational models used in biology. Focusing on two anaerobic digestion models, this article introduces a novel generalized Bayesian procedure, called VarBUQ, ensuring a correct tradeoff between flexibility and computational cost. A benchmark against three existing methods (Fisher's information, bootstrapping and Beale's criteria) was conducted using synthetic data. This Bayesian procedure offered a good compromise between fitting ability and confidence estimation, while the other methods proved to be repeatedly overconfident. The method's performances notably benefitted from inductive bias brought by the prior distribution, although it requires careful construction. This article advocates for more systematic consideration of uncertainty for anaerobic digestion models and showcases a new, computationally efficient Bayesian method. To facilitate future implementations, a Python package called 'aduq' is made available.         _ Less","","arXiv","https://arxiv.org/abs/2405.19824","1","0","origin_of_life"
"Domain adaptation in small-scale and heterogeneous biological datasets","Abstract:                Machine learning techniques are steadily becoming more important in modern biology, and are used to build predictive models, discover patterns, and investigate biological problems. However, models trained on one dataset are often not generalizable to other datasets from different cohorts or laboratories, due to differences in the statistical properties of th_         _ More           Machine learning techniques are steadily becoming more important in modern biology, and are used to build predictive models, discover patterns, and investigate biological problems. However, models trained on one dataset are often not generalizable to other datasets from different cohorts or laboratories, due to differences in the statistical properties of these datasets. These could stem from technical differences, such as the measurement technique used, or from relevant biological differences between the populations studied. Domain adaptation, a type of transfer learning, can alleviate this problem by aligning the statistical distributions of features and samples among different datasets so that similar models can be applied across them. However, a majority of state-of-the-art domain adaptation methods are designed to work with large-scale data, mostly text and images, while biological datasets often suffer from small sample sizes, and possess complexities such as heterogeneity of the feature space. This Review aims to synthetically discuss domain adaptation methods in the context of small-scale and highly heterogeneous biological data. We describe the benefits and challenges of domain adaptation in biological research and critically discuss some of its objectives, strengths, and weaknesses through key representative methodologies. We argue for the incorporation of domain adaptation techniques to the computational biologist's toolkit, with further development of customized approaches.         _ Less","","arXiv","https://arxiv.org/abs/2405.19221","1","2","synthetic_biology"
"CHANI: Correlation-based Hawkes Aggregation of Neurons with bio-Inspiration","Abstract:                The present work aims at proving mathematically that a neural network inspired by biology can learn a classification task thanks to local transformations only. In this purpose, we propose a spiking neural network named CHANI (Correlation-based Hawkes Aggregation of Neurons with bio-Inspiration), whose neurons activity is modeled by Hawkes processes. Synaptic_         _ More           The present work aims at proving mathematically that a neural network inspired by biology can learn a classification task thanks to local transformations only. In this purpose, we propose a spiking neural network named CHANI (Correlation-based Hawkes Aggregation of Neurons with bio-Inspiration), whose neurons activity is modeled by Hawkes processes. Synaptic weights are updated thanks to an expert aggregation algorithm, providing a local and simple learning rule. We were able to prove that our network can learn on average and asymptotically. Moreover, we demonstrated that it automatically produces neuronal assemblies in the sense that the network can encode several classes and that a same neuron in the intermediate layers might be activated by more than one class, and we provided numerical simulations on synthetic dataset. This theoretical approach contrasts with the traditional empirical validation of biologically inspired networks and paves the way for understanding how local learning rules enable neurons to form assemblies able to represent complex concepts.         _ Less","","arXiv","https://arxiv.org/abs/2405.18828","1","0","origin_of_life"
"Guided Multi-objective Generative AI to Enhance Structure-based Drug Design","Abstract:                _silico, optimizing a plurality of target physicochemical properties. We demonstrate our platform's effectiveness by generating ligands with optimized binding affinity and synthetic accessibility on two benchmark sets. IDOLpro produces ligands with binding affinities over 10%-20% better than the next best state-of-the-art method on each test set, producin_         _ More           Generative AI has the potential to revolutionize drug discovery. Yet, despite recent advances in deep learning, existing models cannot generate molecules that satisfy all desired physicochemical properties. Herein, we describe IDOLpro, a generative chemistry AI combining diffusion with multi-objective optimization for structure-based drug design. Differentiable scoring functions guide the latent variables of the diffusion model to explore uncharted chemical space and generate novel ligands in silico, optimizing a plurality of target physicochemical properties. We demonstrate our platform's effectiveness by generating ligands with optimized binding affinity and synthetic accessibility on two benchmark sets. IDOLpro produces ligands with binding affinities over 10%-20% better than the next best state-of-the-art method on each test set, producing more drug-like molecules with generally better synthetic accessibility scores than other methods. We do a head-to-head comparison of IDOLpro against a classic virtual screen of a large database of drug-like molecules. We show that IDOLpro can generate molecules for a range of important disease-related targets with better binding affinity and synthetic accessibility than any molecule found in the virtual screen while being over 100x faster and less expensive to run. On a test set of experimental complexes, IDOLpro is the first to produce molecules with better binding affinities than experimentally observed ligands. IDOLpro can accommodate other scoring functions (e.g. ADME-Tox) to accelerate hit-finding, hit-to-lead, and lead optimization for drug discovery.         _ Less","","arXiv","https://arxiv.org/abs/2405.11785","0","1","synthetic_biology"
"An Autoencoder and Generative Adversarial Networks Approach for Multi-Omics Data Imbalanced Class Handling and Classification","Abstract:                _relentless efforts in enhancing medical diagnostics, the integration of state-of-the-art machine learning methodologies has emerged as a promising research area. In molecular biology, there has been an explosion of data generated from multi-omics sequencing. The advent sequencing equipment can provide large number of complicated measurements per one experime_         _ More           In the relentless efforts in enhancing medical diagnostics, the integration of state-of-the-art machine learning methodologies has emerged as a promising research area. In molecular biology, there has been an explosion of data generated from multi-omics sequencing. The advent sequencing equipment can provide large number of complicated measurements per one experiment. Therefore, traditional statistical methods face challenging tasks when dealing with such high dimensional data. However, most of the information contained in these datasets is redundant or unrelated and can be effectively reduced to significantly fewer variables without losing much information. Dimensionality reduction techniques are mathematical procedures that allow for this reduction; they have largely been developed through statistics and machine learning disciplines. The other challenge in medical datasets is having an imbalanced number of samples in the classes, which leads to biased results in machine learning models. This study, focused on tackling these challenges in a neural network that incorporates autoencoder to extract latent space of the features, and Generative Adversarial Networks (GAN) to generate synthetic samples. Latent space is the reduced dimensional space that captures the meaningful features of the original data. Our model starts with feature selection to select the discriminative features before feeding them to the neural network. Then, the model predicts the outcome of cancer for different datasets. The proposed model outperformed other existing models by scoring accuracy of 95.09% for bladder cancer dataset and 88.82% for the breast cancer dataset.         _ Less","","arXiv","https://arxiv.org/abs/2405.09756","1","0","origin_of_life"
"Nonlinear classification of neural manifolds with contextual information","Abstract:                _contextual input information. We derive an exact formula for the context-dependent capacity that depends on manifold geometry and context correlations, and validate it on synthetic and real data. Our framework's increased expressivity captures representation untanglement in deep networks at early stages of the layer hierarchy, previously inaccessible to_         _ More           Understanding how neural systems efficiently process information through distributed representations is a fundamental challenge at the interface of neuroscience and machine learning. Recent approaches analyze the statistical and geometrical attributes of neural representations as population-level mechanistic descriptors of task implementation. In particular, manifold capacity has emerged as a promising framework linking population geometry to the separability of neural manifolds. However, this metric has been limited to linear readouts. Here, we propose a theoretical framework that overcomes this limitation by leveraging contextual input information. We derive an exact formula for the context-dependent capacity that depends on manifold geometry and context correlations, and validate it on synthetic and real data. Our framework's increased expressivity captures representation untanglement in deep networks at early stages of the layer hierarchy, previously inaccessible to analysis. As context-dependent nonlinearity is ubiquitous in neural systems, our data-driven and theoretically grounded approach promises to elucidate context-dependent computation across scales, datasets, and models.         _ Less","","arXiv","https://arxiv.org/abs/2405.06851","1","0","origin_of_life"
"Boolean matrix logic programming for active learning of gene functions in genome-scale metabolic network models","Abstract:                Techniques to autonomously drive research have been prominent in Computational Scientific Discovery, while Synthetic Biology is a field of science that focuses on designing and constructing new biological systems for useful purposes. Here we seek to apply logic-based machine learning techniques to facilitate cellular e_         _ More           Techniques to autonomously drive research have been prominent in Computational Scientific Discovery, while Synthetic Biology is a field of science that focuses on designing and constructing new biological systems for useful purposes. Here we seek to apply logic-based machine learning techniques to facilitate cellular engineering and drive biological discovery. Comprehensive databases of metabolic processes called genome-scale metabolic network models (GEMs) are often used to evaluate cellular engineering strategies to optimise target compound production. However, predicted host behaviours are not always correctly described by GEMs, often due to errors in the models. The task of learning the intricate genetic interactions within GEMs presents computational and empirical challenges. To address these, we describe a novel approach called Boolean Matrix Logic Programming (BMLP) by leveraging boolean matrices to evaluate large logic programs. We introduce a new system, $BMLP_{active}$, which efficiently explores the genomic hypothesis space by guiding informative experimentation through active learning. In contrast to sub-symbolic methods, $BMLP_{active}$ encodes a state-of-the-art GEM of a widely accepted bacterial host in an interpretable and logical representation using datalog logic programs. Notably, $BMLP_{active}$ can successfully learn the interaction between a gene pair with fewer training examples than random experimentation, overcoming the increase in experimental design space. $BMLP_{active}$ enables rapid optimisation of metabolic models to reliably engineer biological systems for producing useful compounds. It offers a realistic approach to creating a self-driving lab for microbial engineering.         _ Less","","arXiv","https://arxiv.org/abs/2405.06724","1","2","synthetic_biology"
"Impact of phylogeny on the inference of functional sectors from protein sequence data","Abstract:                _is that correlations in amino-acid usage can also arise from the mere fact that homologous sequences share common ancestry, i.e. from phylogeny. Here, we generate controlled synthetic data from a minimal model comprising both phylogeny and functional sectors. We use this data to dissect the impact of phylogeny on sector identification and on mutational effec_         _ More           Statistical analysis of multiple sequence alignments of homologous proteins has revealed groups of coevolving amino acids called sectors. These groups of amino-acid sites feature collective correlations in their amino-acid usage, and they are associated to functional properties. Modeling showed that nonlinear selection on an additive functional trait of a protein is generically expected to give rise to a functional sector. These modeling results motivated a principled method, called ICOD, which is designed to identify functional sectors, as well as mutational effects, from sequence data. However, a challenge for all methods aiming to identify sectors from multiple sequence alignments is that correlations in amino-acid usage can also arise from the mere fact that homologous sequences share common ancestry, i.e. from phylogeny. Here, we generate controlled synthetic data from a minimal model comprising both phylogeny and functional sectors. We use this data to dissect the impact of phylogeny on sector identification and on mutational effect inference by different methods. We find that ICOD is most robust to phylogeny, but that conservation is also quite robust. Next, we consider natural multiple sequence alignments of protein families for which deep mutational scan experimental data is available. We show that in this natural data, conservation and ICOD best identify sites with strong functional roles, in agreement with our results on synthetic data. Importantly, these two methods have different premises, since they respectively focus on conservation and on correlations. Thus, their joint use can reveal complementary information.         _ Less","","arXiv","https://arxiv.org/abs/2405.04920","1","0","origin_of_life"
"Non-Abelian Braiding of Topological Edge Bands","Abstract:                Braiding is a geometric concept that manifests itself in a variety of scientific contexts from biology to physics, and has been employed to classify bulk band topology in topological materials. Topological edge states can also form braiding structures, as demonstrated recently in a type of topological insulators known as M_bius insulators, whose topological_         _ More           Braiding is a geometric concept that manifests itself in a variety of scientific contexts from biology to physics, and has been employed to classify bulk band topology in topological materials. Topological edge states can also form braiding structures, as demonstrated recently in a type of topological insulators known as M_bius insulators, whose topological edge states form two braided bands exhibiting a M_bius twist. While the formation of M_bius twist is inspiring, it belongs to the simple Abelian braid group $\\mathbb{B}_2$. The most fascinating features about topological braids rely on the non-Abelianness in the higher-order braid group $\\mathbb{B}_N$ ($N \\geq 3$), which necessitates multiple edge bands, but so far it has not been discussed. Here, based on the gauge enriched symmetry, we develop a scheme to realize non-Abelian braiding of multiple topological edge bands. We propose tight-binding models of topological insulators that are able to generate topological edge states forming non-Abelian braiding structures. Experimental demonstrations are conducted in two acoustic crystals, which carry three and four braided acoustic edge bands, respectively. The observed braiding structure can correspond to the topological winding in the complex eigenvalue space of projective translation operator, akin to the previously established point-gap winding topology in the bulk of the Hatano-Nelson model. Our work also constitutes the realization of non-Abelian braiding topology on an actual crystal platform, but not based on the 'virtual' synthetic dimensions.         _ Less","","arXiv","https://arxiv.org/abs/2405.04879","1","0","origin_of_life"
"Scalable Amortized GPLVMs for Single Cell Transcriptomics Data","Abstract:                _RNA-seq with specialized encoder, kernel, and likelihood designs. This model matches the performance of the leading single-cell variational inference (scVI) approach on synthetic and real-world COVID datasets and effectively incorporates cell-cycle and batch information to reveal more interpretable latent structures as we demonstrate on an innate immunity da_         _ More           Dimensionality reduction is crucial for analyzing large-scale single-cell RNA-seq data. Gaussian Process Latent Variable Models (GPLVMs) offer an interpretable dimensionality reduction method, but current scalable models lack effectiveness in clustering cell types. We introduce an improved model, the amortized stochastic variational Bayesian GPLVM (BGPLVM), tailored for single-cell RNA-seq with specialized encoder, kernel, and likelihood designs. This model matches the performance of the leading single-cell variational inference (scVI) approach on synthetic and real-world COVID datasets and effectively incorporates cell-cycle and batch information to reveal more interpretable latent structures as we demonstrate on an innate immunity dataset.         _ Less","","arXiv","https://arxiv.org/abs/2405.03879","1","0","origin_of_life"
"Majority consensus thresholds in competitive Lotka--Volterra populations","Abstract:                One of the key challenges in synthetic biology is devising robust signaling primitives for engineered microbial consortia. In such systems, a fundamental signal amplification problem is the majority consensus problem: given a system with two input species with initial difference of $_$ in population sizes, what is the_         _ More           One of the key challenges in synthetic biology is devising robust signaling primitives for engineered microbial consortia. In such systems, a fundamental signal amplification problem is the majority consensus problem: given a system with two input species with initial difference of $_$ in population sizes, what is the probability that the system reaches a state in which only the initial majority species is present?   In this work, we consider a discrete and stochastic version of competitive Lotka--Volterra dynamics, a standard model of microbial community dynamics. We identify new threshold properties for majority consensus under different types of interference competition:   - We show that under so-called self-destructive interference competition between the two input species, majority consensus can be reached with high probability if the initial difference satisfies $_\\in _(\\log^2 n)$, where $n$ is the initial population size. This gives an exponential improvement compared to the previously known bound of $_(\\sqrt{n \\log n})$ by Cho et al. [Distributed Computing, 2021] given for a special case of the competitive Lotka--Volterra model. In contrast, we show that an initial gap of $_\\in _(\\sqrt{\\log n})$ is necessary.   - On the other hand, we prove that under non-self-destructive interference competition, an initial gap of $_(\\sqrt{n})$ is necessary to succeed with high probability and that a $_(\\sqrt{n \\log n})$ gap is sufficient.   This shows a strong qualitative gap between the performance of self-destructive and non-self-destructive interference competition. Moreover, we show that if in addition the populations exhibit interference competition between the individuals of the same species, then majority consensus cannot always be solved with high probability, no matter what the difference in the initial population counts.         _ Less","","arXiv","https://arxiv.org/abs/2405.03568","0","1","synthetic_biology"
"Target-Specific De Novo Peptide Binder Design with DiffPepBuilder","Abstract:                _binder design remains challenging due to the flexibility of peptide structures and the scarcity of protein-peptide complex structure data. In this study, we curated a large synthetic dataset, referred to as PepPC-F, from the abundant protein-protein interface data and developed DiffPepBuilder, a de novo target-specific peptide binder generation method that u_         _ More           Despite the exciting progress in target-specific de novo protein binder design, peptide binder design remains challenging due to the flexibility of peptide structures and the scarcity of protein-peptide complex structure data. In this study, we curated a large synthetic dataset, referred to as PepPC-F, from the abundant protein-protein interface data and developed DiffPepBuilder, a de novo target-specific peptide binder generation method that utilizes an SE(3)-equivariant diffusion model trained on PepPC-F to co-design peptide sequences and structures. DiffPepBuilder also introduces disulfide bonds to stabilize the generated peptide structures. We tested DiffPepBuilder on 30 experimentally verified strong peptide binders with available protein-peptide complex structures. DiffPepBuilder was able to effectively recall the native structures and sequences of the peptide ligands and to generate novel peptide binders with improved binding free energy. We subsequently conducted de novo generation case studies on three targets. In both the regeneration test and case studies, DiffPepBuilder outperformed AfDesign and RFdiffusion coupled with ProteinMPNN, in terms of sequence and structure recall, interface quality, and structural diversity. Molecular dynamics simulations confirmed that the introduction of disulfide bonds enhanced the structural rigidity and binding performance of the generated peptides. As a general peptide binder de novo design tool, DiffPepBuilder can be used to design peptide binders for given protein targets with three dimensional and binding site information.         _ Less","","arXiv","https://arxiv.org/abs/2405.00128","1","0","origin_of_life"
"The Convergence of AI and Synthetic Biology: The Looming Deluge","Abstract:                The convergence of artificial intelligence (AI) and synthetic_         _ More           The convergence of artificial intelligence (AI) and synthetic biology is rapidly accelerating the pace of biological discovery and engineering. AI techniques, such as large language models and biological design tools, are enabling the automated design, build, test, and learning cycles for engineered biological systems. This convergence promises to democratize synthetic biology and unlock novel applications across domains from medicine to environmental sustainability. However, it also poses significant risks around reliability, dual use, and governance. The opacity of AI models, the deskilling of workforces, and the outdated nature of current regulatory frameworks present challenges in ensuring responsible development. Urgent attention is needed to update governance structures, integrate human oversight into increasingly automated workflows, and foster a culture of responsibility among the growing community of bioengineers. Only by proactively addressing these issues can we realize the transformative potential of AI-driven synthetic biology while mitigating its risks.         _ Less","","arXiv","https://arxiv.org/abs/2404.18973","0","1","synthetic_biology"
"Estimating the Distribution of Parameters in Differential Equations with Repeated Cross-Sectional Data","Abstract:                _the dynamics of various systems, offering insights into their future states through parameter estimation fitted to time series data. In fields such as economy, politics, and biology, the observation data points in the time series are often independently obtained (i.e., Repeated Cross-Sectional (RCS) data). With RCS data, we found that traditional methods for_         _ More           Differential equations are pivotal in modeling and understanding the dynamics of various systems, offering insights into their future states through parameter estimation fitted to time series data. In fields such as economy, politics, and biology, the observation data points in the time series are often independently obtained (i.e., Repeated Cross-Sectional (RCS) data). With RCS data, we found that traditional methods for parameter estimation in differential equations, such as using mean values of time trajectories or Gaussian Process-based trajectory generation, have limitations in estimating the shape of parameter distributions, often leading to a significant loss of data information. To address this issue, we introduce a novel method, Estimation of Parameter Distribution (EPD), providing accurate distribution of parameters without loss of data information. EPD operates in three main steps: generating synthetic time trajectories by randomly selecting observed values at each time point, estimating parameters of a differential equation that minimize the discrepancy between these trajectories and the true solution of the equation, and selecting the parameters depending on the scale of discrepancy. We then evaluated the performance of EPD across several models, including exponential growth, logistic population models, and target cell-limited models with delayed virus production, demonstrating its superiority in capturing the shape of parameter distributions. Furthermore, we applied EPD to real-world datasets, capturing various shapes of parameter distributions rather than a normal distribution. These results effectively address the heterogeneity within systems, marking a substantial progression in accurately modeling systems using RCS data.         _ Less","","arXiv","https://arxiv.org/abs/2404.14873","1","1","multiple"
"Generating synthetic light-adapted electroretinogram waveforms using Artificial Intelligence to improve classification of retinal conditions in under-represented populations","Abstract:                _data are used to compare with clinical cases that may be rare or underpowered within a specific demographic. To bolster either reference or case datasets the application of synthetic ERG waveforms may offer benefits to disease classification and case-control studies. In this study and as a proof of concept, artificial intelligence (AI) to generate_         _ More           Visual electrophysiology is often used clinically to determine functional changes associated with retinal or neurological conditions. The full-field flash electroretinogram (ERG) assesses the global contribution of the outer and inner retinal layers initiated by the rods and cone pathways depending on the state of retinal adaptation. Within clinical centers reference normative data are used to compare with clinical cases that may be rare or underpowered within a specific demographic. To bolster either reference or case datasets the application of synthetic ERG waveforms may offer benefits to disease classification and case-control studies. In this study and as a proof of concept, artificial intelligence (AI) to generate synthetic signals using Generative Adversarial Networks is deployed to up-scale male participants within an ISCEV reference dataset containing 68 participants, with waveforms from the right and left eye. Random Forest Classifiers further improved classification for sex within the group from a balanced accuracy of 0.72 to 0.83 with the added synthetic male waveforms. This is the first study to demonstrate the generation of synthetic ERG waveforms to improve machine learning classification modelling with electroretinogram waveforms.         _ Less","","arXiv","https://arxiv.org/abs/2404.11842","0","1","synthetic_biology"
"RiboDiffusion: Tertiary Structure-based RNA Inverse Folding with Generative Diffusion Models","Abstract:                RNA design shows growing applications in synthetic biology and therapeutics, driven by the crucial role of RNA in various biological processes. A fundamental challenge is to find functional RNA sequences that satisfy given structural constraints, known as the inverse folding problem. Computational approaches have emerg_         _ More           RNA design shows growing applications in synthetic biology and therapeutics, driven by the crucial role of RNA in various biological processes. A fundamental challenge is to find functional RNA sequences that satisfy given structural constraints, known as the inverse folding problem. Computational approaches have emerged to address this problem based on secondary structures. However, designing RNA sequences directly from 3D structures is still challenging, due to the scarcity of data, the non-unique structure-sequence mapping, and the flexibility of RNA conformation. In this study, we propose RiboDiffusion, a generative diffusion model for RNA inverse folding that can learn the conditional distribution of RNA sequences given 3D backbone structures. Our model consists of a graph neural network-based structure module and a Transformer-based sequence module, which iteratively transforms random sequences into desired sequences. By tuning the sampling weight, our model allows for a trade-off between sequence recovery and diversity to explore more candidates. We split test sets based on RNA clustering with different cut-offs for sequence or structure similarity. Our model outperforms baselines in sequence recovery, with an average relative improvement of $11\\%$ for sequence similarity splits and $16\\%$ for structure similarity splits. Moreover, RiboDiffusion performs consistently well across various RNA length categories and RNA types. We also apply in-silico folding to validate whether the generated sequences can fold into the given 3D RNA backbones. Our method could be a powerful tool for RNA design that explores the vast sequence space and finds novel solutions to 3D structural constraints.         _ Less","","arXiv","https://arxiv.org/abs/2404.11199","1","1","multiple"
"Learning epidemic trajectories through Kernel Operator Learning: from modelling to optimal control","Abstract:                _of the two approaches with different kernels, including the Neural Tangent Kernels, and compare them with a classical neural network model learning method. Employing synthetic but semi-realistic data, we show how the two introduced approaches are suitable for realizing fast and robust forecasts and scenario analyses, and how these approaches are competitive_         _ More           Since infectious pathogens start spreading into a susceptible population, mathematical models can provide policy makers with reliable forecasts and scenario analyses, which can be concretely implemented or solely consulted. In these complex epidemiological scenarios, machine learning architectures can play an important role, since they directly reconstruct data-driven models circumventing the specific modelling choices and the parameter calibration, typical of classical compartmental models. In this work, we discuss the efficacy of Kernel Operator Learning (KOL) to reconstruct population dynamics during epidemic outbreaks, where the transmission rate is ruled by an input strategy. In particular, we introduce two surrogate models, named KOL-m and KOL-$\\partial$, which reconstruct in two different ways the evolution of the epidemics. Moreover, we evaluate the generalization performances of the two approaches with different kernels, including the Neural Tangent Kernels, and compare them with a classical neural network model learning method. Employing synthetic but semi-realistic data, we show how the two introduced approaches are suitable for realizing fast and robust forecasts and scenario analyses, and how these approaches are competitive for determining optimal intervention strategies with respect to specific performance measures.         _ Less","","arXiv","https://arxiv.org/abs/2404.11130","0","1","synthetic_biology"
"Synthetic Brain Images: Bridging the Gap in Brain Mapping With Generative Adversarial Model","Abstract:                Magnetic Resonance Imaging (MRI) is a vital modality for gaining precise anatomical information, and it plays a significant role in medical imaging for diagnosis and therapy planning. Image synthesis problems have seen a revolution in recent years due to the introduction of deep learning techniques, specifically Generative Adversarial Networks (GANs). This work investigates the use of Deep Convolu_         _ More           Magnetic Resonance Imaging (MRI) is a vital modality for gaining precise anatomical information, and it plays a significant role in medical imaging for diagnosis and therapy planning. Image synthesis problems have seen a revolution in recent years due to the introduction of deep learning techniques, specifically Generative Adversarial Networks (GANs). This work investigates the use of Deep Convolutional Generative Adversarial Networks (DCGAN) for producing high-fidelity and realistic MRI image slices. The suggested approach uses a dataset with a variety of brain MRI scans to train a DCGAN architecture. While the discriminator network discerns between created and real slices, the generator network learns to synthesise realistic MRI image slices. The generator refines its capacity to generate slices that closely mimic real MRI data through an adversarial training approach. The outcomes demonstrate that the DCGAN promise for a range of uses in medical imaging research, since they show that it can effectively produce MRI image slices if we train them for a consequent number of epochs. This work adds to the expanding corpus of research on the application of deep learning techniques for medical image synthesis. The slices that are could be produced possess the capability to enhance datasets, provide data augmentation in the training of deep learning models, as well as a number of functions are made available to make MRI data cleaning easier, and a three ready to use and clean dataset on the major anatomical plans.         _ Less","","arXiv","https://arxiv.org/abs/2404.08703","1","1","multiple"
"Latent Chemical Space Searching for Plug-in Multi-objective Molecule Generation","Abstract:                _experiments. The model also incorporates a novel target-ligand affinity predictor, enhancing the model's utility by supporting three-dimensional information and improving synthetic feasibility. Case studies focused on generating and optimizing drug-like big marine natural products were performed, underscoring PSO-ENP's effectiveness and demonstrating_         _ More           Molecular generation, an essential method for identifying new drug structures, has been supported by advancements in machine learning and computational technology. However, challenges remain in multi-objective generation, model adaptability, and practical application in drug discovery. In this study, we developed a versatile 'plug-in' molecular generation model that incorporates multiple objectives related to target affinity, drug-likeness, and synthesizability, facilitating its application in various drug development contexts. We improved the Particle Swarm Optimization (PSO) in the context of drug discoveries, and identified PSO-ENP as the optimal variant for multi-objective molecular generation and optimization through comparative experiments. The model also incorporates a novel target-ligand affinity predictor, enhancing the model's utility by supporting three-dimensional information and improving synthetic feasibility. Case studies focused on generating and optimizing drug-like big marine natural products were performed, underscoring PSO-ENP's effectiveness and demonstrating its considerable potential for practical drug discovery applications.         _ Less","","arXiv","https://arxiv.org/abs/2404.06691","1","0","origin_of_life"
"A model for membrane degradation using a gelatin invadopodia assay","Abstract:                _degradation of the gelatin is proposed. This is completed with a calibration strategy. We perform a sensitivity analysis and explore a parameter estimation technique both on synthetic and experimental data in order to find the optimal parameters that describe the in vitro experiments. A comparison between numerical and experimental solutions ends the work.         _ More           One of the most crucial and lethal characteristics of solid tumors is represented by the increased ability of cancer cells to migrate and invade other organs during the so-called metastatic spread. This is allowed thanks to the production of matrix metalloproteinases (MMPs), enzymes capable of degrading a type of collagen abundant in the basal membrane separating the epithelial tissue from the connective one. In this work, we employ a synergistic experimental and mathematical modelling approach to explore the invasion process of tumor cells. A athematical model composed of reaction-diffusion equations describing the evolution of the tumor cells density on a gelatin substrate, MMPs enzymes concentration and the degradation of the gelatin is proposed. This is completed with a calibration strategy. We perform a sensitivity analysis and explore a parameter estimation technique both on synthetic and experimental data in order to find the optimal parameters that describe the in vitro experiments. A comparison between numerical and experimental solutions ends the work.         _ Less","","arXiv","https://arxiv.org/abs/2404.05730","0","2","synthetic_biology"
"Quantifying age-specific household contacts in Aotearoa New Zealand for infectious disease modelling","Abstract:                _interest. Here we use a comprehensive household composition dataset based on Aotearoa New Zealand census and administrative data to construct a household contact matrix and a synthetic population that can be used for modelling. We investigate the behaviour of a compartment-based and an agent-based epidemic model parameterised using this data, compared to a c_         _ More           Accounting for population age structure and age-specific contact patterns is crucial for accurate modelling of human infectious disease dynamics and impact. A common approach is to use contact matrices, which estimate the number of contacts between individuals of different ages. These contact matrices are frequently based on data collected from populations with very different demographic and socioeconomic characteristics from the population of interest. Here we use a comprehensive household composition dataset based on Aotearoa New Zealand census and administrative data to construct a household contact matrix and a synthetic population that can be used for modelling. We investigate the behaviour of a compartment-based and an agent-based epidemic model parameterised using this data, compared to a commonly used contact matrix that was constructed by projecting international data onto New Zealand's population. We find that using the New Zealand household data, either in a compartment-based model or in an agent-based model, leads to lower attack rates in older age groups compared to using the projected contact matrix. This difference becomes larger when household transmission is more dominant relative to non-household transmission. We provide electronic versions of the synthetic population and household contact matrix for other researchers to use in infectious disease models.         _ Less","","arXiv","https://arxiv.org/abs/2404.04300","1","1","multiple"
"Propensity Score Alignment of Unpaired Multimodal Data","Abstract:                Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multim_         _ More           Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multimodal representation learning. We draw an analogy between potential outcomes in causal inference and potential views in multimodal observations, which allows us to use Rubin's framework to estimate a common space in which to match samples. Our approach assumes we collect samples that are experimentally perturbed by treatments, and uses this to estimate a propensity score from each modality, which encapsulates all shared information between a latent state and treatment and can be used to define a distance between samples. We experiment with two alignment techniques that leverage this distance -- shared nearest neighbours (SNN) and optimal transport (OT) matching -- and find that OT matching results in significant improvements over state-of-the-art alignment approaches in both a synthetic multi-modal setting and in real-world data from NeurIPS Multimodal Single-Cell Integration Challenge.         _ Less","","arXiv","https://arxiv.org/abs/2404.01595","1","0","origin_of_life"
"Disentangling Hippocampal Shape Variations: A Study of Neurological Disorders Using Mesh Variational Autoencoder with Contrastive Learning","Abstract:                _study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SO_         _ More           This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Mesh Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in patients with Multiple Sclerosis (MS) using the hippocampus data. Our Mesh VAE with Supervised Contrastive Learning shows the volume changes of the hippocampus of MS populations at different ages, and the result is consistent with the current neuroimaging literature. This research provides valuable insights into the relationship between neurological disorder and hippocampal shape changes in different age groups of MS populations using a Mesh VAE with Supervised Contrastive loss. Our code is available at https://github.com/Jakaria08/Explaining_Shape_Variability         _ Less","","arXiv","https://arxiv.org/abs/2404.00785","1","1","multiple"
"Annotated Biomedical Video Generation using Denoising Diffusion Probabilistic Models and Flow Fields","Abstract:                The segmentation and tracking of living cells play a vital role within the biomedical domain, particularly in cancer research, drug development, and developmental biology. These are usually tedious and time-consuming tasks that are traditionally done by biomedical experts. Recently, to automatize these processes, deep learning based segmentation and tracking_         _ More           The segmentation and tracking of living cells play a vital role within the biomedical domain, particularly in cancer research, drug development, and developmental biology. These are usually tedious and time-consuming tasks that are traditionally done by biomedical experts. Recently, to automatize these processes, deep learning based segmentation and tracking methods have been proposed. These methods require large-scale datasets and their full potential is constrained by the scarcity of annotated data in the biomedical imaging domain. To address this limitation, we propose Biomedical Video Diffusion Model (BVDM), capable of generating realistic-looking synthetic microscopy videos. Trained only on a single real video, BVDM can generate videos of arbitrary length with pixel-level annotations that can be used for training data-hungry models. It is composed of a denoising diffusion probabilistic model (DDPM) generating high-fidelity synthetic cell microscopy images and a flow prediction model (FPM) predicting the non-rigid transformation between consecutive video frames. During inference, initially, the DDPM imposes realistic cell textures on synthetic cell masks which are generated based on real data statistics. The flow prediction model predicts the flow field between consecutive masks and applies that to the DDPM output from the previous time frame to create the next one while keeping temporal consistency. BVDM outperforms state-of-the-art synthetic live cell microscopy video generation models. Furthermore, we demonstrate that a sufficiently large synthetic dataset enhances the performance of cell segmentation and tracking models compared to using a limited amount of available real data.         _ Less","","arXiv","https://arxiv.org/abs/2403.17808","1","1","multiple"
"Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View","Abstract:                _dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method.         _ More           Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method.         _ Less","","arXiv","https://arxiv.org/abs/2403.15500","1","1","multiple"
"Competition for binding targets results in paradoxical effects for simultaneous activator and repressor action -- Extended Version","Abstract:                _due to the large number of potential players and the complexity of endogenous intracellular regulatory networks. Instead, this paper analyzes this issue through an analogous synthetic_         _ More           In the context of epigenetic transformations in cancer metastasis, a puzzling effect was recently discovered, in which the elimination (knock-out) of an activating regulatory element leads to increased (rather than decreased) activity of the element being regulated. It has been postulated that this paradoxical behavior can be explained by activating and repressing transcription factors competing for binding to other possible targets. It is very difficult to prove this hypothesis in mammalian cells, due to the large number of potential players and the complexity of endogenous intracellular regulatory networks. Instead, this paper analyzes this issue through an analogous synthetic biology construct which aims to reproduce the paradoxical behavior using standard bacterial gene expression networks. The paper first reviews the motivating cancer biology work, and then describes a proposed synthetic construct. A mathematical model is formulated, and basic properties of uniqueness of steady states and convergence to equilibria are established, as well as an identification of parameter regimes which should lead to observing such paradoxical phenomena (more activator leads to less activity at steady state). A proof is also given to show that this is a steady-state property, and for initial transients the phenomenon will not be observed. This work adds to the general line of work of resource competition in synthetic circuits.         _ Less","","arXiv","https://arxiv.org/abs/2403.14820","2","2","multiple"
"Data-Efficient Sleep Staging with Synthetic Time Series Pretraining","Abstract:                _we propose a pretraining task termed 'frequency pretraining' to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in re_         _ More           Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed 'frequency pretraining' to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research. We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces.         _ Less","","arXiv","https://arxiv.org/abs/2403.08592","1","0","origin_of_life"
"Physics-informed generative model for drug-like molecule conformers","Abstract:                _and geometric parameters from a training set. Conformer sampling is achieved by taking advantage of recent advancements in diffusion-based generation. By training on large, synthetic data sets of diverse, drug-like molecules optimized with the semiempirical GFN2-xTB method, high accuracy is achieved for bonded parameters, exceeding that of conventional, know_         _ More           We present a diffusion-based, generative model for conformer generation. Our model is focused on the reproduction of bonded structure and is constructed from the associated terms traditionally found in classical force fields to ensure a physically relevant representation. Techniques in deep learning are used to infer atom typing and geometric parameters from a training set. Conformer sampling is achieved by taking advantage of recent advancements in diffusion-based generation. By training on large, synthetic data sets of diverse, drug-like molecules optimized with the semiempirical GFN2-xTB method, high accuracy is achieved for bonded parameters, exceeding that of conventional, knowledge-based methods. Results are also compared to experimental structures from the Protein Databank (PDB) and Cambridge Structural Database (CSD).         _ Less","","arXiv","https://arxiv.org/abs/2403.07925","0","1","synthetic_biology"
"The temperature affects the impact levels of synthetic insecticides on a parasitoid wasp used in the biological control of pentatomid pests in soybean crops","Abstract:                _stage). Generally, the highest emergence reduction values were found at the highest temperature studied (30 _C). Our results highlighted the temperature-dependent impact of synthetic insecticides on parasitoids, which should be considered in toxicological risk assessments and under predicted climate change scenarios.         _ More           The impact of climate change has led to growing global concern about the interaction of temperature and xenobiotics in agricultural toxicological studies. Thus, for the first time, we evaluated the lethal, sublethal and transgerational effects of six insecticides used in the management of stink bug complex in soybean crops on the different life stages of the parasitoid Telenomus podisi (Hymenoptera: Scelionidae) in three temperature levels (15, 25 and 30 _C). Telenomus podisi adults (F0 generation), when exposed to insecticides based on acephate, spinosad and thiamethoxam + lambda-cyhalothrin, showed accumulated mortality of 100% at all temperature levels tested. On the other hand, methoxyfenozide + spinetoram caused average mortalities of 88.75% at 15 _C and 38.75% at 25 and 30 _C. In contrast, the mortality rates caused by chlorfenapyr at 15, 25 and 30 _C were 1.25, 71.25 and 71.25%. On the other hand, surviving adults in lethal toxicity bioassay did not show differences in egg parasitism (F0 generation) and emergence of F1 generation in all temperature levels studied; however, the insecticide methoxyfenozide + spinetoram showed the lowest level of parasitism and emergence of T. podisi. In addition, our results demonstrated significant changes in the proportion of emerged males and females as the temperature increased; however, we did not find any differences when comparing the insecticides studied. Furthermore, we detected a significant interaction between insecticides and temperatures by contaminating the host's parasitized eggs (parasitoid pupal stage). Generally, the highest emergence reduction values were found at the highest temperature studied (30 _C). Our results highlighted the temperature-dependent impact of synthetic insecticides on parasitoids, which should be considered in toxicological risk assessments and under predicted climate change scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2403.05479","1","0","origin_of_life"
"Synthetic Privileged Information Enhances Medical Image Representation Learning","Abstract:                _In contrast, image generation methods can work well on very small datasets, and can find mappings between unpaired datasets, meaning an effectively unlimited amount of paired synthetic data can be generated. In this work, we demonstrate that representation learning can be significantly improved by synthetically genera_         _ More           Multimodal self-supervised representation learning has consistently proven to be a highly effective method in medical image analysis, offering strong task performance and producing biologically informed insights. However, these methods heavily rely on large, paired datasets, which is prohibitive for their use in scenarios where paired data does not exist, or there is only a small amount available. In contrast, image generation methods can work well on very small datasets, and can find mappings between unpaired datasets, meaning an effectively unlimited amount of paired synthetic data can be generated. In this work, we demonstrate that representation learning can be significantly improved by synthetically generating paired information, both compared to training on either single-modality (up to 4.4x error reduction) or authentic multi-modal paired datasets (up to 5.6x error reduction).         _ Less","","arXiv","https://arxiv.org/abs/2403.05220","1","0","origin_of_life"
"Cell reprogramming design by transfer learning of functional transcriptional networks","Abstract:                Recent developments in synthetic biology, next-generation sequencing, and machine learning provide an unprecedented opportunity to rationally design new disease treatments based on measured responses to gene perturbations and drugs to reprogram cells. The main challenges to seizing this opportunity are the incomplete k_         _ More           Recent developments in synthetic biology, next-generation sequencing, and machine learning provide an unprecedented opportunity to rationally design new disease treatments based on measured responses to gene perturbations and drugs to reprogram cells. The main challenges to seizing this opportunity are the incomplete knowledge of the cellular network and the combinatorial explosion of possible interventions, both of which are insurmountable by experiments. To address these challenges, we develop a transfer learning approach to control cell behavior that is pre-trained on transcriptomic data associated with human cell fates, thereby generating a model of the network dynamics that can be transferred to specific reprogramming goals. The approach combines transcriptional responses to gene perturbations to minimize the difference between a given pair of initial and target transcriptional states. We demonstrate our approach's versatility by applying it to a microarray dataset comprising >9,000 microarrays across 54 cell types and 227 unique perturbations, and an RNASeq dataset consisting of >10,000 sequencing runs across 36 cell types and 138 perturbations. Our approach reproduces known reprogramming protocols with an AUROC of 0.91 while innovating over existing methods by pre-training an adaptable model that can be tailored to specific reprogramming transitions. We show that the number of gene perturbations required to steer from one fate to another increases with decreasing developmental relatedness and that fewer genes are needed to progress along developmental paths than to regress. These findings establish a proof-of-concept for our approach to computationally design control strategies and provide insights into how gene regulatory networks govern phenotype.         _ Less","","arXiv","https://arxiv.org/abs/2403.04837","0","1","synthetic_biology"
"Pruning neural network models for gene regulatory dynamics using data and domain knowledge","Abstract:                _network pruning by using domain-specific structural information in model fitting and leads to sparser, better interpretable models that are more robust to noise. Using both synthetic data with ground truth information, as well as real-world gene expression data, we show that DASH, using knowledge about gene interaction partners within the putative regulatory_         _ More           The practical utility of machine learning models in the sciences often hinges on their interpretability. It is common to assess a model's merit for scientific discovery, and thus novel insights, by how well it aligns with already available domain knowledge--a dimension that is currently largely disregarded in the comparison of neural network models. While pruning can simplify deep neural network architectures and excels in identifying sparse models, as we show in the context of gene regulatory network inference, state-of-the-art techniques struggle with biologically meaningful structure learning. To address this issue, we propose DASH, a generalizable framework that guides network pruning by using domain-specific structural information in model fitting and leads to sparser, better interpretable models that are more robust to noise. Using both synthetic data with ground truth information, as well as real-world gene expression data, we show that DASH, using knowledge about gene interaction partners within the putative regulatory network, outperforms general pruning methods by a large margin and yields deeper insights into the biological systems being studied.         _ Less","","arXiv","https://arxiv.org/abs/2403.04805","1","0","origin_of_life"
"Hill Function-based Model of Transcriptional Response: Impact of Nonspecific Binding and RNAP Interactions","Abstract:                _biochemical information. Our findings highlight the role of Hill function in modeling/fitting for transcriptional regulation, which also benefits the preparation of synthetic regulatory elements.         _ More           Hill function is one of the widely used gene transcription regulation models. Its attribute of fitting may result in a lack of an underlying physical picture, yet the fitting parameters can provide information about biochemical reactions, such as the number of transcription factors (TFs) and the binding energy between regulatory elements. However, it remains unclear when and how much biochemical information can Hill function provide in addition to fitting. Here, started from the interactions between TFs and RNA polymerase during transcription regulation and both of their association-dissociation reactions at specific/nonspecific sites on DNA, the regulatory effect of TFs was deduced as fold change. We found that, for weak promoter, fold change can degrade into the regulatory factor (Freg) which is closely correlated with Hill function. By directly comparing and fitting with Hill function, the fitting parameters and corresponding biochemical reaction parameters in Freg were analyzed and discussed, where the single TF and multiple TFs that with cooperativity and basic logic effects were considered. We concluded the strength of promoter and interactions between TFs determine whether Hill function can reflect the corresponding biochemical information. Our findings highlight the role of Hill function in modeling/fitting for transcriptional regulation, which also benefits the preparation of synthetic regulatory elements.         _ Less","","arXiv","https://arxiv.org/abs/2403.01702","1","0","origin_of_life"
"Morphological Symmetries in Robotics","Abstract:                _framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot's morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot's stat_         _ More           We present a comprehensive framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot's morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot's state space and both proprioceptive and exteroceptive sensor measurements, resulting in the equivariance of the robot's equations of motion and optimal control policies. Thus, we recognize morphological symmetries as a relevant and previously unexplored physics-informed geometric prior, with significant implications for both data-driven and analytical methods used in modeling, control, estimation and design in robotics. For data-driven methods, we demonstrate that morphological symmetries can enhance the sample efficiency and generalization of machine learning models through data augmentation, or by applying equivariant/invariant constraints on the model's architecture. In the context of analytical methods, we employ abstract harmonic analysis to decompose the robot's dynamics into a superposition of lower-dimensional, independent dynamics. We substantiate our claims with both synthetic and real-world experiments conducted on bipedal and quadrupedal robots. Lastly, we introduce the repository MorphoSymm to facilitate the practical use of the theory and applications outlined in this work.         _ Less","","arXiv","https://arxiv.org/abs/2402.15552","1","1","multiple"
"Contrastive Learning of Shared Spatiotemporal EEG Representations Across Individuals for Naturalistic Neuroscience","Abstract:                _convolutions to simultaneously learn the spatial and temporal patterns inherent in EEG. The versatility of CL-SSTER was demonstrated on three EEG datasets, including a synthetic dataset, a natural speech comprehension EEG dataset, and an emotional video watching EEG dataset. CL-SSTER attained the highest inter-subject correlation (ISC) values compared to the_         _ More           Neural representations induced by naturalistic stimuli offer insights into how humans respond to stimuli in daily life. Understanding neural mechanisms underlying naturalistic stimuli processing hinges on the precise identification and extraction of the shared neural patterns that are consistently present across individuals. Targeting the Electroencephalogram (EEG) technique, known for its rich spatial and temporal information, this study presents a framework for Contrastive Learning of Shared SpatioTemporal EEG Representations across individuals (CL-SSTER). CL-SSTER utilizes contrastive learning to maximize the similarity of EEG representations across individuals for identical stimuli, contrasting with those for varied stimuli. The network employed spatial and temporal convolutions to simultaneously learn the spatial and temporal patterns inherent in EEG. The versatility of CL-SSTER was demonstrated on three EEG datasets, including a synthetic dataset, a natural speech comprehension EEG dataset, and an emotional video watching EEG dataset. CL-SSTER attained the highest inter-subject correlation (ISC) values compared to the state-of-the-art ISC methods. The latent representations generated by CL-SSTER exhibited reliable spatiotemporal EEG patterns, which can be explained by properties of the naturalistic stimuli. CL-SSTER serves as an interpretable and scalable framework for the identification of inter-subject shared neural representations in naturalistic neuroscience.         _ Less","","arXiv","https://arxiv.org/abs/2402.14213","1","0","origin_of_life"
"Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-terminal Coding Sequences","Abstract:                _NCS optimization such as rational design and statistics-guided approaches are labor-intensive yield only relatively small improvements. This paper introduces a deep learning/synthetic biology co-designed few-shot training workflow for NCS optimization. Our method utilizes k-nearest encoding followed by word2vec to enco_         _ More           N-terminal coding sequence (NCS) influences gene expression by impacting the translation initiation rate. The NCS optimization problem is to find an NCS that maximizes gene expression. The problem is important in genetic engineering. However, current methods for NCS optimization such as rational design and statistics-guided approaches are labor-intensive yield only relatively small improvements. This paper introduces a deep learning/synthetic biology co-designed few-shot training workflow for NCS optimization. Our method utilizes k-nearest encoding followed by word2vec to encode the NCS, then performs feature extraction using attention mechanisms, before constructing a time-series network for predicting gene expression intensity, and finally a direct search algorithm identifies the optimal NCS with limited training data. We took green fluorescent protein (GFP) expressed by Bacillus subtilis as a reporting protein of NCSs, and employed the fluorescence enhancement factor as the metric of NCS optimization. Within just six iterative experiments, our model generated an NCS (MLD62) that increased average GFP expression by 5.41-fold, outperforming the state-of-the-art NCS designs. Extending our findings beyond GFP, we showed that our engineered NCS (MLD62) can effectively boost the production of N-acetylneuraminic acid by enhancing the expression of the crucial rate-limiting GNA1 gene, demonstrating its practical utility. We have open-sourced our NCS expression database and experimental procedures for public use.         _ Less","","arXiv","https://arxiv.org/abs/2402.13297","0","1","synthetic_biology"
"A Differentiable Model for Optimizing the Genetic Drivers of Synaptogenesis","Abstract:                _based on the information contained within the genome. Aligning with this perspective, we introduce SynaptoGen, a novel computational framework designed to bring the advent of synthetic biological intelligence closer, facilitating the development of neural biological agents through the precise control of genetic factors governing synaptogenesis. SynaptoGen re_         _ More           There is a growing consensus among neuroscientists that many neural circuits critical for survival result from a process of genomic decompression, hence are constructed based on the information contained within the genome. Aligning with this perspective, we introduce SynaptoGen, a novel computational framework designed to bring the advent of synthetic biological intelligence closer, facilitating the development of neural biological agents through the precise control of genetic factors governing synaptogenesis. SynaptoGen represents the first model in the well-established family of Connectome Models (CMs) to offer a possible mechanistic explanation of synaptic multiplicity based on genetic expression and protein interaction probabilities, modeling connectivity with unprecedented granularity. Furthermore, SynaptoGen connects these genetic factors through a differentiable function, effectively working as a neural network in which each synaptic weight is computed as the average number of synapses between neurons, multiplied by its corresponding conductance, and derived from a specific genetic profile. Differentiability is a critical feature of the framework, enabling its integration with gradient-based optimization techniques. This allows SynaptoGen to generate patterns of genetic expression and/or genetic rules capable of producing pre-wired biological agents tailored to specific tasks. The framework is validated in simulated synaptogenesis scenarios with varying degrees of biological plausibility. It successfully produces biological agents capable of solving tasks in four different reinforcement learning benchmarks, consistently outperforming the state-of-the-art and a control baseline designed to represent populations of neurons where synapses form freely, i.e., without guided manipulations.         _ Less","","arXiv","https://arxiv.org/abs/2402.07242","1","0","origin_of_life"
"Automated Data-Driven Discovery of Material Models Based on Symbolic Regression: A Case Study on Human Brain Cortex","Abstract:                _models -- invariant-based, principal stretch-based, and normal strain-based -- and highlights the versatility of symbolic regression. We validate our new approach using synthetic data from five classic hyperelastic models and experimental data from the human brain to demonstrate algorithmic efficacy. Our results suggest that our symbolic regression robustly_         _ More           We introduce a data-driven framework to automatically identify interpretable and physically meaningful hyperelastic constitutive models from sparse data. Leveraging symbolic regression, an algorithm based on genetic programming, our approach generates elegant hyperelastic models that achieve accurate data fitting through parsimonious mathematic formulae, while strictly adhering to hyperelasticity constraints such as polyconvexity. Our investigation spans three distinct hyperelastic models -- invariant-based, principal stretch-based, and normal strain-based -- and highlights the versatility of symbolic regression. We validate our new approach using synthetic data from five classic hyperelastic models and experimental data from the human brain to demonstrate algorithmic efficacy. Our results suggest that our symbolic regression robustly discovers accurate models with succinct mathematic expressions in invariant-based, stretch-based, and strain-based scenarios. Strikingly, the strain-based model exhibits superior accuracy, while both stretch- and strain-based models effectively capture the nonlinearity and tension-compression asymmetry inherent to human brain tissue. Polyconvexity examinations affirm the rigor of convexity within the training regime and demonstrate excellent extrapolation capabilities beyond this regime for all three models. However, the stretch-based models raise concerns regarding potential convexity loss under large deformations. Finally, robustness tests on noise-embedded data underscore the reliability of our symbolic regression algorithms. Our study confirms the applicability and accuracy of symbolic regression in the automated discovery of hyperelastic models for the human brain and gives rise to a wide variety of applications in other soft matter systems.         _ Less","","arXiv","https://arxiv.org/abs/2402.05238","1","0","origin_of_life"
"When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges","Abstract:                Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance._         _ More           Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This paper explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modeling and uncertainty quantification.         _ Less","","arXiv","https://arxiv.org/abs/2402.03349","1","1","multiple"
"Learning Collective Variables with Synthetic Data Augmentation through Physics-Inspired Geodesic Interpolation","Abstract:                In molecular dynamics simulations, rare events, such as protein folding, are typically studied using enhanced sampling techniques, most of which are based on the definition of a collective variable (CV) along which acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded confor_         _ More           In molecular dynamics simulations, rare events, such as protein folding, are typically studied using enhanced sampling techniques, most of which are based on the definition of a collective variable (CV) along which acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded conformation. We propose a simulation-free data augmentation strategy using physics-inspired metrics to generate geodesic interpolations resembling protein folding transitions, thereby improving sampling efficiency without true transition state samples. This new data can be used to improve the accuracy of classifier-based methods. Alternatively, a regression-based learning scheme for CV models can be adopted by leveraging the interpolation progress parameter.         _ Less","","arXiv","https://arxiv.org/abs/2402.01542","1","1","multiple"
"A Differentiable Partially Observable Generalized Linear Model with Forward-Backward Message Passing","Abstract:                _scheme for the variational model. Comprehensive experiments show that our differentiable POGLMs with our forward-backward message passing produce a better performance on one synthetic and two real-world datasets. Furthermore, our new method yields more interpretable parameters, underscoring its significance in neuroscience.         _ More           The partially observable generalized linear model (POGLM) is a powerful tool for understanding neural connectivity under the assumption of existing hidden neurons. With spike trains only recorded from visible neurons, existing works use variational inference to learn POGLM meanwhile presenting the difficulty of learning this latent variable model. There are two main issues: (1) the sampled Poisson hidden spike count hinders the use of the pathwise gradient estimator in VI; and (2) the existing design of the variational model is neither expressive nor time-efficient, which further affects the performance. For (1), we propose a new differentiable POGLM, which enables the pathwise gradient estimator, better than the score function gradient estimator used in existing works. For (2), we propose the forward-backward message-passing sampling scheme for the variational model. Comprehensive experiments show that our differentiable POGLMs with our forward-backward message passing produce a better performance on one synthetic and two real-world datasets. Furthermore, our new method yields more interpretable parameters, underscoring its significance in neuroscience.         _ Less","","arXiv","https://arxiv.org/abs/2402.01263","1","1","multiple"
"convSeq: Fast and Scalable Method for Detecting Patterns in Spike Data","Abstract:                _method that employs backpropagation for optimizing spatiotemporal filters that effectively identify these neural patterns. Our method's performance is validated on various synthetic data and real neural recordings, revealing spike sequences with unprecedented scalability and efficiency. Significantly surpassing existing methods in speed, convSeq sets a n_         _ More           Spontaneous neural activity, crucial in memory, learning, and spatial navigation, often manifests itself as repetitive spatiotemporal patterns. Despite their importance, analyzing these patterns in large neural recordings remains challenging due to a lack of efficient and scalable detection methods. Addressing this gap, we introduce convSeq, an unsupervised method that employs backpropagation for optimizing spatiotemporal filters that effectively identify these neural patterns. Our method's performance is validated on various synthetic data and real neural recordings, revealing spike sequences with unprecedented scalability and efficiency. Significantly surpassing existing methods in speed, convSeq sets a new standard for analyzing spontaneous neural activity, potentially advancing our understanding of information processing in neural circuits.         _ Less","","arXiv","https://arxiv.org/abs/2402.01130","1","1","multiple"
"Data Augmentation Scheme for Raman Spectra with Highly Correlated Annotations","Abstract:                _in scenarios where large amounts of historical data are available but are currently not used for model training. We demonstrate the capabilities of the proposed method using synthetic spectra of Ralstonia eutropha batch cultivations to monitor substrate, biomass and polyhydroxyalkanoate (PHA) biopolymer concentrations during of the experiments.         _ More           In biotechnology Raman Spectroscopy is rapidly gaining popularity as a process analytical technology (PAT) that measures cell densities, substrate- and product concentrations. As it records vibrational modes of molecules it provides that information non-invasively in a single spectrum. Typically, partial least squares (PLS) is the model of choice to infer information about variables of interest from the spectra. However, biological processes are known for their complexity where convolutional neural networks (CNN) present a powerful alternative. They can handle non-Gaussian noise and account for beam misalignment, pixel malfunctions or the presence of additional substances. However, they require a lot of data during model training, and they pick up non-linear dependencies in the process variables. In this work, we exploit the additive nature of spectra in order to generate additional data points from a given dataset that have statistically independent labels so that a network trained on such data exhibits low correlations between the model predictions. We show that training a CNN on these generated data points improves the performance on datasets where the annotations do not bear the same correlation as the dataset that was used for model training. This data augmentation technique enables us to reuse spectra as training data for new contexts that exhibit different correlations. The additional data allows for building a better and more robust model. This is of interest in scenarios where large amounts of historical data are available but are currently not used for model training. We demonstrate the capabilities of the proposed method using synthetic spectra of Ralstonia eutropha batch cultivations to monitor substrate, biomass and polyhydroxyalkanoate (PHA) biopolymer concentrations during of the experiments.         _ Less","","arXiv","https://arxiv.org/abs/2402.00851","1","0","origin_of_life"
"The whack-a-mole governance challenge for AI-enabled synthetic biology: literature review and emerging frameworks","Abstract:                AI-enabled synthetic_         _ More           AI-enabled synthetic biology has tremendous potential but also significantly increases biorisks and brings about a new set of dual use concerns. The picture is complicated given the vast innovations envisioned to emerge by combining emerging technologies, as AI-enabled synthetic biology potentially scales up bioengineering into industrial biomanufacturing. However, the literature review indicates that goals such as maintaining a reasonable scope for innovation, or more ambitiously to foster a huge bioeconomy don't necessarily contrast with biosafety, but need to go hand in hand. This paper presents a literature review of the issues and describes emerging frameworks for policy and practice that transverse the options of command-and control, stewardship, bottom-up, and laissez-faire governance. How to achieve early warning systems that enable prevention and mitigation of future AI-enabled biohazards from the lab, from deliberate misuse, or from the public realm, will constantly need to evolve, and adaptive, interactive approaches should emerge. Although biorisk is subject to an established governance regime, and scientists generally adhere to biosafety protocols, even experimental, but legitimate use by scientists could lead to unexpected developments. Recent advances in chatbots enabled by generative AI have revived fears that advanced biological insight can more easily get into the hands of malignant individuals or organizations. Given these sets of issues, society needs to rethink how AI-enabled synthetic biology should be governed. The suggested way to visualize the challenge at hand is whack-a-mole governance, although the emerging solutions are perhaps not so different either.         _ Less","","arXiv","https://arxiv.org/abs/2402.00312","1","3","synthetic_biology"
"Modular Construction of Boolean Networks","Abstract:                Boolean networks have been used in a variety of settings, as models for general complex systems as well as models of specific systems in diverse fields, such as biology, engineering, and computer science. Traditionally, their properties as dynamical systems have been studied through simulation studies, due to a lack of mathematical structure. This paper uses_         _ More           Boolean networks have been used in a variety of settings, as models for general complex systems as well as models of specific systems in diverse fields, such as biology, engineering, and computer science. Traditionally, their properties as dynamical systems have been studied through simulation studies, due to a lack of mathematical structure. This paper uses a common mathematical technique to identify a class of Boolean networks with a 'simple' structure and describes an algorithm to construct arbitrary extensions of a collection of simple Boolean networks. In this way, all Boolean networks can be obtained from a collection of simple Boolean networks as building blocks. The paper furthermore provides a formula for the number of extensions of given simple networks and, in some cases, provides a parametrization of those extensions. This has potential applications to the construction of networks with particular properties, for instance in synthetic biology, and can also be applied to develop efficient control algorithms for Boolean network models.         _ Less","","arXiv","https://arxiv.org/abs/2402.00022","0","1","synthetic_biology"
"ReacLLaMA: Merging chemical and textual information in chemical reactivity AI models","Abstract:                _tasks. The vast majority of the reported models are trained solely on chemical information such as reactants, products, reagents, and solvents, but not on the details of a synthetic protocol. Herein incorporation of procedural text with the aim to augment the Graphormer reactivity model and improve its accuracy is presented. Two major approaches are used: tr_         _ More           Chemical reactivity models are developed to predict chemical reaction outcomes in the form of classification (success/failure) or regression (product yield) tasks. The vast majority of the reported models are trained solely on chemical information such as reactants, products, reagents, and solvents, but not on the details of a synthetic protocol. Herein incorporation of procedural text with the aim to augment the Graphormer reactivity model and improve its accuracy is presented. Two major approaches are used: training an adapter Graphormer model that is provided with a GPT-2-derived latent representation of the text procedure (ReacLLaMA-Adapter) and labeling an unlabeled part of a dataset with the LLaMA 2 model followed by training the Graphormer on an extended dataset (Zero-Shot Labeling ReacLLaMA). Both methodologies enhance the discernment of unpromising reactions, thereby providing more accurate models with improved specificity.         _ Less","","arXiv","https://arxiv.org/abs/2401.17267","1","0","origin_of_life"
"Deciphering regulatory architectures from synthetic single-cell expression patterns","Abstract:                _understand the impact of various biological and experimental parameters on the interpretation of experimental data. To that end, in this paper we create tens of thousands of synthetic single-cell gene expression outputs using both equilibrium and out-of-equilibrium models. These models make it possible to imitate the summary statistics (information footprint_         _ More           For the vast majority of genes in sequenced genomes, there is limited understanding of how they are regulated. Without such knowledge, it is not possible to perform a quantitative theory-experiment dialogue on how such genes give rise to physiological and evolutionary adaptation. One category of high-throughput experiments used to understand the sequence-phenotype relationship of the transcriptome is massively parallel reporter assays (MPRAs). However, to improve the versatility and scalability of MPRA pipelines, we need a 'theory of the experiment' to help us better understand the impact of various biological and experimental parameters on the interpretation of experimental data. To that end, in this paper we create tens of thousands of synthetic single-cell gene expression outputs using both equilibrium and out-of-equilibrium models. These models make it possible to imitate the summary statistics (information footprints and expression shift matrices) used to characterize the output of MPRAs and from this summary statistic to infer the underlying regulatory architecture. Specifically, we use a more refined implementation of the so-called thermodynamic models in which the binding energies of each sequence variant are derived from energy matrices. Our simulations reveal important effects of the parameters on MPRA data and we demonstrate our ability to optimize MPRA experimental designs with the goal of generating thermodynamic models of the transcriptome with base-pair specificity. Further, this approach makes it possible to carefully examine the mapping between mutations in binding sites and their corresponding expression profiles, a tool useful not only for better designing MPRAs, but also for exploring regulatory evolution.         _ Less","","arXiv","https://arxiv.org/abs/2401.15880","1","2","synthetic_biology"
"Validation of Golden Gate assemblies using highly multiplexed Nanopore amplicon sequencing","Abstract:                Golden Gate cloning has revolutionized synthetic biology. Its concept of modular, highly characterized libraries of parts that can be combined into higher order assemblies allows engineering principles to be applied to biological systems. The basic parts, typically stored in level 0 plasmids, are sequence validated by_         _ More           Golden Gate cloning has revolutionized synthetic biology. Its concept of modular, highly characterized libraries of parts that can be combined into higher order assemblies allows engineering principles to be applied to biological systems. The basic parts, typically stored in level 0 plasmids, are sequence validated by the method of choice and can be combined into higher order assemblies on demand. Higher order assemblies are typically transcriptional units, and multiple transcriptional units can be assembled into multi-gene constructs. Higher order Golden Gate assembly based on defined and validated parts usually does not introduce sequence changes. Therefore, simple validation of the assemblies, e.g. by colony PCR or restriction digest pattern analysis, is sufficient. However, in many experimental setups, researchers do not use defined parts, but rather part libraries, resulting in assemblies of high combinatorial complexity where sequencing again becomes mandatory. Here we present a detailed protocol for the use of a highly multiplexed dual barcode amplicon sequencing using the Nanopore sequencing platform for in-house sequence validation. The workflow, called DuBA.flow, is a start-to-finish procedure that provides all necessary steps from a single colony to the final easy-to-interpret sequencing report.         _ Less","","arXiv","https://arxiv.org/abs/2401.14191","0","2","synthetic_biology"
"Combining oligo pools and Golden Gate cloning to create protein variant libraries or guide RNA libraries for CRISPR applications","Abstract:                Oligo pools are array-synthesized, user-defined mixtures of single-stranded oligonucleotides that can be used as a source of synthetic DNA for library cloning. While currently offering the most affordable source of synthetic DNA, oligo pools also come with limitations such as a maximum synthesis length (approximately 3_         _ More           Oligo pools are array-synthesized, user-defined mixtures of single-stranded oligonucleotides that can be used as a source of synthetic DNA for library cloning. While currently offering the most affordable source of synthetic DNA, oligo pools also come with limitations such as a maximum synthesis length (approximately 350 bases), a higher error rate compared to alternative synthesis methods, and the presence of truncated molecules in the pool due to incomplete synthesis. Here, we provide users with a comprehensive protocol that details how oligo pools can be used in combination with Golden Gate cloning to create user-defined protein mutant libraries, as well as single guide RNA libraries for CRISPR applications. Our methods are optimized to work within the Yeast Toolkit Golden Gate scheme, but are in principle compatible with any other Golden Gate-based modular cloning toolkit and extendable to other restriction enzyme-based cloning methods beyond Golden Gate. Our methods yield high-quality, affordable, in-house variant libraries.         _ Less","","arXiv","https://arxiv.org/abs/2401.11746","1","2","synthetic_biology"
"Force Propagation in Active Cytoskeletal Networks","Abstract:                _for further exploration into the organization and propagation of forces/stresses in biological systems, thereby paving the way for the engineering of active materials in synthetic biology and soft robotics.         _ More           In biological systems, molecular-scale forces and motions are pivotal for enabling processes like motility, shape change, and replication. These forces and motions are organized, amplified, and transmitted across macroscopic scales by active materials such as the cytoskeleton, which drives micron-scale cellular movement and re-organization. Despite the integral role of active materials, understanding how molecular-scale interactions alter macroscopic structure and force propagation remains elusive. This knowledge gap presents challenges to the harnessing and regulation of such dynamics across diverse length scales. Here, we demonstrate how mediating the bundling of microtubules can shift active matter between a global force-transmitting phase and a local force-dissipating phase. A fivefold increase in microtubule effective length results in the transition from local to global phase with a hundredfold increase in velocity autocorrelation. Through theory and simulation, we identify signatures of a percolation-driven transition between the two phases. This provides evidence for how force propagation can be generated when local molecular interactions reach a sufficient length scale. We show that force propagation in the active matter system enables material transport. Consequently, we demonstrate that the global phase is capable of facilitating millimeter-scale human cell transport and manipulation, as well as powering the movement of aqueous droplets. These findings underscore the potential for designing active materials capable of force organization and transmission. Our results lay the foundation for further exploration into the organization and propagation of forces/stresses in biological systems, thereby paving the way for the engineering of active materials in synthetic biology and soft robotics.         _ Less","","arXiv","https://arxiv.org/abs/2401.04217","0","1","synthetic_biology"
"Discrete transforms of quantized persistence diagrams","Abstract:                Topological data analysis leverages topological features to analyze datasets, with applications in diverse fields like medical sciences and biology. A key tool of this theory is the persistence diagram, which encodes topological information but poses challenges for integration into standard machine learning pipelines. We introduce Qupid (QUantized Persistenc_         _ More           Topological data analysis leverages topological features to analyze datasets, with applications in diverse fields like medical sciences and biology. A key tool of this theory is the persistence diagram, which encodes topological information but poses challenges for integration into standard machine learning pipelines. We introduce Qupid (QUantized Persistence and Integral transforms of Diagrams), a novel and simple method for vectorizing persistence diagrams. First, Qupid uses a binning procedure to turn persistence diagrams into finite measures on a grid and then applies discrete transforms to these measures. Key features are the choice of log-scaled grids that emphasize information contained near the diagonal in persistence diagrams, combined with the use of discrete transforms to enhance and efficiently encode the obtained topological information. We conduct an in-depth experimental analysis of Qupid, showing that the simplicity of our method results in very low computational costs while preserving highly competitive performances compared to state-of-the-art methods across numerous classification tasks on both synthetic and real-world datasets. Finally, we provide experimental evidence that our method is robust to a decrease in the grid resolution used.         _ Less","","arXiv","https://arxiv.org/abs/2312.17093","1","0","origin_of_life"
"Identifying topologically associating domains using differential kernels","Abstract:                _and image processing that is able to accurately identify nested and overlapping TADs. We benchmark this method against state-of-the-art TAD identification methods on both synthetic and experimental data sets. We find that KerTAD consistently has higher true positive rates (TPR) and lower false discovery rates (FDR) than all tested methods for both_         _ More           Chromatin is a polymer complex of DNA and proteins that regulates gene expression. The three-dimensional structure and organization of chromatin controls DNA transcription and replication. High-throughput chromatin conformation capture techniques generate Hi-C maps that can provide insight into the 3D structure of chromatin. Hi-C maps can be represented as a symmetric matrix where each element represents the average contact probability or number of contacts between two chromatin loci. Previous studies have detected topologically associating domains (TADs), or self-interacting regions in Hi-C maps within which the contact probability is greater than that outside the region. Many algorithms have been developed to identify TADs within Hi-C maps. However, most TAD identification algorithms are unable to identify nested or overlapping TADs and for a given Hi-C map there is significant variation in the location and number of TADs identified by different methods. We develop a novel method, KerTAD, using a kernel-based technique from computer vision and image processing that is able to accurately identify nested and overlapping TADs. We benchmark this method against state-of-the-art TAD identification methods on both synthetic and experimental data sets. We find that KerTAD consistently has higher true positive rates (TPR) and lower false discovery rates (FDR) than all tested methods for both synthetic and manually annotated experimental Hi-C maps. The TPR for KerTAD is also largely insensitive to increasing noise and sparsity, in contrast to the other methods. We also find that KerTAD is consistent in the number and size of TADs identified across replicate experimental Hi-C maps for several organisms. KerTAD will improve automated TAD identification and enable researchers to better correlate changes in TADs to biological phenomena, such as enhancer-promoter interactions and disease states.         _ Less","","arXiv","https://arxiv.org/abs/2312.14342","1","0","origin_of_life"
"DiscoBAX: Discovery of Optimal Intervention Sets in Genomic Experiment Design","Abstract:                _experiment campaign. We provide theoretical guarantees of approximate optimality under standard assumptions, and conduct a comprehensive experimental evaluation covering both synthetic as well as real-world experimental design tasks. DiscoBAX outperforms existing state-of-the-art methods for experimental design, selecting effective and diverse perturbations_         _ More           The discovery of therapeutics to treat genetically-driven pathologies relies on identifying genes involved in the underlying disease mechanisms. Existing approaches search over the billions of potential interventions to maximize the expected influence on the target phenotype. However, to reduce the risk of failure in future stages of trials, practical experiment design aims to find a set of interventions that maximally change a target phenotype via diverse mechanisms. We propose DiscoBAX, a sample-efficient method for maximizing the rate of significant discoveries per experiment while simultaneously probing for a wide range of diverse mechanisms during a genomic experiment campaign. We provide theoretical guarantees of approximate optimality under standard assumptions, and conduct a comprehensive experimental evaluation covering both synthetic as well as real-world experimental design tasks. DiscoBAX outperforms existing state-of-the-art methods for experimental design, selecting effective and diverse perturbations in biological systems.         _ Less","","arXiv","https://arxiv.org/abs/2312.04064","1","1","multiple"
"Navigating the Synthetic Realm: Harnessing Diffusion-based Models for Laparoscopic Text-to-Image Generation","Abstract:                Recent advances in synthetic imaging open up opportunities for obtaining additional data in the field of surgical imaging. This data can provide reliable supplements supporting surgical applications and decision-making through computer vision. Particularly the field of image-guided surgery, such as laparoscopic and robotic-assisted surgery, benefits strongly_         _ More           Recent advances in synthetic imaging open up opportunities for obtaining additional data in the field of surgical imaging. This data can provide reliable supplements supporting surgical applications and decision-making through computer vision. Particularly the field of image-guided surgery, such as laparoscopic and robotic-assisted surgery, benefits strongly from synthetic image datasets and virtual surgical training methods. Our study presents an intuitive approach for generating synthetic laparoscopic images from short text prompts using diffusion-based generative models. We demonstrate the usage of state-of-the-art text-to-image architectures in the context of laparoscopic imaging with regard to the surgical removal of the gallbladder as an example. Results on fidelity and diversity demonstrate that diffusion-based models can acquire knowledge about the style and semantics in the field of image-guided surgery. A validation study with a human assessment survey underlines the realistic nature of our synthetic data, as medical personnel detects actual images in a pool with generated images causing a false-positive rate of 66%. In addition, the investigation of a state-of-the-art machine learning model to recognize surgical actions indicates enhanced results when trained with additional generated images of up to 5.20%. Overall, the achieved image quality contributes to the usage of computer-generated images in surgical applications and enhances its path to maturity.         _ Less","","arXiv","https://arxiv.org/abs/2312.03043","1","1","multiple"
"InfoFlowNet: A Multi-head Attention-based Self-supervised Learning Model with Surrogate Approach for Uncovering Brain Effective Connectivity","Abstract:                _of model inference resulting from the shuffling of the time order of the original time series. To evaluate the feasibility of InfoFlowNet, we conducted experiments using a synthetic time series and two EEG datasets. The results demonstrate that InfoFlowNet can extract time-varying causal relationships among processes, reflected in the fluctuation of dIF valu_         _ More           Deciphering brain network topology can enhance the depth of neuroscientific knowledge and facilitate the development of neural engineering methods. Effective connectivity, a measure of brain network dynamics, is particularly useful for investigating the directional influences among different brain regions. In this study, we introduce a novel brain causal inference model named InfoFlowNet, which leverages the self-attention mechanism to capture associations among electroencephalogram (EEG) time series. The proposed method estimates the magnitude of directional information flow (dIF) among EEG processes by measuring the loss of model inference resulting from the shuffling of the time order of the original time series. To evaluate the feasibility of InfoFlowNet, we conducted experiments using a synthetic time series and two EEG datasets. The results demonstrate that InfoFlowNet can extract time-varying causal relationships among processes, reflected in the fluctuation of dIF values. Compared with the Granger causality model and temporal causal discovery framework, InfoFlowNet can identify more significant causal edges underlying EEG processes while maintaining an acceptable computation time. Our work demonstrates the potential of InfoFlowNet for analyzing effective connectivity in EEG data. The findings highlight the importance of effective connectivity in understanding the complex dynamics of the brain network.         _ Less","","arXiv","https://arxiv.org/abs/2311.18527","1","0","origin_of_life"
"Automatic Implementation of Neural Networks through Reaction Networks -- Part I: Circuit Design and Convergence Analysis","Abstract:                _the cellular environment is essential for biological organisms. The implementation of molecular computational systems holds significant interest and potential in the fields of synthetic biology and molecular computation. This two-part article aims to introduce a programmable biochemical reaction network (BCRN) system e_         _ More           Information processing relying on biochemical interactions in the cellular environment is essential for biological organisms. The implementation of molecular computational systems holds significant interest and potential in the fields of synthetic biology and molecular computation. This two-part article aims to introduce a programmable biochemical reaction network (BCRN) system endowed with mass action kinetics that realizes the fully connected neural network (FCNN) and has the potential to act automatically in vivo. In part I, the feedforward propagation computation, the backpropagation component, and all bridging processes of FCNN are ingeniously designed as specific BCRN modules based on their dynamics. This approach addresses a design gap in the biochemical assignment module and judgment termination module and provides a novel precise and robust realization of bi-molecular reactions for the learning process. Through equilibrium approaching, we demonstrate that the designed BCRN system achieves FCNN functionality with exponential convergence to target computational results, thereby enhancing the theoretical support for such work. Finally, the performance of this construction is further evaluated on two typical logic classification problems.         _ Less","","arXiv","https://arxiv.org/abs/2311.18313","1","3","synthetic_biology"
"Personalized Predictions of Glioblastoma Infiltration: Mathematical Models, Physics-Informed Neural Networks and Multimodal Scans","Abstract:                _specific parameters. Additionally, the diffuse domain method is employed to handle the complex brain geometry within the PINN framework. Our method is validated both on synthetic and patient datasets, and shows promise for real-time parametric inference in the clinical setting for personalized GBM treatment.         _ More           Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is crucial for understanding tumor growth dynamics and designing personalized radiotherapy treatment plans.Mathematical models of GBM growth can complement the data in the prediction of spatial distributions of tumor cells. However, this requires estimating patient-specific parameters of the model from clinical data, which is a challenging inverse problem due to limited temporal data and the limited time between imaging and diagnosis. This work proposes a method that uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific parameters of a reaction-diffusion PDE model of GBM growth from a single 3D structural MRI snapshot. PINNs embed both the data and the PDE into a loss function, thus integrating theory and data. Key innovations include the identification and estimation of characteristic non-dimensional parameters, a pre-training step that utilizes the non-dimensional parameters and a fine-tuning step to determine the patient specific parameters. Additionally, the diffuse domain method is employed to handle the complex brain geometry within the PINN framework. Our method is validated both on synthetic and patient datasets, and shows promise for real-time parametric inference in the clinical setting for personalized GBM treatment.         _ Less","","arXiv","https://arxiv.org/abs/2311.16536","0","1","synthetic_biology"
"Beyond the aggregated paradigm: phenology and structure in mutualistic networks","Abstract:                _within a season -- to fully understand the effects of temporal variability on network architecture. In this paper, by using two empirical datasets together with a set of synthetic models, we propose a framework to characterize phenology on ecological networks and assess the effect of temporal variability. Analyses reveal that non-trivial information is misse_         _ More           Mutualistic interactions, where species interact to obtain mutual benefits, constitute an essential component of natural ecosystems. The use of ecological networks to represent the species and their ecological interactions allows the study of structural and dynamic patterns common to different ecosystems. However, by neglecting the temporal dimension of mutualistic communities, relevant insights into the organization and functioning of natural ecosystems can be lost. Therefore, it is crucial to incorporate empirical phenology -- the cycles of species' activity within a season -- to fully understand the effects of temporal variability on network architecture. In this paper, by using two empirical datasets together with a set of synthetic models, we propose a framework to characterize phenology on ecological networks and assess the effect of temporal variability. Analyses reveal that non-trivial information is missed when portraying the network of interactions as static, which leads to overestimating the value of fundamental structural features. We discuss the implications of our findings for mutualistic relationships and intra-guild competition for common resources. We show that recorded interactions and species' activity duration are pivotal factors in accurately replicating observed patterns within mutualistic communities. Furthermore, our exploration of synthetic models underscores the system-specific character of the mechanisms driving phenology, increasing our understanding of the complexities of natural ecosystems.         _ Less","","arXiv","https://arxiv.org/abs/2311.15059","1","0","origin_of_life"
"RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation","Abstract:                Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to aid chemists in finding appropriate reactant molecules and synthetic pathways given determined product molecules. With the reactant and product represented as 2D graphs, retrosynthesis constitutes a conditional graph-to-graph generative task. Inspired by the recent advancements in_         _ More           Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to aid chemists in finding appropriate reactant molecules and synthetic pathways given determined product molecules. With the reactant and product represented as 2D graphs, retrosynthesis constitutes a conditional graph-to-graph generative task. Inspired by the recent advancements in discrete diffusion models for graph generation, we introduce Retrosynthesis Diffusion (RetroDiff), a novel diffusion-based method designed to address this problem. However, integrating a diffusion-based graph-to-graph framework while retaining essential chemical reaction template information presents a notable challenge. Our key innovation is to develop a multi-stage diffusion process. In this method, we decompose the retrosynthesis procedure to first sample external groups from the dummy distribution given products and then generate the external bonds to connect the products and generated groups. Interestingly, such a generation process is exactly the reverse of the widely adapted semi-template retrosynthesis procedure, i.e. from reaction center identification to synthon completion, which significantly reduces the error accumulation. Experimental results on the benchmark have demonstrated the superiority of our method over all other semi-template methods.         _ Less","","arXiv","https://arxiv.org/abs/2311.14077","1","0","origin_of_life"
"Directed Evolution of Microorganisms for Engineered Living Materials","Abstract:                Microorganisms can create engineered materials with exquisite structures and living functionalities. Although synthetic biology tools to genetically manipulate microorganisms continue to expand, the bottom-up rational design of engineered living materials still relies on prior knowledge of genotype-phenotype links for_         _ More           Microorganisms can create engineered materials with exquisite structures and living functionalities. Although synthetic biology tools to genetically manipulate microorganisms continue to expand, the bottom-up rational design of engineered living materials still relies on prior knowledge of genotype-phenotype links for the function of interest. Here, we utilize a high-throughput directed evolution platform to enhance the fitness of whole microorganisms under selection pressure and identify novel genetic pathways to program the functionalities of engineered living materials. Using Komagataeibacter sucrofermentans as a model cellulose-producing microorganism, we show that our droplet-based microfluidic platform enables the directed evolution of these bacteria towards a small number of cellulose overproducers from an initial pool of 40'000 random mutants. Sequencing of the evolved strains reveals an unexpected link between the cellulose-forming ability of the bacteria and a gene encoding a protease complex responsible for protein turnover in the cell. The ability to enhance the fitness of microorganisms towards specific phenotypes and to discover new genotype-phenotype links makes this high-throughput directed evolution platform a promising tool for the development of the next generation of engineered living materials.         _ Less","","arXiv","https://arxiv.org/abs/2311.13342","0","3","synthetic_biology"
"Velde: constructing cell potential landscapes by RNA velocity vector field decomposition","Abstract:                _functions, potential landscapes for both cell differentiation and the cell cycle are obtained. Finally, the efficacy of this method is demonstrated through its application to synthetic and real datasets.         _ More           The Waddington landscape serves as a metaphor illustrating the developmental process of cells, likening it to a small ball rolling down various trajectories into valleys. Constructing an epigenetic landscape of this nature aids in visualizing and gaining insights into cell differentiation. Development encompasses intricate processes involving both cell differentiation and cell cycles. However, current landscape methods solely focus on constructing a potential landscape for cell differentiation, neglecting the accompanying cell cycle. This paper introduces a novel method that simultaneously constructs two types of potential landscapes using single-cell RNA sequencing data. Specifically, it presents the natural Helmholtz-Hodge decomposition (nHHD) of a continuous vector field within a bounded domain in n-dimensional Euclidean space. This decomposition uniquely breaks down the vector field into a gradient field, a rotation field, and a harmonic field. Utilizing this approach, the RNA velocity vector field is separated into a curl-free component representing cell differentiation and a curl component representing the cell cycle. By calculating the corresponding potential functions, potential landscapes for both cell differentiation and the cell cycle are obtained. Finally, the efficacy of this method is demonstrated through its application to synthetic and real datasets.         _ Less","","arXiv","https://arxiv.org/abs/2311.10403","0","1","synthetic_biology"
"The optimal resolution level of a protein is an emergent property of its structure and dynamics","Abstract:                _method (PROPRE), an unsupervised approach built on information theory principles that determines the smallest number of atoms that need to be retained in order to attain a synthetic yet informative description of a protein. By applying the method to a protein dataset and two particular case studies, we show that this number is typically between 1.5 and 2 tim_         _ More           Molecular dynamics simulations provide a wealth of data whose in-depth analysis can be computationally demanding and, sometimes, even unnecessary. Dimensionality reduction techniques are thus routinely employed to simplify and improve the interpretation of trajectories focusing on specific subsets of the system's atoms; a still open problem, in this context, is to determine the optimal resolution level of the molecule, i.e. the smallest number of atoms needed to preserve the largest information content from the full atomistic trajectory. Here, we introduce the protein optimal resolution identification method (PROPRE), an unsupervised approach built on information theory principles that determines the smallest number of atoms that need to be retained in order to attain a synthetic yet informative description of a protein. By applying the method to a protein dataset and two particular case studies, we show that this number is typically between 1.5 and 2 times the amount of residues in a protein; furthermore, the degree of structural variability of the system influences the optimal resolution level importantly, in that a broader range of large-scale conformations correlates with fewer retained sites. The PROPRE method is implemented in efficient and user-friendly python scripts, which are made available for download on a github repository.         _ Less","","arXiv","https://arxiv.org/abs/2311.08076","1","0","origin_of_life"
"Evaluating the Potential of Leading Large Language Models in Reasoning Biology Questions","Abstract:                _into biological research and education. This study evaluated the capabilities of leading LLMs, including GPT-4, GPT-3.5, PaLM2, Claude2, and SenseNova, in answering conceptual biology questions. The models were tested on a 108-question multiple-choice exam covering_         _ More           Recent advances in Large Language Models (LLMs) have presented new opportunities for integrating Artificial General Intelligence (AGI) into biological research and education. This study evaluated the capabilities of leading LLMs, including GPT-4, GPT-3.5, PaLM2, Claude2, and SenseNova, in answering conceptual biology questions. The models were tested on a 108-question multiple-choice exam covering biology topics in molecular biology, biological techniques, metabolic engineering, and synthetic biology. Among the models, GPT-4 achieved the highest average score of 90 and demonstrated the greatest consistency across trials with different prompts. The results indicated GPT-4's proficiency in logical reasoning and its potential to aid biology research through capabilities like data analysis, hypothesis generation, and knowledge integration. However, further development and validation are still required before the promise of LLMs in accelerating biological discovery can be realized.         _ Less","","arXiv","https://arxiv.org/abs/2311.07582","0","1","synthetic_biology"
"PepLand: a large-scale pre-trained peptide representation model for a comprehensive landscape of both canonical and non-canonical amino acids","Abstract:                _protein-protein interactions, permeability, solubility, and synthesizability. The rigorous evaluation confirms PepLand's unparalleled capability in capturing salient synthetic peptide features, thereby laying a robust foundation for transformative advances in peptide-centric research domains. We have made all the source code utilized in this study public_         _ More           In recent years, the scientific community has become increasingly interested on peptides with non-canonical amino acids due to their superior stability and resistance to proteolytic degradation. These peptides present promising modifications to biological, pharmacological, and physiochemical attributes in both endogenous and engineered peptides. Notwithstanding their considerable advantages, the scientific community exhibits a conspicuous absence of an effective pre-trained model adept at distilling feature representations from such complex peptide sequences. We herein propose PepLand, a novel pre-training architecture for representation and property analysis of peptides spanning both canonical and non-canonical amino acids. In essence, PepLand leverages a comprehensive multi-view heterogeneous graph neural network tailored to unveil the subtle structural representations of peptides. Empirical validations underscore PepLand's effectiveness across an array of peptide property predictions, encompassing protein-protein interactions, permeability, solubility, and synthesizability. The rigorous evaluation confirms PepLand's unparalleled capability in capturing salient synthetic peptide features, thereby laying a robust foundation for transformative advances in peptide-centric research domains. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/pepland         _ Less","","arXiv","https://arxiv.org/abs/2311.04419","1","1","multiple"
"Combining Compositional Data Sets Introduces Error in Covariance Network Reconstruction","Abstract:                _data involved using standard network inference techniques. We quantify the challenges of cross-kingdom network inference from both a theoretical and practical viewpoint using synthetic and real-world microbiome data. We detail the theoretical issue presented by combining compositional data sets drawn from the same environment, e.g. 16S and ITS sequencing of_         _ More           Microbial communities are diverse biological systems that include taxa from across multiple kingdoms of life. Notably, interactions between bacteria and fungi play a significant role in determining community structure. However, these statistical associations across kingdoms are more difficult to infer than intra-kingdom associations due to the nature of the data involved using standard network inference techniques. We quantify the challenges of cross-kingdom network inference from both a theoretical and practical viewpoint using synthetic and real-world microbiome data. We detail the theoretical issue presented by combining compositional data sets drawn from the same environment, e.g. 16S and ITS sequencing of a single set of samples, and survey common network inference techniques for their ability to handle this error. We then test these techniques for the accuracy and usefulness of their intra- and inter-kingdom associations by inferring networks from a set of simulated samples for which a ground-truth set of associations is known. We show that while two methods mitigate the error of cross-kingdom inference, there is little difference between techniques for key practical applications including identification of strong correlations and identification of possible keystone taxa (i.e. hub nodes in the network). Furthermore, we identify a signature of the error caused transkingdom network inference and demonstrate that it appears in networks constructed using real-world environmental microbiome data.         _ Less","","arXiv","https://arxiv.org/abs/2311.04357","1","1","multiple"
"Auto-ICell: An Accessible and Cost-Effective Integrative Droplet Microfluidic System for Real-Time Single-Cell Morphological and Apoptotic Analysis","Abstract:                _in advancing biological research and personalized disease treatment, with promising applications in cell culture, biochemical microreactors, drug carriers, cell-based assays, synthetic biology, and point-of-care diagnostics.         _ More           The Auto-ICell system, a novel, and cost-effective integrated droplet microfluidic system, is introduced for real-time analysis of single-cell morphology and apoptosis. This system integrates a 3D-printed microfluidic chip with image analysis algorithms, enabling the generation of uniform droplet reactors and immediate image analysis. The system employs a color-based image analysis algorithm in the bright field for droplet content analysis. Meanwhile, in the fluorescence field, cell apoptosis is quantitatively measured through a combination of deep-learning-enabled multiple fluorescent channel analysis and a live/dead cell stain kit. Breast cancer cells are encapsulated within uniform droplets, with diameters ranging from 70 _m to 240 _m, generated at a high throughput of 1,500 droplets per minute. Real-time image analysis results are displayed within 2 seconds on a custom graphical user interface (GUI). The system provides an automatic calculation of the distribution and ratio of encapsulated dyes in the bright field, and in the fluorescent field, cell blebbing and cell circularity are observed and quantified respectively. The Auto-ICell system is non-invasive and provides online detection, offering a robust, time-efficient, user-friendly, and cost-effective solution for single-cell analysis. It significantly enhances the detection throughput of droplet single-cell analysis by reducing setup costs and improving operational performance. This study highlights the potential of the Auto-ICell system in advancing biological research and personalized disease treatment, with promising applications in cell culture, biochemical microreactors, drug carriers, cell-based assays, synthetic biology, and point-of-care diagnostics.         _ Less","","arXiv","https://arxiv.org/abs/2311.02927","0","1","synthetic_biology"
"Dissipative quadratizations of polynomial ODE systems","Abstract:                _the original model, specifically dissipativity at given equilibria. This preservation is desirable in many applications of quadratization including reachability analysis and synthetic biology. We establish the existence of dissipativity-preserving quadratizations, develop an algorithm for their computation, and demonst_         _ More           Quadratization refers to a transformation of an arbitrary system of polynomial ordinary differential equations to a system with at most quadratic right-hand side. Such a transformation unveils new variables and model structures that facilitate model analysis, simulation, and control and offers a convenient parameterization for data-driven approaches. Quadratization techniques have found applications in diverse fields, including systems theory, fluid mechanics, chemical reaction modeling, and mathematical analysis.   In this study, we focus on quadratizations that preserve the stability properties of the original model, specifically dissipativity at given equilibria. This preservation is desirable in many applications of quadratization including reachability analysis and synthetic biology. We establish the existence of dissipativity-preserving quadratizations, develop an algorithm for their computation, and demonstrate it in several case studies.         _ Less","","arXiv","https://arxiv.org/abs/2311.02508","1","1","multiple"
"An algorithmic framework for synthetic cost-aware decision making in molecular design","Abstract:                _on expert chemist intuition. We propose a quantitative decision-making framework, SPARROW, that prioritizes molecules for evaluation by balancing expected information gain and synthetic cost. SPARROW integrates molecular design, property prediction, and retrosynthetic planning to balance the utility of testing a molecule with the cost of batch synthesis. We_         _ More           Small molecules exhibiting desirable property profiles are often discovered through an iterative process of designing, synthesizing, and testing sets of molecules. The selection of molecules to synthesize from all possible candidates is a complex decision-making process that typically relies on expert chemist intuition. We propose a quantitative decision-making framework, SPARROW, that prioritizes molecules for evaluation by balancing expected information gain and synthetic cost. SPARROW integrates molecular design, property prediction, and retrosynthetic planning to balance the utility of testing a molecule with the cost of batch synthesis. We demonstrate through three case studies that the developed algorithm captures the non-additive costs inherent to batch synthesis, leverages common reaction steps and intermediates, and scales to hundreds of molecules. SPARROW is open source and can be found at http://github.com/coleygroup/sparrow.         _ Less","","arXiv","https://arxiv.org/abs/2311.02187","1","0","origin_of_life"
"Deciphering circulating tumor cells binding in a microfluidic system thanks to a parameterized mathematical model","Abstract:                _the strong influence of fluid velocity on adhesion and confirms the expected role of several proteins in the deceleration of CTCs. Finally, it enables the generation of synthetic cells, even for unobserved experimental conditions, opening the way to a digital twin for flowing cells with adhesion.         _ More           The spread of metastases is a crucial process in which some questions remain unanswered. In this work, we focus on tumor cells circulating in the bloodstream, the so-called Circulating Tumor Cells (CTCs). Our aim is to characterize their trajectories under the influence of hemodynamic and adhesion forces. We focus on already available in vitro measurements performed with a microfluidic device corresponding to the trajectories of CTCs -- without or with different protein depletions -- interacting with an endothelial layer. A key difficulty is the weak knowledge of the fluid velocity that has to be reconstructed. Our strategy combines a differential equation model -- a Poiseuille model for the fluid velocity and an ODE system for the cell adhesion model -- and a robust and well-designed calibration procedure. The parameterized model quantifies the strong influence of fluid velocity on adhesion and confirms the expected role of several proteins in the deceleration of CTCs. Finally, it enables the generation of synthetic cells, even for unobserved experimental conditions, opening the way to a digital twin for flowing cells with adhesion.         _ Less","","arXiv","https://arxiv.org/abs/2311.02091","0","1","synthetic_biology"
"The physical origin of aneurysm growth, dissection, and rupture","Abstract:                _rupture because the fundamental physics driving aneurysm progression is unknown. Here, via in-vitro experiments, we show that a blood-wall, fluttering instability manifests in synthetic arteries under pulsatile forcing. We establish a phase space to prove that the transition from stable flow to unstable aortic flutter is accurately predicted by a flutter ins_         _ More           Rupture of aortic aneurysms is by far the most fatal heart disease, with a mortality rate exceeding 80%. There are no reliable clinical protocols to predict growth, dissection, and rupture because the fundamental physics driving aneurysm progression is unknown. Here, via in-vitro experiments, we show that a blood-wall, fluttering instability manifests in synthetic arteries under pulsatile forcing. We establish a phase space to prove that the transition from stable flow to unstable aortic flutter is accurately predicted by a flutter instability parameter derived from first principles. Time resolved strain maps of the evolving system reveal the dynamical characteristics of aortic flutter that drive aneurysm progression. We show that low level instability can trigger permanent aortic growth, even in the absence of material remodeling. Sufficiently large flutter beyond a secondary threshold localizes strain in the walls to the length scale clinically observed in aortic dissection. Lastly, significant physical flutter beyond a tertiary threshold can ultimately induce aneurysm rupture via failure modes reported from necropsy. Resolving the fundamental physics of aneurysm progression directly leads to clinical protocols that forecast growth as well as intercept dissection and rupture by pinpointing their physical origin.         _ Less","","arXiv","https://arxiv.org/abs/2311.00652","0","1","synthetic_biology"
"Spatial information allows inference of the prevalence of direct cell-to-cell viral infection","Abstract:                _work, we conduct a simulation-estimation study to probe the practical identifiability of the proportion of cell-to-cell infection, using two standard mathematical models and synthetic data that would likely be realistic to obtain in the laboratory. We show that this quantity cannot be estimated using non-spatial data alone, and that the collection of a data_         _ More           The role of direct cell-to-cell spread in viral infections - where virions spread between host and susceptible cells without needing to be secreted into the extracellular environment - has come to be understood as essential to the dynamics of medically significant viruses like hepatitis C and influenza. Recent work in both the experimental and mathematical modelling literature has attempted to quantify the prevalence of cell-to-cell infection compared to the conventional free virus route using a variety of methods and experimental data. However, estimates are subject to significant uncertainty and moreover rely on data collected by inhibiting one mode of infection by either chemical or physical factors, which may influence the other mode of infection to an extent which is difficult to quantify. In this work, we conduct a simulation-estimation study to probe the practical identifiability of the proportion of cell-to-cell infection, using two standard mathematical models and synthetic data that would likely be realistic to obtain in the laboratory. We show that this quantity cannot be estimated using non-spatial data alone, and that the collection of a data which describes the spatial structure of the infection is necessary to infer the proportion of cell-to-cell infection. Our results provide guidance for the design of relevant experiments and mathematical tools for accurately inferring the prevalence of cell-to-cell infection in $\\textit{in vitro}$ and $\\textit{in vivo}$ contexts.         _ Less","","arXiv","https://arxiv.org/abs/2310.19481","1","0","origin_of_life"
"Modular Golden Gate Assembly of Linear DNA Templates for Cell-free Prototyping","Abstract:                _as a powerful tool for testing genetic regulatory elements and circuits. Cell-free prototyping can dramatically accelerate the design-build-test cycle of new functions in synthetic biology, in particular when linear DNA templates are used. Here we describe a Golden Gate assisted workflow to rapidly produce linear DNA t_         _ More           Cell-free transcription and translation (TXTL) systems have emerged as a powerful tool for testing genetic regulatory elements and circuits. Cell-free prototyping can dramatically accelerate the design-build-test cycle of new functions in synthetic biology, in particular when linear DNA templates are used. Here we describe a Golden Gate assisted workflow to rapidly produce linear DNA templates for TXTL reactions by assembling transcriptional units from basic genetic parts of a modular cloning toolbox. Functional DNA templates composed of multiple parts such as promoter, ribosomal binding site (RBS), coding sequence, and terminator are produced in vitro in a one-pot Golden Gate assembly reaction followed by PCR amplification. By eliminating lengthy transformation and cloning steps in cells and by taking advantage of modular cloning toolboxes, our cell-free prototyping workflow can produce data for large numbers of new constructs within a single day.         _ Less","","arXiv","https://arxiv.org/abs/2310.13665","1","1","multiple"
"Tree Search in DAG Space with Model-based Reinforcement Learning for Causal Discovery","Abstract:                Identifying causal structure is central to many fields ranging from strategic decision-making to biology and economics. In this work, we propose CD-UCT, a model-based reinforcement learning method for causal discovery based on tree search that builds directed acyclic graphs incrementally. We also formalize and prove the correctness of an efficient algorithm_         _ More           Identifying causal structure is central to many fields ranging from strategic decision-making to biology and economics. In this work, we propose CD-UCT, a model-based reinforcement learning method for causal discovery based on tree search that builds directed acyclic graphs incrementally. We also formalize and prove the correctness of an efficient algorithm for excluding edges that would introduce cycles, which enables deeper discrete search and sampling in DAG space. The proposed method can be applied broadly to causal Bayesian networks with both discrete and continuous random variables. We conduct a comprehensive evaluation on synthetic and real-world datasets, showing that CD-UCT substantially outperforms the state-of-the-art model-free reinforcement learning technique and greedy search, constituting a promising advancement for combinatorial methods.         _ Less","","arXiv","https://arxiv.org/abs/2310.13576","1","1","multiple"
"Single-Molecule Morphology of Topologically Digested Olympic Networks","Abstract:                _of DNA minicircles and found in the mitochondrion of certain parasites. The evolution, replication and self-assembly of this structure are fascinating open questions in biology that can also inform us how to realise synthetic Olympic networks in vitro. To obtain a deeper understanding of the structure and assembly of k_         _ More           The kinetoplast DNA (kDNA) is the archetype of a two-dimensional Olympic network, composed of thousands of DNA minicircles and found in the mitochondrion of certain parasites. The evolution, replication and self-assembly of this structure are fascinating open questions in biology that can also inform us how to realise synthetic Olympic networks in vitro. To obtain a deeper understanding of the structure and assembly of kDNA networks, we sequenced the Crithidia fasciculata kDNA genome and performed high-resolution Atomic Force Microscopy (AFM) and analysis of kDNA networks that had been partially digested by selected restriction enzymes. We discovered that these topological perturbations lead to networks with significantly different geometrical features and morphologies with respect to the unperturbed kDNA, and that these changes are strongly dependent on the class of DNA circles targeted by the restriction enzymes. Specifically, cleaving maxicircles leads to a dramatic reduction in network size once adsorbed onto the surface, whilst cleaving both maxicircles and a minor class of minicircles yields non-circular and deformed structures. We argue that our results are a consequence of a precise positioning of the maxicircles at the boundary of the network, and we discuss our findings in the context of kDNA biogenesis, design of artificial Olympic networks and detection of in vivo perturbations.         _ Less","","arXiv","https://arxiv.org/abs/2310.13399","0","3","synthetic_biology"
"Multi-omics Sampling-based Graph Transformer for Synthetic Lethality Prediction","Abstract:        Synthetic lethality (SL) prediction is used to identify if the co-mutation of two genes results in cell death. The prevalent strategy is to abstract SL prediction as an edge classification task on gene nodes within SL data and achieve it through graph neural networks (GNNs). However, GNNs suffer from limitations in their message passing mechanisms, including_         _ More   Synthetic lethality (SL) prediction is used to identify if the co-mutation of two genes results in cell death. The prevalent strategy is to abstract SL prediction as an edge classification task on gene nodes within SL data and achieve it through graph neural networks (GNNs). However, GNNs suffer from limitations in their message passing mechanisms, including over-smoothing and over-squashing issues. Moreover, harnessing the information of non-SL gene relationships within large-scale multi-omics data to facilitate SL prediction poses a non-trivial challenge. To tackle these issues, we propose a new multi-omics sampling-based graph transformer for SL prediction (MSGT-SL). Concretely, we introduce a shallow multi-view GNN to acquire local structural patterns from both SL and multi-omics data. Further, we input gene features that encode multi-view information into the standard self-attention to capture long-range dependencies. Notably, starting with batch genes from SL data, we adopt parallel random walk sampling across multiple omics gene graphs encompassing them. Such sampling effectively and modestly incorporates genes from omics in a structure-aware manner before using self-attention. We showcase the effectiveness of MSGT-SL on real-world SL tasks, demonstrating the empirical benefits gained from the graph transformer and multi-omics data.         _ Less","","arXiv","https://arxiv.org/abs/2310.11082","1","0","origin_of_life"
"Chemotactic crawling of multivalent vesicles along ligand-density gradients","Abstract:                _and perform chemotactic motion towards higher ligand concentrations. Adhesion occurs via vesicle-anchored receptors and substrate-anchored ligands, both consisting of synthetic DNA linkers that allow precise control over binding strength. Experimental data, rationalised through numerical and theoretical models, reveal that motion directionality is correlate_         _ More           Living cells are capable of interacting with their environments in a variety of ways, including cell signalling, adhesion, and directed motion. These behaviours are often mediated by receptor molecules embedded in the cell membrane, which bind specific ligands. Adhesion mediated by a large number of weakly binding moieties - multivalent binding - is prevalent in a range of active cellular processes, such as cell crawling and pathogen-host invasion. In these circumstances, motion is often caused by gradients in ligand density, which constitutes a simple example of chemotaxis. To unravel the biophysics of chemotactic multivalent adhesion, we have designed an experimental system in which artificial cell models based on lipid vesicles adhere to a substrate through multivalent interactions, and perform chemotactic motion towards higher ligand concentrations. Adhesion occurs via vesicle-anchored receptors and substrate-anchored ligands, both consisting of synthetic DNA linkers that allow precise control over binding strength. Experimental data, rationalised through numerical and theoretical models, reveal that motion directionality is correlated to both binding strength and vesicle size. Besides providing insights into the biophysics of chemotactic multivalent adhesion, our results highlight design rules applicable to the development of biomimetic motile systems for synthetic biology and therapeutic applications.         _ Less","","arXiv","https://arxiv.org/abs/2310.09990","1","3","synthetic_biology"
"DNA-Based Data Storage Systems: A Review of Implementations and Code Constructions","Abstract:                _we delve into the nascent field of molecular data storage, focusing on system implementations and code constructions. We start by providing an overview of basic concepts in synthetic and computational biology. Afterwards, we proceed with a review of the diverse approaches followed to implement such systems. In the pro_         _ More           In this review paper, we delve into the nascent field of molecular data storage, focusing on system implementations and code constructions. We start by providing an overview of basic concepts in synthetic and computational biology. Afterwards, we proceed with a review of the diverse approaches followed to implement such systems. In the process, we identify new problems in communication and coding theory, and discuss some relevant results pertaining to DNA sequence profiles, coded trace reconstruction, coding for DNA punchcard systems and coding for unique reconstruction.         _ Less","","arXiv","https://arxiv.org/abs/2310.04694","2","2","multiple"
"Theory of the center-of-mass diffusion and viscosity of microstructured and variable sequence copolymer liquids","Abstract:                _intracellular materials in a membrane-less fashion. Traditionally, these condensates have been regarded as homogeneous isotropic liquids. However, in analogy with some synthetic copolymer systems, our recent theoretical research has demonstrated that model biomolecular condensates can exhibit a microemulsion-like internal structure, contingent upon the speci_         _ More           Biomolecular condensates formed through the phase separation of proteins and nucleic acids are widely observed, offering a fundamental means of organizing intracellular materials in a membrane-less fashion. Traditionally, these condensates have been regarded as homogeneous isotropic liquids. However, in analogy with some synthetic copolymer systems, our recent theoretical research has demonstrated that model biomolecular condensates can exhibit a microemulsion-like internal structure, contingent upon the specific sequence, inter-chain site-site interactions, and concentrated phase polymer density. In this study, we present a microscopic dynamical theory for the self-diffusion constant and viscosity of concentrated unentangled A/B regular multiblock copolymer solutions. Our approach integrates static equilibrium local and microdomain scale structural information obtained from PRISM integral equation theory and the time evolution of the autocorrelation function of monomer scale forces at the center-of-mass level that determine the polymer diffusion constant and viscosity in a weak caging regime far from a glass or gel transition. We focus on regular multi-block systems both for simplicity and for its relevance to synthetic macromolecular science. The impact of sequence and inter-chain attraction strength on the slowing down of copolymer mass transport and flow due to local clustering enhanced collisional friction and retardation of motion due to emergent microdomain scale ordering are established. Analytic analysis and metrics employed in the study of biomolecular condensates are employed to identify key order parameters that quantity how attractive forces, packing structure, multiblock sequence, and copolymer density determine dynamical slowing down above and below the crossover to a fluctuating polymeric microemulsion state.         _ Less","","arXiv","https://arxiv.org/abs/2310.04524","1","1","multiple"
"Causal Inference in Gene Regulatory Networks with GFlowNet: Towards Scalability in Large Systems","Abstract:                _concerns. Specifically, Swift-DynGFN exploits gene-wise independence to boost parallelization and to lower computational cost. Experiments on real single-cell RNA velocity and synthetic GRN datasets showcase the advancement in learning causal structure in GRNs and scalability in larger systems.         _ More           Understanding causal relationships within Gene Regulatory Networks (GRNs) is essential for unraveling the gene interactions in cellular processes. However, causal discovery in GRNs is a challenging problem for multiple reasons including the existence of cyclic feedback loops and uncertainty that yields diverse possible causal structures. Previous works in this area either ignore cyclic dynamics (assume acyclic structure) or struggle with scalability. We introduce Swift-DynGFN as a novel framework that enhances causal structure learning in GRNs while addressing scalability concerns. Specifically, Swift-DynGFN exploits gene-wise independence to boost parallelization and to lower computational cost. Experiments on real single-cell RNA velocity and synthetic GRN datasets showcase the advancement in learning causal structure in GRNs and scalability in larger systems.         _ Less","","arXiv","https://arxiv.org/abs/2310.03579","0","1","synthetic_biology"
"Synthetic CT Generation via Variant Invertible Network for All-digital Brain PET Attenuation Correction","Abstract:                _brain PET imaging. Specifically, an invertible network combined with the variable augmentation strategy that can achieve the bidirectional inference processes is proposed for synthetic CT generation (IVNAC). To evaluate the performance of the proposed algorithm, we conducted a comprehensive study on a total of 1440 data from 37 clinical patients using compar_         _ More           Attenuation correction (AC) is essential for the generation of artifact-free and quantitatively accurate positron emission tomography (PET) images. However, AC of PET faces challenges including inter-scan motion and erroneous transformation of structural voxel-intensities to PET attenuation-correction factors. Nowadays, the problem of AC for quantitative PET have been solved to a large extent after the commercial availability of devices combining PET with computed tomography (CT). Meanwhile, considering the feasibility of a deep learning approach for PET AC without anatomical imaging, this paper develops a PET AC method, which uses deep learning to generate continuously valued CT images from non-attenuation corrected PET images for AC on brain PET imaging. Specifically, an invertible network combined with the variable augmentation strategy that can achieve the bidirectional inference processes is proposed for synthetic CT generation (IVNAC). To evaluate the performance of the proposed algorithm, we conducted a comprehensive study on a total of 1440 data from 37 clinical patients using comparative algorithms (such as Cycle-GAN and Pix2pix). Perceptual analysis and quantitative evaluations illustrate that the invertible network for PET AC outperforms other existing AC models, which demonstrates the potential of the proposed method and the feasibility of achieving brain PET AC without CT.         _ Less","","arXiv","https://arxiv.org/abs/2310.01885","2","1","origin_of_life"
"A comprehensive comparison of tools for fitting mutational signatures","Abstract:                _is lacking for tools that fit known mutational signatures to a given catalog of mutations. We fill this gap by comprehensively evaluating twelve signature fitting tools on synthetic mutational catalogs with empirically-driven signature weights corresponding to eight cancer types. On average, SigProfilerSingleSample and SigProfilerAssignment/MuSiCal perform b_         _ More           Mutational signatures connect characteristic mutational patterns in the genome with biological or chemical processes that take place in cancers. Analysis of mutational signatures can help elucidate tumor evolution, prognosis, and therapeutic strategies. Although tools for extracting mutational signatures de novo have been extensively benchmarked, a similar effort is lacking for tools that fit known mutational signatures to a given catalog of mutations. We fill this gap by comprehensively evaluating twelve signature fitting tools on synthetic mutational catalogs with empirically-driven signature weights corresponding to eight cancer types. On average, SigProfilerSingleSample and SigProfilerAssignment/MuSiCal perform best for small and large numbers of mutations per sample, respectively. We further show that ad hoc constraining the list of reference signatures is likely to produce inferior results. Evaluation of real mutational catalogs suggests that the activity of signatures that are absent in the reference catalog poses considerable problems to all evaluated tools.         _ Less","","arXiv","https://arxiv.org/abs/2310.01562","1","2","synthetic_biology"
"AI-Aristotle: A Physics-Informed framework for Systems Biology Gray-Box Identification","Abstract:                _challenge in scientific research. We present a new physics-informed framework for parameter estimation and missing physics identification (gray-box) in the field of Systems Biology. The proposed framework -- named AI-Aristotle -- combines eXtreme Theory of Functional Connections (X-TFC) domain-decomposition and Physics-Informed Neural Networks (PINNs) with s_         _ More           Discovering mathematical equations that govern physical and biological systems from observed data is a fundamental challenge in scientific research. We present a new physics-informed framework for parameter estimation and missing physics identification (gray-box) in the field of Systems Biology. The proposed framework -- named AI-Aristotle -- combines eXtreme Theory of Functional Connections (X-TFC) domain-decomposition and Physics-Informed Neural Networks (PINNs) with symbolic regression (SR) techniques for parameter discovery and gray-box identification. We test the accuracy, speed, flexibility and robustness of AI-Aristotle based on two benchmark problems in Systems Biology: a pharmacokinetics drug absorption model, and an ultradian endocrine model for glucose-insulin interactions. We compare the two machine learning methods (X-TFC and PINNs), and moreover, we employ two different symbolic regression techniques to cross-verify our results. While the current work focuses on the performance of AI-Aristotle based on synthetic data, it can equally handle noisy experimental data and can even be used for black-box identification in just a few minutes on a laptop. More broadly, our work provides insights into the accuracy, cost, scalability, and robustness of integrating neural networks with symbolic regressors, offering a comprehensive guide for researchers tackling gray-box identification challenges in complex dynamical systems in biomedicine and beyond.         _ Less","","arXiv","https://arxiv.org/abs/2310.01433","1","1","multiple"
"Automation and miniaturization of Golden Gate DNA assembly reactions using acoustic dispensers","Abstract:                _robots that use sound to transfer liquids in the nL range from a source plate to a target plate. These acoustic dispensers have become particularly popular in the field of synthetic biology. The use of this technology allows miniaturization and parallelization of molecular reactions in a tip-free manner, making it sust_         _ More           Golden Gate cloning has become one of the most popular DNA assembly techniques. Its modular and hierarchical structure allows the construction of complex DNA fragments. Over time, Golden Gate cloning allows for the creation of a repository of reusable parts, reducing the cost of frequent sequence validation. However, as the number of reactions and fragments increases, so does the cost of consumables and the potential for human error. Typically, Golden Gate reactions are performed in volumes of 10 to 25 microlitre. Recent technological advances have led to the development of liquid handling robots that use sound to transfer liquids in the nL range from a source plate to a target plate. These acoustic dispensers have become particularly popular in the field of synthetic biology. The use of this technology allows miniaturization and parallelization of molecular reactions in a tip-free manner, making it sustainable by reducing plastic waste and reagent usage. Here, we provide a step-by-step protocol for performing and parallelizing Golden Gate cloning reactions in 1 microlitre total volume.         _ Less","","arXiv","https://arxiv.org/abs/2310.00325","0","1","synthetic_biology"
"A rigorous benchmarking of methods for SARS-CoV-2 lineage abundance estimation in wastewater","Abstract:                _benchmarking of 18 bioinformatics methods for estimating the relative abundance of SARS-CoV-2 (sub)lineages in wastewater by using data from 36 in vitro mixtures of synthetic lineage and sublineage genomes. In addition, we use simulated data from 78 mixtures of lineages and sublineages co-occurring in the clinical setting with proportions mirroring their pre_         _ More           In light of the continuous transmission and evolution of SARS-CoV-2 coupled with a significant decline in clinical testing, there is a pressing need for scalable, cost-effective, long-term, passive surveillance tools to effectively monitor viral variants circulating in the population. Wastewater genomic surveillance of SARS-CoV-2 has arrived as an alternative to clinical genomic surveillance, allowing to continuously monitor the prevalence of viral lineages in communities of various size at a fraction of the time, cost, and logistic effort and serving as an early warning system for emerging variants, critical for developed communities and especially for underserved ones. Importantly, lineage prevalence estimates obtained with this approach aren't distorted by biases related to clinical testing accessibility and participation. However, the relative performance of bioinformatics methods used to measure relative lineage abundances from wastewater sequencing data is unknown, preventing both the research community and public health authorities from making informed decisions regarding computational tool selection. Here, we perform comprehensive benchmarking of 18 bioinformatics methods for estimating the relative abundance of SARS-CoV-2 (sub)lineages in wastewater by using data from 36 in vitro mixtures of synthetic lineage and sublineage genomes. In addition, we use simulated data from 78 mixtures of lineages and sublineages co-occurring in the clinical setting with proportions mirroring their prevalence ratios observed in real data. Importantly, we investigate how the accuracy of the evaluated methods is impacted by the sequencing technology used, the associated error rate, the read length, read depth, but also by the exposure of the synthetic RNA mixtures to wastewater, with the goal of capturing the effects induced by the wastewater matrix, including RNA fragmentation and degradation.         _ Less","","arXiv","https://arxiv.org/abs/2309.16994","1","2","synthetic_biology"
"Node-Aligned Graph-to-Graph (NAG2G): Elevating Template-Free Deep Learning Approaches in Single-Step Retrosynthesis","Abstract:                _drug candidate molecules. This not only proves NAG2G's robustness but also its potential to revolutionize the prediction of complex chemical synthesis processes for future synthetic route design tasks.         _ More           Single-step retrosynthesis (SSR) in organic chemistry is increasingly benefiting from deep learning (DL) techniques in computer-aided synthesis design. While template-free DL models are flexible and promising for retrosynthesis prediction, they often ignore vital 2D molecular information and struggle with atom alignment for node generation, resulting in lower performance compared to the template-based and semi-template-based methods. To address these issues, we introduce Node-Aligned Graph-to-Graph (NAG2G), a transformer-based template-free DL model. NAG2G combines 2D molecular graphs and 3D conformations to retain comprehensive molecular details and incorporates product-reactant atom mapping through node alignment which determines the order of the node-by-node graph outputs process in an auto-regressive manner. Through rigorous benchmarking and detailed case studies, we have demonstrated that NAG2G stands out with its remarkable predictive accuracy on the expansive datasets of USPTO-50k and USPTO-FULL. Moreover, the model's practical utility is underscored by its successful prediction of synthesis pathways for multiple drug candidate molecules. This not only proves NAG2G's robustness but also its potential to revolutionize the prediction of complex chemical synthesis processes for future synthetic route design tasks.         _ Less","","arXiv","https://arxiv.org/abs/2309.15798","2","2","multiple"
"A Stein's Method Approach to the Linear Noise Approximation for Stationary Distributions of Chemical Reaction Networks","Abstract:                _chain models that describe the time evolution of the molecular counts of species interacting stochastically via discrete reactions. Such models are ubiquitous in systems and synthetic biology, but often have a large or infinite number of states, and thus are not amenable to computation and analysis. Due to this, approx_         _ More           Stochastic Chemical Reaction Networks are continuous time Markov chain models that describe the time evolution of the molecular counts of species interacting stochastically via discrete reactions. Such models are ubiquitous in systems and synthetic biology, but often have a large or infinite number of states, and thus are not amenable to computation and analysis. Due to this, approximations that rely on the molecular counts and the volume being large are commonly used, with the most common being the Reaction Rate Equations and the Linear Noise Approximation. For finite time intervals, Kurtz established the validity of the Reaction Rate Equations and Linear Noise Approximation, by proving law of large numbers and central limit theorem results respectively. However, the analogous question for the stationary distribution of the Markov chain model has remained mostly unanswered, except for chemical reaction networks with special structures or bounded molecular counts. In this work, we use Stein's Method to obtain sufficient conditions for the stationary distribution of an appropriately scaled Stochastic Chemical Reaction Network to converge to the Linear Noise Approximation as the system size goes to infinity. Our results give non asymptotic bounds on the error in the Reaction Rate Equations and in the Linear Noise Approximation as applied to the stationary distribution. As a special case, we give conditions under which the global exponential stability of an equilibrium point of the Reaction Rate Equations is sufficient to obtain our error bounds, thus permitting one to obtain conclusions about the Markov chain by analyzing the deterministic Reaction Rate Equations.         _ Less","","arXiv","https://arxiv.org/abs/2309.07386","0","3","synthetic_biology"
"Discovering Dynamic Effective Connectome of Brain with Bayesian Dynamic DAG Learning","Abstract:                _method allows the incorporation of prior knowledge into the process of dynamic causal discovery which further enhances the accuracy of results. Comprehensive simulations on synthetic data and experiments on Human Connectome Project (HCP) data demonstrate that our method can handle both of the two main challenges, yielding more accurate and reliable DEC compa_         _ More           Understanding the complex mechanisms of the brain can be unraveled by extracting the Dynamic Effective Connectome (DEC). Recently, score-based Directed Acyclic Graph (DAG) discovery methods have shown significant improvements in extracting the causal structure and inferring effective connectivity. However, learning DEC through these methods still faces two main challenges: one with the fundamental impotence of high-dimensional dynamic DAG discovery methods and the other with the low quality of fMRI data. In this paper, we introduce Bayesian Dynamic DAG learning with M-matrices Acyclicity characterization (BDyMA) method to address the challenges in discovering DEC. The presented dynamic causal model enables us to discover direct feedback loop edges as well. Leveraging an unconstrained framework in the BDyMA method leads to more accurate results in detecting high-dimensional networks, achieving sparser outcomes, making it particularly suitable for extracting DEC. Additionally, the score function of the BDyMA method allows the incorporation of prior knowledge into the process of dynamic causal discovery which further enhances the accuracy of results. Comprehensive simulations on synthetic data and experiments on Human Connectome Project (HCP) data demonstrate that our method can handle both of the two main challenges, yielding more accurate and reliable DEC compared to state-of-the-art and traditional methods. Additionally, we investigate the trustworthiness of DTI data as prior knowledge for DEC discovery and show the improvements in DEC discovery when the DTI data is incorporated into the process.         _ Less","","arXiv","https://arxiv.org/abs/2309.07080","1","2","synthetic_biology"
"Unraveling biochemical spatial patterns: machine learning approaches to the inverse problem of Turing patterns","Abstract:                _through a prototype involving an experimentally obtained chemical pattern. The findings reveal the significant promise of machine learning in steering the creation of synthetic patterns in bioengineering, thereby advancing our grasp of morphological intricacies within biological systems while acknowledging existing limitations.         _ More           The diffusion-driven Turing instability is a potential mechanism for spatial pattern formation in numerous biological and chemical systems. However, engineering these patterns and demonstrating that they are produced by this mechanism is challenging. To address this, we aim to solve the inverse problem in artificial and experimental Turing patterns. This task is challenging since high levels of noise corrupt the patterns and slight changes in initial conditions can lead to different patterns. We used both least squares to explore the problem and physics-informed neural networks to build a noise-robust method. We elucidate the functionality of our network in scenarios mimicking biological noise levels and showcase its application through a prototype involving an experimentally obtained chemical pattern. The findings reveal the significant promise of machine learning in steering the creation of synthetic patterns in bioengineering, thereby advancing our grasp of morphological intricacies within biological systems while acknowledging existing limitations.         _ Less","","arXiv","https://arxiv.org/abs/2309.06339","1","0","origin_of_life"
"ECG-based estimation of respiratory modulation of AV nodal conduction during atrial fibrillation","Abstract:                _to estimate respiratory modulation of AV nodal conduction properties from 1-minute segments of RR series, respiration signals, and atrial fibrillatory rates (AFR) using synthetic data that replicates clinical ECG-derived data. The_         _ More           Information about autonomic nervous system (ANS) activity may be valuable for personalized atrial fibrillation (AF) treatment but is not easily accessible from the ECG. In this study, we propose a new approach for ECG-based assessment of respiratory modulation in AV nodal refractory period and conduction delay. A 1-dimensional convolutional neural network (1D-CNN) was trained to estimate respiratory modulation of AV nodal conduction properties from 1-minute segments of RR series, respiration signals, and atrial fibrillatory rates (AFR) using synthetic data that replicates clinical ECG-derived data. The synthetic data were generated using a network model of the AV node and 4 million unique model parameter sets. The 1D-CNN was then used to analyze respiratory modulation in clinical deep breathing test data of 28 patients in AF, where a ECG-derived respiration signal was extracted using a novel approach based on periodic component analysis. We demonstrated using synthetic data that the 1D-CNN can predict the respiratory modulation from RR series alone ($_$ = 0.805) and that the addition of either respiration signal ($_$ = 0.830), AFR ($_$ = 0.837), or both ($_$ = 0.855) improves the prediction. Results from analysis of clinical ECG data of 20 patients with sufficient signal quality suggest that respiratory modulation decreased in response to deep breathing for five patients, increased for five patients, and remained similar for ten patients, indicating a large inter-patient variability.         _ Less","","arXiv","https://arxiv.org/abs/2309.05458","1","0","origin_of_life"
"A General Description of Criticality in Neural Network Models","Abstract:                _mean-dominated regime. Moreover, we apply the ensemble Kalman filter to determine and track effective connections for the neuronal network. The method is validated on noisy synthetic BOLD signals and could exactly reproduce the corresponding critical network activity. Our results provide a special perspective to understand and model the criticality, which ca_         _ More           Recent experimental observations have supported the hypothesis that the cerebral cortex operates in a dynamical regime near criticality, where the neuronal network exhibits a mixture of ordered and disordered patterns. However, A comprehensive study of how criticality emerges and how to reproduce it is still lacking. In this study, we investigate coupled networks with conductance-based neurons and illustrate the co-existence of different spiking patterns, including asynchronous irregular (AI) firing and synchronous regular (SR) state, along with a scale-invariant neuronal avalanche phenomenon (criticality). We show that fast-acting synaptic coupling can evoke neuronal avalanches in the mean-dominated regime but has little effect in the fluctuation-dominated regime. In a narrow region of parameter space, the network exhibits avalanche dynamics with power-law avalanche size and duration distributions. We conclude that three stages which may be responsible for reproducing the synchronized bursting: mean-dominated subthreshold dynamics, fast-initiating a spike event, and time-delayed inhibitory cancellation. Remarkably, we illustrate the mechanisms underlying critical avalanches in the presence of noise, which can be explained as a stochastic crossing state around the Hopf bifurcation under the mean-dominated regime. Moreover, we apply the ensemble Kalman filter to determine and track effective connections for the neuronal network. The method is validated on noisy synthetic BOLD signals and could exactly reproduce the corresponding critical network activity. Our results provide a special perspective to understand and model the criticality, which can be useful for large-scale modeling and computation of brain dynamics.         _ Less","","arXiv","https://arxiv.org/abs/2309.03348","1","1","multiple"
"Enumeration of saturated and unsaturated substituted N-heterocycles","Abstract:                _but hypothetically possible structures. Nitrogen containing heterocycles such as aziridine, azetidine and pyrrolidine bear a high potential in pharmacology, biotechnology and synthetic biology. Here, we present a mathematical enumeration procedure for all possible azaheterocycles with at least one substituent dependin_         _ More           Mathematical and computational approaches in chemistry and biochemistry fill a gap in respect to the analysis of the physicochemical features of compounds and their functionality and provide an overview of known as well as yet unknown, but hypothetically possible structures. Nitrogen containing heterocycles such as aziridine, azetidine and pyrrolidine bear a high potential in pharmacology, biotechnology and synthetic biology. Here, we present a mathematical enumeration procedure for all possible azaheterocycles with at least one substituent depending on the number of atoms in the ring, in the sense of saturated and unsaturated congeners. One subgroup belonging to that substance class is constituted by ring-shaped amino acids with a secondary amino group such as proline. A recursion formula is derived, which results in a modified Lucas number series. Moreover, an explicit formula for determining the number of such substances based on the Golden Ratio is given and a second one, based on binomial coefficients, is newly derived. This enumeration is a helpful tool for construction or complementation of virtual compound databases and for computer-assisted chemical synthesis route planning.         _ Less","","arXiv","https://arxiv.org/abs/2309.02343","2","2","multiple"
"Inverse modeling of time-delayed interactions via the dynamic-entropy formalism","Abstract:                _but also the time required by the couplings to completely transfer information among the units. We demonstrate the validity of our approach providing excellent results on synthetic datasets of non-Markovian trajectories generated by the Heisenberg-Kuramoto and Vicsek models equipped with delayed interactions. As a proof of concept, we also apply the method_         _ More           Although instantaneous interactions are unphysical, a large variety of maximum entropy statistical inference methods match the model-inferred and the empirically-measured equal-time correlation functions. Focusing on collective motion of active units, this constraint is reasonable when the interaction timescale is much faster than that of the interacting units, as in starling flocks, yet it fails in a number of counter examples, as in leukocyte coordination (where signalling proteins diffuse among two cells). Here, we relax this assumption and develop a path integral approach to maximum-entropy framework, which includes delay in signalling. Our method is able to infer the strength of couplings and fields, but also the time required by the couplings to completely transfer information among the units. We demonstrate the validity of our approach providing excellent results on synthetic datasets of non-Markovian trajectories generated by the Heisenberg-Kuramoto and Vicsek models equipped with delayed interactions. As a proof of concept, we also apply the method to experiments on dendritic migration, where matching equal-time correlations results in a significant information loss.         _ Less","","arXiv","https://arxiv.org/abs/2309.01229","1","0","origin_of_life"
"Adaptive whitening with fast gain modulation and slow synaptic plasticity","Abstract:                _the inverse whitening matrix into basis vectors, which correspond to synaptic weights, and a diagonal matrix, which corresponds to neuronal gains. We test our model on synthetic and natural datasets and find that the synapses learn optimal configurations over long timescales that enable adaptive whitening on short timescales using gain modulation.         _ More           Neurons in early sensory areas rapidly adapt to changing sensory statistics, both by normalizing the variance of their individual responses and by reducing correlations between their responses. Together, these transformations may be viewed as an adaptive form of statistical whitening. Existing mechanistic models of adaptive whitening exclusively use either synaptic plasticity or gain modulation as the biological substrate for adaptation; however, on their own, each of these models has significant limitations. In this work, we unify these approaches in a normative multi-timescale mechanistic model that adaptively whitens its responses with complementary computational roles for synaptic plasticity and gain modulation. Gains are modified on a fast timescale to adapt to the current statistical context, whereas synapses are modified on a slow timescale to match structural properties of the input statistics that are invariant across contexts. Our model is derived from a novel multi-timescale whitening objective that factorizes the inverse whitening matrix into basis vectors, which correspond to synaptic weights, and a diagonal matrix, which corresponds to neuronal gains. We test our model on synthetic and natural datasets and find that the synapses learn optimal configurations over long timescales that enable adaptive whitening on short timescales using gain modulation.         _ Less","","arXiv","https://arxiv.org/abs/2308.13633","1","1","multiple"
"Generative Bayesian modeling to nowcast the effective reproduction number from line list data with missing symptom onset dates","Abstract:                _list data with missing symptom onset dates. We then use this framework to compare the performance of nowcasting approaches with different stepwise and generative components on synthetic line list data for multiple outbreak scenarios and across different epidemic phases. We find that under long reporting delays, intermediate smoothing, as is common practice i_         _ More           The time-varying effective reproduction number $R_t$ is a widely used indicator of transmission dynamics during infectious disease outbreaks. Timely estimates of $R_t$ can be obtained from observations close to the original date of infection, such as the date of symptom onset. However, these data often have missing information and are subject to right truncation. Previous methods have addressed these problems independently by first imputing missing onset dates, then adjusting truncated case counts, and finally estimating the effective reproduction number. This stepwise approach makes it difficult to propagate uncertainty and can introduce subtle biases during real-time estimation due to the continued impact of assumptions made in previous steps. In this work, we integrate imputation, truncation adjustment, and $R_t$ estimation into a single generative Bayesian model, allowing direct joint inference of case counts and $R_t$ from line list data with missing symptom onset dates. We then use this framework to compare the performance of nowcasting approaches with different stepwise and generative components on synthetic line list data for multiple outbreak scenarios and across different epidemic phases. We find that under long reporting delays, intermediate smoothing, as is common practice in stepwise approaches, can bias nowcasts of case counts and $R_t$, which is avoided in a joint generative approach due to shared regularization of all model components. On incomplete line list data, a fully generative approach enables the quantification of uncertainty due to missing onset dates without the need for an initial multiple imputation step. In a real-world comparison using hospitalization line list data from the COVID-19 pandemic in Switzerland, we observe the same qualitative differences between approaches. Our generative modeling components have been integrated into the R package epinowcast.         _ Less","","arXiv","https://arxiv.org/abs/2308.13262","1","1","multiple"
"Human Comprehensible Active Learning of Genome-Scale Metabolic Networks","Abstract:                An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach tha_         _ More           An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach that efficiently explores the hypothesis space and guides experimental design is urgently needed for the Design-Build-Test-Learn (DBTL) cycle of the host cell system. We introduce a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. In contrast to numerical models, ILP-iML1515 is built on comprehensible logical representations of a genome-scale metabolic model and can update the model by learning new logical structures from auxotrophic mutant trials. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that reduce the experimental cost of learning gene functions in comparison to randomly selected experiments.         _ Less","","arXiv","https://arxiv.org/abs/2308.12740","0","1","synthetic_biology"
"Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model and Consensus Aggregation","Abstract:                _Consensus Zero Inflated Poisson Tensor Factorization (C-ZIPTF), which combines ZIPTF with a consensus-based meta-analysis. We evaluate our proposed ZIPTF and C-ZIPTF on synthetic zero-inflated count data and synthetic and real scRNA-seq data. ZIPTF consistently outperforms baseline matrix and tensor factorization metho_         _ More           Tensor factorizations (TF) are powerful tools for the efficient representation and analysis of multidimensional data. However, classic TF methods based on maximum likelihood estimation underperform when applied to zero-inflated count data, such as single-cell RNA sequencing (scRNA-seq) data. Additionally, the stochasticity inherent in TFs results in factors that vary across repeated runs, making interpretation and reproducibility of the results challenging. In this paper, we introduce Zero Inflated Poisson Tensor Factorization (ZIPTF), a novel approach for the factorization of high-dimensional count data with excess zeros. To address the challenge of stochasticity, we introduce Consensus Zero Inflated Poisson Tensor Factorization (C-ZIPTF), which combines ZIPTF with a consensus-based meta-analysis. We evaluate our proposed ZIPTF and C-ZIPTF on synthetic zero-inflated count data and synthetic and real scRNA-seq data. ZIPTF consistently outperforms baseline matrix and tensor factorization methods in terms of reconstruction accuracy for zero-inflated data. When the probability of excess zeros is high, ZIPTF achieves up to $2.4\\times$ better accuracy. Additionally, C-ZIPTF significantly improves the consistency and accuracy of the factorization. When tested on both synthetic and real scRNA-seq data, ZIPTF and C-ZIPTF consistently recover known and biologically meaningful gene expression programs.         _ Less","","arXiv","https://arxiv.org/abs/2308.08060","1","1","multiple"
"Topological classification of tumour-immune interactions and dynamics","Abstract:                _and radial filtrations at static time points, and persistence images for zigzag filtrations and persistence vineyards varying in time. To demonstrate the approach, synthetic data are generated from an agent-based model with varying parameters. We compare the performance of topological summaries in predicting - with logistic regression at various time steps -_         _ More           The complex and dynamic crosstalk between tumour and immune cells results in tumours that can exhibit distinct qualitative behaviours - elimination, equilibrium, and escape - and intricate spatial patterns, yet share similar cell configurations in the early stages. We offer a topological approach to analyse time series of spatial data of cell locations (including tumour cells and macrophages) in order to predict malignant behaviour. We propose four topological vectorisations specialised to such cell data: persistence images of Vietoris-Rips and radial filtrations at static time points, and persistence images for zigzag filtrations and persistence vineyards varying in time. To demonstrate the approach, synthetic data are generated from an agent-based model with varying parameters. We compare the performance of topological summaries in predicting - with logistic regression at various time steps - whether tumour niches surrounding blood vessels are present at the end of the simulation, as a proxy for metastasis (i.e., tumour escape). We find that both static and time-dependent methods accurately identify perivascular niche formation, significantly earlier than simpler markers such as the number of tumour cells and the macrophage phenotype ratio. We find additionally that dimension 0 persistence applied to macrophage data, representing multi-scale clusters of the spatial arrangement of macrophages, performs best at this classification task at early time steps, prior to full tumour development, and performs even better when time-dependent data are included; in contrast, topological measures capturing the shape of the tumour, such as tortuosity and punctures in the cell arrangement, perform best at intermediate and later stages. The logistic regression coefficients reveal detailed shape differences between the classes.         _ Less","","arXiv","https://arxiv.org/abs/2308.05294","1","0","origin_of_life"
"Current Studies and Applications of Krill Herd and Gravitational Search Algorithms in Healthcare","Abstract:                _function to find solutions to complicated issues in many contexts. As a consequence of this, ground-breaking research has been conducted in a variety of domains, including synthetic immune functions, neural networks, the intelligence of swarm, as well as computing of evolutionary. In the domains of biology, physics, en_         _ More           Nature-Inspired Computing or NIC for short is a relatively young field that tries to discover fresh methods of computing by researching how natural phenomena function to find solutions to complicated issues in many contexts. As a consequence of this, ground-breaking research has been conducted in a variety of domains, including synthetic immune functions, neural networks, the intelligence of swarm, as well as computing of evolutionary. In the domains of biology, physics, engineering, economics, and management, NIC techniques are used. In real-world classification, optimization, forecasting, and clustering, as well as engineering and science issues, meta-heuristics algorithms are successful, efficient, and resilient. There are two active NIC patterns: the gravitational search algorithm and the Krill herd algorithm. The study on using the Krill Herd Algorithm (KH) and the Gravitational Search Algorithm (GSA) in medicine and healthcare is given a worldwide and historical review in this publication. Comprehensive surveys have been conducted on some other nature-inspired algorithms, including KH and GSA. The various versions of the KH and GSA algorithms and their applications in healthcare are thoroughly reviewed in the present article. Nonetheless, no survey research on KH and GSA in the healthcare field has been undertaken. As a result, this work conducts a thorough review of KH and GSA to assist researchers in using them in diverse domains or hybridizing them with other popular algorithms. It also provides an in-depth examination of the KH and GSA in terms of application, modification, and hybridization. It is important to note that the goal of the study is to offer a viewpoint on GSA with KH, particularly for academics interested in investigating the capabilities and performance of the algorithm in the healthcare and medical domains.         _ Less","","arXiv","https://arxiv.org/abs/2308.01268","3","4","synthetic_biology"
"Lipid bilayer fluidity and degree of order regulates small EVs adsorption on model cell membrane","Abstract:                _physical properties on the uptake are still lacking. Here we explore this problem using sEVs from a cellular model of triple-negative breast cancer fusing to a range of synthetic planar lipid bilayers both with and without cholesterol, and designed to mimic the formation of raft-like nanodomains in cell membranes. Using time-resolved Atomic Force Microscopy_         _ More           Small extracellular vesicles (sEVs) are known to play an important role in the communication between distant cells and to deliver biological information throughout the body. To date, many studies have focused on the role of sEVs characteristics such as cell origin, surface composition, and molecular cargo on the resulting uptake by the recipient cell. Yet, a full understanding of the sEV fusion process with recipient cells and in particular the role of cell membrane physical properties on the uptake are still lacking. Here we explore this problem using sEVs from a cellular model of triple-negative breast cancer fusing to a range of synthetic planar lipid bilayers both with and without cholesterol, and designed to mimic the formation of raft-like nanodomains in cell membranes. Using time-resolved Atomic Force Microscopy we were able to track the sEVs interaction with the different model membranes, showing the process to be strongly dependent on the local membrane fluidity. The strongest interaction and fusion is observed over the less fluid regions, with sEVs even able to disrupt ordered domains at sufficiently high cholesterol concentration. Our findings suggest the biophysical characteristics of recipient cell membranes to be crucial for sEVs uptake regulation.         _ Less","","arXiv","https://arxiv.org/abs/2307.14903","2","1","origin_of_life"
"CortexMorph: fast cortical thickness estimation via diffeomorphic registration using VoxelMorph","Abstract:                _thickness using a diffeomorphic deformation of the gray-white matter interface towards the pial surface, offers an alternative to surface-based methods. Recent studies using a synthetic cortical thickness phantom have demonstrated that the combination of DiReCT and deep-learning-based segmentation is more sensitive to subvoxel cortical thinning than Freesurf_         _ More           The thickness of the cortical band is linked to various neurological and psychiatric conditions, and is often estimated through surface-based methods such as Freesurfer in MRI studies. The DiReCT method, which calculates cortical thickness using a diffeomorphic deformation of the gray-white matter interface towards the pial surface, offers an alternative to surface-based methods. Recent studies using a synthetic cortical thickness phantom have demonstrated that the combination of DiReCT and deep-learning-based segmentation is more sensitive to subvoxel cortical thinning than Freesurfer.   While anatomical segmentation of a T1-weighted image now takes seconds, existing implementations of DiReCT rely on iterative image registration methods which can take up to an hour per volume. On the other hand, learning-based deformable image registration methods like VoxelMorph have been shown to be faster than classical methods while improving registration accuracy. This paper proposes CortexMorph, a new method that employs unsupervised deep learning to directly regress the deformation field needed for DiReCT. By combining CortexMorph with a deep-learning-based segmentation model, it is possible to estimate region-wise thickness in seconds from a T1-weighted image, while maintaining the ability to detect cortical atrophy. We validate this claim on the OASIS-3 dataset and the synthetic cortical thickness phantom of Rusak et al.         _ Less","","arXiv","https://arxiv.org/abs/2307.11567","1","0","origin_of_life"
"Accurate Detection of Spiking Motifs by Learning Heterogeneous Delays of a Spiking Neural Network","Abstract:                _allows us to formulate a supervised learning approach using a gradient descent on the binary cross-entropy loss. To assess the model's ability to detect spiking motifs in synthetic data, we first perform numerical evaluations. This analysis highlights the advantages of using spiking motifs over traditional firing rate based population codes. We then succ_         _ More           Recently, interest has grown in exploring the hypothesis that neural activity conveys information through precise spiking motifs. To investigate this phenomenon, various algorithms have been proposed to detect such motifs in Single Unit Activity (SUA) recorded from populations of neurons. In this study, we present a novel detection model based on the inversion of a generative model of raster plot synthesis. Using this generative model, we derive an optimal detection procedure that takes the form of logistic regression combined with temporal convolution. A key advantage of this model is its differentiability, which allows us to formulate a supervised learning approach using a gradient descent on the binary cross-entropy loss. To assess the model's ability to detect spiking motifs in synthetic data, we first perform numerical evaluations. This analysis highlights the advantages of using spiking motifs over traditional firing rate based population codes. We then successfully demonstrate that our learning method can recover synthetically generated spiking motifs, indicating its potential for further applications. In the future, we aim to extend this method to real neurobiological data, where the ground truth is unknown, to explore and detect spiking motifs in a more natural and biologically relevant context.         _ Less","","arXiv","https://arxiv.org/abs/2307.11555","1","0","origin_of_life"
"Perturbing a Neural Network to Infer Effective Connectivity: Evidence from Synthetic EEG Data","Abstract:                _(EC) between the perturbed EEG channel and the rest of the channels. The EC reflects the causal impact of perturbing one node on others. The performance was tested on the synthetic EEG generated by a biological-plausible Jansen-Rit model. CNN and Transformer obtained the best performance on both 3-channel and 90-channel_         _ More           Identifying causal relationships among distinct brain areas, known as effective connectivity, holds key insights into the brain's information processing and cognitive functions. Electroencephalogram (EEG) signals exhibit intricate dynamics and inter-areal interactions within the brain. However, methods for characterizing nonlinear causal interactions among multiple brain regions remain relatively underdeveloped. In this study, we proposed a data-driven framework to infer effective connectivity by perturbing the trained neural networks. Specifically, we trained neural networks (i.e., CNN, vanilla RNN, GRU, LSTM, and Transformer) to predict future EEG signals according to historical data and perturbed the networks' input to obtain effective connectivity (EC) between the perturbed EEG channel and the rest of the channels. The EC reflects the causal impact of perturbing one node on others. The performance was tested on the synthetic EEG generated by a biological-plausible Jansen-Rit model. CNN and Transformer obtained the best performance on both 3-channel and 90-channel synthetic EEG data, outperforming the classical Granger causality method. Our work demonstrated the potential of perturbing an artificial neural network, learned to predict future system dynamics, to uncover the underlying causal structure.         _ Less","","arXiv","https://arxiv.org/abs/2307.09770","1","1","multiple"
"A Computational Topology-based Spatiotemporal Analysis Technique for Honeybee Aggregation","Abstract:                _reduction techniques to these matrices and then use classic clustering and change-point detection algorithms on the resulting scalar data. A test of this methodology on synthetic data from an agent-based model of honeybees and their trophallaxis behavior shows two distinct phases: a dispersed phase that occurs before food is introduced, followed by a food-ex_         _ More           A primary challenge in understanding collective behavior is characterizing the spatiotemporal dynamics of the group. We employ topological data analysis to explore the structure of honeybee aggregations that form during trophallaxis, which is the direct exchange of food among nestmates. From the positions of individual bees, we build topological summaries called CROCKER matrices to track the morphology of the group as a function of scale and time. Each column of a CROCKER matrix records the number of topological features, such as the number of components or holes, that exist in the data for a range of analysis scales at a given point in time. To detect important changes in the morphology of the group from this information, we first apply dimensionality reduction techniques to these matrices and then use classic clustering and change-point detection algorithms on the resulting scalar data. A test of this methodology on synthetic data from an agent-based model of honeybees and their trophallaxis behavior shows two distinct phases: a dispersed phase that occurs before food is introduced, followed by a food-exchange phase during which aggregations form. We then move to laboratory data, successfully detecting the same two phases across multiple experiments. Interestingly, our method reveals an additional phase change towards the end of the experiments, suggesting the possibility of another dispersed phase that follows the food-exchange phase.         _ Less","","arXiv","https://arxiv.org/abs/2307.09720","1","0","origin_of_life"
"Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces","Abstract:                _be used to find the global solution for large-scale problems with thousands of points. We compare the computational complexity of our approach with state-of-the-art methods on synthetic problems and apply it to a near-symmetrical problem which is of particular interest in computational biology.         _ More           This paper presents a framework for computing the Gromov-Wasserstein problem between two sets of points in low dimensional spaces, where the discrepancy is the squared Euclidean norm. The Gromov-Wasserstein problem is a generalization of the optimal transport problem that finds the assignment between two sets preserving pairwise distances as much as possible. This can be used to quantify the similarity between two formations or shapes, a common problem in AI and machine learning. The problem can be formulated as a Quadratic Assignment Problem (QAP), which is in general computationally intractable even for small problems. Our framework addresses this challenge by reformulating the QAP as an optimization problem with a low-dimensional domain, leveraging the fact that the problem can be expressed as a concave quadratic optimization problem with low rank. The method scales well with the number of points, and it can be used to find the global solution for large-scale problems with thousands of points. We compare the computational complexity of our approach with state-of-the-art methods on synthetic problems and apply it to a near-symmetrical problem which is of particular interest in computational biology.         _ Less","","arXiv","https://arxiv.org/abs/2307.09057","1","0","origin_of_life"
"Complete characterization of robust perfect adaptation in biochemical reaction networks","Abstract:                _work significantly advances our understanding of regulatory mechanisms that lead to RPA in endogenous biochemical systems, and it also provides rational design principles for synthetic controllers. The present results indicate that an RPA property is essentially equivalent to the existence of a 'topological invariant', which is an instance of what we_         _ More           Perfect adaptation is a phenomenon whereby the output variables of a system can maintain certain values despite external disturbances. Robust perfect adaptation (RPA) refers to an adaptation property that does not require fine-tuning of system parameters. RPA plays a vital role for the survival of living systems in unpredictable environments. However, complex interaction patterns in biochemical systems pose a significant challenge in identifying RPA and associated regulatory mechanisms. The goal of this paper is to present a novel approach for finding all RPA properties that are realized for a generic choice of kinetics for general deterministic chemical reaction systems. This is accomplished by proving that an RPA property is represented by a subnetwork with certain topological features. This connection is exploited to show that these structures generate all kinetics-independent RPA properties, allowing us to systematically identify all RPA properties by enumerating these subnetworks. An efficient method is developed for this enumeration, and we provide a computational package for this purpose. We pinpoint the integral feedback controllers that work in concert to realize each RPA property, casting our results into the familiar control-theoretic paradigm of the Internal Model Principle. We further generalize the regulation problem to the multi-output scenario where the target values belong to a manifold of nonzero dimension, and provide a sufficient condition for this. The present work significantly advances our understanding of regulatory mechanisms that lead to RPA in endogenous biochemical systems, and it also provides rational design principles for synthetic controllers. The present results indicate that an RPA property is essentially equivalent to the existence of a 'topological invariant', which is an instance of what we call the 'Robust Adaptation is Topological'(RAT) principle.         _ Less","","arXiv","https://arxiv.org/abs/2307.07444","0","2","synthetic_biology"
"Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics","Abstract:                _genetics, RNA or protein sequences data. Traditional training methods encounter difficulties due to inefficient Markov chain Monte Carlo mixing, which affects the diversity of synthetic data and increases generation times. To address these issues, we use a novel training algorithm that exploits non-equilibrium effects. This approach, applied on the Restricte_         _ More           In this study, we address the challenge of using energy-based models to produce high-quality, label-specific data in complex structured datasets, such as population genetics, RNA or protein sequences data. Traditional training methods encounter difficulties due to inefficient Markov chain Monte Carlo mixing, which affects the diversity of synthetic data and increases generation times. To address these issues, we use a novel training algorithm that exploits non-equilibrium effects. This approach, applied on the Restricted Boltzmann Machine, improves the model's ability to correctly classify samples and generate high-quality synthetic data in only a few sampling steps. The effectiveness of this method is demonstrated by its successful application to four different types of data: handwritten digits, mutations of human genomes classified by continental origin, functionally characterized sequences of an enzyme protein family, and homologous RNA sequences from specific taxonomies.         _ Less","","arXiv","https://arxiv.org/abs/2307.06797","0","1","synthetic_biology"
"NLP Meets RNA: Unsupervised Embedding Learning for Ribozymes with Word2Vec","Abstract:                Ribozymes, RNA molecules with distinct 3D structures and catalytic activity, have widespread applications in synthetic biology and therapeutics. However, relatively little research has focused on leveraging deep learning to enhance our understanding of ribozymes. This study implements Word2Vec, an unsupervised learning_         _ More           Ribozymes, RNA molecules with distinct 3D structures and catalytic activity, have widespread applications in synthetic biology and therapeutics. However, relatively little research has focused on leveraging deep learning to enhance our understanding of ribozymes. This study implements Word2Vec, an unsupervised learning technique for natural language processing, to learn ribozyme embeddings. Ribo2Vec was trained on over 9,000 diverse ribozymes, learning to map sequences to 128 and 256-dimensional vector spaces. Using Ribo2Vec, sequence embeddings for five classes of ribozymes (hatchet, pistol, hairpin, hovlinc, and twister sister) were calculated. Principal component analysis demonstrated the ability of these embeddings to distinguish between ribozyme classes. Furthermore, a simple SVM classifier trained on ribozyme embeddings showed promising results in accurately classifying ribozyme types. Our results suggest that the embedding vectors contained meaningful information about ribozymes. Interestingly, 256-dimensional embeddings behaved similarly to 128-dimensional embeddings, suggesting that a lower dimension vector space is generally sufficient to capture ribozyme features. This approach demonstrates the potential of Word2Vec for bioinformatics, opening new avenues for ribozyme research. Future research includes using a Transformer-based method to learn RNA embeddings, which can capture long-range interactions between nucleotides.         _ Less","","arXiv","https://arxiv.org/abs/2307.05537","1","1","multiple"
"On Estimating Derivatives of Input Signals in Biochemistry","Abstract:                _give a detailed mathematical analysis of that CRN, thus clarifying the computed quantity and quantifying the error done as a function of the reaction kinetic parameters. In a synthetic_         _ More           The online estimation of the derivative of an input signal is widespread in control theory and engineering. In the realm of chemical reaction networks (CRN), this raises however a number of specific issues on the different ways to achieve it. A CRN pattern for implementing a derivative block has already been proposed for the PID control of biochemical processes, and proved correct using Tikhonov's limit theorem. In this paper, we give a detailed mathematical analysis of that CRN, thus clarifying the computed quantity and quantifying the error done as a function of the reaction kinetic parameters. In a synthetic biology perspective, we show how this can be used to design error correcting terms to compute online functions involving derivatives with CRNs. In the systems biology perspective, we give the list of models in BioModels containing (in the sense of subgraph epimorphisms) the core derivative CRN, most of which being models of oscillators and control systems in the cell, and discuss in detail two such examples: one model of the circadian clock and one model of a bistable switch.         _ Less","","arXiv","https://arxiv.org/abs/2307.04397","0","2","synthetic_biology"
"Theoretical Limits of Energy Extraction in Active Fluids","Abstract:                _a class of far-from-equilibrium systems that are driven internally and exhibit self-organization which can be harnessed to perform mechanical work. Inspired by experiments on synthetic active networks we examine limits of work extraction from an active viscoelastic medium by analyzing the transport of a particle. The active viscoelastic material possesses an_         _ More           Active materials form a class of far-from-equilibrium systems that are driven internally and exhibit self-organization which can be harnessed to perform mechanical work. Inspired by experiments on synthetic active networks we examine limits of work extraction from an active viscoelastic medium by analyzing the transport of a particle. The active viscoelastic material possesses an equilibrium density where the active and passive forces are balanced out. In one dimension, a gliding activation front (AF) that converts a passive to an active medium, provides active energy at a constant rate, which is injected into the system at one end and propagates to the other. We demonstrate that there exists a maximum velocity of the AF, above which the activated region fails to deliver the transport power. We hypothesize, and intuitively argue based on the limit cases, that the feasibility and the velocity of transport can be interpreted in terms of the velocity of an equilibration Domain Wall of the field, which is set by two parameters: a measure of activity, and the viscoelastic timescale. The phase diagram comprises Transport and No-Transport sectors, namely for any pair of the two parameters, there exists a threshold velocity of the AF above which the particle transport becomes impossible. Constructing the phase diagram we find that there are regions of the phase diagram for which the threshold velocity of the AF diverges. Larger viscoelastic timescale makes the transport region more accessible, and increases the transport velocity therein. Also, we find that increasing the velocity of AF results in larger extracted power but smaller transport coefficient; the ratio of the transport velocity and that of the AF. Our model provides a framework for understanding the energetics of transport phenomena in biology, and designing efficient mechanisms of transport in synthetic active materials.         _ Less","","arXiv","https://arxiv.org/abs/2307.00489","0","1","synthetic_biology"
"Application of data engineering approaches to address challenges in microbiome data for optimal medical decision-making","Abstract:                _boosting (XGB) decision trees) were implemented on a previously published dataset. The issue of class imbalance and high dimensionality of the data was addressed through synthetic minority oversampling technique (SMOTE) and principal component analysis (PCA). Our results indicate that ensemble classifiers (RF and XGB decision trees) exhibit superior classifi_         _ More           The human gut microbiota is known to contribute to numerous physiological functions of the body and also implicated in a myriad of pathological conditions. Prolific research work in the past few decades have yielded valuable information regarding the relative taxonomic distribution of gut microbiota. Unfortunately, the microbiome data suffers from class imbalance and high dimensionality issues that must be addressed. In this study, we have implemented data engineering algorithms to address the above-mentioned issues inherent to microbiome data. Four standard machine learning classifiers (logistic regression (LR), support vector machines (SVM), random forests (RF), and extreme gradient boosting (XGB) decision trees) were implemented on a previously published dataset. The issue of class imbalance and high dimensionality of the data was addressed through synthetic minority oversampling technique (SMOTE) and principal component analysis (PCA). Our results indicate that ensemble classifiers (RF and XGB decision trees) exhibit superior classification accuracy in predicting the host phenotype. The application of PCA significantly reduced testing time while maintaining high classification accuracy. The highest classification accuracy was obtained at the levels of species for most classifiers. The prototype employed in the study addresses the issues inherent to microbiome datasets and could be highly beneficial for providing personalized medicine.         _ Less","","arXiv","https://arxiv.org/abs/2307.00033","1","0","origin_of_life"
"Assessing the Performance of 1D-Convolution Neural Networks to Predict Concentration of Mixture Components from Raman Spectra","Abstract:                _environment is challenging due to the lack of freely available Raman mixture datasets. The RaMix Python package addresses this challenge by enabling the generation of synthetic Raman mixture datasets with controllable noise levels to assess the utility of different chemometric algorithm types for real-time monitoring applications. To demonstrate the capabili_         _ More           An emerging application of Raman spectroscopy is monitoring the state of chemical reactors during biologic drug production. Raman shift intensities scale linearly with the concentrations of chemical species and thus can be used to analytically determine real-time concentrations using non-destructive light irradiation in a label-free manner. Chemometric algorithms are used to interpret Raman spectra produced from complex mixtures of bioreactor contents as a reaction evolves. Finding the optimal algorithm for a specific bioreactor environment is challenging due to the lack of freely available Raman mixture datasets. The RaMix Python package addresses this challenge by enabling the generation of synthetic Raman mixture datasets with controllable noise levels to assess the utility of different chemometric algorithm types for real-time monitoring applications. To demonstrate the capabilities of this package and compare the performance of different chemometric algorithms, 48 datasets of simulated spectra were generated using the RaMix Python package. The four tested algorithms include partial least squares regression (PLS), a simple neural network, a simple convolutional neural network (simple CNN), and a 1D convolutional neural network with a ResNet architecture (ResNet). The performance of the PLS and simple CNN model was found to be comparable, with the PLS algorithm slightly outperforming the other models on 83\\% of the data sets. The simple CNN model outperforms the other models on large, high noise datasets, demonstrating the superior capability of convolutional neural networks compared to PLS in analyzing noisy spectra. These results demonstrate the promise of CNNs to automatically extract concentration information from unprocessed, noisy spectra, allowing for better process control of industrial drug production. Code for this project is available at github.com/DexterAntonio/RaMix.         _ Less","","arXiv","https://arxiv.org/abs/2306.16621","1","0","origin_of_life"
"FP-IRL: Fokker-Planck-based Inverse Reinforcement Learning -- A Physics-Constrained Approach to Markov Decision Processes","Abstract:                _in FP, which consequently allows the evaluation of reward, transition, and policy by leveraging the conjecture. We demonstrate the effectiveness of FP-IRL by applying it to a synthetic benchmark and a biological problem of cancer cell dynamics, where the transition function is inaccessible.         _ More           Inverse Reinforcement Learning (IRL) is a compelling technique for revealing the rationale underlying the behavior of autonomous agents. IRL seeks to estimate the unknown reward function of a Markov decision process (MDP) from observed agent trajectories. However, IRL needs a transition function, and most algorithms assume it is known or can be estimated in advance from data. It therefore becomes even more challenging when such transition dynamics is not known a-priori, since it enters the estimation of the policy in addition to determining the system's evolution. When the dynamics of these agents in the state-action space is described by stochastic differential equations (SDE) in It^{o} calculus, these transitions can be inferred from the mean-field theory described by the Fokker-Planck (FP) equation. We conjecture there exists an isomorphism between the time-discrete FP and MDP that extends beyond the minimization of free energy (in FP) and maximization of the reward (in MDP). We identify specific manifestations of this isomorphism and use them to create a novel physics-aware IRL algorithm, FP-IRL, which can simultaneously infer the transition and reward functions using only observed trajectories. We employ variational system identification to infer the potential function in FP, which consequently allows the evaluation of reward, transition, and policy by leveraging the conjecture. We demonstrate the effectiveness of FP-IRL by applying it to a synthetic benchmark and a biological problem of cancer cell dynamics, where the transition function is inaccessible.         _ Less","","arXiv","https://arxiv.org/abs/2306.10407","0","1","synthetic_biology"
"CryoChains: Heterogeneous Reconstruction of Molecular Assembly of Semi-flexible Chains from Cryo-EM Images","Abstract:                Cryogenic electron microscopy (cryo-EM) has transformed structural biology by allowing to reconstruct 3D biomolecular structures up to near-atomic resolution. However, the 3D reconstruction process remains challenging, as the 3D structures may exhibit substantial shape variations, while the 2D image acquisition suffers from a low signal-to-noise ratio, requi_         _ More           Cryogenic electron microscopy (cryo-EM) has transformed structural biology by allowing to reconstruct 3D biomolecular structures up to near-atomic resolution. However, the 3D reconstruction process remains challenging, as the 3D structures may exhibit substantial shape variations, while the 2D image acquisition suffers from a low signal-to-noise ratio, requiring to acquire very large datasets that are time-consuming to process. Current reconstruction methods are precise but computationally expensive, or faster but lack a physically-plausible model of large molecular shape variations. To fill this gap, we propose CryoChains that encodes large deformations of biomolecules via rigid body transformation of their chains, while representing their finer shape variations with the normal mode analysis framework of biophysics. Our synthetic data experiments on the human GABA\\textsubscript{B} and heat shock protein show that CryoChains gives a biophysically-grounded quantification of the heterogeneous conformations of biomolecules, while reconstructing their 3D molecular structures at an improved resolution compared to the current fastest, interpretable deep learning method.         _ Less","","arXiv","https://arxiv.org/abs/2306.07274","1","0","origin_of_life"
"Microscopy image reconstruction with physics-informed denoising diffusion probabilistic model","Abstract:                _this by incorporating the physical problem of microscopy image formation into the model's loss function. To overcome the lack of microscopy data, we train this model with synthetic data. We simulate the effects of the microscope optics through the theoretical point spread function and varying the noise levels to obtain_         _ More           Light microscopy is a widespread and inexpensive imaging technique facilitating biomedical discovery and diagnostics. However, light diffraction barrier and imperfections in optics limit the level of detail of the acquired images. The details lost can be reconstructed among others by deep learning models. Yet, deep learning models are prone to introduce artefacts and hallucinations into the reconstruction. Recent state-of-the-art image synthesis models like the denoising diffusion probabilistic models (DDPMs) are no exception to this. We propose to address this by incorporating the physical problem of microscopy image formation into the model's loss function. To overcome the lack of microscopy data, we train this model with synthetic data. We simulate the effects of the microscope optics through the theoretical point spread function and varying the noise levels to obtain synthetic data. Furthermore, we incorporate the physical model of a light microscope into the reverse process of a conditioned DDPM proposing a physics-informed DDPM (PI-DDPM). We show consistent improvement and artefact reductions when compared to model-based methods, deep-learning regression methods and regular conditioned DDPMs.         _ Less","","arXiv","https://arxiv.org/abs/2306.02929","1","0","origin_of_life"
"Role of Nano-fertilizer in Plants Nutrient Use Efficiency (NUE)- A mini-review","Abstract:                Over the past half-century, the combination of technology and innovation has been developed to manage the negative impact of synthetic fertilizer on land ecosystems to identify the limitations of sustainability and optimize agricultural systems. The application of nano-fertilizers has achieved considerable interest due to their significant role as environmen_         _ More           Over the past half-century, the combination of technology and innovation has been developed to manage the negative impact of synthetic fertilizer on land ecosystems to identify the limitations of sustainability and optimize agricultural systems. The application of nano-fertilizers has achieved considerable interest due to their significant role as environmentally sustainable resources and soil health. Moreover, the increasing global population increased food insecurity, especially under climate change. Nanotechnology has emerged as a promising alternative to help improving crop growth and productivity. However, un-balanced presence and long-term use of nano-particles alter photosynthesis, and induce cellular redox imbalances resulting in lipid peroxidation, protein oxidation and DNA oxidative damage in plants, so more studies are still needed on their safe application with minimum side effects. In this paper, we reviewed nano-fertilizer mechanisms in plant, as well as their effects on microbiome and interaction with soil colloids. This study reviews the recent studies and findings about role of Nanotechnology in plant nutrition use efficiency to summarize a better understanding of this important issue. A comprehensive picture of ecological issues such as soil and water contamination in response to nano-fertilizer application will also be assessed.         _ Less","","arXiv","https://arxiv.org/abs/2305.14357","2","3","synthetic_biology"
"Generation of 3D Molecules in Pockets via Language Model","Abstract:                _structures. The Directory of Useful Decoys-Enhanced (DUD-E) dataset was used for evaluation. Lingo3DMol outperformed state-of-the-art methods in terms of drug-likeness, synthetic accessibility, pocket binding mode, and molecule generation speed.         _ More           Generative models for molecules based on sequential line notation (e.g. SMILES) or graph representation have attracted an increasing interest in the field of structure-based drug design, but they struggle to capture important 3D spatial interactions and often produce undesirable molecular structures. To address these challenges, we introduce Lingo3DMol, a pocket-based 3D molecule generation method that combines language models and geometric deep learning technology. A new molecular representation, fragment-based SMILES with local and global coordinates, was developed to assist the model in learning molecular topologies and atomic spatial positions. Additionally, we trained a separate noncovalent interaction predictor to provide essential binding pattern information for the generative model. Lingo3DMol can efficiently traverse drug-like chemical spaces, preventing the formation of unusual structures. The Directory of Useful Decoys-Enhanced (DUD-E) dataset was used for evaluation. Lingo3DMol outperformed state-of-the-art methods in terms of drug-likeness, synthetic accessibility, pocket binding mode, and molecule generation speed.         _ Less","","arXiv","https://arxiv.org/abs/2305.10133","1","0","origin_of_life"
"Interfacial Stresses on Droplet Interface Bilayers Using Two Photon Fluorescence Lifetime Imaging Microscopy","Abstract:                Response of lipid bilayers to external mechanical stimuli is an active area of research with implications for fundamental and synthetic cell biology. However, there is a lack of tools for systematically imposing mechanical strains and non-invasively mapping out interfacial (membrane) stress distributions on lipid bilay_         _ More           Response of lipid bilayers to external mechanical stimuli is an active area of research with implications for fundamental and synthetic cell biology. However, there is a lack of tools for systematically imposing mechanical strains and non-invasively mapping out interfacial (membrane) stress distributions on lipid bilayers. In this article, we report a miniature platform to manipulate model cell membranes in the form of droplet interface bilayers (DIBs), and non-invasively measure spatio-temporally resolved interfacial stresses using two photon fluorescence lifetime imaging of an interfacially active molecular flipper (Flipper-TR). We established the effectiveness of the developed framework by investigating interfacial stresses accompanying three key processes associated with DIBs: thin film drainage between lipid monolayer coated droplets, bilayer formation, and bilayer separation. Interestingly, the measurements also revealed fundamental aspects of DIBs including the existence of a radially decaying interfacial stress distribution post bilayer formation, and the simultaneous build up and decay of stress respectively at the bilayer corner and center during bilayer separation. Finally, utilizing interfacial rheology measurements and MD simulations, we also reveal that the tested molecular flipper is sensitive to membrane fluidity that changes with interfacial stress - expanding the scientific understanding of how molecular motors sense stress.         _ Less","","arXiv","https://arxiv.org/abs/2305.05151","1","1","multiple"
"Inferring Local Structure from Pairwise Correlations","Abstract:                To construct models of large, multivariate complex systems, such as those in biology, one needs to constrain which variables are allowed to interact. This can be viewed as detecting 'local' structures among the variables. In the context of a simple toy model of 2D natural and synthetic images, we show that pair_         _ More           To construct models of large, multivariate complex systems, such as those in biology, one needs to constrain which variables are allowed to interact. This can be viewed as detecting 'local' structures among the variables. In the context of a simple toy model of 2D natural and synthetic images, we show that pairwise correlations between the variables -- even when severely undersampled -- provide enough information to recover local relations, including the dimensionality of the data, and to reconstruct arrangement of pixels in fully scrambled images. This proves to be successful even though higher order interaction structures are present in our data. We build intuition behind the success, which we hope might contribute to modeling complex, multivariate systems and to explaining the success of modern attention-based machine learning approaches.         _ Less","","arXiv","https://arxiv.org/abs/2305.04386","1","0","origin_of_life"
"A Latent Diffusion Model for Protein Structure Generation","Abstract:                Proteins are complex biomolecules that perform a variety of crucial functions within living organisms. Designing and generating novel proteins can pave the way for many future synthetic biology applications, including drug discovery. However, it remains a challenging computational task due to the large modeling space o_         _ More           Proteins are complex biomolecules that perform a variety of crucial functions within living organisms. Designing and generating novel proteins can pave the way for many future synthetic biology applications, including drug discovery. However, it remains a challenging computational task due to the large modeling space of protein structures. In this study, we propose a latent diffusion model that can reduce the complexity of protein modeling while flexibly capturing the distribution of natural protein structures in a condensed latent space. Specifically, we propose an equivariant protein autoencoder that embeds proteins into a latent space and then uses an equivariant diffusion model to learn the distribution of the latent protein representations. Experimental results demonstrate that our method can effectively generate novel protein backbone structures with high designability and efficiency. The code will be made publicly available at https://github.com/divelab/AIRS/tree/main/OpenProt/LatentDiff         _ Less","","arXiv","https://arxiv.org/abs/2305.04120","0","1","synthetic_biology"
"In silico design, in vitro construction and in vivo application of synthetic small regulatory RNAs in bacteria","Abstract:                _sciences for example to fine-tune genetic circuits or biotechnological processes. Even though sRNAs often have a rather simple and modular structure, the design of functional synthetic sRNAs is not necessarily trivial. This protocol outlines how to use computational predictions and_         _ More           Small regulatory RNAs (sRNAs) are short non-coding RNAs in bacteria capable of post-transcriptional regulation. sRNAs have recently gained attention as tools in basic and applied sciences for example to fine-tune genetic circuits or biotechnological processes. Even though sRNAs often have a rather simple and modular structure, the design of functional synthetic sRNAs is not necessarily trivial. This protocol outlines how to use computational predictions and synthetic biology approaches to design, construct and validate synthetic sRNA functionality for their application in bacteria. The computational tool, SEEDling, matches the optimal seed region with the user-selected sRNA scaffold for repression of target mRNAs. The synthetic sRNAs are assembled using Golden Gate cloning and their functionality is subsequently validated. The protocol uses the acrA mRNA as an exemplary proof-of-concept target in Escherichia coli. Since AcrA is part of a multidrug efflux pump, acrA repression can be revealed by assessing oxacillin susceptibility in a phenotypic screen. However, in case target repression does not result in a screenable phenotype, an alternative validation of synthetic sRNA functionality based on a fluorescence reporter is described.         _ Less","","arXiv","https://arxiv.org/abs/2304.14932","0","1","synthetic_biology"
"Modulating human brain responses via optimal natural image selection and synthetic image generation","Abstract:                _activations, and the activation gain is positively associated with the encoding model accuracy. Furthermore, aTLfaces and FBA1 had higher activation in response to maximal synthetic images compared to maximal natural images. In our second experiment, we found that_         _ More           Understanding how human brains interpret and process information is important. Here, we investigated the selectivity and inter-individual differences in human brain responses to images via functional MRI. In our first experiment, we found that images predicted to achieve maximal activations using a group level encoding model evoke higher responses than images predicted to achieve average activations, and the activation gain is positively associated with the encoding model accuracy. Furthermore, aTLfaces and FBA1 had higher activation in response to maximal synthetic images compared to maximal natural images. In our second experiment, we found that synthetic images derived using a personalized encoding model elicited higher responses compared to synthetic images from group-level or other subjects' encoding models. The finding of aTLfaces favoring synthetic images than natural images was also replicated. Our results indicate the possibility of using data-driven and generative approaches to modulate macro-scale brain region responses and probe inter-individual differences in and functional specialization of the human visual system.         _ Less","","arXiv","https://arxiv.org/abs/2304.09225","1","0","origin_of_life"
"Generative modeling of living cells with SO(3)-equivariant implicit neural representations","Abstract:                _cell tracking and segmentation methods in biomedical imaging require diverse and information-rich training data. In cases where the number of training samples is limited, synthetic computer-generated data sets can be used to improve these methods. This requires the synthesis of cell shapes as well as corresponding microscopy images using generative models. T_         _ More           Data-driven cell tracking and segmentation methods in biomedical imaging require diverse and information-rich training data. In cases where the number of training samples is limited, synthetic computer-generated data sets can be used to improve these methods. This requires the synthesis of cell shapes as well as corresponding microscopy images using generative models. To synthesize realistic living cell shapes, the shape representation used by the generative model should be able to accurately represent fine details and changes in topology, which are common in cells. These requirements are not met by 3D voxel masks, which are restricted in resolution, and polygon meshes, which do not easily model processes like cell growth and mitosis. In this work, we propose to represent living cell shapes as level sets of signed distance functions (SDFs) which are estimated by neural networks. We optimize a fully-connected neural network to provide an implicit representation of the SDF value at any point in a 3D+time domain, conditioned on a learned latent code that is disentangled from the rotation of the cell shape. We demonstrate the effectiveness of this approach on cells that exhibit rapid deformations (Platynereis dumerilii), cells that grow and divide (C. elegans), and cells that have growing and branching filopodial protrusions (A549 human lung carcinoma cells). A quantitative evaluation using shape features and Dice similarity coefficients of real and synthetic cell shapes shows that our model can generate topologically plausible complex cell shapes in 3D+time with high similarity to real living cell shapes. Finally, we show how microscopy images of living cells that correspond to our generated cell shapes can be synthesized using an image-to-image model.         _ Less","","arXiv","https://arxiv.org/abs/2304.08960","1","2","synthetic_biology"
"Modeling and forecasting age-specific drug overdose mortality in the United States","Abstract:                _we develop an age-structured model for drug addiction. Using an augmented ensemble Kalman filter (EnKF), we show through a simple example how our model can be combined with synthetic observation data to estimate mortality rate and an age-distribution parameter. Finally, we use an EnKF to combine our model with observation data on overdose fatalities in the_         _ More           Drug overdose deaths continue to increase in the United States for all major drug categories. Over the past two decades the total number of overdose fatalities has increased more than five-fold; since 2013 the surge in overdose rates is primarily driven by fentanyl and methamphetamines. Different drug categories and factors such as age, gender, and ethnicity are associated with different overdose mortality characteristics that may also change in time. For example, the average age at death from a drug overdose has decreased from 1940 to 1990 while the overall mortality rate has steadily increased. To provide insight into the population-level dynamics of drug-overdose mortality, we develop an age-structured model for drug addiction. Using an augmented ensemble Kalman filter (EnKF), we show through a simple example how our model can be combined with synthetic observation data to estimate mortality rate and an age-distribution parameter. Finally, we use an EnKF to combine our model with observation data on overdose fatalities in the United States from 1999 to 2020 to forecast the evolution of overdose trends and estimate model parameters.         _ Less","","arXiv","https://arxiv.org/abs/2303.16172","0","1","synthetic_biology"
"CSK Realization for MC via Spatially Distributed Multicellular Consortia","Abstract:                _signals is the key to unleashing the potential of MC for interdisciplinary applications. By controlling the signaling pathway and molecule exchange between cell devices, synthetic biology provides the MC community with tools and techniques to achieve various signal processing functions. In this paper, we propose a desi_         _ More           The design and engineering of molecular communication (MC) components capable of processing chemical concentration signals is the key to unleashing the potential of MC for interdisciplinary applications. By controlling the signaling pathway and molecule exchange between cell devices, synthetic biology provides the MC community with tools and techniques to achieve various signal processing functions. In this paper, we propose a design framework to realize any order concentration shift keying (CSK) systems based on simple and reusable single-input single-output cells. The design framework also exploits the distributed multicellular consortia with spatial segregation, which has advantages in system scalability, low genetic manipulation, and signal orthogonality. We also create a small library of reusable engineered cells and apply them to implement binary CSK (BCSK) and quadruple CSK (QCSK) systems to demonstrate the feasibility of our proposed design framework. Importantly, we establish a mathematical framework to theoretically characterize our proposed distributed multicellular systems. Specially, we divide a system into fundamental building blocks, from which we derive the impulse response of each block and the cascade of the impulse responses leads to the end-to-end response of the system. Simulation results obtained from the agent-based simulator BSim not only validate our CSK design framework but also demonstrate the accuracy of the proposed mathematical analysis.         _ Less","","arXiv","https://arxiv.org/abs/2303.12088","0","2","synthetic_biology"
"Learning interpretable causal networks from very large datasets, application to 400,000 medical records of breast cancer patients","Abstract:                _principle, which greatly improves the precision of inferred causal relations while distinguishing genuine causes from putative and latent causal effects. We showcase iMIIC on synthetic and real-life healthcare data from 396,179 breast cancer patients from the US Surveillance, Epidemiology, and End Results program. More than 90\\% of predicted causal effects a_         _ More           Discovering causal effects is at the core of scientific investigation but remains challenging when only observational data is available. In practice, causal networks are difficult to learn and interpret, and limited to relatively small datasets. We report a more reliable and scalable causal discovery method (iMIIC), based on a general mutual information supremum principle, which greatly improves the precision of inferred causal relations while distinguishing genuine causes from putative and latent causal effects. We showcase iMIIC on synthetic and real-life healthcare data from 396,179 breast cancer patients from the US Surveillance, Epidemiology, and End Results program. More than 90\\% of predicted causal effects appear correct, while the remaining unexpected direct and indirect causal effects can be interpreted in terms of diagnostic procedures, therapeutic timing, patient preference or socio-economic disparity. iMIIC's unique capabilities open up new avenues to discover reliable and interpretable causal networks across a range of research fields.         _ Less","","arXiv","https://arxiv.org/abs/2303.06423","1","0","origin_of_life"
"Self-contained Beta-with-Spikes Approximation for Inference Under a Wright-Fisher Model","Abstract:                _frequencies predicted by the Wright-Fisher model. We introduce a self-contained scheme for estimating the parameters in the approximation, and demonstrate its robustness with synthetic data, especially in the strong-selection and near-extinction regimes where previous approaches fail. We further apply to allele frequency data for baker's yeast (Saccharom_         _ More           We construct a reliable estimation of evolutionary parameters within the Wright-Fisher model, which describes changes in allele frequencies due to selection and genetic drift, from time-series data. Such data exists for biological populations, for example via artificial evolution experiments, and for the cultural evolution of behavior, such as linguistic corpora that document historical usage of different words with similar meanings. Our method of analysis builds on a Beta-with-Spikes approximation to the distribution of allele frequencies predicted by the Wright-Fisher model. We introduce a self-contained scheme for estimating the parameters in the approximation, and demonstrate its robustness with synthetic data, especially in the strong-selection and near-extinction regimes where previous approaches fail. We further apply to allele frequency data for baker's yeast (Saccharomyces cerevisiae), finding a significant signal of selection in cases where independent evidence supports such a conclusion. We further demonstrate the possibility of detecting time-points at which evolutionary parameters change in the context of a historical spelling reform in the Spanish language.         _ Less","","arXiv","https://arxiv.org/abs/2303.04691","0","1","synthetic_biology"
"Conformational Fluctuations and Phases in Fused in Sarcoma (FUS) Low-Complexity Domain","Abstract:                The well known phenomenon of phase separation in synthetic polymers and proteins has become a major topic in biophysics because it has been invoked as a mechanism of compartment formation in cells, without the need for membranes. Most of the coacervates (or condensates) are composed of Intrinsically Disordered Proteins (IDPs) or regions that are structureles_         _ More           The well known phenomenon of phase separation in synthetic polymers and proteins has become a major topic in biophysics because it has been invoked as a mechanism of compartment formation in cells, without the need for membranes. Most of the coacervates (or condensates) are composed of Intrinsically Disordered Proteins (IDPs) or regions that are structureless, often in interaction with RNA and DNA. One of the more intriguing IDPs is the 526-residue RNA binding protein, Fused In Sarcoma (FUS), whose monomer conformations and condensates exhibit unusual behavior that are sensitive to solution conditions. By focussing principally on the N-terminus low complexity domain (FUS-LC comprising residues 1-214) and other truncations, we rationalize the findings of solid state NMR experiments, which show that FUS-LC adopts a non-polymorphic fibril (core-1) involving residues 39-95, flanked by fuzzy coats on both the N- and C- terminal ends. An alternate structure (core-2), whose free energy is comparable to core-1, emerges only in the truncated construct (residues 110-214). Both core-1 and core-2 fibrils are stabilized by a Tyrosine ladder as well as hydrophilic interactions. The morphologies (gels, fibrils, and glass-like behavior) adopted by FUS seem to vary greatly, depending on the experimental conditions. The effect of phosphorylation is site specific and affects the stability of the fibril depending on the sites that are phosphorylated. Many of the peculiarities associated with FUS may also be shared by other IDPs, such as TDP43 and hnRNPA2. We outline a number of problems for which there is no clear molecular understanding.         _ Less","","arXiv","https://arxiv.org/abs/2303.04215","1","0","origin_of_life"
"Exploring The Potential Of GANs In Biological Sequence Analysis","Abstract:                _with biological sequence datasets, which hinders their performance. Although various strategies are present to address this issue, like the SMOTE algorithm, which creates synthetic data, however, they focus on local information rather than the overall class distribution. In this work, we explore a novel approach to handle the data imbalance issue based on Ge_         _ More           Biological sequence analysis is an essential step toward building a deeper understanding of the underlying functions, structures, and behaviors of the sequences. It can help in identifying the characteristics of the associated organisms, like viruses, etc., and building prevention mechanisms to eradicate their spread and impact, as viruses are known to cause epidemics that can become pandemics globally. New tools for biological sequence analysis are provided by machine learning (ML) technologies to effectively analyze the functions and structures of the sequences. However, these ML-based methods undergo challenges with data imbalance, generally associated with biological sequence datasets, which hinders their performance. Although various strategies are present to address this issue, like the SMOTE algorithm, which creates synthetic data, however, they focus on local information rather than the overall class distribution. In this work, we explore a novel approach to handle the data imbalance issue based on Generative Adversarial Networks (GANs) which use the overall data distribution. GANs are utilized to generate synthetic data that closely resembles the real one, thus this generated data can be employed to enhance the ML models' performance by eradicating the class imbalance problem for biological sequence analysis. We perform 3 distinct classification tasks by using 3 different sequence datasets (Influenza A Virus, PALMdb, VDjDB) and our results illustrate that GANs can improve the overall classification performance.         _ Less","","arXiv","https://arxiv.org/abs/2303.02421","1","0","origin_of_life"
"A Neuro-Symbolic AI Approach to Personal Health Risk Assessment and Immune Age Characterisation using Common Blood Markers","Abstract:                _chronological age with an estimation of biological age based on common immune-relevant markers used in current clinical practice. We demonstrate its efficacy on real and synthetic data from medically relevant cases, extreme cases, and empirical blood cell count data from 100K data records in the Centers for Disease Control and Prevention's National Healt_         _ More           We introduce a simulated digital model that learns a person's baseline blood health over time. Using an adaptive learning algorithm, the model provides a risk assessment score that compares an individual's chronological age with an estimation of biological age based on common immune-relevant markers used in current clinical practice. We demonstrate its efficacy on real and synthetic data from medically relevant cases, extreme cases, and empirical blood cell count data from 100K data records in the Centers for Disease Control and Prevention's National Health and Nutrition Examination Survey (CDC NHANES) that spans 13 years. We find that the score is informative in distinguishing healthy individuals from those with diseases, both self-reported and as manifested via abnormal blood test results, providing an entry-level score for patient triaging. The risk assessment score is not a machine learning black-box approach but can interact with ML and DL approaches to help guide, control the attention given to specific features, and assign proper explainable weight to an otherwise transparent adaptive learning algorithm. This approach may allow fast and scalable deployment to personalised, sensitive, and predictive derivative indexes within digital medicine, without the need for a new test, assay, or prospective sampling, unlike other biological ageing-related scores and methods. It demonstrates the potential of clinical informatics and deep medicine in digital healthcare as drivers of innovation in preventive patient care.         _ Less","","arXiv","https://arxiv.org/abs/2303.01444","1","1","multiple"
"Chemical relaxation oscillator designed to control molecular computation","Abstract:                Embedding efficient calculation instructions into biochemical system has always been a research focus in synthetic biology. One of the key problems is how to sequence the chemical reaction modules that act as units of computation and make them alternate spontaneously. Our work takes the design of chemical clock signals_         _ More           Embedding efficient calculation instructions into biochemical system has always been a research focus in synthetic biology. One of the key problems is how to sequence the chemical reaction modules that act as units of computation and make them alternate spontaneously. Our work takes the design of chemical clock signals as a solution and presents a $4$-dimensional chemical oscillator model based on relaxation oscillation to generate a pair of symmetric clock signals for two-module regulation. We give detailed dynamical analysis of the model and discuss how to control the period and occurrence order of clock signals. We also demonstrate the loop control of molecular computations and provide termination strategy for them. We can expect that our design for module regulation and loop termination will help advance the embedding of more complicate calculations into biochemical environments.         _ Less","","arXiv","https://arxiv.org/abs/2302.14226","0","1","synthetic_biology"
"DeepBrainPrint: A Novel Contrastive Framework for Brain MRI Re-Identification","Abstract:                _disease progression in patients. We tested DeepBrainPrint on a large dataset of T1-weighted brain MRIs from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and on a synthetic dataset designed to evaluate retrieval performance with different image modalities. Our results show that DeepBrainPrint outperforms previous methods, including simple simila_         _ More           Recent advances in MRI have led to the creation of large datasets. With the increase in data volume, it has become difficult to locate previous scans of the same patient within these datasets (a process known as re-identification). To address this issue, we propose an AI-powered medical imaging retrieval framework called DeepBrainPrint, which is designed to retrieve brain MRI scans of the same patient. Our framework is a semi-self-supervised contrastive deep learning approach with three main innovations. First, we use a combination of self-supervised and supervised paradigms to create an effective brain fingerprint from MRI scans that can be used for real-time image retrieval. Second, we use a special weighting function to guide the training and improve model convergence. Third, we introduce new imaging transformations to improve retrieval robustness in the presence of intensity variations (i.e. different scan contrasts), and to account for age and disease progression in patients. We tested DeepBrainPrint on a large dataset of T1-weighted brain MRIs from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and on a synthetic dataset designed to evaluate retrieval performance with different image modalities. Our results show that DeepBrainPrint outperforms previous methods, including simple similarity metrics and more advanced contrastive deep learning frameworks.         _ Less","","arXiv","https://arxiv.org/abs/2302.13057","1","0","origin_of_life"
"Aligned Diffusion Schr_dinger Bridges","Abstract:                _training procedure with lower variance, which we further augment with principled regularization schemes. This ultimately leads to sizeable improvements across experiments on synthetic and real data, including the tasks of predicting conformational changes in proteins and temporal evolution of cellular differentiation processes.         _ More           Diffusion Schr_dinger bridges (DSB) have recently emerged as a powerful framework for recovering stochastic dynamics via their marginal observations at different time points. Despite numerous successful applications, existing algorithms for solving DSBs have so far failed to utilize the structure of aligned data, which naturally arises in many biological phenomena. In this paper, we propose a novel algorithmic framework that, for the first time, solves DSBs while respecting the data alignment. Our approach hinges on a combination of two decades-old ideas: The classical Schr_dinger bridge theory and Doob's $h$-transform. Compared to prior methods, our approach leads to a simpler training procedure with lower variance, which we further augment with principled regularization schemes. This ultimately leads to sizeable improvements across experiments on synthetic and real data, including the tasks of predicting conformational changes in proteins and temporal evolution of cellular differentiation processes.         _ Less","","arXiv","https://arxiv.org/abs/2302.11419","1","1","multiple"
"Two Cellular Resource Based Models Linking Growth and Parts Characteristics Aids the Study and Optimization of Synthetic Gene Circuits","Abstract:                A major challenge in synthetic genetic circuit development is the inter-dependency between heterologous gene expressions by circuits and host's growth rate. Increasing heterologous gene expression increases burden to the host, resulting in host growth reduction; which reduces overall heterologous protein abundance. Hence, it is difficult to design predic_         _ More           A major challenge in synthetic genetic circuit development is the inter-dependency between heterologous gene expressions by circuits and host's growth rate. Increasing heterologous gene expression increases burden to the host, resulting in host growth reduction; which reduces overall heterologous protein abundance. Hence, it is difficult to design predictable genetic circuits. Here, we develop two biophysical models; one for promoter, another for RBS; to correlate heterologous gene expression and growth reduction. We model cellular resource allocation in E. coli to describe the burden, as growth reduction, caused by genetic circuits. To facilitate their uses in genetic circuit design, inputs to the model are common characteristics of biological parts [e.g. relative promoter strength (RPU) and relative ribosome binding sites strength (RRU)]. The models suggest that E. coli's growth rate reduces linearly with increasing RPU / RRU of the genetic circuits; thus, providing 2 handy models taking parts characteristics as input to estimate growth rate reduction for fine tuning genetic circuit design in silico prior to construction. Our promoter model correlates well with experiments using various genetic circuits, both single and double expression cassettes, up to a relative promoter unit of 3.7 with a 60% growth rate reduction (average R2 ~ 0.9).         _ Less","","arXiv","https://arxiv.org/abs/2302.09563","0","2","synthetic_biology"
"Approaching epidemiological dynamics of COVID-19 with physics-informed neural networks","Abstract:                _(SIR) model is devised to understand the temporal evolution dynamics of infectious diseases. Firstly, the effectiveness of this approach is demonstrated on synthetic data as generated from the numerical solution of the susceptible-asymptomatic-infected-recovered-dead (SAIRD) model. Then, the method is applied to COVID-19 data reported for Germany and shows t_         _ More           A physics-informed neural network (PINN) embedded with the susceptible-infected-removed (SIR) model is devised to understand the temporal evolution dynamics of infectious diseases. Firstly, the effectiveness of this approach is demonstrated on synthetic data as generated from the numerical solution of the susceptible-asymptomatic-infected-recovered-dead (SAIRD) model. Then, the method is applied to COVID-19 data reported for Germany and shows that it can accurately identify and predict virus spread trends. The results indicate that an incomplete physics-informed model can approach more complicated dynamics efficiently. Thus, the present work demonstrates the high potential of using machine learning methods, e.g., PINNs, to study and predict epidemic dynamics in combination with compartmental models.         _ Less","","arXiv","https://arxiv.org/abs/2302.08796","0","1","synthetic_biology"
"Chemical logic gates on active colloids","Abstract:        Synthetic active colloidal systems are being studied extensively because of the diverse and often unusual phenomena these nonequilibrium systems manifest, and their potential applications in fields ranging from_         _ More   Synthetic active colloidal systems are being studied extensively because of the diverse and often unusual phenomena these nonequilibrium systems manifest, and their potential applications in fields ranging from biology to material science. Recent studies have shown that active colloidal motors that use enzymatic reactions for propulsion hold special promise for applications that require motors to carry out active sensing tasks in complicated biomedical environments. In such applications it would be desirable to have active colloids with some capability of computation so that they could act autonomously to sense their surroundings and alter their own dynamics to perform specific tasks. Here we describe how small chemical networks that make use of enzymatic chemical reactions on the colloid surface can be used to construct motor-based chemical logic gates. Some basic features of coupled enzymatic reactions that are responsible for propulsion and underlie the construction and function of chemical gates are described using continuum theory and molecular simulation. Examples are given that show how colloids with specific chemical logic gates can perform simple sensing tasks. Due to the diverse functions of different enzyme gates, operating alone or in circuits, the work presented here supports the suggestion that synthetic motors using such gates could be designed to operate in an autonomous way in order to complete complicated tasks.         _ Less","","arXiv","https://arxiv.org/abs/2302.07670","0","1","synthetic_biology"
"Leveraging Interactions in Microfluidic Droplets for Enhanced Biotechnology Screens","Abstract:                _product design. Moreover, we highlight pioneering advancements that extend droplet-based screens into new domains: cargo delivery within human bodies, application of synthetic gene circuits in natural environments, 3D-printing, and the development of droplet structures responsive to environmental signals. The potential of this field is profound and only set_         _ More           Microfluidic droplet screens serve as an innovative platform for high-throughput biotechnology, enabling significant advancements in discovery, product optimization, and analysis. This review sheds light on the emerging trend of interaction assays in microfluidic droplets, underscoring the unique suitability of droplets for these applications. Encompassing a diverse range of biological entities such as antibodies, enzymes, DNA, RNA, various microbial and mammalian cell types, drugs, and other molecules, these assays demonstrate their versatility and scope. Recent methodological breakthroughs have escalated these screens to novel scales of bioanalysis and biotechnological product design. Moreover, we highlight pioneering advancements that extend droplet-based screens into new domains: cargo delivery within human bodies, application of synthetic gene circuits in natural environments, 3D-printing, and the development of droplet structures responsive to environmental signals. The potential of this field is profound and only set to increase.         _ Less","","arXiv","https://arxiv.org/abs/2302.00142","1","3","synthetic_biology"
"Automating Knowledge-Driven Model Recommendation: Methodology, Evaluation, and Key Challenges","Abstract:                _human curated models and do not recapitulate experimental results. Here, we outline the process of automated model assembly and extension, while demonstrating it on both synthetic models and human-curated models of biological signaling networks. We begin with an iterative, greedy, and combinatoric approach to automated assembly and demonstrate the key diffic_         _ More           There is significant interest in using existing repositories of biological entities, relationships, and models to automate biological model assembly and extension. Current methods aggregate human-curated biological information into executable, simulatable models, but these models do not resemble human curated models and do not recapitulate experimental results. Here, we outline the process of automated model assembly and extension, while demonstrating it on both synthetic models and human-curated models of biological signaling networks. We begin with an iterative, greedy, and combinatoric approach to automated assembly and demonstrate the key difficulties inherent to contextless assembly. We publicly release the software used in this paper to enable further exploration of this problem.         _ Less","","arXiv","https://arxiv.org/abs/2301.11397","1","0","origin_of_life"
"Neuronal architecture extracts statistical temporal patterns","Abstract:                _mean, which in turn enables the synergistic use of information encoded in multiple cumulants to maximize the classification accuracy. The approach is demonstrated both on a synthetic and on real world datasets of multivariate time series. Moreover, we show that the biologically inspired architecture makes better use of the number of trainable parameters as c_         _ More           Neuronal systems need to process temporal signals. We here show how higher-order temporal (co-)fluctuations can be employed to represent and process information. Concretely, we demonstrate that a simple biologically inspired feedforward neuronal model is able to extract information from up to the third order cumulant to perform time series classification. This model relies on a weighted linear summation of synaptic inputs followed by a nonlinear gain function. Training both - the synaptic weights and the nonlinear gain function - exposes how the non-linearity allows for the transfer of higher order correlations to the mean, which in turn enables the synergistic use of information encoded in multiple cumulants to maximize the classification accuracy. The approach is demonstrated both on a synthetic and on real world datasets of multivariate time series. Moreover, we show that the biologically inspired architecture makes better use of the number of trainable parameters as compared to a classical machine-learning scheme. Our findings emphasize the benefit of biological neuronal architectures, paired with dedicated learning algorithms, for the processing of information embedded in higher-order statistical cumulants of temporal (co-)fluctuations.         _ Less","","arXiv","https://arxiv.org/abs/2301.10203","1","0","origin_of_life"
"Efficiently Computing Sparse Fourier Transforms of $q$-ary Functions","Abstract:                _-ary alphabet? These types of functions arise naturally in many areas including biology. A typical workaround is to encode the $q$-ary sequence in binary, however, this approach is computationally inefficient and fundamentally incompatible with the existing sparse Fourier transform techniques. Herein, we develop a sparse Fourier transform algorithm specifica_         _ More           Fourier transformations of pseudo-Boolean functions are popular tools for analyzing functions of binary sequences. Real-world functions often have structures that manifest in a sparse Fourier transform, and previous works have shown that under the assumption of sparsity the transform can be computed efficiently. But what if we want to compute the Fourier transform of functions defined over a $q$-ary alphabet? These types of functions arise naturally in many areas including biology. A typical workaround is to encode the $q$-ary sequence in binary, however, this approach is computationally inefficient and fundamentally incompatible with the existing sparse Fourier transform techniques. Herein, we develop a sparse Fourier transform algorithm specifically for $q$-ary functions of length $n$ sequences, dubbed $q$-SFT, which provably computes an $S$-sparse transform with vanishing error as $q^n \\rightarrow \\infty$ in $O(Sn)$ function evaluations and $O(S n^2 \\log q)$ computations, where $S = q^{n_}$ for some $_< 1$. Under certain assumptions, we show that for fixed $q$, a robust version of $q$-SFT has a sample complexity of $O(Sn^2)$ and a computational complexity of $O(Sn^3)$ with the same asymptotic guarantees. We present numerical simulations on synthetic and real-world RNA data, demonstrating the scalability of $q$-SFT to massively high dimensional $q$-ary functions.         _ Less","","arXiv","https://arxiv.org/abs/2301.06200","1","0","origin_of_life"
"Short-length SSVEP data extension by a novel generative adversarial networks based framework","Abstract:                _which hinders the deployment in real-world applications. Recently, generative adversarial networks (GANs)-based data generation methods have been widely adopted to create synthetic electroencephalography (EEG) data, holds promise to address these issues. In this paper, we proposed a GAN-based end-to-end signal transformation network for Time-window length E_         _ More           Steady-state visual evoked potentials (SSVEPs) based brain-computer interface (BCI) has received considerable attention due to its high information transfer rate (ITR) and available quantity of targets. However, the performance of frequency identification methods heavily hinges on the amount of user calibration data and data length, which hinders the deployment in real-world applications. Recently, generative adversarial networks (GANs)-based data generation methods have been widely adopted to create synthetic electroencephalography (EEG) data, holds promise to address these issues. In this paper, we proposed a GAN-based end-to-end signal transformation network for Time-window length Extension, termed as TEGAN. TEGAN transforms short-length SSVEP signals into long-length artificial SSVEP signals. By incorporating a novel U-Net generator architecture and an auxiliary classifier into the network architecture, the TEGAN could produce conditioned features in the synthetic data. Additionally, we introduced a two-stage training strategy and the LeCam-divergence regularization term to regularize the training process of GAN during the network implementation. The proposed TEGAN was evaluated on two public SSVEP datasets (a 4-class dataset and a 12-class dataset). With the assistance of TEGAN, the performance of traditional frequency recognition methods and deep learning-based methods have been significantly improved under limited calibration data. And the classification performance gap of various frequency recognition methods has been narrowed. This study substantiates the feasibility of the proposed method to extend the data length for short-time SSVEP signals for developing a high-performance BCI system. The proposed GAN-based methods have the great potential of shortening the calibration time and cutting down the budget for various real-world BCI-based applications.         _ Less","","arXiv","https://arxiv.org/abs/2301.05599","1","0","origin_of_life"
"On Phase Change Rate Maximization with Practical Applications","Abstract:                _the phase change rate maximization result to two practical applications. The first is a magnetic levitation system, while the second is a repressilator with time-delay in synthetic biology.         _ More           We recapitulate the notion of phase change rate maximization and demonstrate the usefulness of its solution on analyzing the robust instability of a cyclic network of multi-agent systems subject to a homogenous multiplicative perturbation. Subsequently, we apply the phase change rate maximization result to two practical applications. The first is a magnetic levitation system, while the second is a repressilator with time-delay in synthetic biology.         _ Less","","arXiv","https://arxiv.org/abs/2301.04775","0","1","synthetic_biology"
"Learning Personalized Brain Functional Connectivity of MDD Patients from Multiple Sites via Federated Bayesian Networks","Abstract:                _use the iterative proximal projection method to deal with the group fused lasso penalty in the global update step. We evaluate the performance of the proposed method on both synthetic and real-world multi-site rs-fMRI datasets. The results suggest that the proposed NOTEARS-PFL yields superior effectiveness and accuracy than the comparable methods.         _ More           Identifying functional connectivity biomarkers of major depressive disorder (MDD) patients is essential to advance understanding of the disorder mechanisms and early intervention. However, due to the small sample size and the high dimension of available neuroimaging data, the performance of existing methods is often limited. Multi-site data could enhance the statistical power and sample size, while they are often subject to inter-site heterogeneity and data-sharing policies. In this paper, we propose a federated joint estimator, NOTEARS-PFL, for simultaneous learning of multiple Bayesian networks (BNs) with continuous optimization, to identify disease-induced alterations in MDD patients. We incorporate information shared between sites and site-specific information into the proposed federated learning framework to learn personalized BN structures by introducing the group fused lasso penalty. We develop the alternating direction method of multipliers, where in the local update step, the neuroimaging data is processed at each local site. Then the learned network structures are transmitted to the center for the global update. In particular, we derive a closed-form expression for the local update step and use the iterative proximal projection method to deal with the group fused lasso penalty in the global update step. We evaluate the performance of the proposed method on both synthetic and real-world multi-site rs-fMRI datasets. The results suggest that the proposed NOTEARS-PFL yields superior effectiveness and accuracy than the comparable methods.         _ Less","","arXiv","https://arxiv.org/abs/2301.02423","1","0","origin_of_life"
"CI-GNN: A Granger Causality-Inspired Graph Neural Network for Interpretable Brain Network-Based Psychiatric Diagnosis","Abstract:                _regulation in capturing the causal relationship. We also empirically evaluate the performance of CI-GNN against three baseline GNNs and four state-of-the-art GNN explainers on synthetic data and three large-scale brain disease datasets. We observe that CI-GNN achieves the best performance in a wide range of metrics and provides more reliable and concise expl_         _ More           There is a recent trend to leverage the power of graph neural networks (GNNs) for brain-network based psychiatric diagnosis, which,in turn, also motivates an urgent need for psychiatrists to fully understand the decision behavior of the used GNNs. However, most of the existing GNN explainers are either post-hoc in which another interpretive model needs to be created to explain a well-trained GNN, or do not consider the causal relationship between the extracted explanation and the decision, such that the explanation itself contains spurious correlations and suffers from weak faithfulness. In this work, we propose a granger causality-inspired graph neural network (CI-GNN), a built-in interpretable model that is able to identify the most influential subgraph (i.e., functional connectivity within brain regions) that is causally related to the decision (e.g., major depressive disorder patients or healthy controls), without the training of an auxillary interpretive network. CI-GNN learns disentangled subgraph-level representations _ and \\b{eta} that encode, respectively, the causal and noncausal aspects of original graph under a graph variational autoencoder framework, regularized by a conditional mutual information (CMI) constraint. We theoretically justify the validity of the CMI regulation in capturing the causal relationship. We also empirically evaluate the performance of CI-GNN against three baseline GNNs and four state-of-the-art GNN explainers on synthetic data and three large-scale brain disease datasets. We observe that CI-GNN achieves the best performance in a wide range of metrics and provides more reliable and concise explanations which have clinical evidence.The source code and implementation details of CI-GNN are freely available at GitHub repository (https://github.com/ZKZ-Brain/CI-GNN/).         _ Less","","arXiv","https://arxiv.org/abs/2301.01642","1","0","origin_of_life"
"Synthesis-driven design of 3D molecules for structure-based drug discovery using geometric transformers","Abstract:                _3D molecules that combines structure-based de novo drug design with a reaction-based generation framework. Besides producing 3D molecular structures, the model also proposes synthetic pathways for generated molecules, which greatly assists the retro-synthetic analysis. To achieve this, we developed a new way to enforce_         _ More           Finding drug-like compounds with high bioactivity is essential for drug discovery, but the task is complicated by the high cost of chemical synthesis and validation. With their outstanding performance in de novo drug design, deep generative models represent promising tools for tackling this challenge. In recently years, 3D molecule generative models have gained increasing attention due to their ability to directly utilize the 3D interaction information between the target and ligand. However, it remains challenging to synthesize the molecules generated by these models, limiting the speed of bioactivity validation and further structure optimization. In this work, we propose DeepLigBuilder+, a deep generative model for 3D molecules that combines structure-based de novo drug design with a reaction-based generation framework. Besides producing 3D molecular structures, the model also proposes synthetic pathways for generated molecules, which greatly assists the retro-synthetic analysis. To achieve this, we developed a new way to enforce the synthesizability constraint using a tree-based organization of purchasable building blocks. This method enjoys high scalability and is compatible with existing atom-based generative models. Additionally, for structure-based design tasks, we developed an SE(3)-equivariant transformer conditioned on the shape and pharmacophore-based inputs, and combine it with the Monte Carlo tree search. Using the ATP-binding pocket of BTK and the NAD+ binding pocket of PHGDH for case studies, we demonstrate that DeepLigBuilder+ is capable of enriching drug-like molecules with high predicted binding affinity and desirable interaction modes while maintaining the synthesizability constraint. We believe that DeepLigBuilder+ is a powerful tool for accelerating the process of drug discovery.         _ Less","","arXiv","https://arxiv.org/abs/2301.00167","1","0","origin_of_life"
"Mind the Retrosynthesis Gap: Bridging the divide between Single-step and Multi-step Retrosynthesis Prediction","Abstract:                _route for a molecule. As more single-step models develop, we see increasing accuracy in the prediction of molecular disconnections, potentially improving the creation of synthetic paths. Multi-step approaches repeatedly apply the chemical information stored in single-step retrosynthesis models. However, this connection is not reflected in contemporary resear_         _ More           Retrosynthesis is the task of breaking down a chemical compound recursively step-by-step into molecular precursors until a set of commercially available molecules is found. Consequently, the goal is to provide a valid synthesis route for a molecule. As more single-step models develop, we see increasing accuracy in the prediction of molecular disconnections, potentially improving the creation of synthetic paths. Multi-step approaches repeatedly apply the chemical information stored in single-step retrosynthesis models. However, this connection is not reflected in contemporary research, fixing either the single-step model or the multi-step algorithm in the process. In this work, we establish a bridge between both tasks by benchmarking the performance and transfer of different single-step retrosynthesis models to the multi-step domain by leveraging two common search algorithms, Monte Carlo Tree Search and Retro*. We show that models designed for single-step retrosynthesis, when extended to multi-step, can have a tremendous impact on the route finding capabilities of current multi-step methods, improving performance by up to +30% compared to the most widely used model. Furthermore, we observe no clear link between contemporary single-step and multi-step evaluation metrics, showing that single-step models need to be developed and tested for the multi-step domain and not as an isolated task to find synthesis routes for molecules of interest.         _ Less","","arXiv","https://arxiv.org/abs/2212.11809","1","0","origin_of_life"
"Detecting Temporal shape changes with the Euler Characteristic Transform","Abstract:                _our method on a data set of segmented videos of mouse small intestine organoid experiments and show that it outperforms classical shape descriptors. We verify our method on a synthetic organoid data set and illustrate how it generalises to 3D. We conclude that DETECT offers rigorous quantification of organoids and opens up computationally scalable methods fo_         _ More           Organoids are multi-cellular structures which are cultured in vitro from stem cells to resemble specific organs (e.g., brain, liver) in their three-dimensional composition. Dynamic changes in the shape and composition of these model systems can be used to understand the effect of mutations and treatments in health and disease. In this paper, we propose a new technique in the field of topological data analysis for DEtecting Temporal shape changes with the Euler Characteristic Transform (DETECT). DETECT is a rotationally invariant signature of dynamically changing shapes. We demonstrate our method on a data set of segmented videos of mouse small intestine organoid experiments and show that it outperforms classical shape descriptors. We verify our method on a synthetic organoid data set and illustrate how it generalises to 3D. We conclude that DETECT offers rigorous quantification of organoids and opens up computationally scalable methods for distinguishing different growth regimes and assessing treatment effects.         _ Less","","arXiv","https://arxiv.org/abs/2212.10883","0","1","synthetic_biology"
"Embedding Positive Process Models into Lognormal Bayesian State Space Frameworks using Moment Matching","Abstract:                _allows for more flexibility in fitting techniques. We discuss two existing lognormal state space models, and examine how they differ from the method presented here. We use 180 synthetic datasets to compare the forecasting performance under model misspecification and assess estimability of precision parameters between our method and existing methods. We find_         _ More           In ecology it is common for processes to be bounded based on physical constraints of the system. One common example is the positivity constraint, which applies to phenomena such as duration times, population sizes, and total stock of a system's commodity. In this paper, we propose a novel method for embedding these dynamical systems into a lognormal state space model using an approach based on moment matching. Our method enforces the positivity constraint, allows for embedding of arbitrary mean evolution and variance structure, and has a closed-form Markov transition density which allows for more flexibility in fitting techniques. We discuss two existing lognormal state space models, and examine how they differ from the method presented here. We use 180 synthetic datasets to compare the forecasting performance under model misspecification and assess estimability of precision parameters between our method and existing methods. We find that our models well under misspecification, and that fixing the observation variance both helps to improve estimation of the process variance and improves forecast performance. To test our method on a difficult problem, we compare the predictive performance of two lognormal state space models in predicting Leaf Area Index over a 151 day horizon by embedding a process-based ecosystem model. We find that our moment matching model performs better than its competitor, and is better suited for long predictive horizons. Overall, our study helps to inform practitioners about the importance of embedding sensible dynamics when using models complex systems to predict out of sample.         _ Less","","arXiv","https://arxiv.org/abs/2212.10697","0","1","synthetic_biology"
"Quantifying Extrinsic Curvature in Neural Manifolds","Abstract:                _do not bear meaningful neuroscience information, such as permutation of the order in which neurons are recorded. We show empirically that we correctly estimate the geometry of synthetic manifolds generated from smooth deformations of circles, spheres, and tori, using realistic noise levels. We additionally validate our methodology on simulated and real neura_         _ More           The neural manifold hypothesis postulates that the activity of a neural population forms a low-dimensional manifold whose structure reflects that of the encoded task variables. In this work, we combine topological deep generative models and extrinsic Riemannian geometry to introduce a novel approach for studying the structure of neural manifolds. This approach (i) computes an explicit parameterization of the manifolds and (ii) estimates their local extrinsic curvature--hence quantifying their shape within the neural state space. Importantly, we prove that our methodology is invariant with respect to transformations that do not bear meaningful neuroscience information, such as permutation of the order in which neurons are recorded. We show empirically that we correctly estimate the geometry of synthetic manifolds generated from smooth deformations of circles, spheres, and tori, using realistic noise levels. We additionally validate our methodology on simulated and real neural data, and show that we recover geometric structure known to exist in hippocampal place cells. We expect this approach to open new avenues of inquiry into geometric neural correlates of perception and behavior.         _ Less","","arXiv","https://arxiv.org/abs/2212.10414","1","0","origin_of_life"
"Ensemble reweighting using Cryo-EM particles","Abstract:                _in conformational space from single-molecule data. To validate the framework, we study the extraction of state populations and free energies for a simple toy model and from synthetic cryo-EM images of a simulated protein that explores multiple folded and unfolded conformations.         _ More           Cryo-electron microscopy (cryo-EM) has recently become a premier method for obtaining high-resolution structures of biological macromolecules. However, it is limited to biomolecular samples with low conformational heterogeneity, where all the conformations can be well-sampled at many projection angles. While cryo-EM technically provides single-molecule data for heterogeneous molecules, most existing reconstruction tools cannot extract the full distribution of possible molecular configurations. To overcome these limitations, we build on a prior Bayesian approach and develop an ensemble refinement framework that estimates the ensemble density from a set of cryo-EM particles by reweighting a prior ensemble of conformations, e.g., from molecular dynamics simulations or structure prediction tools. Our work is a general approach to recovering the equilibrium probability density of the biomolecule directly in conformational space from single-molecule data. To validate the framework, we study the extraction of state populations and free energies for a simple toy model and from synthetic cryo-EM images of a simulated protein that explores multiple folded and unfolded conformations.         _ Less","","arXiv","https://arxiv.org/abs/2212.05320","1","0","origin_of_life"
"Resolution enhancement of NMR by decoupling with low-rank Hankel model","Abstract:                _coupling value as prior knowledge, and Hankel property of exponential NMR signal to achieve the broadband heteronuclear decoupling using the low-rank method. Our results on synthetic and realistic HMQC spectra demonstrate that the proposed method not only effectively enhances resolution by decoupling, but also maintains sensitivity and suppresses spectral ar_         _ More           Nuclear magnetic resonance (NMR) spectroscopy has become a formidable tool for biochemistry and medicine. Although J-coupling carries essential structural information it may also limit the spectral resolution. Homonuclear decoupling remains a challenging problem. In this work, we introduce a new approach that uses a specific coupling value as prior knowledge, and Hankel property of exponential NMR signal to achieve the broadband heteronuclear decoupling using the low-rank method. Our results on synthetic and realistic HMQC spectra demonstrate that the proposed method not only effectively enhances resolution by decoupling, but also maintains sensitivity and suppresses spectral artefacts. The approach can be combined with the non-uniform sampling, which means that the resolution can be further improved without any extra acquisition time         _ Less","","arXiv","https://arxiv.org/abs/2212.01144","1","0","origin_of_life"
"Hybrid Life: Integrating Biological, Artificial, and Cognitive Systems","Abstract:                _sciences. Artificial life aims to foster a comprehensive study of life beyond 'life as we know it' and towards 'life as it could be', with theoretical, synthetic and empirical models of the fundamental properties of living systems. While still a relatively young field, artificial life has flourished as an environment for researchers with diff_         _ More           Artificial life is a research field studying what processes and properties define life, based on a multidisciplinary approach spanning the physical, natural and computational sciences. Artificial life aims to foster a comprehensive study of life beyond 'life as we know it' and towards 'life as it could be', with theoretical, synthetic and empirical models of the fundamental properties of living systems. While still a relatively young field, artificial life has flourished as an environment for researchers with different backgrounds, welcoming ideas and contributions from a wide range of subjects. Hybrid Life is an attempt to bring attention to some of the most recent developments within the artificial life community, rooted in more traditional artificial life studies but looking at new challenges emerging from interactions with other fields. In particular, Hybrid Life focuses on three complementary themes: 1) theories of systems and agents, 2) hybrid augmentation, with augmented architectures combining living and artificial systems, and 3) hybrid interactions among artificial and biological systems. After discussing some of the major sources of inspiration for these themes, we will focus on an overview of the works that appeared in Hybrid Life special sessions, hosted by the annual Artificial Life Conference between 2018 and 2022.         _ Less","","arXiv","https://arxiv.org/abs/2212.00285","2","2","multiple"
"Graph Neural Networks for Breast Cancer Data Integration","Abstract:                _used to generate the lower-latent space representations: Graph Neural Networks, Variational Graph Autoencoders and Deep Graph Infomax. In parallel, the pipeline is tested on a synthetic dataset to demonstrate that the characteristics of the underlying data, such as homophily levels, greatly influence the performance of the pipeline, which ranges between 51\\%_         _ More           International initiatives such as METABRIC (Molecular Taxonomy of Breast Cancer International Consortium) have collected several multigenomic and clinical data sets to identify the undergoing molecular processes taking place throughout the evolution of various cancers. Numerous Machine Learning and statistical models have been designed and trained to analyze these types of data independently, however, the integration of such differently shaped and sourced information streams has not been extensively studied. To better integrate these data sets and generate meaningful representations that can ultimately be leveraged for cancer detection tasks could lead to giving well-suited treatments to patients. Hence, we propose a novel learning pipeline comprising three steps - the integration of cancer data modalities as graphs, followed by the application of Graph Neural Networks in an unsupervised setting to generate lower-dimensional embeddings from the combined data, and finally feeding the new representations on a cancer sub-type classification model for evaluation. The graph construction algorithms are described in-depth as METABRIC does not store relationships between the patient modalities, with a discussion of their influence over the quality of the generated embeddings. We also present the models used to generate the lower-latent space representations: Graph Neural Networks, Variational Graph Autoencoders and Deep Graph Infomax. In parallel, the pipeline is tested on a synthetic dataset to demonstrate that the characteristics of the underlying data, such as homophily levels, greatly influence the performance of the pipeline, which ranges between 51\\% to 98\\% accuracy on artificial data, and 13\\% and 80\\% on METABRIC. This project has the potential to improve cancer data understanding and encourages the transition of regular data sets to graph-shaped data.         _ Less","","arXiv","https://arxiv.org/abs/2211.15561","1","1","multiple"
"Latent Space Diffusion Models of Cryo-EM Structures","Abstract:                Cryo-electron microscopy (cryo-EM) is unique among tools in structural biology in its ability to image large, dynamic protein complexes. Key to this ability is image processing algorithms for heterogeneous cryo-EM reconstruction, including recent deep learning-based approaches. The state-of-the-art method cryoDRGN uses a Variational Autoencoder (VAE) framewo_         _ More           Cryo-electron microscopy (cryo-EM) is unique among tools in structural biology in its ability to image large, dynamic protein complexes. Key to this ability is image processing algorithms for heterogeneous cryo-EM reconstruction, including recent deep learning-based approaches. The state-of-the-art method cryoDRGN uses a Variational Autoencoder (VAE) framework to learn a continuous distribution of protein structures from single particle cryo-EM imaging data. While cryoDRGN can model complex structural motions, the Gaussian prior distribution of the VAE fails to match the aggregate approximate posterior, which prevents generative sampling of structures especially for multi-modal distributions (e.g. compositional heterogeneity). Here, we train a diffusion model as an expressive, learnable prior in the cryoDRGN framework. Our approach learns a high-quality generative model over molecular conformations directly from cryo-EM imaging data. We show the ability to sample from the model on two synthetic and two real datasets, where samples accurately follow the data distribution unlike samples from the VAE prior distribution. We also demonstrate how the diffusion model prior can be leveraged for fast latent space traversal and interpolation between states of interest. By learning an accurate model of the data distribution, our method unlocks tools in generative modeling, sampling, and distribution analysis for heterogeneous cryo-EM ensembles.         _ Less","","arXiv","https://arxiv.org/abs/2211.14169","1","0","origin_of_life"
"A small-correlation expansion to quantify information in noisy sensory systems","Abstract:                _population of neurons, yielding interpretable analytical expressions in terms of the neurons' firing rates and pairwise correlations. We validate the approximation on synthetic data and demonstrate its applicability to electrophysiological recordings in the vertebrate retina, allowing us to quantify the effects of noise correlations between neurons and o_         _ More           Neural networks encode information through their collective spiking activity in response to external stimuli. This population response is noisy and strongly correlated, with complex interplay between correlations induced by the stimulus, and correlations caused by shared noise. Understanding how these correlations affect information transmission has so far been limited to pairs or small groups of neurons, because the curse of dimensionality impedes the evaluation of mutual information in larger populations. Here we develop a small-correlation expansion to compute the stimulus information carried by a large population of neurons, yielding interpretable analytical expressions in terms of the neurons' firing rates and pairwise correlations. We validate the approximation on synthetic data and demonstrate its applicability to electrophysiological recordings in the vertebrate retina, allowing us to quantify the effects of noise correlations between neurons and of memory in single neurons.         _ Less","","arXiv","https://arxiv.org/abs/2211.13712","1","0","origin_of_life"
"Nonlocal Mechanistic Models in Ecology: Numerical Methods and Parameter Inferencing","Abstract:                _densities. Finally, we propose a method using maximum likelihood estimation to determine the most important factors driving species' movements and test this method using synthetic data.         _ More           Animals use various processes to inform themselves about their environment and make decisions about how to move and form their territory. In some cases, populations inform themselves of competing groups through observations at distances, scent markings, or memories of locations where an individual has encountered competing populations. As the process of gathering this information is inherently nonlocal, mechanistic models that include nonlocal terms have been proposed to investigate the movement of species. Naturally, these models present analytical and computational challenges. In this work we study a multi-species model with nonlocal advection. We introduce an efficient numerical scheme using spectral methods to compute solutions of a nonlocal reaction-advection-diffusion system for a large number of interacting species. Moreover, we investigate the effects that the parameters and interaction potentials have on the population densities. Finally, we propose a method using maximum likelihood estimation to determine the most important factors driving species' movements and test this method using synthetic data.         _ Less","","arXiv","https://arxiv.org/abs/2211.08503","1","0","origin_of_life"
"Exploring the Impact of Noise and Degradations on Heart Sound Classification Models","Abstract:                _different noise and degradations in heart sound signals impact the accuracy of data-driven classification models remains unexplored. To answer this question, we produced a synthetic heart sound dataset including normal and abnormal heart sounds contaminated with a large variety of noise and degradations. We used this dataset to investigate the impact of nois_         _ More           The development of data-driven heart sound classification models has been an active area of research in recent years. To develop such data-driven models in the first place, heart sound signals need to be captured using a signal acquisition device. However, it is almost impossible to capture noise-free heart sound signals due to the presence of internal and external noises in most situations. Such noises and degradations in heart sound signals can potentially reduce the accuracy of data-driven classification models. Although different techniques have been proposed in the literature to address the noise issue, how and to what extent different noise and degradations in heart sound signals impact the accuracy of data-driven classification models remains unexplored. To answer this question, we produced a synthetic heart sound dataset including normal and abnormal heart sounds contaminated with a large variety of noise and degradations. We used this dataset to investigate the impact of noise and degradation in heart sound recordings on the performance of different classification models. The results show different noises and degradations affect the performance of heart sound classification models to a different extent; some are more problematic for classification models, and others are less destructive. Comparing the findings of this study with the results of a survey we previously carried out with a group of clinicians shows noise and degradations that are more detrimental to classification models are also more disruptive to accurate auscultation. The findings of this study can be leveraged to develop targeted heart sound quality enhancement approaches - which adapt the type and aggressiveness of quality enhancement based on the characteristics of noise and degradation in heart sound signals.         _ Less","","arXiv","https://arxiv.org/abs/2211.07445","1","1","multiple"
"Generalization of generative model for neuronal ensemble inference method","Abstract:                _perform soft clustering and apply the method to non-stationary neuroactivity data. In addition, for the effectiveness of the method, we apply the developed method to multiple synthetic fluorescence data generated from the electrical potential data in leaky integrated-and-fire model.         _ More           Various brain functions that are necessary to maintain life activities materialize through the interaction of countless neurons. Therefore, it is important to analyze functional neuronal network. To elucidate the mechanism of brain function, many studies are being actively conducted on functional neuronal ensemble and hub, including all areas of neuroscience. In addition, recent study suggests that the existence of functional neuronal ensembles and hubs contributes to the efficiency of information processing. For these reasons, there is a demand for methods to infer functional neuronal ensembles from neuronal activity data, and methods based on Bayesian inference have been proposed. However, there is a problem in modeling the activity in Bayesian inference. The features of each neuron's activity have non-stationarity depending on physiological experimental conditions. As a result, the assumption of stationarity in Bayesian inference model impedes inference, which leads to destabilization of inference results and degradation of inference accuracy. In this study, we extend the range of the variable for expressing the neuronal state, and generalize the likelihood of the model for extended variables. By comparing with the previous study, our model can express the neuronal state in larger space. This generalization without restriction of the binary input enables us to perform soft clustering and apply the method to non-stationary neuroactivity data. In addition, for the effectiveness of the method, we apply the developed method to multiple synthetic fluorescence data generated from the electrical potential data in leaky integrated-and-fire model.         _ Less","","arXiv","https://arxiv.org/abs/2211.05634","1","1","multiple"
"A Universal Method for Analysing Copolymer Growth","Abstract:                Polymers consisting of more than one type of monomer, known as copolymers, are vital to both living and synthetic systems. Copolymerisation has been studied theoretically in a number of contexts, often by considering a Markov process in which monomers are added or removed from the growing tip of a long copolymer. To date, the analysis of the most general mod_         _ More           Polymers consisting of more than one type of monomer, known as copolymers, are vital to both living and synthetic systems. Copolymerisation has been studied theoretically in a number of contexts, often by considering a Markov process in which monomers are added or removed from the growing tip of a long copolymer. To date, the analysis of the most general models of this class has necessitated simulation. We present a general method for analysing such processes without resorting to simulation. Our method can be applied to models with an arbitrary network of sub-steps prior to addition or removal of a monomer, including non-equilibrium kinetic proofreading cycles. Moreover, the approach allows for a dependency of addition and removal reactions on the neighbouring site in the copolymer, and thermodynamically self-consistent models in which all steps are assumed to be microscopically reversible. Using our approach, thermodynamic quantities such as chemical work; kinetic quantities such as time taken to grow; and statistical quantities such as the distribution of monomer types in the growing copolymer can be derived either analytically or numerically directly from the model definition.         _ Less","","arXiv","https://arxiv.org/abs/2211.02498","0","1","synthetic_biology"
"Closing the Loop on Morphogenesis: A Mathematical Model of Morphogenesis by Closed-Loop Reaction-Diffusion","Abstract:                _of morphological computation, which can be used to understand evolved developmental mechanisms, manipulate them in regenerative medicine settings, or embed a degree of synthetic intelligence into novel bioengineered constructs.         _ More           Morphogenesis, the establishment and repair of emergent complex anatomy by groups of cells, is a fascinating and biomedically-relevant problem. One of its most fascinating aspects is that a developing embryo can reliably recover from disturbances, such as splitting into twins. While this reliability implies some type of goal-seeking error minimization over a morphogenic field, there are many gaps with respect to detailed, constructive models of such a process being used to implement the collective intelligence of cellular swarms. We describe a closed-loop negative-feedback system for creating reaction-diffusion (RD) patterns with high reliability. It uses a cellular automaton to characterize a morphogen pattern, then compares it to a goal and adjusts accordingly, providing a framework for modeling anatomical homeostasis and robust generation of target morphologies. Specifically, we create a RD pattern with N repetitions, where N is easily changeable. Furthermore, the individual repetitions of the RD pattern can be easily stretched or shrunk under genetic control to create, e.g., some morphological features larger than others. Finally, the cellular automaton uses a computation wave that scans the morphogen pattern unidirectionally to characterize the features that the negative feedback then controls. By taking advantage of a prior process asymmetrically establishing planar polarity (e.g., head vs. tail), our automaton is greatly simplified. This work contributes to the exciting effort of understanding design principles of morphological computation, which can be used to understand evolved developmental mechanisms, manipulate them in regenerative medicine settings, or embed a degree of synthetic intelligence into novel bioengineered constructs.         _ Less","","arXiv","https://arxiv.org/abs/2211.01313","0","1","synthetic_biology"
"Perspectives for self-driving labs in synthetic biology","Abstract:                _world is probed, interpreted, and explained by machines for human benefit. While there are functioning SDLs in the fields of chemistry and materials science, we contend that synthetic_         _ More           Self-driving labs (SDLs) combine fully automated experiments with artificial intelligence (AI) that decides the next set of experiments. Taken to their ultimate expression, SDLs could usher a new paradigm of scientific research, where the world is probed, interpreted, and explained by machines for human benefit. While there are functioning SDLs in the fields of chemistry and materials science, we contend that synthetic biology provides a unique opportunity since the genome provides a single target for affecting the incredibly wide repertoire of biological cell behavior. However, the level of investment required for the creation of biological SDLs is only warranted if directed towards solving difficult and enabling biological questions. Here, we discuss challenges and opportunities in creating SDLs for synthetic biology.         _ Less","","arXiv","https://arxiv.org/abs/2210.09085","0","1","synthetic_biology"
"Hypergraphs for multiscale cycles in structured data","Abstract:                _validate its robustness to noise. We demonstrate the power of computing higher-order topological structures on spatial curves arising frequently in ecology, biophysics, and biology, but also in high-dimensional financial datasets. We find that hyperTDA can select between synthetic trajectories from the landmark 2020 An_         _ More           Scientific data has been growing in both size and complexity across the modern physical, engineering, life and social sciences. Spatial structure, for example, is a hallmark of many of the most important real-world complex systems, but its analysis is fraught with statistical challenges. Topological data analysis can provide a powerful computational window on complex systems. Here we present a framework to extend and interpret persistent homology summaries to analyse spatial data across multiple scales. We introduce hyperTDA, a topological pipeline that unifies local (e.g. geodesic) and global (e.g. Euclidean) metrics without losing spatial information, even in the presence of noise. Homology generators offer an elegant and flexible description of spatial structures and can capture the information computed by persistent homology in an interpretable way. Here the information computed by persistent homology is transformed into a weighted hypergraph, where hyperedges correspond to homology generators. We consider different choices of generators (e.g. matroid or minimal) and find that centrality and community detection are robust to either choice. We compare hyperTDA to existing geometric measures and validate its robustness to noise. We demonstrate the power of computing higher-order topological structures on spatial curves arising frequently in ecology, biophysics, and biology, but also in high-dimensional financial datasets. We find that hyperTDA can select between synthetic trajectories from the landmark 2020 AnDi challenge and quantifies movements of different animal species, even when data is limited.         _ Less","","arXiv","https://arxiv.org/abs/2210.07545","1","0","origin_of_life"
"MechRetro is a chemical-mechanism-driven graph learning framework for interpretable retrosynthesis prediction and pathway planning","Abstract:                _for retrosynthetic prediction with a large margin on large-scale benchmark datasets. Extending MechRetro to the multi-step retrosynthesis analysis, we identify efficient synthetic routes via an interpretable reasoning mechanism, leading to a better understanding in the realm of knowledgeable synthetic chemists. We also_         _ More           Leveraging artificial intelligence for automatic retrosynthesis speeds up organic pathway planning in digital laboratories. However, existing deep learning approaches are unexplainable, like 'black box' with few insights, notably limiting their applications in real retrosynthesis scenarios. Here, we propose MechRetro, a chemical-mechanism-driven graph learning framework for interpretable retrosynthetic prediction and pathway planning, which learns several retrosynthetic actions to simulate a reverse reaction via elaborate self-adaptive joint learning. By integrating chemical knowledge as prior information, we design a novel Graph Transformer architecture to adaptively learn discriminative and chemically meaningful molecule representations, highlighting the strong capacity in molecule feature representation learning. We demonstrate that MechRetro outperforms the state-of-the-art approaches for retrosynthetic prediction with a large margin on large-scale benchmark datasets. Extending MechRetro to the multi-step retrosynthesis analysis, we identify efficient synthetic routes via an interpretable reasoning mechanism, leading to a better understanding in the realm of knowledgeable synthetic chemists. We also showcase that MechRetro discovers a novel pathway for protokylol, along with energy scores for uncertainty assessment, broadening the applicability for practical scenarios. Overall, we expect MechRetro to provide meaningful insights for high-throughput automated organic synthesis in drug discovery.         _ Less","","arXiv","https://arxiv.org/abs/2210.02630","1","0","origin_of_life"
"FusionRetro: Molecule Representation Fusion via In-Context Learning for Retrosynthetic Planning","Abstract:                Retrosynthetic planning aims to devise a complete multi-step synthetic route from starting materials to a target molecule. Current strategies use a decoupled approach of single-step retrosynthesis models and search algorithms, taking only the product as the input to predict the reactants for each planning step and ignoring valuable context information along_         _ More           Retrosynthetic planning aims to devise a complete multi-step synthetic route from starting materials to a target molecule. Current strategies use a decoupled approach of single-step retrosynthesis models and search algorithms, taking only the product as the input to predict the reactants for each planning step and ignoring valuable context information along the synthetic route. In this work, we propose a novel framework that utilizes context information for improved retrosynthetic planning. We view synthetic routes as reaction graphs and propose to incorporate context through three principled steps: encode molecules into embeddings, aggregate information over routes, and readout to predict reactants. Our approach is the first attempt to utilize in-context learning for retrosynthesis prediction in retrosynthetic planning. The entire framework can be efficiently optimized in an end-to-end fashion and produce more practical and accurate predictions. Comprehensive experiments demonstrate that by fusing in the context information over routes, our model significantly improves the performance of retrosynthetic planning over baselines that are not context-aware, especially for long synthetic routes. Code is available at https://github.com/SongtaoLiu0823/FusionRetro.         _ Less","","arXiv","https://arxiv.org/abs/2209.15315","2","1","origin_of_life"
"Heterogeneous reconstruction of deformable atomic models in Cryo-EM","Abstract:                _center of the molecule . The physics-based decoder aggregates a representation of the heterogeneity readily interpretable at the atomic level. We illustrate our method on 3 synthetic datasets corresponding to different distributions along a simulated trajectory of adenylate kinase transitioning from its open to its closed structures. We show for each distrib_         _ More           Cryogenic electron microscopy (cryo-EM) provides a unique opportunity to study the structural heterogeneity of biomolecules. Being able to explain this heterogeneity with atomic models would help our understanding of their functional mechanisms but the size and ruggedness of the structural space (the space of atomic 3D cartesian coordinates) presents an immense challenge. Here, we describe a heterogeneous reconstruction method based on an atomistic representation whose deformation is reduced to a handful of collective motions through normal mode analysis. Our implementation uses an autoencoder. The encoder jointly estimates the amplitude of motion along the normal modes and the 2D shift between the center of the image and the center of the molecule . The physics-based decoder aggregates a representation of the heterogeneity readily interpretable at the atomic level. We illustrate our method on 3 synthetic datasets corresponding to different distributions along a simulated trajectory of adenylate kinase transitioning from its open to its closed structures. We show for each distribution that our approach is able to recapitulate the intermediate atomic models with atomic-level accuracy.         _ Less","","arXiv","https://arxiv.org/abs/2209.15121","1","0","origin_of_life"
"Noise in Biomolecular Systems: Modeling, Analysis, and Control Implications","Abstract:                _of a species or implement certain functions that would have been difficult or even impossible otherwise. In this article, we review the role and impact of noise in systems and synthetic_         _ More           While noise is generally associated with uncertainties and often has a negative connotation in engineering, living organisms have evolved to adapt to (and even exploit) such uncertainty to ensure the survival of a species or implement certain functions that would have been difficult or even impossible otherwise. In this article, we review the role and impact of noise in systems and synthetic biology, with a particular emphasis on its role in the genetic control of biological systems, an area we refer to as Cybergenetics. The main modeling paradigm is that of stochastic reaction networks, whose applicability goes beyond biology, as these networks can represent any population dynamics system, including ecological, epidemiological, and opinion dynamics networks. We review different ways to mathematically represent these systems, and we notably argue that the concept of ergodicity presents a particularly suitable way to characterize their stability. We then discuss noise-induced properties and show that noise can be both an asset and a nuisance in this setting. Finally, we discuss recent results on (stochastic) Cybergenetics and explore their relationships to noise. Along the way, we detail the different technical and biological constraints that need to be respected when designing synthetic biological circuits. Finally, we discuss the concepts, problems, and solutions exposed in the article; raise criticisms and concerns about current ideas and approaches; suggest current (open) problems with potential solutions; and provide some ideas for future research directions.         _ Less","","arXiv","https://arxiv.org/abs/2209.13901","1","3","synthetic_biology"
"Resource competition in Three-gene-motif & Emergence of Feed-forward response: A Spatiotemporal Study","Abstract:                _characteristic pattern formation under a concentration gradient of input signals have also been observed. This study pinpoints a larger area of research and exploration in synthetic and cellular systems, which will reveal novel controlling ideas and unique behavioral changes in the system for its context dependencies.         _ More           Feed-forward dynamics, which is well-known to have several important implications in nonlinear dynamical systems, frequently occurs in gene expression motifs, and has been well explored experimentally and mathematically. However, dependency of the components of a genetic circuit upon its host, due to the requirement for resources like ribosome, ATP, transcription factors, tRNA, etc., and related effects are of utmost importance, which is commonly ignored in mathematical models. In a resource-limited environment, two apparently unconnected genes can compete for resources for their respective expression and may exhibit indirect regulatory connection; an emergent response thus arises in the system completely because of resource competition. In this work, we have shown how the responses of the feed-forward loop (FFL), a well-studied regulatory genetic motif, can be recreated considering the resource competition in a three-gene pathway. Exploring the genetic system with temporal as well as spatiotemporal stability analysis, interesting transient and steady-state responses have been observed. The genetic motifs explored in this paper show many of the characteristic features of the conventional FFL structure, like response delay and pulse generation. Most interestingly, in a two-dimensional cellular arrangement, characteristic pattern formation under a concentration gradient of input signals have also been observed. This study pinpoints a larger area of research and exploration in synthetic and cellular systems, which will reveal novel controlling ideas and unique behavioral changes in the system for its context dependencies.         _ Less","","arXiv","https://arxiv.org/abs/2209.13886","2","0","origin_of_life"
"Impact of phylogeny on structural contact inference from protein sequence data","Abstract:                _share a common ancestry, their sequences also feature phylogenetic correlations, which can impair contact inference. We investigate this effect by generating controlled synthetic data from a minimal model where the importance of contacts and of phylogeny can be tuned. We demonstrate that global inference methods, specifically Potts models, are more resilient_         _ More           Local and global inference methods have been developed to infer structural contacts from multiple sequence alignments of homologous proteins. They rely on correlations in amino-acid usage at contacting sites. Because homologous proteins share a common ancestry, their sequences also feature phylogenetic correlations, which can impair contact inference. We investigate this effect by generating controlled synthetic data from a minimal model where the importance of contacts and of phylogeny can be tuned. We demonstrate that global inference methods, specifically Potts models, are more resilient to phylogenetic correlations than local methods, based on covariance or mutual information. This holds whether or not phylogenetic corrections are used, and may explain the success of global methods. We analyse the roles of selection strength and of phylogenetic relatedness. We show that sites that mutate early in the phylogeny yield false positive contacts. We consider natural data and realistic synthetic data, and our findings generalise to these cases. Our results highlight the impact of phylogeny on contact prediction from protein sequences and illustrate the interplay between the rich structure of biological data and inference.         _ Less","","arXiv","https://arxiv.org/abs/2209.13045","1","0","origin_of_life"
"Simulation-based inference of single-molecule force spectroscopy","Abstract:                _Bayesian posterior, and extract reduced quantitative models from smFS, by encoding a mechanistic model into a simulator in combination with probabilistic deep learning. Using synthetic data, we could systematically disentangle the measurement of hidden molecular properties from experimental artifacts. The integration of physical models with machine learning_         _ More           Single-molecule force spectroscopy (smFS) is a powerful approach to studying molecular self-organization. However, the coupling of the molecule with the ever-present experimental device introduces artifacts, that complicates the interpretation of these experiments. Performing statistical inference to learn hidden molecular properties is challenging because these measurements produce non-Markovian time-series, and even minimal models lead to intractable likelihoods. To overcome these challenges, we developed a computational framework built on novel statistical methods called simulation-based inference (SBI). SBI enabled us to directly estimate the Bayesian posterior, and extract reduced quantitative models from smFS, by encoding a mechanistic model into a simulator in combination with probabilistic deep learning. Using synthetic data, we could systematically disentangle the measurement of hidden molecular properties from experimental artifacts. The integration of physical models with machine learning density estimation is general, transparent, easy to use, and broadly applicable to other types of biophysical experiments.         _ Less","","arXiv","https://arxiv.org/abs/2209.10392","0","1","synthetic_biology"
"Designing experimental conditions to use the Lotka-Volterra model to infer tumor cell line interaction types","Abstract:                The Lotka-Volterra model is widely used to model interactions between two species. Here, we generate synthetic data mimicking competitive, mutualistic and antagonistic interactions between two tumor cell lines, and then use the Lotka-Volterra model to infer the interaction type. Structural identifiability of the Lotka-Volterra model is confirmed, and practic_         _ More           The Lotka-Volterra model is widely used to model interactions between two species. Here, we generate synthetic data mimicking competitive, mutualistic and antagonistic interactions between two tumor cell lines, and then use the Lotka-Volterra model to infer the interaction type. Structural identifiability of the Lotka-Volterra model is confirmed, and practical identifiability is assessed for three experimental designs: (a) use of a single data set, with a mixture of both cell lines observed over time, (b) a sequential design where growth rates and carrying capacities are estimated using data from experiments in which each cell line is grown in isolation, and then interaction parameters are estimated from an experiment involving a mixture of both cell lines, and (c) a parallel experimental design where all model parameters are fitted to data from two mixtures simultaneously. In addition to assessing each design for practical identifiability, we investigate how the predictive power of the model-i.e., its ability to fit data for initial ratios other than those to which it was calibrated-is affected by the choice of experimental design. The parallel calibration procedure is found to be optimal and is further tested on in silico data generated from a spatially-resolved cellular automaton model, which accounts for oxygen consumption and allows for variation in the intensity level of the interaction between the two cell lines. We use this study to highlight the care that must be taken when interpreting parameter estimates for the spatially-averaged Lotka-Volterra model when it is calibrated against data produced by the spatially-resolved cellular automaton model, since baseline competition for space and resources in the CA model may contribute to a discrepancy between the type of interaction used to generate the CA data and the type of interaction inferred by the LV model.         _ Less","","arXiv","https://arxiv.org/abs/2209.08402","0","1","synthetic_biology"
"Deep Speech Synthesis from Articulatory Representations","Abstract:                _system. To help bridge this gap, we propose a time-domain articulatory synthesis methodology and demonstrate its efficacy with both electromagnetic articulography (EMA) and synthetic articulatory feature inputs. Our model is computationally efficient and achieves a transcription word error rate (WER) of 18.5% for the EMA-to-speech task, yielding an improveme_         _ More           In the articulatory synthesis task, speech is synthesized from input features containing information about the physical behavior of the human vocal tract. This task provides a promising direction for speech synthesis research, as the articulatory space is compact, smooth, and interpretable. Current works have highlighted the potential for deep learning models to perform articulatory synthesis. However, it remains unclear whether these models can achieve the efficiency and fidelity of the human speech production system. To help bridge this gap, we propose a time-domain articulatory synthesis methodology and demonstrate its efficacy with both electromagnetic articulography (EMA) and synthetic articulatory feature inputs. Our model is computationally efficient and achieves a transcription word error rate (WER) of 18.5% for the EMA-to-speech task, yielding an improvement of 11.6% compared to prior work. Through interpolation experiments, we also highlight the generalizability and interpretability of our approach.         _ Less","","arXiv","https://arxiv.org/abs/2209.06337","1","0","origin_of_life"
"Spectral decomposition of atomic structures in heterogeneous cryo-EM","Abstract:                _by means of a well-known technique in manifold learning, based on the construction of a graph Laplacian using the cryo-EM dataset. Finally, we test our approach with synthetic datasets, for which we recover the atomic model of two-dimensional and three-dimensional flexible structures from noisy tomographic projections.         _ More           We consider the problem of recovering the three-dimensional atomic structure of a flexible macromolecule from a heterogeneous cryo-EM dataset. The dataset contains noisy tomographic projections of the electrostatic potential of the macromolecule, taken from different viewing directions, and in the heterogeneous case, each image corresponds to a different conformation of the macromolecule. Under the assumption that the macromolecule can be modelled as a chain, or discrete curve (as it is for instance the case for a protein backbone with a single chain of amino-acids), we introduce a method to estimate the deformation of the atomic model with respect to a given conformation, which is assumed to be known a priori. Our method consists on estimating the torsion and bond angles of the atomic model in each conformation as a linear combination of the eigenfunctions of the Laplace operator in the manifold of conformations. These eigenfunctions can be approximated by means of a well-known technique in manifold learning, based on the construction of a graph Laplacian using the cryo-EM dataset. Finally, we test our approach with synthetic datasets, for which we recover the atomic model of two-dimensional and three-dimensional flexible structures from noisy tomographic projections.         _ Less","","arXiv","https://arxiv.org/abs/2209.05546","1","0","origin_of_life"
"How Do AI Timelines Affect Existential Risk?","Abstract:                _However, since ASI could reduce most risks, delaying the creation of ASI could also increase other existential risks, especially from advanced future technologies such as synthetic biology and molecular nanotechnology.   If AI existential risk is high relative to the sum of other existential risk, delaying the creat_         _ More           Superhuman artificial general intelligence could be created this century and would likely be a significant source of existential risk. Delaying the creation of superintelligent AI (ASI) could decrease total existential risk by increasing the amount of time humanity has to work on the AI alignment problem.   However, since ASI could reduce most risks, delaying the creation of ASI could also increase other existential risks, especially from advanced future technologies such as synthetic biology and molecular nanotechnology.   If AI existential risk is high relative to the sum of other existential risk, delaying the creation of ASI will tend to decrease total existential risk and vice-versa.   Other factors such as war and a hardware overhang could increase AI risk and cognitive enhancement could decrease AI risk. To reduce total existential risk, humanity should take robustly positive actions such as working on existential risk analysis, AI governance and safety, and reducing all sources of existential risk by promoting differential technological development.         _ Less","","arXiv","https://arxiv.org/abs/2209.05459","0","1","synthetic_biology"
"Design of universal chemical relaxation oscillator to control molecular computation","Abstract:                Embedding efficient command operation into biochemical system has always been a research focus in synthetic biology. One of the key problems is how to sequence the chemical reactions that act as units of computation. The answer is to design chemical oscillator, a component that acts as a clock signal to turn correspond_         _ More           Embedding efficient command operation into biochemical system has always been a research focus in synthetic biology. One of the key problems is how to sequence the chemical reactions that act as units of computation. The answer is to design chemical oscillator, a component that acts as a clock signal to turn corresponding reaction on or off. Some previous work mentioned the use of chemical oscillations. However, the models used either lack a systematic analysis of the mechanism and properties of oscillation, or are too complex to be tackled with in practice. Our work summarizes the universal process for designing chemical oscillators, including generating robust oscillatory species, constructing clock signals from these species, and setting up termination component to eventually end the loop of whole reaction modules. We analyze the dynamic properties of the proposed oscillator model in the context of ordinary differential equations, and discuss how to determine parameters for the effect we want in detail. Our model corresponds to abstract chemical reactions based on mass-action kinetics which are expected to be implemented into chemistry with the help of DNA strand displacement cascades. Our consideration of ordering chemical reaction modules helps advance the embedding of more complex calculations into biochemical environments.         _ Less","","arXiv","https://arxiv.org/abs/2209.03033","0","1","synthetic_biology"
"Time-distance vision transformers in lung cancer diagnosis from longitudinal computed tomography","Abstract:                _time and (2) a temporal emphasis model to scale self-attention weights. The two algorithms are evaluated based on benign versus malignant lung cancer discrimination of synthetic pulmonary nodules and lung screening computed tomography studies from the National Lung Screening Trial (NLST). Experiments evaluating the time-distance ViTs on_         _ More           Features learned from single radiologic images are unable to provide information about whether and how much a lesion may be changing over time. Time-dependent features computed from repeated images can capture those changes and help identify malignant lesions by their temporal behavior. However, longitudinal medical imaging presents the unique challenge of sparse, irregular time intervals in data acquisition. While self-attention has been shown to be a versatile and efficient learning mechanism for time series and natural images, its potential for interpreting temporal distance between sparse, irregularly sampled spatial features has not been explored. In this work, we propose two interpretations of a time-distance vision transformer (ViT) by using (1) vector embeddings of continuous time and (2) a temporal emphasis model to scale self-attention weights. The two algorithms are evaluated based on benign versus malignant lung cancer discrimination of synthetic pulmonary nodules and lung screening computed tomography studies from the National Lung Screening Trial (NLST). Experiments evaluating the time-distance ViTs on synthetic nodules show a fundamental improvement in classifying irregularly sampled longitudinal images when compared to standard ViTs. In cross-validation on screening chest CTs from the NLST, our methods (0.785 and 0.786 AUC respectively) significantly outperform a cross-sectional approach (0.734 AUC) and match the discriminative performance of the leading longitudinal medical imaging algorithm (0.779 AUC) on benign versus malignant classification. This work represents the first self-attention-based framework for classifying longitudinal medical images. Our code is available at https://github.com/tom1193/time-distance-transformer.         _ Less","","arXiv","https://arxiv.org/abs/2209.01676","1","0","origin_of_life"
"StreamNet: A WAE for White Matter Streamline Analysis","Abstract:                _not only accurately captures the distributive structures of streamlines in the population, but is also able to achieve superior reconstruction performance between real and synthetic streamlines. Experimental model performance is evaluated on white matter streamlines resulting from T1-weighted diffusion imaging of 40 healthy controls using recent state of the_         _ More           We present StreamNet, an autoencoder architecture for the analysis of the highly heterogeneous geometry of large collections of white matter streamlines. This proposed framework takes advantage of geometry-preserving properties of the Wasserstein-1 metric in order to achieve direct encoding and reconstruction of entire bundles of streamlines. We show that the model not only accurately captures the distributive structures of streamlines in the population, but is also able to achieve superior reconstruction performance between real and synthetic streamlines. Experimental model performance is evaluated on white matter streamlines resulting from T1-weighted diffusion imaging of 40 healthy controls using recent state of the art bundle comparison metric that measures fiber-shape similarities.         _ Less","","arXiv","https://arxiv.org/abs/2209.01498","1","1","multiple"
"Single-Molecule Structure and Topology of Kinetoplast DNA Networks","Abstract:                _kb-long DNA minicircles found in certain parasites called Trypanosomes. Understanding the self-assembly and replication of this structure are not only major open questions in biology but can also inform the design of synthetic topological materials. Here we report the first high-resolution, single-molecule study of kDN_         _ More           The Kinetoplast DNA (kDNA) is a two-dimensional Olympic-ring-like network of mutually linked 2.5 kb-long DNA minicircles found in certain parasites called Trypanosomes. Understanding the self-assembly and replication of this structure are not only major open questions in biology but can also inform the design of synthetic topological materials. Here we report the first high-resolution, single-molecule study of kDNA network topology using AFM and steered molecular dynamics simulations. We map out the DNA density within the network and the distribution of linking number and valence of the minicircles. We also characterise the DNA hubs that surround the network and show that they cause a buckling transition akin to that of a 2D elastic thermal sheet in the bulk. Intriguingly, we observe a broad distribution of density and valence of the minicircles, indicating heterogeneous network structure and individualism of different kDNA structures. Our findings explain outstanding questions in the field and offer single-molecule insights into the properties of a unique topological material.         _ Less","","arXiv","https://arxiv.org/abs/2209.01293","0","1","synthetic_biology"
"Inference of Mixed Graphical Models for Dichotomous Phenotypes using Markov Random Field Model","Abstract:                _to minimize the effect of sparseness in the networks. The fast proximal gradient method (PGM) was used to optimize the target function. Method validity was measured using synthetic datasets that simulate power-law network structures, and it was found that FMGM showed superior performance, especially in terms of F1 scores, compared with the previous method in_         _ More           In this article, we propose a new method named fused mixed graphical model (FMGM), which can infer network structures for dichotomous phenotypes. We assumed that the interplay of different omics markers is associated with disease status and proposed an FMGM-based method to detect the associated omics marker network difference. The statistical models of the networks were based on a pairwise Markov random field model, and penalty functions were added to minimize the effect of sparseness in the networks. The fast proximal gradient method (PGM) was used to optimize the target function. Method validity was measured using synthetic datasets that simulate power-law network structures, and it was found that FMGM showed superior performance, especially in terms of F1 scores, compared with the previous method inferring the networks sequentially (0.392 and 0.546). FMGM performed better not only in identifying the differences (0.217 and 0.410) but also in identifying the networks (0.492 and 0.572). The proposed method was applied to multi-omics profiles of 6-month-old infants with and without atopic dermatitis (AD), and different correlations were found between the abundance of microbial genes related to carotenoid biosynthesis and RNA degradation according to disease status, suggesting the importance of metabolism related to oxidative stress and microbial RNA balance.         _ Less","","arXiv","https://arxiv.org/abs/2208.14959","0","2","synthetic_biology"
"Causal Entropy Optimization","Abstract:                _optimizing the causal effect on a target variable of an unknown causal graph in which interventions can be performed. This problem arises in many areas of science including biology, operations research and healthcare. We propose Causal Entropy Optimization (CEO), a framework that generalizes Causal Bayesian Optimization (CBO) to account for all sources of un_         _ More           We study the problem of globally optimizing the causal effect on a target variable of an unknown causal graph in which interventions can be performed. This problem arises in many areas of science including biology, operations research and healthcare. We propose Causal Entropy Optimization (CEO), a framework that generalizes Causal Bayesian Optimization (CBO) to account for all sources of uncertainty, including the one arising from the causal graph structure. CEO incorporates the causal structure uncertainty both in the surrogate models for the causal effects and in the mechanism used to select interventions via an information-theoretic acquisition function. The resulting algorithm automatically trades-off structure learning and causal effect optimization, while naturally accounting for observation noise. For various synthetic and real-world structural causal models, CEO achieves faster convergence to the global optimum compared with CBO while also learning the graph. Furthermore, our joint approach to structure learning and causal optimization improves upon sequential, structure-learning-first approaches.         _ Less","","arXiv","https://arxiv.org/abs/2208.10981","1","0","origin_of_life"
"Synchronization Fronts in a Spatially Extended System of Hybrid Rayleigh-van der Pol Oscillators","Abstract:                _of model parameters and corroborate its validity via a numerical finite-difference method algorithm. Finally, we review our results in light of some experimental systems in synthetic biology based on a synchronised quorum of genetic clocks, coupled via a diffusive auto-inducer signalling molecule analogue to our Hooke-_         _ More           Numerous biological systems exhibit transitions to synchronised oscillations via a population-density-dependant mechanism known as quorum sensing. Here we propose a model system, based on spatially distributed limit-cycle oscillators, that allows us to capture the dynamics of synchronization fronts by taking the continuum limit as the number of coupled oscillators tends to infinity. We explore analytically a family of wavefront-type solutions to the system in terms of model parameters and corroborate its validity via a numerical finite-difference method algorithm. Finally, we review our results in light of some experimental systems in synthetic biology based on a synchronised quorum of genetic clocks, coupled via a diffusive auto-inducer signalling molecule analogue to our Hooke-like coupling scheme within the proposed hybrid Rayleigh-van der Pol model.         _ Less","","arXiv","https://arxiv.org/abs/2208.09119","1","2","synthetic_biology"
"Can a latent Hawkes process be used for epidemiological modelling?","Abstract:                _to the number of infections making it possible to use particle filter type algorithms, such as the KDPF. We demonstrate the performance of the proposed algorithm on synthetic data sets and COVID-19 reported cases in various local authorities in the UK, and benchmark our model to alternative approaches.         _ More           Understanding the spread of COVID-19 has been the subject of numerous studies, highlighting the significance of reliable epidemic models. Here, we introduce a novel epidemic model using a latent Hawkes process with temporal covariates for modelling the infections. Unlike other models, we model the reported cases via a probability distribution driven by the underlying Hawkes process. Modelling the infections via a Hawkes process allows us to estimate by whom an infected individual was infected. We propose a Kernel Density Particle Filter (KDPF) for inference of both latent cases and reproduction number and for predicting the new cases in the near future. The computational effort is proportional to the number of infections making it possible to use particle filter type algorithms, such as the KDPF. We demonstrate the performance of the proposed algorithm on synthetic data sets and COVID-19 reported cases in various local authorities in the UK, and benchmark our model to alternative approaches.         _ Less","","arXiv","https://arxiv.org/abs/2208.07340","0","1","synthetic_biology"
"Statistical-physics approaches to RNA molecules, families and networks","Abstract:                _and in particular the concept of a disordered (energy/fitness) landscape. After an introduction to RNA molecules and the perspectives they open not only in evolutionary and synthetic biology but also in medicine, we will introduce the important notions of energy and fitness landscapes for these molecules. In Section I_         _ More           This contribution focuses on the fascinating RNA molecule, its sequence-dependent folding driven by base-pairing interactions, the interplay between these interactions and natural evolution, and its multiple regulatory roles. The four of us have dug into these topics using the tools and the spirit of the statistical physics of disordered systems, and in particular the concept of a disordered (energy/fitness) landscape. After an introduction to RNA molecules and the perspectives they open not only in evolutionary and synthetic biology but also in medicine, we will introduce the important notions of energy and fitness landscapes for these molecules. In Section III we will review some models and algorithms for RNA sequence-to-secondary-structure mapping. Section IV discusses how the secondary-structure energy landscape can be derived from unzipping data. Section V deals with the inference of RNA structure from evolutionary sequence data sampled in different organisms. This will shift the focus from the `sequence-to-structure' mapping described in Section III to a `sequence-to-function' landscape that can be inferred from laboratory evolutionary data on DNA aptamers. Finally, in Section VI, we shall discuss the rich theoretical picture linking networks of interacting RNA molecules to the organization of robust, systemic regulatory programs. Along this path, we will therefore explore phenomena across multiple scales in space, number of molecules and time, showing how the biological complexity of the RNA world can be captured by the unifying concepts of statistical physics.         _ Less","","arXiv","https://arxiv.org/abs/2207.13402","2","3","synthetic_biology"
"Actomyosin-driven division of a synthetic cell","Abstract:                One of the major challenges of bottom-up synthetic_         _ More           One of the major challenges of bottom-up synthetic biology is rebuilding a minimal division machinery. The animal cell division apparatus is mechanically the simplest, in which an actin-based ring constricts the membrane, as compared to microbes and plant cells where a cell wall is involved. Furthermore, reconstitution of the actin division machinery helps to understand the physical and molecular mechanisms of cytokinesis in animal cells and thus our own cells. In this review, we describe the state-of-the-art research on reconstitution of minimal actin-mediated cytokinetic machineries. Based on the conceptual requirements that we obtained from the physics of the shape changes involved in cell division, we propose two major routes for building a minimal actin apparatus capable of division. Importantly, we acknowledge both the passive and active roles that the confining lipid membrane can play in synthetic cytokinesis. We conclude this chapter by identifying the most pressing challenges for future reconstitution work, thereby laying out a roadmap for building a synthetic cell equipped with a minimal actin division machinery.         _ Less","","arXiv","https://arxiv.org/abs/2207.06862","1","4","synthetic_biology"
"Developing an NLP-based Recommender System for the Ethical, Legal, and Social Implications of Synthetic Biology","Abstract:        Synthetic_         _ More   Synthetic biology is an emerging field that involves the engineering and re-design of organisms for purposes such as food security, health, and environmental protection. As such, it poses numerous ethical, legal, and social implications (ELSI) for researchers and policy makers. Various efforts to ensure socially responsible synthetic biology are underway. Policy making is one regulatory avenue, and other initiatives have sought to embed social scientists and ethicists on synthetic biology projects. However, given the nascency of synthetic biology, the number of heterogeneous domains it spans, and the open nature of many ethical questions, it has proven challenging to establish widespread concrete policies, and including social scientists and ethicists on synthetic biology teams has met with mixed success.   This text proposes a different approach, asking instead is it possible to develop a well-performing recommender model based upon natural language processing (NLP) to connect synthetic biologists with information on the ELSI of their specific research? This recommender was developed as part of a larger project building a Synthetic Biology Knowledge System (SBKS) to accelerate discovery and exploration of the synthetic biology design space. Our approach aims to distill for synthetic biologists relevant ethical and social scientific information and embed it into synthetic biology research workflows.         _ Less","","arXiv","https://arxiv.org/abs/2207.06360","1","1","multiple"
"Accurate RNA 3D structure prediction using a language model-based deep learning approach","Abstract:                _(3D) structure remains an unsolved challenge. Determining RNA 3D structures is crucial for understanding their functions and informing RNA-targeting drug development and synthetic biology design. The structural flexibility of RNA, which leads to scarcity of experimentally determined data, complicates computational pred_         _ More           Accurate prediction of RNA three-dimensional (3D) structure remains an unsolved challenge. Determining RNA 3D structures is crucial for understanding their functions and informing RNA-targeting drug development and synthetic biology design. The structural flexibility of RNA, which leads to scarcity of experimentally determined data, complicates computational prediction efforts. Here, we present RhoFold+, an RNA language model-based deep learning method that accurately predicts 3D structures of single-chain RNAs from sequences. By integrating an RNA language model pre-trained on ~23.7 million RNA sequences and leveraging techniques to address data scarcity, RhoFold+ offers a fully automated end-to-end pipeline for RNA 3D structure prediction. Retrospective evaluations on RNA-Puzzles and CASP15 natural RNA targets demonstrate RhoFold+'s superiority over existing methods, including human expert groups. Its efficacy and generalizability are further validated through cross-family and cross-type assessments, as well as time-censored benchmarks. Additionally, RhoFold+ predicts RNA secondary structures and inter-helical angles, providing empirically verifiable features that broaden its applicability to RNA structure and function studies.         _ Less","","arXiv","https://arxiv.org/abs/2207.01586","0","1","synthetic_biology"
"Biological Robots: Perspectives on an Emerging Interdisciplinary Field","Abstract:                _disciplines such that they better facilitate, not restrict, experimental approaches and capabilities. In this essay, we discuss issues at the intersection of developmental biology, computer science, and robotics. In the context of biological robots, we explore changes across concepts and previously distinct fields that are driven by recent advances in materi_         _ More           Advances in science and engineering often reveal the limitations of classical approaches initially used to understand, predict, and control phenomena. With progress, conceptual categories must often be re-evaluated to better track recently discovered invariants across disciplines. It is essential to refine frameworks and resolve conflicting boundaries between disciplines such that they better facilitate, not restrict, experimental approaches and capabilities. In this essay, we discuss issues at the intersection of developmental biology, computer science, and robotics. In the context of biological robots, we explore changes across concepts and previously distinct fields that are driven by recent advances in materials, information, and life sciences. Herein, each author provides their own perspective on the subject, framed by their own disciplinary training. We argue that as with computation, certain aspects of developmental biology and robotics are not tied to specific materials; rather, the consilience of these fields can help to shed light on issues of multi-scale control, self-assembly, and relationships between form and function. We hope new fields can emerge as boundaries arising from technological limitations are overcome, furthering practical applications from regenerative medicine to useful synthetic living machines.         _ Less","","arXiv","https://arxiv.org/abs/2207.00880","1","1","multiple"
"Functional Synthetic Biology","Abstract:        Synthetic biologists have made great progress over the past decade in developing methods for modular assembly of genetic sequences and in engineering biological systems with a wide variety of functions in various contexts and organisms. However, current paradigms in the field entangle sequence and functionality in a manner that makes abstraction difficult, r_         _ More   Synthetic biologists have made great progress over the past decade in developing methods for modular assembly of genetic sequences and in engineering biological systems with a wide variety of functions in various contexts and organisms. However, current paradigms in the field entangle sequence and functionality in a manner that makes abstraction difficult, reduces engineering flexibility, and impairs predictability and design reuse. Functional Synthetic Biology aims to overcome these impediments by focusing the design of biological systems on function, rather than on sequence. This reorientation will decouple the engineering of biological devices from the specifics of how those devices are put to use, requiring both conceptual and organizational change, as well as supporting software tooling. Realizing this vision of Functional Synthetic Biology will allow more flexibility in how devices are used, more opportunity for reuse of devices and data, improvements in predictability, and reductions in technical risk and cost.         _ Less","","arXiv","https://arxiv.org/abs/2207.00538","0","1","synthetic_biology"
"A Phylogenetic Model of the Evolution of Discrete Matrices for the Joint Inference of Lexical and Phonological Language Histories","Abstract:                _and infer jointly the phylogeny, model parameters, and latent variables representing cognate births and phonological transformations. We successfully apply this method to synthetic and real data of moderate size.         _ More           We propose a model of the evolution of a matrix along a phylogenetic tree, in which transformations affect either entire rows or columns of the matrix. This represents the change of both lexical and phonological aspects of linguistic data, by allowing for new words to appear and for systematic phonological changes to affect the entire vocabulary. We implement a Sequential Monte Carlo method to sample from the posterior distribution, and infer jointly the phylogeny, model parameters, and latent variables representing cognate births and phonological transformations. We successfully apply this method to synthetic and real data of moderate size.         _ Less","","arXiv","https://arxiv.org/abs/2206.12473","1","1","multiple"
"Statistical network isomorphism","Abstract:                _which there is no known polynomial-time solution. Nevertheless, assessing (dis)similarity between two or more networks is a key task in many areas, such as image recognition, biology, chemistry, computer and social networks. Moreover, questions of similarity are typically more general and their answers more widely applicable than the more restrictive isomorp_         _ More           Graph isomorphism is a problem for which there is no known polynomial-time solution. Nevertheless, assessing (dis)similarity between two or more networks is a key task in many areas, such as image recognition, biology, chemistry, computer and social networks. Moreover, questions of similarity are typically more general and their answers more widely applicable than the more restrictive isomorphism question. In this article, we offer a statistical answer to the following questions: a) {\\it ``Are networks $G_1$ and $G_2$ similar?''}, b) {\\it ``How different are the networks $G_1$ and $G_2$?''} and c) {\\it ``Is $G_3$ more similar to $G_1$ or $G_2$?''}. Our comparisons begin with the transformation of each graph into an all-pairs distance matrix. Our node-node distance, Jaccard distance, has been shown to offer a good reflection of the graph's connectivity structure. We then model these distances as probability distributions. Finally, we use well-established statistical tools to gauge the (dis)similarities in terms of probability distribution (dis)similarity. This comparison procedure aims to detect (dis)similarities in connectivity structure, not in easily observable graph characteristics, such as degrees, edge counts or density. We validate our hypothesis that graphs can be meaningfully summarized and compared via their node-node distance distributions, using several synthetic and real-world graphs. Empirical results demonstrate its validity and the accuracy of our comparison technique.         _ Less","","arXiv","https://arxiv.org/abs/2206.10074","1","0","origin_of_life"
"Sustained unidirectional rotation of a self-organized DNA rotor on a nanopore","Abstract:                _rotary motors drive functional processes in human society such as windmills and water wheels. Although examples of such rotary motors also feature prominently in cell biology, their synthetic construction at the nanoscale has thus far remained elusive. Here, we demonstrate flow-driven rotary motion of a self-organized_         _ More           Flow-driven rotary motors drive functional processes in human society such as windmills and water wheels. Although examples of such rotary motors also feature prominently in cell biology, their synthetic construction at the nanoscale has thus far remained elusive. Here, we demonstrate flow-driven rotary motion of a self-organized DNA nanostructure that is docked onto a nanopore in a thin solid-state membrane. An elastic DNA bundle self assembles into a chiral conformation upon phoretic docking onto the solid-state nanopore, and subsequently displays a sustained unidirectional rotary motion of up to 20 revolutions/s. The rotors harness energy from a nanoscale water and ion flow that is generated by a static (electro)chemical potential gradient in the nanopore that is established through a salt gradient or applied voltage. These artificial nanoengines self-organize and operate autonomously in physiological conditions, paving a new direction in constructing energy-transducing motors at nanoscale interfaces.         _ Less","","arXiv","https://arxiv.org/abs/2206.06613","1","1","multiple"
"Modeling membrane curvature generation using mechanics and machine learning","Abstract:                _selecting a set of mechanical parameters (including bending modulus and membrane tension) from a large set of reasonable values. We used the Helfrich model to generate a large synthetic dataset from a random sampling of realistic mechanical parameters and used this dataset to train machine learning models. These models produced promising results, accurately_         _ More           The deformation of cellular membranes regulates trafficking processes, such as exocytosis and endocytosis. Classically, the Helfrich continuum model is used to characterize the forces and mechanical parameters that cells tune to accomplish membrane shape changes. While this classical model effectively captures curvature generation, one of the core challenges in using it to approximate a biological process is selecting a set of mechanical parameters (including bending modulus and membrane tension) from a large set of reasonable values. We used the Helfrich model to generate a large synthetic dataset from a random sampling of realistic mechanical parameters and used this dataset to train machine learning models. These models produced promising results, accurately classifying model behavior and predicting membrane shape from mechanical parameters. We also note emerging methods in machine learning that can leverage the physical insight of the Helfrich model to improve performance and draw greater insight into how cells control membrane shape change.         _ Less","","arXiv","https://arxiv.org/abs/2206.05307","1","0","origin_of_life"
"Seq2Seq Model-Based Chatbot with LSTM and Attention Mechanism for Enhanced User Interaction","Abstract:                A chatbot is an intelligent software application that automates conversations and engages users in natural language through messaging platforms. Leveraging artificial intelligence (AI), chatbots serve various functions, including customer service, information gathering, and casual conversation. Existing virtual assistant chatbots, such as ChatGPT and Gemini,_         _ More           A chatbot is an intelligent software application that automates conversations and engages users in natural language through messaging platforms. Leveraging artificial intelligence (AI), chatbots serve various functions, including customer service, information gathering, and casual conversation. Existing virtual assistant chatbots, such as ChatGPT and Gemini, demonstrate the potential of AI in Natural Language Processing (NLP). However, many current solutions rely on predefined APIs, which can result in vendor lock-in and high costs. To address these challenges, this work proposes a chatbot developed using a Sequence-to-Sequence (Seq2Seq) model with an encoder-decoder architecture that incorporates attention mechanisms and Long Short-Term Memory (LSTM) cells. By avoiding predefined APIs, this approach ensures flexibility and cost-effectiveness. The chatbot is trained, validated, and tested on a dataset specifically curated for the tourism sector in Draa-Tafilalet, Morocco. Key evaluation findings indicate that the proposed Seq2Seq model-based chatbot achieved high accuracies: approximately 99.58% in training, 98.03% in validation, and 94.12% in testing. These results demonstrate the chatbot's effectiveness in providing relevant and coherent responses within the tourism domain, highlighting the potential of specialized AI applications to enhance user experience and satisfaction in niche markets.         _ Less","","arXiv","https://arxiv.org/abs/2501.00049","1","0","origin_of_life"
"Unified Local and Global Attention Interaction Modeling for Vision Transformers","Abstract:                _detection tasks and generalizes across multiple benchmark datasets and challenging medical datasets. We publish source code and a novel dataset of cancerous tumors (chimeric cell clusters).         _ More           We present a novel method that extends the self-attention mechanism of a vision transformer (ViT) for more accurate object detection across diverse datasets. ViTs show strong capability for image understanding tasks such as object detection, segmentation, and classification. This is due in part to their ability to leverage global information from interactions among visual tokens. However, the self-attention mechanism in ViTs are limited because they do not allow visual tokens to exchange local or global information with neighboring features before computing global attention. This is problematic because tokens are treated in isolation when attending (matching) to other tokens, and valuable spatial relationships are overlooked. This isolation is further compounded by dot-product similarity operations that make tokens from different semantic classes appear visually similar. To address these limitations, we introduce two modifications to the traditional self-attention framework; a novel aggressive convolution pooling strategy for local feature mixing, and a new conceptual attention transformation to facilitate interaction and feature exchange between semantic concepts. Experimental results demonstrate that local and global information exchange among visual features before self-attention significantly improves performance on challenging object detection tasks and generalizes across multiple benchmark datasets and challenging medical datasets. We publish source code and a novel dataset of cancerous tumors (chimeric cell clusters).         _ Less","","arXiv","https://arxiv.org/abs/2412.18778","1","0","origin_of_life"
"An AI-directed analytical study on the optical transmission microscopic images of Pseudomonas aeruginosa in planktonic and biofilm states","Abstract:                Biofilms are resistant microbial cell aggregates that pose risks to health and food industries and produce environmental contamination. Accurate and efficient detection and prevention of biofilms are challenging and demand interdisciplinary approaches. This multidisciplinary research reports the application of a deep learning-based_         _ More           Biofilms are resistant microbial cell aggregates that pose risks to health and food industries and produce environmental contamination. Accurate and efficient detection and prevention of biofilms are challenging and demand interdisciplinary approaches. This multidisciplinary research reports the application of a deep learning-based artificial intelligence (AI) model for detecting biofilms produced by Pseudomonas aeruginosa with high accuracy. Aptamer DNA templated silver nanocluster (Ag-NC) was used to prevent biofilm formation, which produced images of the planktonic states of the bacteria. Large-volume bright field images of bacterial biofilms were used to design the AI model. In particular, we used U-Net with ResNet encoder enhancement to segment biofilm images for AI analysis. Different degrees of biofilm structures can be efficiently detected using ResNet18 and ResNet34 backbones. The potential applications of this technique are also discussed.         _ Less","","arXiv","https://arxiv.org/abs/2412.18205","1","0","origin_of_life"
"scReader: Prompting Large Language Models to Interpret scRNA-seq Data","Abstract:                _in modeling the hidden relationships within text sequences. This innovation presents a unique opportunity in the field of life sciences, where vast collections of single-cell omics data from multiple species provide a foundation for training foundational models. However, the challenge lies in the disparity of data scales across different species, hindering t_         _ More           Large language models (LLMs) have demonstrated remarkable advancements, primarily due to their capabilities in modeling the hidden relationships within text sequences. This innovation presents a unique opportunity in the field of life sciences, where vast collections of single-cell omics data from multiple species provide a foundation for training foundational models. However, the challenge lies in the disparity of data scales across different species, hindering the development of a comprehensive model for interpreting genetic data across diverse organisms. In this study, we propose an innovative hybrid approach that integrates the general knowledge capabilities of LLMs with domain-specific representation models for single-cell omics data interpretation. We begin by focusing on genes as the fundamental unit of representation. Gene representations are initialized using functional descriptions, leveraging the strengths of mature language models such as LLaMA-2. By inputting single-cell gene-level expression data with prompts, we effectively model cellular representations based on the differential expression levels of genes across various species and cell types. In the experiments, we constructed developmental cells from humans and mice, specifically targeting cells that are challenging to annotate. We evaluated our methodology through basic tasks such as cell annotation and visualization analysis. The results demonstrate the efficacy of our approach compared to other methods using LLMs, highlighting significant improvements in accuracy and interoperability. Our hybrid approach enhances the representation of single-cell data and offers a robust framework for future research in cross-species genetic analysis.         _ Less","","arXiv","https://arxiv.org/abs/2412.18156","1","1","multiple"
"From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer","Abstract:                It is clinically crucial and potentially very beneficial to be able to analyze and model directly the spatial distributions of cells in histopathology whole slide images (WSI). However, most existing WSI datasets lack_         _ More           It is clinically crucial and potentially very beneficial to be able to analyze and model directly the spatial distributions of cells in histopathology whole slide images (WSI). However, most existing WSI datasets lack cell-level annotations, owing to the extremely high cost over giga-pixel images. Thus, it remains an open question whether deep learning models can directly and effectively analyze WSIs from the semantic aspect of cell distributions. In this work, we construct a large-scale WSI dataset with more than 5 billion cell-level annotations, termed WSI-Cell5B, and a novel hierarchical Cell Cloud Transformer (CCFormer) to tackle these challenges. WSI-Cell5B is based on 6,998 WSIs of 11 cancers from The Cancer Genome Atlas Program, and all WSIs are annotated per cell by coordinates and types. To the best of our knowledge, WSI-Cell5B is the first WSI-level large-scale dataset integrating cell-level annotations. On the other hand, CCFormer formulates the collection of cells in each WSI as a cell cloud and models cell spatial distribution. Specifically, Neighboring Information Embedding (NIE) is proposed to characterize the distribution of cells within the neighborhood of each cell, and a novel Hierarchical Spatial Perception (HSP) module is proposed to learn the spatial relationship among cells in a bottom-up manner. The clinical analysis indicates that WSI-Cell5B can be used to design clinical evaluation metrics based on counting cells that effectively assess the survival risk of patients. Extensive experiments on survival prediction and cancer staging show that learning from cell spatial distribution alone can already achieve state-of-the-art (SOTA) performance, i.e., CCFormer strongly outperforms other competing methods.         _ Less","","arXiv","https://arxiv.org/abs/2412.16715","1","1","multiple"
"Structural Cellular Hash Chemistry","Abstract:                Hash Chemistry, a minimalistic artificial chemistry model of open-ended evolution, has recently been extended to non-spatial and cellular versions. The non-spatial version successfully demonstrated continuous adaptation and unbounded growth of complexity of self-replicating entities, but it did not simulate multiscale ecological interactions among the entiti_         _ More           Hash Chemistry, a minimalistic artificial chemistry model of open-ended evolution, has recently been extended to non-spatial and cellular versions. The non-spatial version successfully demonstrated continuous adaptation and unbounded growth of complexity of self-replicating entities, but it did not simulate multiscale ecological interactions among the entities. On the contrary, the cellular version explicitly represented multiscale spatial ecological interactions among evolving patterns, yet it failed to show meaningful adaptive evolution or complexity growth. It remains an open question whether it is possible to create a similar minimalistic evolutionary system that can exhibit all of those desired properties at once within a computationally efficient framework. Here we propose an improved version called Structural Cellular Hash Chemistry (SCHC). In SCHC, individual identities of evolving patterns are explicitly represented and processed as the connected components of the nearest neighbor graph of active cells. The neighborhood connections are established by connecting active cells with other active cells in their Moore neighborhoods in a 2D cellular grid. Evolutionary dynamics in SCHC are simulated via pairwise competitions of two randomly selected patterns, following the approach used in the non-spatial Hash Chemistry. SCHC's computational cost was significantly less than the original and non-spatial versions. Numerical simulations showed that these model modifications achieved spontaneous movement, self-replication and unbounded growth of complexity of spatial evolving patterns, which were clearly visible in space in a highly intuitive manner. Detailed analysis of simulation results showed that there were spatial ecological interactions among self-replicating patterns and their diversity was also substantially promoted in SCHC, neither of which was present in the non-spatial version.         _ Less","","arXiv","https://arxiv.org/abs/2412.12790","0","5","synthetic_biology"
"TTVD: Towards a Geometric Framework for Test-Time Adaptation Based on Voronoi Diagram","Abstract:                _methods to provide richer information. 2) Power Diagram (PD): A generalized version of the Voronoi Diagram that refines partitions by assigning weights to each Voronoi cell. Our experiments under rigid, peer-reviewed settings on CIFAR-10-C, CIFAR-100-C, ImageNet-C, and ImageNet-R shows that TTVD achieves remarkable improvements compared to state-of-the-art m_         _ More           Deep learning models often struggle with generalization when deploying on real-world data, due to the common distributional shift to the training data. Test-time adaptation (TTA) is an emerging scheme used at inference time to address this issue. In TTA, models are adapted online at the same time when making predictions to test data. Neighbor-based approaches have gained attention recently, where prototype embeddings provide location information to alleviate the feature shift between training and testing data. However, due to their inherit limitation of simplicity, they often struggle to learn useful patterns and encounter performance degradation. To confront this challenge, we study the TTA problem from a geometric point of view. We first reveal that the underlying structure of neighbor-based methods aligns with the Voronoi Diagram, a classical computational geometry model for space partitioning. Building on this observation, we propose the Test-Time adjustment by Voronoi Diagram guidance (TTVD), a novel framework that leverages the benefits of this geometric property. Specifically, we explore two key structures: 1) Cluster-induced Voronoi Diagram (CIVD): This integrates the joint contribution of self-supervision and entropy-based methods to provide richer information. 2) Power Diagram (PD): A generalized version of the Voronoi Diagram that refines partitions by assigning weights to each Voronoi cell. Our experiments under rigid, peer-reviewed settings on CIFAR-10-C, CIFAR-100-C, ImageNet-C, and ImageNet-R shows that TTVD achieves remarkable improvements compared to state-of-the-art methods. Moreover, extensive experimental results also explore the effects of batch size and class imbalance, which are two scenarios commonly encountered in real-world applications. These analyses further validate the robustness and adaptability of our proposed framework.         _ Less","","arXiv","https://arxiv.org/abs/2412.07980","2","2","multiple"
"DRC-Coder: Automated DRC Checker Code Generation Using LLM Autonomous Agent","Abstract:                _design an auto-evaluation function for LLMs to enable DRC code debugging. Experimental results show that targeting on a sub-3nm technology node for a state-of-the-art standard cell layout tool, DRC-Coder achieves perfect F1 score 1.000 in generating DRC codes for meeting the standard of a commercial DRC tool, highly outperforming standard prompting technique_         _ More           In the advanced technology nodes, the integrated design rule checker (DRC) is often utilized in place and route tools for fast optimization loops for power-performance-area. Implementing integrated DRC checkers to meet the standard of commercial DRC tools demands extensive human expertise to interpret foundry specifications, analyze layouts, and debug code iteratively. However, this labor-intensive process, requiring to be repeated by every update of technology nodes, prolongs the turnaround time of designing circuits. In this paper, we present DRC-Coder, a multi-agent framework with vision capabilities for automated DRC code generation. By incorporating vision language models and large language models (LLM), DRC-Coder can effectively process textual, visual, and layout information to perform rule interpretation and coding by two specialized LLMs. We also design an auto-evaluation function for LLMs to enable DRC code debugging. Experimental results show that targeting on a sub-3nm technology node for a state-of-the-art standard cell layout tool, DRC-Coder achieves perfect F1 score 1.000 in generating DRC codes for meeting the standard of a commercial DRC tool, highly outperforming standard prompting techniques (F1=0.631). DRC-Coder can generate code for each design rule within four minutes on average, which significantly accelerates technology advancement and reduces engineering costs.         _ Less","","arXiv","https://arxiv.org/abs/2412.05311","1","0","origin_of_life"
"Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements","Abstract:                _research. It enables precise identification, monitoring, and spatiotemporal analysis of objects across sequential frames, providing insights into dynamic behaviors. In cell biology, object tracking is vital for uncovering cellular mechanisms, such as migration, interactions, and responses to drugs or pathogens. These insights drive breakthroughs in understan_         _ More           Object tracking is a fundamental tool in modern innovation, with applications in defense systems, autonomous vehicles, and biomedical research. It enables precise identification, monitoring, and spatiotemporal analysis of objects across sequential frames, providing insights into dynamic behaviors. In cell biology, object tracking is vital for uncovering cellular mechanisms, such as migration, interactions, and responses to drugs or pathogens. These insights drive breakthroughs in understanding disease progression and therapeutic interventions.   Over time, object tracking methods have evolved from traditional feature-based approaches to advanced machine learning and deep learning frameworks. While classical methods are reliable in controlled settings, they struggle in complex environments with occlusions, variable lighting, and high object density. Deep learning models address these challenges by delivering greater accuracy, adaptability, and robustness.   This review categorizes object tracking techniques into traditional, statistical, feature-based, and machine learning paradigms, with a focus on biomedical applications. These methods are essential for tracking cells and subcellular structures, advancing our understanding of health and disease. Key performance metrics, including accuracy, efficiency, and adaptability, are discussed. The paper explores limitations of current methods and highlights emerging trends to guide the development of next-generation tracking systems for biomedical research and broader scientific domains.         _ Less","","arXiv","https://arxiv.org/abs/2412.01119","1","1","multiple"
"Rethinking Cognition: Morphological Info-Computation and the Embodied Paradigm in Life and Artificial Intelligence","Abstract:                _was believed to be exclusive to humans and a result of brain activity. However, recent studies reveal it as a fundamental characteristic of all life forms, ranging from single cells to complex multicellular organisms and their networks. Yet, the literature and general understanding of cognition still largely remain human-brain-focused, leading to conceptual_         _ More           This study aims to place Lorenzo Magnanis Eco-Cognitive Computationalism within the broader context of current work on information, computation, and cognition. Traditionally, cognition was believed to be exclusive to humans and a result of brain activity. However, recent studies reveal it as a fundamental characteristic of all life forms, ranging from single cells to complex multicellular organisms and their networks. Yet, the literature and general understanding of cognition still largely remain human-brain-focused, leading to conceptual gaps and incoherency. This paper presents a variety of computational (information processing) approaches, including an info-computational approach to cognition, where natural structures represent information and dynamical processes on natural structures are regarded as computation, relative to an observing cognizing agent. We model cognition as a web of concurrent morphological computations, driven by processes of self-assembly, self-organisation, and autopoiesis across physical, chemical, and biological domains. We examine recent findings linking morphological computation, morphogenesis, agency, basal cognition, extended evolutionary synthesis, and active inference. We establish a connection to Magnanis Eco-Cognitive Computationalism and the idea of computational domestication of ignorant entities. Novel theoretical and applied insights question the boundaries of conventional computational models of cognition. The traditional models prioritize symbolic processing and often neglect the inherent constraints and potentialities in the physical embodiment of agents on different levels of organization. Gaining a better info-computational grasp of cognitive embodiment is crucial for the advancement of fields such as biology, evolutionary studies, artificial intelligence, robotics, medicine, and more.         _ Less","","arXiv","https://arxiv.org/abs/2412.00751","1","4","synthetic_biology"
"S$^2$ALM: Sequence-Structure Pre-trained Large Language Model for Comprehensive Antibody Representation Learning","Abstract:                _ALM can be adopted for diverse downstream tasks: accurately predicting antigen-antibody binding affinities, precisely distinguishing B cell maturation stages, identifying antibody crucial binding positions, and specifically designing novel coronavirus-binding antibodies. Remarkably, S$^2$ALM outperforms well-established and renowned baselines and sets new st_         _ More           Antibodies safeguard our health through their precise and potent binding to specific antigens, demonstrating promising therapeutic efficacy in the treatment of numerous diseases, including COVID-19. Recent advancements in biomedical language models have shown the great potential to interpret complex biological structures and functions. However, existing antibody specific models have a notable limitation that they lack explicit consideration for antibody structural information, despite the fact that both 1D sequence and 3D structure carry unique and complementary insights into antibody behavior and functionality. This paper proposes Sequence-Structure multi-level pre-trained Antibody Language Model (S$^2$ALM), combining holistic sequential and structural information in one unified, generic antibody foundation model. We construct a hierarchical pre-training paradigm incorporated with two customized multi-level training objectives to facilitate the modeling of comprehensive antibody representations. S$^2$ALM's representation space uncovers inherent functional binding mechanisms, biological evolution properties and structural interaction patterns. Pre-trained over 75 million sequences and 11.7 million structures, S$^2$ALM can be adopted for diverse downstream tasks: accurately predicting antigen-antibody binding affinities, precisely distinguishing B cell maturation stages, identifying antibody crucial binding positions, and specifically designing novel coronavirus-binding antibodies. Remarkably, S$^2$ALM outperforms well-established and renowned baselines and sets new state-of-the-art performance across extensive antibody specific understanding and generation tasks. S$^2$ALM's ability to model comprehensive and generalized representations further positions its potential to advance real-world therapeutic antibody development, potentially addressing unmet academic, industrial, and clinical needs.         _ Less","","arXiv","https://arxiv.org/abs/2411.15215","2","2","multiple"
"Comparative Analysis of Machine Learning and Deep Learning Models for Classifying Squamous Epithelial Cells of the Cervix","Abstract:                The cervix is the narrow end of the uterus that connects to the vagina in the female reproductive system. Abnormal cell growth in the squamous epithelial lining of the cervix leads to cervical cancer in females. A Pap smear is a diagnostic procedure used to detect cervical cancer by gently collecting_         _ More           The cervix is the narrow end of the uterus that connects to the vagina in the female reproductive system. Abnormal cell growth in the squamous epithelial lining of the cervix leads to cervical cancer in females. A Pap smear is a diagnostic procedure used to detect cervical cancer by gently collecting cells from the surface of the cervix with a small brush and analyzing their changes under a microscope. For population-based cervical cancer screening, visual inspection with acetic acid is a cost-effective method with high sensitivity. However, Pap smears are also suitable for mass screening due to their higher specificity. The current Pap smear analysis method is manual, time-consuming, labor-intensive, and prone to human error. Therefore, an artificial intelligence (AI)-based approach for automatic cell classification is needed. In this study, we aimed to classify cells in Pap smear images into five categories: superficial-intermediate, parabasal, koilocytes, dyskeratotic, and metaplastic. Various machine learning (ML) algorithms, including Gradient Boosting, Random Forest, Support Vector Machine, and k-Nearest Neighbor, as well as deep learning (DL) approaches like ResNet-50, were employed for this classification task. The ML models demonstrated high classification accuracy; however, ResNet-50 outperformed the others, achieving a classification accuracy of 93.06%. This study highlights the efficiency of DL models for cell-level classification and their potential to aid in the early diagnosis of cervical cancer from Pap smear images.         _ Less","","arXiv","https://arxiv.org/abs/2411.13535","0","1","synthetic_biology"
"Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion","Abstract:                _tailored to multiplexed WSIs by leveraging scaled dot-product attention (SDPA) to interpretably fuse information across disparate channels. On a cohort of 434 non-small cell lung cancer (NSCLC) samples, we show that the Fluoroformer both obtains strong prognostic performance and recapitulates immuno-oncological hallmarks of NSCLC. Our technique thereby provi_         _ More           Though multiple instance learning (MIL) has been a foundational strategy in computational pathology for processing whole slide images (WSIs), current approaches are designed for traditional hematoxylin and eosin (H&E) slides rather than emerging multiplexed technologies. Here, we present an MIL strategy, the Fluoroformer module, that is specifically tailored to multiplexed WSIs by leveraging scaled dot-product attention (SDPA) to interpretably fuse information across disparate channels. On a cohort of 434 non-small cell lung cancer (NSCLC) samples, we show that the Fluoroformer both obtains strong prognostic performance and recapitulates immuno-oncological hallmarks of NSCLC. Our technique thereby provides a path for adapting state-of-the-art AI techniques to emerging spatial biology assays.         _ Less","","arXiv","https://arxiv.org/abs/2411.08975","1","0","origin_of_life"
"From Dark Matter Minihalos to Large-Scale Radiative Feedback: A Self-Consistent 3D Simulation of the First Stars and Galaxies using Neural Networks","Abstract:                _100 Mpc. We present a novel approach to this issue in which we utilize artificial neural networks (NNs) to emulate the Population III (PopIII) and Population II (PopII) star formation histories of many small-scale_         _ More           A key obstacle to accurate models of the first stars and galaxies is the vast range of distance scales that must be considered. While star formation occurs on sub-parsec scales within dark matter (DM) minihalos, it is influenced by large-scale baryon-dark matter streaming velocities ($v_{\\rm bc}$) and Lyman-Werner (LW) radiative feedback which vary significantly on scales of $\\sim$100 Mpc. We present a novel approach to this issue in which we utilize artificial neural networks (NNs) to emulate the Population III (PopIII) and Population II (PopII) star formation histories of many small-scale cells given by a more complex semi-analytic framework based on DM halo merger trees. Within each simulation cell, the NN takes a set of input parameters that depend on the surrounding large-scale environment, such as the cosmic overdensity, $_(\\vec{x})$, and $v_{\\rm bc}$ of the cell, then outputs the resulting star formation far more efficiently than is possible with the semi-analytic model. This rapid emulation allows us to self-consistently determine the LW background intensity on $\\sim$100 Mpc scales, while simultaneously including the detailed merger histories (and corresponding star formation histories) of the low-mass minihalos that host the first stars. Comparing with the full semi-analytic framework utilizing DM halo merger trees, our NN emulators yield star formation histories with redshift-averaged errors of $\\sim$10.2\\% and $\\sim$9.2\\% for PopII and PopIII, respectively. When compared to a simpler sub-grid star formation prescription reliant on halo mass function integration, we find that the diversity of halo merger histories in our simulation leads to enhanced spatial fluctuations, an earlier transition from PopIII to PopII dominated star formation, and more scatter in star formation histories overall.         _ Less","","arXiv","https://arxiv.org/abs/2411.07875","1","0","origin_of_life"
"Enhancing frozen histological section images using permanent-section-guided deep learning with nuclei attention","Abstract:                _rapid diagnosis during surgeries, as they can be produced within minutes. However, they suffer from artifacts and often lack crucial diagnostic details, particularly within the cell nuclei region. Permanent sections, on the other hand, contain more diagnostic detail but require a time-intensive preparation process. Here, we present a generative deep learning_         _ More           In histological pathology, frozen sections are often used for rapid diagnosis during surgeries, as they can be produced within minutes. However, they suffer from artifacts and often lack crucial diagnostic details, particularly within the cell nuclei region. Permanent sections, on the other hand, contain more diagnostic detail but require a time-intensive preparation process. Here, we present a generative deep learning approach to enhance frozen section images by leveraging guidance from permanent sections. Our method places a strong emphasis on the nuclei region, which contains critical information in both frozen and permanent sections. Importantly, our approach avoids generating artificial data in blank regions, ensuring that the network only enhances existing features without introducing potentially unreliable information. We achieve this through a segmented attention network, incorporating nuclei-segmented images during training and adding an additional loss function to refine the nuclei details in the generated permanent images. We validated our method across various tissues, including kidney, breast, and colon. This approach significantly improves histological efficiency and diagnostic accuracy, enhancing frozen section images within seconds, and seamlessly integrating into existing laboratory workflows.         _ Less","","arXiv","https://arxiv.org/abs/2411.06583","1","0","origin_of_life"
"Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model","Abstract:                _pre-specifying the number of part families to be formed. The process route of family formation is the first stage in a hierarchical procedure. For the second stage (machine cell formation), two procedures, a quadratic assignment programming (QAP) formulation, and a heuristic procedure, are proposed. The QAP simultaneously assigns process route families and m_         _ More           This paper focuses on the generalized grouping problem in the context of cellular manufacturing systems (CMS), where parts may have more than one process route. A process route lists the machines corresponding to each part of the operation. Inspired by the extensive and widespread use of network flow algorithms, this research formulates the process route family formation for generalized grouping as a unit capacity minimum cost network flow model. The objective is to minimize dissimilarity (based on the machines required) among the process routes within a family. The proposed model optimally solves the process route family formation problem without pre-specifying the number of part families to be formed. The process route of family formation is the first stage in a hierarchical procedure. For the second stage (machine cell formation), two procedures, a quadratic assignment programming (QAP) formulation, and a heuristic procedure, are proposed. The QAP simultaneously assigns process route families and machines to a pre-specified number of cells in such a way that total machine utilization is maximized. The heuristic procedure for machine cell formation is hierarchical in nature. Computational results for some test problems show that the QAP and the heuristic procedure yield the same results.         _ Less","","arXiv","https://arxiv.org/abs/2411.04685","1","0","origin_of_life"
"Automating Exploratory Proteomics Research via Language Models","Abstract:                With the development of artificial intelligence, its contribution to science is evolving from simulating a complex problem to automating entire research processes and producing novel discoveries. Achieving this advancement requires both specialized general models grounded in real-world scientific data and iterative, exploratory frameworks that mirror human s_         _ More           With the development of artificial intelligence, its contribution to science is evolving from simulating a complex problem to automating entire research processes and producing novel discoveries. Achieving this advancement requires both specialized general models grounded in real-world scientific data and iterative, exploratory frameworks that mirror human scientific methodologies. In this paper, we present PROTEUS, a fully automated system for scientific discovery from raw proteomics data. PROTEUS uses large language models (LLMs) to perform hierarchical planning, execute specialized bioinformatics tools, and iteratively refine analysis workflows to generate high-quality scientific hypotheses. The system takes proteomics datasets as input and produces a comprehensive set of research objectives, analysis results, and novel biological hypotheses without human intervention. We evaluated PROTEUS on 12 proteomics datasets collected from various biological samples (e.g. immune cells, tumors) and different sample types (single-cell and bulk), generating 191 scientific hypotheses. These were assessed using both automatic LLM-based scoring on 5 metrics and detailed reviews from human experts. Results demonstrate that PROTEUS consistently produces reliable, logically coherent results that align well with existing literature while also proposing novel, evaluable hypotheses. The system's flexible architecture facilitates seamless integration of diverse analysis tools and adaptation to different proteomics data types. By automating complex proteomics analysis workflows and hypothesis generation, PROTEUS has the potential to considerably accelerate the pace of scientific discovery in proteomics research, enabling researchers to efficiently explore large-scale datasets and uncover biological insights.         _ Less","","arXiv","https://arxiv.org/abs/2411.03743","2","3","synthetic_biology"
"Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking","Abstract:                _for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease. Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer_         _ More           Nanorobots are a promising development in targeted drug delivery and the treatment of neurological disorders, with potential for crossing the blood-brain barrier (BBB). These small devices leverage advancements in nanotechnology and bioengineering for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease. Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer cells through biomarker analysis. This study presents a new reinforcement learning (RL) framework for optimizing nanorobot navigation in complex biological environments, focusing on cancer cell detection by analyzing the concentration gradients of surrounding biomarkers. We utilize a computer simulation model to explore the behavior of nanorobots in a three-dimensional space with cancer cells and biological barriers. The proposed method uses Q-learning to refine movement strategies based on real-time biomarker concentration data, enabling nanorobots to autonomously navigate to cancerous tissues for targeted drug delivery. This research lays the groundwork for future laboratory experiments and clinical applications, with implications for personalized medicine and less invasive cancer treatments. The integration of intelligent nanorobots could revolutionize therapeutic strategies, reducing side effects and enhancing treatment effectiveness for cancer patients. Further research will investigate the practical deployment of these technologies in medical settings, aiming to unlock the full potential of nanorobotics in healthcare.         _ Less","","arXiv","https://arxiv.org/abs/2411.02345","0","1","synthetic_biology"
"Differentiable architecture search with multi-dimensional attention for spiking neural networks","Abstract:                Spiking Neural Networks (SNNs) have gained enormous popularity in the field of artificial intelligence due to their low power consumption. However, the majority of SNN methods directly inherit the structure of_         _ More           Spiking Neural Networks (SNNs) have gained enormous popularity in the field of artificial intelligence due to their low power consumption. However, the majority of SNN methods directly inherit the structure of Artificial Neural Networks (ANN), usually leading to sub-optimal model performance in SNNs. To alleviate this problem, we integrate Neural Architecture Search (NAS) method and propose Multi-Attention Differentiable Architecture Search (MA-DARTS) to directly automate the search for the optimal network structure of SNNs. Initially, we defined a differentiable two-level search space and conducted experiments within micro architecture under a fixed layer. Then, we incorporated a multi-dimensional attention mechanism and implemented the MA-DARTS algorithm in this search space. Comprehensive experiments demonstrate our model achieves state-of-the-art performance on classification compared to other methods under the same parameters with 94.40% accuracy on CIFAR10 dataset and 76.52% accuracy on CIFAR100 dataset. Additionally, we monitored and assessed the number of spikes (NoS) in each cell during the whole experiment. Notably, the number of spikes of the whole model stabilized at approximately 110K in validation and 100k in training on datasets.         _ Less","","arXiv","https://arxiv.org/abs/2411.00902","1","1","multiple"
"Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection","Abstract:                Uncontrolled cell division in the brain is what gives rise to brain tumors. If the tumor size increases by more than half, there is little hope for the patient's recovery. This emphasizes the need of rapid and precise brain tumor diagnosis. When it comes to analyzing, diagnosing, and planning therapy for brain tumors, MRI imaging plays a crucial role. A_         _ More           Uncontrolled cell division in the brain is what gives rise to brain tumors. If the tumor size increases by more than half, there is little hope for the patient's recovery. This emphasizes the need of rapid and precise brain tumor diagnosis. When it comes to analyzing, diagnosing, and planning therapy for brain tumors, MRI imaging plays a crucial role. A brain tumor's development history is crucial information for doctors to have. When it comes to distinguishing between human soft tissues, MRI scans are superior. In order to get reliable classification results from MRI scans quickly, deep learning is one of the most practical methods. Early human illness diagnosis has been demonstrated to be more accurate when deep learning methods are used. In the case of diagnosing a brain tumor, when even a little misdiagnosis might have serious consequences, accuracy is especially important. Disclosure of brain tumors in medical images is still a difficult task. Brain MRIs are notoriously imprecise in revealing the presence or absence of tumors. Using MRI scans of the brain, a Convolutional Neural Network (CNN) was trained to identify the presence of a tumor in this research. Results from the CNN model showed an accuracy of 99.17%. The CNN model's characteristics were also retrieved. In order to evaluate the CNN model's capability for processing images, we applied the features via the following machine learning models: KNN, Logistic regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine learning models were also evaluated using the standard metrics of Precision, Recall, Specificity, and F1 score. The significance of the doctor's diagnosis enhanced the accuracy of the CNN model's assistance in identifying the existence of tumor and treating the patient.         _ Less","","arXiv","https://arxiv.org/abs/2410.22619","1","0","origin_of_life"
"Self-organized homogenization of flow networks","Abstract:                From the vasculature of animals to the porous media making up batteries, transport by fluid flow within complex networks is crucial to service all cells or media with resources. Yet, living flow networks have a key advantage over porous media: they are adaptive and can self-organize their geometry to achieve a homogeneous perfusion throughout the network. He_         _ More           From the vasculature of animals to the porous media making up batteries, transport by fluid flow within complex networks is crucial to service all cells or media with resources. Yet, living flow networks have a key advantage over porous media: they are adaptive and can self-organize their geometry to achieve a homogeneous perfusion throughout the network. Here, we show that, through erosion, artificial flow networks self-organize to a geometry where perfusion is more homogeneous. Flowing a pulse of cleaving enzyme through a network patterned into an erodible hydrogel, with initial channels disparate in width, we observe a homogenization in channel resistances. Experimental observations are matched with numerical simulations of the diffusion-advection-sorption dynamics of an eroding enzyme within a network. Analyzing transport dynamics theoretically, we show that homogenization only occurs if the pulse of eroding enzyme lasts longer than the time it takes any channel to equilibrate to the pulse concentration. The equilibration time scale derived analytically is in agreement with simulations. Lastly, we show both numerically and experimentally that erosion leads to homogenization of complex networks containing loops. Erosion being an omnipresent reaction, our results pave the way for a very versatile self-organized increase in the performance of porous media.         _ Less","","arXiv","https://arxiv.org/abs/2410.19089","0","1","synthetic_biology"
"Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for Kidney Tumor Segmentation","Abstract:                Renal tumors, especially renal cell carcinoma (RCC), show significant heterogeneity, posing challenges for diagnosis using radiology images such as MRI, echocardiograms, and CT scans. U-Net based deep learning techniques are emerging as a promising approach for automated medical image segmentation for minimally invasive diagnosis of renal tumors. However, cu_         _ More           Renal tumors, especially renal cell carcinoma (RCC), show significant heterogeneity, posing challenges for diagnosis using radiology images such as MRI, echocardiograms, and CT scans. U-Net based deep learning techniques are emerging as a promising approach for automated medical image segmentation for minimally invasive diagnosis of renal tumors. However, current techniques need further improvements in accuracy to become clinically useful to radiologists. In this study, we present an improved U-Net based model for end-to-end automated semantic segmentation of CT scan images to identify renal tumors. The model uses residual connections across convolution layers, integrates a multi-layer feature fusion (MFF) and cross-channel attention (CCA) within encoder blocks, and incorporates skip connections augmented with additional information derived using MFF and CCA. We evaluated our model on the KiTS19 dataset, which contains data from 210 patients. For kidney segmentation, our model achieves a Dice Similarity Coefficient (DSC) of 0.97 and a Jaccard index (JI) of 0.95. For renal tumor segmentation, our model achieves a DSC of 0.96 and a JI of 0.91. Based on a comparison of available DSC scores, our model outperforms the current leading models.         _ Less","","arXiv","https://arxiv.org/abs/2410.15472","1","0","origin_of_life"
"Long-range order in two-dimensional systems with fluctuating active stresses","Abstract:                _limit. We then introduce two numerical cell tissue models which feature these pair-wise active forces. First a vertex model, in which the_         _ More           In two-dimensional tissues, such as developing germ layers, pair-wise forces (or active stresses) arise from the contractile activity of the cytoskeleton, with dissipation provided by the three-dimensional surroundings. We show analytically how these pair-wise stochastic forces, unlike the particle-wise independent fluctuating forces usually considered in active matter systems, produce conserved centre-of-mass dynamics and so are able to damp large-wavelength displacement fluctuations in elastic systems. A consequence of this is the stabilisation of long-range translational order in two dimensions, in clear violation of the celebrated Mermin-Wagner theorem, and the emergence of hyperuniformity with a structure factor $S(q) \\sim q^2$ in the $q \\to 0$ limit. We then introduce two numerical cell tissue models which feature these pair-wise active forces. First a vertex model, in which the cell tissue is represented by a tiling of polygons where the edges represent cell junctions and with activity provided by stochastic junctional contractions. Second an active disk model, derived from active Brownian particles, but with pairs of equal and opposite stochastic forces between particles. We confirm our analytical prediction of long-range order in both numerical models and show that hyperuniformity survives in the disordered phase, thus constituting a hidden order in our model tissue. Owing to the generality of this mechanism, we expect our results to be testable in living organisms, and to also apply to artificial systems with the same symmetry.         _ Less","","arXiv","https://arxiv.org/abs/2410.14840","1","0","origin_of_life"
"Comparison of hydroxyapatite and honeycomb micro-structure in bone tissue engineering using electrospun beads-on-string fibers","Abstract:                _electrospun scaffold with nanoparticles of hydroxyapatite (nHA) recently demonstrated its potential to promote proliferation and differentiation of a murine embryonic cell line (C3H10T1/2) to osteoblasts. In order to distinguish the respective effects of the structure and the composition on_         _ More           Thick honeycomb-like electrospun scaffold with nanoparticles of hydroxyapatite (nHA) recently demonstrated its potential to promote proliferation and differentiation of a murine embryonic cell line (C3H10T1/2) to osteoblasts. In order to distinguish the respective effects of the structure and the composition on cell differentiation, beads-on-string fibers were used to manufacture thick honeycomb-like scaffolds without nHA. Mechanical and biological impacts of those beads-on string fibers were evaluated. Uniaxial tensile test showed that beads-on-string fibers decreased the Young Modulus and maximal stress but kept them appropriate for tissue engineering. C3H10T1/2 were seeded and cultured for 6 days on the scaffolds without any growth factors. Viability assays revealed the biocompatibility of the beads-on-string scaffolds, with adequate cells-materials interactions observed by confocal microscopy. Alkaline phosphatase staining was performed at day 6 in order to compare the early differentiation of cells to bone fate. The measure of stained area and intensity confirmed the beneficial effect of both honeycomb structure and nHA, independently. Finally, we showed that honeycomb-like electrospun scaffolds could be relevant candidates for promoting bone fate to cells in the absence of nHA. It offers an easier and faster manufacture process, in particular in bone-interface tissue engineering, permitting to avoid the dispersion of nHA and their interaction with the other cells.         _ Less","","arXiv","https://arxiv.org/abs/2410.14226","0","1","synthetic_biology"
"Digital Humanities in the TIME-US Project: Richness and Contribution of Interdisciplinary Methods for Labour History","Abstract:                _1 Although this observation did not exclusively refer to the new possibilities offered by the technological advancements of the time -particularly in the field of artificial intelligence 2 -it was nonetheless motivated by these rapid and numerous changes, which also affect the historiographical landscape. A year earlier, St_phane Lamass_ and Philippe Rygiel_         _ More           In 2015, the Annales journal, traditionally open to interdisciplinary approaches in history, referred to 'the current historiographical moment [as] call [ing] for an experimentation of approaches'. 1 Although this observation did not exclusively refer to the new possibilities offered by the technological advancements of the time -particularly in the field of artificial intelligence 2 -it was nonetheless motivated by these rapid and numerous changes, which also affect the historiographical landscape. A year earlier, St_phane Lamass_ and Philippe Rygiel spoke of the 'new frontiers of the historian', frontiers opened a few years earlier by the realisation of the unprecedented impact of new technologies on historical practices, leading to a 'mutation des conditions de production et de diffusion des connaissances historiques, voire de la nature de celles-ci' ('transformation of the conditions of production and dissemination of historical knowledge, and even the nature of this knowledge'). 3 It was in this fertile ground, conducive to the cross-fertilisation of approaches, that the TIME-US project was born in 2016. TIME-US is directly the result of this awareness and reflects the transformations induced by major technological advancements, disrupting not only our daily practices but also our historical practices. 1 Annales 2015, 216. 2 For example, convolutional neural networks, which have revolutionised the field of artificial intelligence, began to gain popularity just before the 2010s. 3 Translated by the author. Lamass_ and Rygiel 2014. To quantify women's work in the past, labour historians cannot rely on the classic sources of their discipline, which allow to produce large statistical data series, systematically treatable in the form of databases. What to do when such data are not available? Should the task simply be abandoned? As Maria _gren points out, the invisibility of women's participation in the labour market does not mean non-existence 8 ; there must therefore be traces of it. To quantify women's economic activity, Sara Horrell and Jane Humphries, for example, turned to household budgets from 59 different sources (from Parliamentary Papers to autobiographical texts), which had never before been systematically used to identify women's work patterns and their contribution to family income. 9 In her study A Bitter Living: Women, Markets, and Social Capital in Early Modern Germany published in 2003, Sheilagh Ogilvie used information contained in court records to identify activities carried out by women and the time spent on these activities. Court records were not intended to record such information; yet, in their testimonies, witnesses often described in detail the activities they were engaged in while a crime was unfolding before their eyes. Sheilagh Ogilvie thus identified nearly 3000 such observations. 10 These works have opened two main avenues for the TIME-US project. First, making already digitised sources accessible in homogeneous corpora. 11 Following the example of previous research, TIME-US mobilised varied sources containing traces of professional activities carried out by women in France during the period studied: these include both printed (posters and petitions, working-class newspapers, and contemporary surveys on workers) and handwritten sources (labour court decisions, police reports, company archives, personal archives, surveys, petitions). 12 One of the project's objectives was to gather and 8 _gren 2018a, 144. 9 Horrell and Humphries 1995.         _ Less","","arXiv","https://arxiv.org/abs/2410.14222","2","2","multiple"
"scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers","Abstract:                Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data, such as Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq), where the regulation of each_         _ More           Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data, such as Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq), where the regulation of each cell was measured from different modalities, i.e. genes and proteins. scMulti-omics can reveal heterogeneity inside tumors and understand the distinct genetic properties of diverse cell types, which is crucial to targeted therapy. Currently, deep learning methods based on attention structures in the bioinformatics area face two challenges. The first challenge is the vast number of genes in a single cell. Traditional attention-based modules struggled to effectively leverage all gene information due to their limited capacity for long-context learning and high-complexity computing. The second challenge is that genes in the human genome are ordered and influence each other's expression. Most of the methods ignored this sequential information. The recently introduced Test-Time Training (TTT) layer is a novel sequence modeling approach, particularly suitable for handling long contexts like genomics data because TTT layer is a linear complexity sequence modeling structure and is better suited to data with sequential relationships. In this paper, we propose scFusionTTT, a novel method for Single-Cell multimodal omics Fusion with TTT-based masked autoencoder. Of note, we combine the order information of genes and proteins in the human genome with the TTT layer, fuse multimodal omics, and enhance unimodal omics analysis. Finally, the model employs a three-stage training strategy, which yielded the best performance across most metrics in four multimodal omics datasets and four unimodal omics datasets, demonstrating the superior performance of our model. The dataset and code will be available on https://github.com/DM0815/scFusionTTT.         _ Less","","arXiv","https://arxiv.org/abs/2410.13257","1","0","origin_of_life"
"KPROJ: A Program for Unfolding Electronic and Phononic Bands","Abstract:                _-points in the Brillouin zone of the artificial primitive cell. It allows for obtaining an effective 'local' band structure by performing partial integration over the wavefunctions, e.g., the unfolded band structure with layer-projection for interfaces and the weighted band structure in the vacuum for slabs. Th_         _ More           We introduce a program named KPROJ that unfolds the electronic and phononic band structure of materials modeled by supercells. The program is based on the $\\textit{k}$-projection method, which projects the wavefunction of the supercell onto the ${\\textbf{k}}$-points in the Brillouin zone of the artificial primitive cell. It allows for obtaining an effective 'local' band structure by performing partial integration over the wavefunctions, e.g., the unfolded band structure with layer-projection for interfaces and the weighted band structure in the vacuum for slabs. The layer projection is accelerated by a scheme that combines the Fast Fourier Transform (FFT) and the inverse FFT algorithms. It is now interfaced with a few first-principles codes based on plane waves such as VASP, Quantum Espresso, and ABINIT. In addition, it also has interfaces with ABACUS, a first-principles simulation package based on numerical atomic basis sets, and PHONOPY, a program for phonon calculations.         _ Less","","arXiv","https://arxiv.org/abs/2410.10910","1","0","origin_of_life"
"Over-the-Air Federated Learning in Cell-Free MIMO with Long-term Power Constraint","Abstract:                Wireless networks supporting artificial intelligence have gained significant attention, with Over-the-Air Federated Learning emerging as a key application due to its unique transmission and distributed computing characteristics. This paper derives error bounds for Over-the-Air Federated Learning in a Cell-free MIMO sys_         _ More           Wireless networks supporting artificial intelligence have gained significant attention, with Over-the-Air Federated Learning emerging as a key application due to its unique transmission and distributed computing characteristics. This paper derives error bounds for Over-the-Air Federated Learning in a Cell-free MIMO system and formulates an optimization problem to minimize optimality gap via joint optimization of power control and beamforming. We introduce the MOP-LOFPC algorithm, which employs Lyapunov optimization to decouple long-term constraints across rounds while requiring only causal channel state information. Experimental results demonstrate that MOP-LOFPC achieves a better and more flexible trade-off between the model's training loss and adherence to long-term power constraints compared to existing baselines.         _ Less","","arXiv","https://arxiv.org/abs/2410.05354","1","0","origin_of_life"
"Topology-Informed Machine Learning for Efficient Prediction of Solid Oxide Fuel Cell Electrode Polarization","Abstract:                Machine learning has emerged as a potent computational tool for expediting research and development in solid oxide fuel cell electrodes. The effective application of machine learning for performance prediction requires transforming electrode microstructure into a format compatible with_         _ More           Machine learning has emerged as a potent computational tool for expediting research and development in solid oxide fuel cell electrodes. The effective application of machine learning for performance prediction requires transforming electrode microstructure into a format compatible with artificial neural networks. Input data may range from a comprehensive digital material representation of the electrode to a selected set of microstructural parameters. The chosen representation significantly influences the performance and results of the network. Here, we show a novel approach utilizing persistence representation derived from computational topology. Using 500 microstructures and current-voltage characteristics obtained with 3D first-principles simulations, we have prepared an artificial neural network model that can replicate current-voltage characteristics of unseen microstructures based on their persistent image representation. The artificial neural network can accurately predict the polarization curve of solid oxide fuel cell electrodes. The presented method incorporates complex microstructural information from the digital material representation while requiring substantially less computational resources (preprocessing and prediction time approximately 1 min) compared to our high-fidelity simulations (simulation time approximately 1 hour) to obtain a single current-potential characteristic for one microstructure.         _ Less","","arXiv","https://arxiv.org/abs/2410.05307","2","1","origin_of_life"
"TableRAG: Million-Token Table Understanding with Language Models","Abstract:                _TableRAG, a Retrieval-Augmented Generation (RAG) framework specifically designed for LM-based table understanding. TableRAG leverages query expansion combined with schema and cell retrieval to pinpoint crucial information before providing it to the LMs. This enables more efficient data encoding and precise retrieval, significantly reducing prompt lengths and_         _ More           Recent advancements in language models (LMs) have notably enhanced their ability to reason with tabular data, primarily through program-aided mechanisms that manipulate and analyze tables. However, these methods often require the entire table as input, leading to scalability challenges due to the positional bias or context length constraints. In response to these challenges, we introduce TableRAG, a Retrieval-Augmented Generation (RAG) framework specifically designed for LM-based table understanding. TableRAG leverages query expansion combined with schema and cell retrieval to pinpoint crucial information before providing it to the LMs. This enables more efficient data encoding and precise retrieval, significantly reducing prompt lengths and mitigating information loss. We have developed two new million-token benchmarks from the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's effectiveness at scale. Our results demonstrate that TableRAG's retrieval design achieves the highest retrieval quality, leading to the new state-of-the-art performance on large-scale table understanding.         _ Less","","arXiv","https://arxiv.org/abs/2410.04739","1","0","origin_of_life"
"Learning grid cells by predictive coding","Abstract:                Grid cells in the medial entorhinal cortex (MEC) of the mammalian brain exhibit a strikingly regular hexagonal firing field over space. These_         _ More           Grid cells in the medial entorhinal cortex (MEC) of the mammalian brain exhibit a strikingly regular hexagonal firing field over space. These cells are learned after birth and are thought to support spatial navigation but also more abstract computations. Although various computational models, including those based on artificial neural networks, have been proposed to explain the formation of grid cells, the process through which the MEC circuit ${\\it learns}$ to develop grid cells remains unclear. In this study, we argue that predictive coding, a biologically plausible plasticity rule known to learn visual representations, can also train neural networks to develop hexagonal grid representations from spatial inputs. We demonstrate that grid cells emerge robustly through predictive coding in both static and dynamic environments, and we develop an understanding of this grid cell learning capability by analytically comparing predictive coding with existing models. Our work therefore offers a novel and biologically plausible perspective on the learning mechanisms underlying grid cells. Moreover, it extends the predictive coding theory to the hippocampal formation, suggesting a unified learning algorithm for diverse cortical representations.         _ Less","","arXiv","https://arxiv.org/abs/2410.01022","1","0","origin_of_life"
"Reprogrammable, in-materia matrix-vector multiplication with floppy modes","Abstract:                Matrix-vector multiplications are a fundamental building block of artificial intelligence; this essential role has motivated their implementation in a variety of physical substrates, from memristor crossbar arrays to photonic integrated circuits. Yet their realization in soft-matter intelligent systems remains elusive. Here, we experimentally demonstrate a r_         _ More           Matrix-vector multiplications are a fundamental building block of artificial intelligence; this essential role has motivated their implementation in a variety of physical substrates, from memristor crossbar arrays to photonic integrated circuits. Yet their realization in soft-matter intelligent systems remains elusive. Here, we experimentally demonstrate a reprogrammable elastic metamaterial that computes matrix-vector multiplications using floppy modes -- deformations with near-zero stored elastic energy. Floppy modes allow us to program complex deformations without being hindered by the natural stiffness of the material; but their practical application is challenging, as their existence depends on global topological properties of the system. To overcome this challenge, we introduce a continuously parameterized unit cell design with well-defined compatibility characteristics. This unit cell is then combined to form arbitrary matrix-vector multiplications that can even be reprogrammed after fabrication. Our results demonstrate that floppy modes can act as key enablers for embodied intelligence, smart MEMS devices and in-sensor edge computing.         _ Less","","arXiv","https://arxiv.org/abs/2409.20425","1","0","origin_of_life"
"An Integrated Deep Learning Framework for Effective Brain Tumor Localization, Segmentation, and Classification from Magnetic Resonance Images","Abstract:                Tumors in the brain result from abnormal cell growth within the brain tissue, arising from various types of brain_         _ More           Tumors in the brain result from abnormal cell growth within the brain tissue, arising from various types of brain cells. When left undiagnosed, they lead to severe neurological deficits such as cognitive impairment, motor dysfunction, and sensory loss. As the tumor grows, it causes an increase in intracranial pressure, potentially leading to life-threatening complications such as brain herniation. Therefore, early detection and treatment are necessary to manage the complications caused by such tumors to slow down their growth. Numerous works involving deep learning (DL) and artificial intelligence (AI) are being carried out to assist physicians in early diagnosis by utilizing the scans obtained through Magnetic Resonance Imaging (MRI). Our research proposes DL frameworks for localizing, segmenting, and classifying the grade of these gliomas from MRI images to solve this critical issue. In our localization framework, we enhance the LinkNet framework with a VGG19- inspired encoder architecture for improved multimodal tumor feature extraction, along with spatial and graph attention mechanisms to refine feature focus and inter-feature relationships. Following this, we integrated the SeResNet101 CNN model as the encoder backbone into the LinkNet framework for tumor segmentation, which achieved an IoU Score of 96%. To classify the segmented tumors, we combined the SeResNet152 feature extractor with an Adaptive Boosting classifier, which yielded an accuracy of 98.53%. Our proposed models demonstrated promising results, with the potential to advance medical AI by enabling early diagnosis and providing more accurate treatment options for patients.         _ Less","","arXiv","https://arxiv.org/abs/2409.17273","0","1","synthetic_biology"
"Transformer based time series prediction of the maximum power point for solar photovoltaic cells","Abstract:                This paper proposes an improved deep learning based maximum power point tracking (MPPT) in solar photovoltaic cells considering various time series based environmental inputs. Generally, artificial neural network based MPPT algorithms use basic neural network architectures and inputs which do not represent the ambient_         _ More           This paper proposes an improved deep learning based maximum power point tracking (MPPT) in solar photovoltaic cells considering various time series based environmental inputs. Generally, artificial neural network based MPPT algorithms use basic neural network architectures and inputs which do not represent the ambient conditions in a comprehensive manner. In this article, the ambient conditions of a location are represented through a comprehensive set of environmental features. Furthermore, the inclusion of time based features in the input data is considered to model cyclic patterns temporally within the atmospheric conditions leading to robust modeling of the MPPT algorithm. A transformer based deep learning architecture is trained as a time series prediction model using multidimensional time series input features. The model is trained on a dataset containing typical meteorological year data points of ambient weather conditions from 50 locations. The attention mechanism in the transformer modules allows the model to learn temporal patterns in the data efficiently. The proposed model achieves a 0.47% mean average percentage error of prediction on non zero operating voltage points in a test dataset consisting of data collected over a period of 200 consecutive hours resulting in the average power efficiency of 99.54% and peak power efficiency of 99.98%. The proposed model is validated through real time simulations. The proposed model performs power point tracking in a robust, dynamic, and nonlatent manner, over a wide range of atmospheric conditions.         _ Less","","arXiv","https://arxiv.org/abs/2409.16342","1","1","multiple"
"Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection","Abstract:                _evolution of Large Language Models (LLMs). However, LLMs face challenges due to hallucination issues and a lack of domain-specific database knowledge(such as table schema and cell values). As a result, they can make errors in generating table names, columns, and matching values to the correct columns in SQL statements. This paper introduces a method of knowl_         _ More           Text-to-SQL is a subtask in semantic parsing that has seen rapid progress with the evolution of Large Language Models (LLMs). However, LLMs face challenges due to hallucination issues and a lack of domain-specific database knowledge(such as table schema and cell values). As a result, they can make errors in generating table names, columns, and matching values to the correct columns in SQL statements. This paper introduces a method of knowledge injection to enhance LLMs' ability to understand schema contents by incorporating prior knowledge. This approach improves their performance in Text-to-SQL tasks. Experimental results show that pre-training LLMs on domain-specific database knowledge and fine-tuning them on downstream Text-to-SQL tasks significantly improves the Execution Match (EX) and Exact Match (EM) metrics across various models. This effectively reduces errors in generating column names and matching values to the columns. Furthermore, the knowledge-injected models can be applied to many downstream Text-to-SQL tasks, demonstrating the generalizability of the approach presented in this paper.         _ Less","","arXiv","https://arxiv.org/abs/2409.15907","0","1","synthetic_biology"
"Automotive innovation landscaping using LLM","Abstract:                _the vehicle ecosystem (such as safety, Advanced Driver Assistance Systems and more).The result demonstrates the implementation of this method to create a landscape of fuel cell technology using open-source patent data. This approach provides a comprehensive overview of the current state of fuel cell technology, offerin_         _ More           The process of landscaping automotive innovation through patent analysis is crucial for Research and Development teams. It aids in comprehending innovation trends, technological advancements, and the latest technologies from competitors. Traditionally, this process required intensive manual efforts. However, with the advent of Large Language Models (LLMs), it can now be automated, leading to faster and more efficient patent categorization & state-of-the-art of inventive concept extraction. This automation can assist various R\\&D teams in extracting relevant information from extensive patent databases. This paper introduces a method based on prompt engineering to extract essential information for landscaping. The information includes the problem addressed by the patent, the technology utilized, and the area of innovation within the vehicle ecosystem (such as safety, Advanced Driver Assistance Systems and more).The result demonstrates the implementation of this method to create a landscape of fuel cell technology using open-source patent data. This approach provides a comprehensive overview of the current state of fuel cell technology, offering valuable insights for future research and development in this field.         _ Less","","arXiv","https://arxiv.org/abs/2409.14436","3","2","origin_of_life"
"High-Speed Multifunctional Photonic Memory on a Foundry-Processed Photonic Platform","Abstract:                The integration of computing with memory is essential for distributed, massively parallel, and adaptive architectures such as neural networks in artificial intelligence (AI). Accelerating AI can be achieved through photonic computing, but it requires nonvolatile photonic memory capable of rapid updates during on-chip training sessions or when new information_         _ More           The integration of computing with memory is essential for distributed, massively parallel, and adaptive architectures such as neural networks in artificial intelligence (AI). Accelerating AI can be achieved through photonic computing, but it requires nonvolatile photonic memory capable of rapid updates during on-chip training sessions or when new information becomes available during deployment. Phase-change materials (PCMs) are promising for providing compact, nonvolatile optical weighting; however, they face limitations in terms of bit precision, programming speed, and cycling endurance. Here, we propose a novel photonic memory cell that merges nonvolatile photonic weighting using PCMs with high-speed, volatile tuning enabled by an integrated PN junction. Our experiments demonstrate that the same PN modulator, fabricated via a foundry compatible process, can achieve dual functionality. It supports coarse programmability for setting initial optical weights and facilitates high-speed fine-tuning to adjust these weights dynamically. The result showcases a 400-fold increase in volatile tuning speed and a 10,000-fold enhancement in efficiency. This multifunctional photonic memory with volatile and nonvolatile capabilities could significantly advance the performance and versatility of photonic memory cells, providing robust solutions for dynamic computing environments.         _ Less","","arXiv","https://arxiv.org/abs/2409.13954","1","0","origin_of_life"
"How to Build the Virtual Cell with Artificial Intelligence: Priorities and Opportunities","Abstract:                The cell is arguably the most fundamental unit of life and is central to understanding biology. Accurate modeling of_         _ More           The cell is arguably the most fundamental unit of life and is central to understanding biology. Accurate modeling of cells is important for this understanding as well as for determining the root causes of disease. Recent advances in artificial intelligence (AI), combined with the ability to generate large-scale experimental data, present novel opportunities to model cells. Here we propose a vision of leveraging advances in AI to construct virtual cells, high-fidelity simulations of cells and cellular systems under different conditions that are directly learned from biological data across measurements and scales. We discuss desired capabilities of such AI Virtual Cells, including generating universal representations of biological entities across scales, and facilitating interpretable in silico experiments to predict and understand their behavior using virtual instruments. We further address the challenges, opportunities and requirements to realize this vision including data needs, evaluation strategies, and community standards and engagement to ensure biological accuracy and broad utility. We envision a future where AI Virtual Cells help identify new drug targets, predict cellular responses to perturbations, as well as scale hypothesis exploration. With open science collaborations across the biomedical ecosystem that includes academia, philanthropy, and the biopharma and AI industries, a comprehensive predictive understanding of cell mechanisms and interactions has come into reach.         _ Less","","arXiv","https://arxiv.org/abs/2409.11654","1","1","multiple"
"A Semantic Segmentation Approach on Sweet Orange Leaf Diseases Detection Utilizing YOLO","Abstract:                This research introduces an advanced method for diagnosing diseases in sweet orange leaves by utilising advanced artificial intelligence models like YOLOv8 . Due to their significance as a vital agricultural product, sweet oranges encounter significant threats from a variety of diseases that harmfully affect both their yield and quality. Conventional methods_         _ More           This research introduces an advanced method for diagnosing diseases in sweet orange leaves by utilising advanced artificial intelligence models like YOLOv8 . Due to their significance as a vital agricultural product, sweet oranges encounter significant threats from a variety of diseases that harmfully affect both their yield and quality. Conventional methods for disease detection primarily depend on manual inspection which is ineffective and frequently leads to errors, resulting in delayed treatment and increased financial losses. In response to this challenge, the research utilized YOLOv8 , harnessing their proficiencies in detecting objects and analyzing images. YOLOv8 is recognized for its rapid and precise performance, while VIT is acknowledged for its detailed feature extraction abilities. Impressively, during both the training and validation stages, YOLOv8 exhibited a perfect accuracy of 80.4%, while VIT achieved an accuracy of 99.12%, showcasing their potential to transform disease detection in agriculture. The study comprehensively examined the practical challenges related to the implementation of AI technologies in agriculture, encompassing the computational demands and user accessibility, and offering viable solutions for broader usage. Moreover, it underscores the environmental considerations, particularly the potential for reduced pesticide usage, thereby promoting sustainable farming and environmental conservation. These findings provide encouraging insights into the application of AI in agriculture, suggesting a transition towards more effective, sustainable, and technologically advanced farming methods. This research not only highlights the efficacy of YOLOv8 within a specific agricultural domain but also lays the foundation for further studies that encompass a broader application in crop management and sustainable agricultural practices.         _ Less","","arXiv","https://arxiv.org/abs/2409.06671","1","1","multiple"
"CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities","Abstract:                _prone to human error. This study introduces CerviXpert, a multi-structural convolutional neural network model designed to efficiently classify cervix types and detect cervical cell abnormalities. CerviXpert is built as a computationally efficient model that classifies cervical cancer using images from the publicly available SiPaKMeD dataset. The model archit_         _ More           Cervical cancer is a major cause of cancer-related mortality among women worldwide, and its survival rate improves significantly with early detection. Traditional diagnostic methods such as Pap smears and cervical biopsies rely heavily on cytologist expertise, making the process prone to human error. This study introduces CerviXpert, a multi-structural convolutional neural network model designed to efficiently classify cervix types and detect cervical cell abnormalities. CerviXpert is built as a computationally efficient model that classifies cervical cancer using images from the publicly available SiPaKMeD dataset. The model architecture emphasizes simplicity, using a limited number of convolutional layers followed by max pooling and dense layers, trained from scratch.   We assessed the performance of CerviXpert against other state of the art convolutional neural network models including ResNet50, VGG16, MobileNetV2, and InceptionV3, evaluating them on accuracy, computational efficiency, and robustness using five fold cross validation. CerviXpert achieved an accuracy of 98.04 percent in classifying cervical cell abnormalities into three classes and 98.60 percent for five class cervix type classification, outperforming MobileNetV2 and InceptionV3 in both accuracy and computational requirements. It showed comparable results to ResNet50 and VGG16 while reducing computational complexity and resource needs.   CerviXpert provides an effective solution for cervical cancer screening and diagnosis, balancing accuracy with computational efficiency. Its streamlined design enables deployment in resource constrained environments, potentially enhancing early detection and management of cervical cancer.         _ Less","","arXiv","https://arxiv.org/abs/2409.06220","1","1","multiple"
"SIP-IFVM: An efficient time-accurate implicit MHD model of corona and CME with strong magnetic field","Abstract:                _the solar surface to 20 Rs in the background corona of CR 2219. It can finish the CME simulation covering 6 hours of physical time by less than 0.5 hours (192 CPU cores, 1 M cells) without much loss in temporal accuracy. Besides, an ad hoc simulation with initial magnetic fields artificially increased shows that this m_         _ More           CMEs are one of the main drivers of space weather. However, robust and efficient numerical modeling of the initial stages of CME propagation and evolution process in the sub-Alfvenic corona is still lacking. Based on the highly efficient quasi-steady-state implicit MHD coronal model (Feng et al. 2021; Wang et al. 2022a), we further develop an efficient and time-accurate coronal model and employ it to simulate the CME's evolution and propagation. A pseudo-time marching method, where a pseudo time, tau, is introduced at each physical time step to update the solution by solving a steady-state problem on tau, is devised to improve the temporal accuracy. Moreover, an RBSL flux rope whose axis can be designed in an arbitrary shape is inserted into the background corona to trigger the CME event. We call it the SIP-IFVM coronal model and utilize it to simulate a CME evolution process from the solar surface to 20 Rs in the background corona of CR 2219. It can finish the CME simulation covering 6 hours of physical time by less than 0.5 hours (192 CPU cores, 1 M cells) without much loss in temporal accuracy. Besides, an ad hoc simulation with initial magnetic fields artificially increased shows that this model can effectively deal with time-dependent low-beta problems (beta<0.0005). Additionally, an Orszag-Tang MHD vortex flow simulation demonstrates that the pseudo-time-marching method adopted in this coronal model is also capable of simulating small-scale unsteady-state flows. The simulation results show that this MHD coronal model is very efficient and numerically stable and is promising to timely and accurately simulate time-varying events in solar corona with low plasma beta.         _ Less","","arXiv","https://arxiv.org/abs/2409.02022","0","1","synthetic_biology"
"PDDFormer: Pairwise Distance Distribution Graph Transformer for Crystal Material Property Prediction","Abstract:                _to directly apply PDD to crystal material property prediction tasks. To address these challenges, we propose the atom-Weighted Pairwise Distance Distribution (WPDD) and Unit cell Pairwise Distance Distribution (UPDD) for the first time, incorporating them into the construction of multi-edge crystal graphs. Based on this, we further developed WPDDFormer and U_         _ More           The crystal structure can be simplified as a periodic point set repeating across the entire three-dimensional space along an underlying lattice. Traditionally, methods for representing crystals rely on descriptors like lattice parameters, symmetry, and space groups to characterize the structure. However, in reality, atoms in material always vibrate above absolute zero, causing continuous fluctuations in their positions. This dynamic behavior disrupts the underlying periodicity of the lattice, making crystal graphs based on static lattice parameters and conventional descriptors discontinuous under even slight perturbations. To this end, chemists proposed the Pairwise Distance Distribution (PDD) method, which has been used to distinguish all periodic structures in the world's largest real materials collection, the Cambridge Structural Database. However, achieving the completeness of PDD requires defining a large number of neighboring atoms, resulting in high computational costs. Moreover, it does not account for atomic information, making it challenging to directly apply PDD to crystal material property prediction tasks. To address these challenges, we propose the atom-Weighted Pairwise Distance Distribution (WPDD) and Unit cell Pairwise Distance Distribution (UPDD) for the first time, incorporating them into the construction of multi-edge crystal graphs. Based on this, we further developed WPDDFormer and UPDDFormer, graph transformer architecture constructed using WPDD and UPDD crystal graphs. We demonstrate that this method maintains the continuity and completeness of crystal graphs even under slight perturbations in atomic positions.         _ Less","","arXiv","https://arxiv.org/abs/2408.12984","1","0","origin_of_life"
"Cell-ontology guided transcriptome foundation model","Abstract:                Transcriptome foundation models TFMs hold great promises of deciphering the transcriptomic language that dictate diverse cell functions by self-supervised learning on large-scale single-_         _ More           Transcriptome foundation models TFMs hold great promises of deciphering the transcriptomic language that dictate diverse cell functions by self-supervised learning on large-scale single-cell gene expression data, and ultimately unraveling the complex mechanisms of human diseases. However, current TFMs treat cells as independent samples and ignore the taxonomic relationships between cell types, which are available in cell ontology graphs. We argue that effectively leveraging this ontology information during the TFM pre-training can improve learning biologically meaningful gene co-expression patterns while preserving TFM as a general purpose foundation model for downstream zero-shot and fine-tuning tasks. To this end, we present \\textbf{s}ingle \\textbf{c}ell, \\textbf{Cell}-\\textbf{o}ntology guided TFM scCello. We introduce cell-type coherence loss and ontology alignment loss, which are minimized along with the masked gene expression prediction loss during the pre-training. The novel loss component guide scCello to learn the cell-type-specific representation and the structural relation between cell types from the cell ontology graph, respectively. We pre-trained scCello on 22 million cells from CellxGene database leveraging their cell-type labels mapped to the cell ontology graph from Open Biological and Biomedical Ontology Foundry. Our TFM demonstrates competitive generalization and transferability performance over the existing TFMs on biologically important tasks including identifying novel cell types of unseen cells, prediction of cell-type-specific marker genes, and cancer drug responses.         _ Less","","arXiv","https://arxiv.org/abs/2408.12373","1","0","origin_of_life"
"DRExplainer: Quantifiable Interpretability in Drug Response Prediction with Directed Graph Convolutional Network","Abstract:                Predicting the response of a cancer cell line to a therapeutic drug is pivotal for personalized medicine. Despite numerous deep learning methods that have been developed for drug response prediction, integrating diverse information about biological entities and predicting the directional response remain major challenges. Here, we propose a novel interpretabl_         _ More           Predicting the response of a cancer cell line to a therapeutic drug is pivotal for personalized medicine. Despite numerous deep learning methods that have been developed for drug response prediction, integrating diverse information about biological entities and predicting the directional response remain major challenges. Here, we propose a novel interpretable predictive model, DRExplainer, which leverages a directed graph convolutional network to enhance the prediction in a directed bipartite network framework. DRExplainer constructs a directed bipartite network integrating multi-omics profiles of cell lines, the chemical structure of drugs and known drug response to achieve directed prediction. Then, DRExplainer identifies the most relevant subgraph to each prediction in this directed bipartite network by learning a mask, facilitating critical medical decision-making. Additionally, we introduce a quantifiable method for model interpretability that leverages a ground truth benchmark dataset curated from biological features. In computational experiments, DRExplainer outperforms state-of-the-art predictive methods and another graph-based explanation method under the same experimental setting. Finally, the case studies further validate the interpretability and the effectiveness of DRExplainer in predictive novel drug response. Our code is available at: https://github.com/vshy-dream/DRExplainer.         _ Less","","arXiv","https://arxiv.org/abs/2408.12139","1","0","origin_of_life"
"Distributed Noncoherent Joint Transmission Based on Multi-Agent Reinforcement Learning for Dense Small Cell MISO Systems","Abstract:                We consider a dense small cell (DSC) network where multi-antenna small cell base stations (SBSs) transmit data to single-antenna users over a shared frequency band. To enhance capacity, a state-of-the-art technique known as noncoherent joint transmission (JT) is applied, enabling users to receive data from multiple coo_         _ More           We consider a dense small cell (DSC) network where multi-antenna small cell base stations (SBSs) transmit data to single-antenna users over a shared frequency band. To enhance capacity, a state-of-the-art technique known as noncoherent joint transmission (JT) is applied, enabling users to receive data from multiple coordinated SBSs. However, the sum rate maximization problem with noncoherent JT is inherently nonconvex and NP-hard. While existing optimization-based noncoherent JT algorithms can provide near-optimal performance, they require global channel state information (CSI) and multiple iterations, which makes them difficult to be implemeted in DSC networks.To overcome these challenges, we first prove that the optimal beamforming structure is the same for both the power minimization problem and the sum rate maximization problem, and then mathematically derive the optimal beamforming structure for both problems by solving the power minimization problem.The optimal beamforming structure can effectively reduces the variable dimensions.By exploiting the optimal beamforming structure, we propose a deep deterministic policy gradient-based distributed noncoherent JT scheme to maximize the system sum rate.In the proposed scheme, each SBS utilizes global information for training and uses local CSI to determine beamforming vectors. Simulation results demonstrate that the proposed scheme achieves comparable performance with considerably lower computational complexity and information overhead compared to centralized iterative optimization-based techniques, making it more attractive for practical deployment.         _ Less","","arXiv","https://arxiv.org/abs/2408.12067","1","0","origin_of_life"
"Topological Representational Similarity Analysis in Brains and Beyond","Abstract:                Understanding how the brain represents and processes information is crucial for advancing neuroscience and artificial intelligence. Representational similarity analysis (RSA) has been instrumental in characterizing neural representations, but traditional RSA relies solely on geometric properties, overlooking crucial topological information. This thesis intro_         _ More           Understanding how the brain represents and processes information is crucial for advancing neuroscience and artificial intelligence. Representational similarity analysis (RSA) has been instrumental in characterizing neural representations, but traditional RSA relies solely on geometric properties, overlooking crucial topological information. This thesis introduces Topological RSA (tRSA), a novel framework combining geometric and topological properties of neural representations.   tRSA applies nonlinear monotonic transforms to representational dissimilarities, emphasizing local topology while retaining intermediate-scale geometry. The resulting geo-topological matrices enable model comparisons robust to noise and individual idiosyncrasies. This thesis introduces several key methodological advances: (1) Topological RSA (tRSA) for identifying computational signatures and testing topological hypotheses; (2) Adaptive Geo-Topological Dependence Measure (AGTDM) for detecting complex multivariate relationships; (3) Procrustes-aligned Multidimensional Scaling (pMDS) for revealing neural computation stages; (4) Temporal Topological Data Analysis (tTDA) for uncovering developmental trajectories; and (5) Single-cell Topological Simplicial Analysis (scTSA) for characterizing cell population complexity.   Through analyses of neural recordings, biological data, and neural network simulations, this thesis demonstrates the power and versatility of these methods in understanding brains, computational models, and complex biological systems. They not only offer robust approaches for adjudicating among competing models but also reveal novel theoretical insights into the nature of neural computation. This work lays the foundation for future investigations at the intersection of topology, neuroscience, and time series analysis, paving the way for more nuanced understanding of brain function and dysfunction.         _ Less","","arXiv","https://arxiv.org/abs/2408.11948","1","0","origin_of_life"
"5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges","Abstract:                In this paper, we present a novel approach to interference detection in 5G New Radio (5G-NR) networks using Convolutional Neural Networks (CNN). Interference in 5G networks challenges high-quality service due to dense user equipment deployment and increased wireless environment complexity. Our CNN-based model is designed to detect Physical Random Access Channel (PRACH) sequences amidst various int_         _ More           In this paper, we present a novel approach to interference detection in 5G New Radio (5G-NR) networks using Convolutional Neural Networks (CNN). Interference in 5G networks challenges high-quality service due to dense user equipment deployment and increased wireless environment complexity. Our CNN-based model is designed to detect Physical Random Access Channel (PRACH) sequences amidst various interference scenarios, leveraging the spatial and temporal characteristics of PRACH signals to enhance detection accuracy and robustness. Comprehensive datasets of simulated PRACH signals under controlled interference conditions were generated to train and validate the model. Experimental results show that our CNN-based approach outperforms traditional PRACH detection methods in accuracy, precision, recall and F1-score. This study demonstrates the potential of AI/ML techniques in advancing interference management in 5G networks, providing a foundation for future research and practical applications in optimizing network performance and reliability.         _ Less","","arXiv","https://arxiv.org/abs/2408.11659","1","1","multiple"
"An Overlooked Role of Context-Sensitive Dendrites","Abstract:                _with greater implications for ongoing learning and processing in the brain than previously realized. In addition to the FB, the apical tuft receives signals from neighboring cells of the same network as proximal (P) context, other parts of the brain as distal (D) context, and overall coherent information across the network as universal (U) context. The inte_         _ More           To date, most dendritic studies have predominantly focused on the apical zone of pyramidal two-point neurons (TPNs) receiving only feedback (FB) connections from higher perceptual layers and using them for learning. Recent cellular neurophysiology and computational neuroscience studies suggests that the apical input (context), coming from feedback and lateral connections, is multifaceted and far more diverse, with greater implications for ongoing learning and processing in the brain than previously realized. In addition to the FB, the apical tuft receives signals from neighboring cells of the same network as proximal (P) context, other parts of the brain as distal (D) context, and overall coherent information across the network as universal (U) context. The integrated context (C) amplifies and suppresses the transmission of coherent and conflicting feedforward (FF) signals, respectively. Specifically, we show that complex context-sensitive (CS)-TPNs flexibly integrate C moment-by-moment with the FF somatic current at the soma such that the somatic current is amplified when both feedforward (FF) and C are coherent; otherwise, it is attenuated. This generates the event only when the FF and C currents are coherent, which is then translated into a singlet or a burst based on the FB information. Spiking simulation results show that this flexible integration of somatic and contextual currents enables the propagation of more coherent signals (bursts), making learning faster with fewer neurons. Similar behavior is observed when this functioning is used in conventional artificial networks, where orders of magnitude fewer neurons are required to process vast amounts of heterogeneous real-world audio-visual (AV) data trained using backpropagation (BP). The computational findings presented here demonstrate the universality of CS-TPNs, suggesting a dendritic narrative that was previously overlooked.         _ Less","","arXiv","https://arxiv.org/abs/2408.11019","1","0","origin_of_life"
"Single-cell Curriculum Learning-based Deep Graph Embedding Clustering","Abstract:                The swift advancement of single-cell RNA sequencing (scRNA-seq) technologies enables the investigation of cellular-level tissue heterogeneity._         _ More           The swift advancement of single-cell RNA sequencing (scRNA-seq) technologies enables the investigation of cellular-level tissue heterogeneity. Cell annotation significantly contributes to the extensive downstream analysis of scRNA-seq data. However, The analysis of scRNA-seq for biological inference presents challenges owing to its intricate and indeterminate data distribution, characterized by a substantial volume and a high frequency of dropout events. Furthermore, the quality of training samples varies greatly, and the performance of the popular scRNA-seq data clustering solution GNN could be harmed by two types of low-quality training nodes: 1) nodes on the boundary; 2) nodes that contribute little additional information to the graph. To address these problems, we propose a single-cell curriculum learning-based deep graph embedding clustering (scCLG). We first propose a Chebyshev graph convolutional autoencoder with multi-criteria (ChebAE) that combines three optimization objectives, including topology reconstruction loss of cell graphs, zero-inflated negative binomial (ZINB) loss, and clustering loss, to learn cell-cell topology representation. Meanwhile, we employ a selective training strategy to train GNN based on the features and entropy of nodes and prune the difficult nodes based on the difficulty scores to keep the high-quality graph. Empirical results on a variety of gene expression datasets show that our model outperforms state-of-the-art methods. The code of scCLG will be made publicly available at https://github.com/LFD-byte/scCLG.         _ Less","","arXiv","https://arxiv.org/abs/2408.10511","1","0","origin_of_life"
"Dynamic Shaping of Multi-Touch Stimuli by Programmable Acoustic Metamaterial","Abstract:                Acoustic metamaterials are artificial structures, often lattice of resonators, with unusual properties. They can be engineered to stop wave propagation in specific frequency bands. Once manufactured, their dispersive qualities remain invariant in time and space, limiting their practical use. Actively tuned arrangements have received growing interest to addre_         _ More           Acoustic metamaterials are artificial structures, often lattice of resonators, with unusual properties. They can be engineered to stop wave propagation in specific frequency bands. Once manufactured, their dispersive qualities remain invariant in time and space, limiting their practical use. Actively tuned arrangements have received growing interest to address this issue. Here, we introduce a new class of active metamaterial made from dual-state unit cells, either vibration sources when powered or passive resonators when left disconnected. They possess self-tuning capabilities, enabling deep subwavelength band gaps to automatically match the carrier signal of powered cells, typically around 200Hz. Swift electronic commutations between both states establish the basis for real-time reconfiguration of waveguides and shaping of vibration patterns. A series of experiments highlight how these tailored acceleration fields can spatially encode information relevant to human touch. This novel metamaterial can readily be made using off-the-shelf smartphone vibration motors, paving the way for a widespread adoption of multi-touch tactile displays.         _ Less","","arXiv","https://arxiv.org/abs/2408.09829","1","0","origin_of_life"
"In-Memory Learning Automata Architecture using Y-Flash Cell","Abstract:                _uses a new machine learning algorithm, the Tsetlin Machine (TM), for in-memory processing architecture. The TM's learning element, Automaton, is mapped into a single Y-Flash cell, where the Automaton's range is transferred into the Y-Flash's conductance scope. Through comprehensive simulations, the proposed hardware implementation of the learning_         _ More           The modern implementation of machine learning architectures faces significant challenges due to frequent data transfer between memory and processing units. In-memory computing, primarily through memristor-based analog computing, offers a promising solution to overcome this von Neumann bottleneck. In this technology, data processing and storage are located inside the memory. Here, we introduce a novel approach that utilizes floating-gate Y-Flash memristive devices manufactured with a standard 180 nm CMOS process. These devices offer attractive features, including analog tunability and moderate device-to-device variation; such characteristics are essential for reliable decision-making in ML applications. This paper uses a new machine learning algorithm, the Tsetlin Machine (TM), for in-memory processing architecture. The TM's learning element, Automaton, is mapped into a single Y-Flash cell, where the Automaton's range is transferred into the Y-Flash's conductance scope. Through comprehensive simulations, the proposed hardware implementation of the learning automata, particularly for Tsetlin machines, has demonstrated enhanced scalability and on-edge learning capabilities.         _ Less","","arXiv","https://arxiv.org/abs/2408.09456","1","1","multiple"
"A Novel Generative Artificial Intelligence Method for Interference Study on Multiplex Brightfield Immunohistochemistry Images","Abstract:                _same cellular compartment, two representative biomarker sets were selected as assay models - cMET-PDL1-EGFR and CD8-LAG3-PDL1, where all three biomarkers can co-localize on the cell membrane. One of the most crucial preliminary stages for analyzing such assay is identifying each unique chromogen on individual cells. Th_         _ More           Multiplex brightfield imaging offers the advantage of simultaneously analyzing multiple biomarkers on a single slide, as opposed to single biomarker labeling on multiple consecutive slides. To accurately analyze multiple biomarkers localized at the same cellular compartment, two representative biomarker sets were selected as assay models - cMET-PDL1-EGFR and CD8-LAG3-PDL1, where all three biomarkers can co-localize on the cell membrane. One of the most crucial preliminary stages for analyzing such assay is identifying each unique chromogen on individual cells. This is a challenging problem due to the co-localization of membrane stains from all the three biomarkers. It requires advanced color unmixing for creating the equivalent singleplex images from each triplex image for each biomarker.   In this project, we developed a cycle-Generative Adversarial Network (cycle-GAN) method for unmixing the triplex images generated from the above-mentioned assays. Three different models were designed to generate the singleplex image for each of the three stains Tamra (purple), QM-Dabsyl (yellow) and Green. A notable novelty of our approach was that the input to the network were images in the optical density domain instead of conventionally used RGB images. The use of the optical density domain helped in reducing the blurriness of the synthetic singleplex images, which was often observed when the network was trained on RGB images.   The cycle-GAN models were validated on 10,800 lung, gastric and colon images for the cMET-PDL1-EGFR assay and 3600 colon images for the CD8-LAG3-PDL1 assay. Visual as well as quantified assessments demonstrated that the proposed method is effective and efficient when compared with the manual reviewing results and is readily applicable to various multiplex assays.         _ Less","","arXiv","https://arxiv.org/abs/2408.07860","1","1","multiple"
"A POD-TANN approach for the multiscale modeling of materials and macroelement derivation in geomechanics","Abstract:                This paper introduces a novel approach that combines Proper Orthogonal Decomposition (POD) with Thermodynamics-based Artificial Neural Networks (TANN) to capture the macroscopic behavior of complex inelastic systems and derive macroelements in geomechanics.   The methodology leverages POD to extract macroscopic Internal State Variables from microscopic state_         _ More           This paper introduces a novel approach that combines Proper Orthogonal Decomposition (POD) with Thermodynamics-based Artificial Neural Networks (TANN) to capture the macroscopic behavior of complex inelastic systems and derive macroelements in geomechanics.   The methodology leverages POD to extract macroscopic Internal State Variables from microscopic state information, thereby enriching the macroscopic state description used to train an energy potential network within the TANN framework. The thermodynamic consistency provided by TANN, combined with the hierarchical nature of POD, allows to reproduce complex, non-linear inelastic material behaviors as well as macroscopic geomechanical systems responses.   The approach is validated through applications of increasing complexity, demonstrating its capability to reproduce high-fidelity simulation data. The applications proposed include the homogenization of continuous inelastic representative unit cells and the derivation of a macroelement for a geotechnical system involving a monopile in a clay layer subjected to horizontal loading. Eventually, the projection operators directly obtained via POD, are exploit to easily reconstruct the microscopic fields.   The results indicate that the POD-TANN approach not only offers accuracy in reproducing the studied constitutive responses, but also reduces computational costs, making it a practical tool for the multiscale modeling of heterogeneous inelastic geomechanical systems.         _ Less","","arXiv","https://arxiv.org/abs/2408.07165","1","0","origin_of_life"
"2D-OOB: Attributing Data Contribution Through Joint Valuation Framework","Abstract:                _as a powerful framework for quantifying each datum's contribution to the training of a machine learning model. However, it is crucial to recognize that the quality of cells within a single data point can vary greatly in practice. For example, even in the case of an abnormal data point, not all_         _ More           Data valuation has emerged as a powerful framework for quantifying each datum's contribution to the training of a machine learning model. However, it is crucial to recognize that the quality of cells within a single data point can vary greatly in practice. For example, even in the case of an abnormal data point, not all cells are necessarily noisy. The single scalar score assigned by existing data valuation methods blurs the distinction between noisy and clean cells of a data point, making it challenging to interpret the data values. In this paper, we propose 2D-OOB, an out-of-bag estimation framework for jointly determining helpful (or detrimental) samples as well as the particular cells that drive them. Our comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art performance across multiple use cases while being exponentially faster. Specifically, 2D-OOB shows promising results in detecting and rectifying fine-grained outliers at the cell level, and localizing backdoor triggers in data poisoning attacks.         _ Less","","arXiv","https://arxiv.org/abs/2408.03572","1","1","multiple"
"Tabular Data Augmentation for Machine Learning: Progress and Prospects of Embracing Generative AI","Abstract:                _data, and generation-based methods, which generate synthetic data. We further subdivide these methods based on the granularity of the augmentation process at the row, column, cell, and table levels. Post-augmentation focuses on the datasets, evaluation and optimization aspects of TDA. We also summarize current trends and future directions for TDA, highlighti_         _ More           Machine learning (ML) on tabular data is ubiquitous, yet obtaining abundant high-quality tabular data for model training remains a significant obstacle. Numerous works have focused on tabular data augmentation (TDA) to enhance the original table with additional data, thereby improving downstream ML tasks. Recently, there has been a growing interest in leveraging the capabilities of generative AI for TDA. Therefore, we believe it is time to provide a comprehensive review of the progress and future prospects of TDA, with a particular emphasis on the trending generative AI. Specifically, we present an architectural view of the TDA pipeline, comprising three main procedures: pre-augmentation, augmentation, and post-augmentation. Pre-augmentation encompasses preparation tasks that facilitate subsequent TDA, including error handling, table annotation, table simplification, table representation, table indexing, table navigation, schema matching, and entity matching. Augmentation systematically analyzes current TDA methods, categorized into retrieval-based methods, which retrieve external data, and generation-based methods, which generate synthetic data. We further subdivide these methods based on the granularity of the augmentation process at the row, column, cell, and table levels. Post-augmentation focuses on the datasets, evaluation and optimization aspects of TDA. We also summarize current trends and future directions for TDA, highlighting promising opportunities in the era of generative AI. In addition, the accompanying papers and related resources are continuously updated and maintained in the GitHub repository at https://github.com/SuDIS-ZJU/awesome-tabular-data-augmentation to reflect ongoing advancements in the field.         _ Less","","arXiv","https://arxiv.org/abs/2407.21523","2","2","multiple"
"Knowledge Models for Cancer Clinical Practice Guidelines : Construction, Management and Usage in Question Answering","Abstract:                _base to study our ability to query the knowledge models. We compiled a set of 32 question-answer pairs derived from two reliable data sources for the treatment of Non-Small Cell Lung Cancer (NSCLC) to evaluate the Q&A framework. The framework was evaluated against the question-answer pairs from one data source, and it can generate the answers with 54.5%_         _ More           An automated knowledge modeling algorithm for Cancer Clinical Practice Guidelines (CPGs) extracts the knowledge contained in the CPG documents and transforms it into a programmatically interactable, easy-to-update structured model with minimal human intervention. The existing automated algorithms have minimal scope and cannot handle the varying complexity of the knowledge content in the CPGs for different cancer types. This work proposes an improved automated knowledge modeling algorithm to create knowledge models from the National Comprehensive Cancer Network (NCCN) CPGs in Oncology for different cancer types. The proposed algorithm has been evaluated with NCCN CPGs for four different cancer types. We also proposed an algorithm to compare the knowledge models for different versions of a guideline to discover the specific changes introduced in the treatment protocol of a new version. We created a question-answering (Q&A) framework with the guideline knowledge models as the augmented knowledge base to study our ability to query the knowledge models. We compiled a set of 32 question-answer pairs derived from two reliable data sources for the treatment of Non-Small Cell Lung Cancer (NSCLC) to evaluate the Q&A framework. The framework was evaluated against the question-answer pairs from one data source, and it can generate the answers with 54.5% accuracy from the treatment algorithm and 81.8% accuracy from the discussion part of the NCCN NSCLC guideline knowledge model.         _ Less","","arXiv","https://arxiv.org/abs/2407.21053","1","1","multiple"
"Predicting the Progression of Cancerous Tumors in Mice: A Machine and Deep Learning Intuition","Abstract:                The study explores Artificial Intelligence (AI) powered modeling to predict the evolution of cancer tumor_         _ More           The study explores Artificial Intelligence (AI) powered modeling to predict the evolution of cancer tumor cells in mice under different forms of treatment. The AI models are analyzed against varying ambient and systemic parameters, e.g. drug dosage, volume of the cancer cell mass, and time taken to destroy the cancer cell mass. The data required for the analysis have been synthetically extracted from plots available in both published and unpublished literature (primarily using a Matlab architecture called 'Grabit'), that are then statistically standardized around the same baseline for comparison. Three forms of treatment are considered - saline (multiple concentrations used), magnetic nanoparticles (mNPs) and fluorodeoxyglycose iron oxide magnetic nanoparticles (mNP-FDGs) - analyzed using three Machine Learning (ML) algorithms, Decision Tree (DT), Random Forest (RF), Multilinear Regression (MLR), and a Deep Learning (DL) module, the Adaptive Neural Network (ANN). The AI models are trained on 60-80% data, the rest used for validation. Assessed over all three forms of treatment, ANN consistently outperforms other predictive models. Our models predict mNP-FDG as the most potent treatment regime that kills the cancerous tumor completely in ca 13 days from the start of treatment. The models can be generalized to other forms of cancer treatment regimens.         _ Less","","arXiv","https://arxiv.org/abs/2407.19277","0","1","synthetic_biology"
"A Survey on Cell Nuclei Instance Segmentation and Classification: Leveraging Context and Attention","Abstract:                Manually annotating nuclei from the gigapixel Hematoxylin and Eosin (H&E)-stained Whole Slide Images (WSIs) is a laborious and costly task, meaning automated algorithms for cell nuclei instance segmentation and classification could alleviate the workload of pathologists and clinical researchers and at the same time facilitate the automatic extraction of_         _ More           Manually annotating nuclei from the gigapixel Hematoxylin and Eosin (H&E)-stained Whole Slide Images (WSIs) is a laborious and costly task, meaning automated algorithms for cell nuclei instance segmentation and classification could alleviate the workload of pathologists and clinical researchers and at the same time facilitate the automatic extraction of clinically interpretable features. But due to high intra- and inter-class variability of nuclei morphological and chromatic features, as well as H&E-stains susceptibility to artefacts, state-of-the-art algorithms cannot correctly detect and classify instances with the necessary performance. In this work, we hypothesise context and attention inductive biases in artificial neural networks (ANNs) could increase the generalization of algorithms for cell nuclei instance segmentation and classification. We conduct a thorough survey on context and attention methods for cell nuclei instance segmentation and classification from H&E-stained microscopy imaging, while providing a comprehensive discussion of the challenges being tackled with context and attention. Besides, we illustrate some limitations of current approaches and present ideas for future research. As a case study, we extend both a general instance segmentation and classification method (Mask-RCNN) and a tailored cell nuclei instance segmentation and classification model (HoVer-Net) with context- and attention-based mechanisms, and do a comparative analysis on a multi-centre colon nuclei identification and counting dataset. Although pathologists rely on context at multiple levels while paying attention to specific Regions of Interest (RoIs) when analysing and annotating WSIs, our findings suggest translating that domain knowledge into algorithm design is no trivial task, but to fully exploit these mechanisms, the scientific understanding of these methods should be addressed.         _ Less","","arXiv","https://arxiv.org/abs/2407.18673","2","2","multiple"
"FMDNN: A Fuzzy-guided Multi-granular Deep Neural Network for Histopathological Image Classification","Abstract:                _significance for early disease detection and treatment. In the diagnostic process of pathologists, a multi-tiered approach is typically employed to assess abnormalities in cell regions at different magnifications. However, feature extraction is often performed at a single granularity, overlooking the multi-granular characteristics of_         _ More           Histopathological image classification constitutes a pivotal task in computer-aided diagnostics. The precise identification and categorization of histopathological images are of paramount significance for early disease detection and treatment. In the diagnostic process of pathologists, a multi-tiered approach is typically employed to assess abnormalities in cell regions at different magnifications. However, feature extraction is often performed at a single granularity, overlooking the multi-granular characteristics of cells. To address this issue, we propose the Fuzzy-guided Multi-granularity Deep Neural Network (FMDNN). Inspired by the multi-granular diagnostic approach of pathologists, we perform feature extraction on cell structures at coarse, medium, and fine granularity, enabling the model to fully harness the information in histopathological images. We incorporate the theory of fuzzy logic to address the challenge of redundant key information arising during multi-granular feature extraction. Cell features are described from different perspectives using multiple fuzzy membership functions, which are fused to create universal fuzzy features. A fuzzy-guided cross-attention module guides universal fuzzy features toward multi-granular features. We propagate these features through an encoder to all patch tokens, aiming to achieve enhanced classification accuracy and robustness. In experiments on multiple public datasets, our model exhibits a significant improvement in accuracy over commonly used classification methods for histopathological image classification and shows commendable interpretability.         _ Less","","arXiv","https://arxiv.org/abs/2407.15312","1","0","origin_of_life"
"Improving Health Information Access in the World's Largest Maternal Mobile Health Program via Bandit Algorithms","Abstract:                Harnessing the wide-spread availability of cell phones, many nonprofits have launched mobile health (mHealth) programs to deliver information via voice or text to beneficiaries in underserved communities, with maternal and infant health being a key area of such mHealth programs. Unfortunately, dwindling listenership is a major challenge, requiring targeted i_         _ More           Harnessing the wide-spread availability of cell phones, many nonprofits have launched mobile health (mHealth) programs to deliver information via voice or text to beneficiaries in underserved communities, with maternal and infant health being a key area of such mHealth programs. Unfortunately, dwindling listenership is a major challenge, requiring targeted interventions using limited resources. This paper focuses on Kilkari, the world's largest mHealth program for maternal and child care - with over 3 million active subscribers at a time - launched by India's Ministry of Health and Family Welfare (MoHFW) and run by the non-profit ARRMAN. We present a system called CHAHAK that aims to reduce automated dropouts as well as boost engagement with the program through the strategic allocation of interventions to beneficiaries. Past work in a similar domain has focused on a much smaller scale mHealth program and used markovian restless multiarmed bandits to optimize a single limited intervention resource. However this paper demonstrates the challenges in adopting a markovian approach in Kilkari; therefore CHAHAK instead relies on non-markovian time-series restless bandits, and optimizes multiple interventions to improve listenership. We use real Kilkari data from the Odisha state in India to show CHAHAK's effectiveness in harnessing multiple interventions to boost listenership, benefiting marginalized communities. When deployed CHAHAK will assist the largest maternal mHealth program to date.         _ Less","","arXiv","https://arxiv.org/abs/2407.12131","1","0","origin_of_life"
"Artificial intelligence and machine learning applications for cultured meat","Abstract:                _to date on the use of machine learning in cultured meat and explores future possibilities. We address four major areas of cultured meat research and development: establishing cell lines, cell culture media design, microscopy and image analysis, and bioprocessing and food processing optimization. This review aims to pro_         _ More           Cultured meat has the potential to provide a complementary meat industry with reduced environmental, ethical, and health impacts. However, major technological challenges remain which require time- and resource-intensive research and development efforts. Machine learning has the potential to accelerate cultured meat technology by streamlining experiments, predicting optimal results, and reducing experimentation time and resources. However, the use of machine learning in cultured meat is in its infancy. This review covers the work available to date on the use of machine learning in cultured meat and explores future possibilities. We address four major areas of cultured meat research and development: establishing cell lines, cell culture media design, microscopy and image analysis, and bioprocessing and food processing optimization. This review aims to provide the foundation necessary for both cultured meat and machine learning scientists to identify research opportunities at the intersection between cultured meat and machine learning.         _ Less","","arXiv","https://arxiv.org/abs/2407.09982","1","1","multiple"
"CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell Data Analysis","Abstract:                Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for biological research, as it enables the precise characterization of cellular heterogeneity. However, manual manipulation of various tools to achieve desired outcomes can be labor-intensive for researchers. To address this, we introduce CellAgent (http://cell.agent4science.cn/), an LLM-driven_         _ More           Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for biological research, as it enables the precise characterization of cellular heterogeneity. However, manual manipulation of various tools to achieve desired outcomes can be labor-intensive for researchers. To address this, we introduce CellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework, specifically designed for the automatic processing and execution of scRNA-seq data analysis tasks, providing high-quality results with no human intervention. Firstly, to adapt general LLMs to the biological field, CellAgent constructs LLM-driven biological expert roles - planner, executor, and evaluator - each with specific responsibilities. Then, CellAgent introduces a hierarchical decision-making mechanism to coordinate these biological experts, effectively driving the planning and step-by-step execution of complex data analysis tasks. Furthermore, we propose a self-iterative optimization mechanism, enabling CellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing output quality. We evaluate CellAgent on a comprehensive benchmark dataset encompassing dozens of tissues and hundreds of distinct cell types. Evaluation results consistently show that CellAgent effectively identifies the most suitable tools and hyperparameters for single-cell analysis tasks, achieving optimal performance. This automated framework dramatically reduces the workload for science data analyses, bringing us into the 'Agent for Science' era.         _ Less","","arXiv","https://arxiv.org/abs/2407.09811","1","1","multiple"
"Multimodal contrastive learning for spatial gene expression prediction using histology images","Abstract:                _cost of ST technology remains a significant barrier to its widespread adoption in large-scale studies. An alternative, more cost-effective strategy involves employing artificial intelligence to predict gene expression levels using readily accessible whole-slide images (WSIs) stained with Hematoxylin and Eosin (H\\&E). However, existing methods have yet to_         _ More           In recent years, the advent of spatial transcriptomics (ST) technology has unlocked unprecedented opportunities for delving into the complexities of gene expression patterns within intricate biological systems. Despite its transformative potential, the prohibitive cost of ST technology remains a significant barrier to its widespread adoption in large-scale studies. An alternative, more cost-effective strategy involves employing artificial intelligence to predict gene expression levels using readily accessible whole-slide images (WSIs) stained with Hematoxylin and Eosin (H\\&E). However, existing methods have yet to fully capitalize on multimodal information provided by H&E images and ST data with spatial location. In this paper, we propose \\textbf{mclSTExp}, a multimodal contrastive learning with Transformer and Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We conceptualize each spot as a 'word', integrating its intrinsic features with spatial context through the self-attention mechanism of a Transformer encoder. This integration is further enriched by incorporating image features via contrastive learning, thereby enhancing the predictive capability of our model. Our extensive evaluation of \\textbf{mclSTExp} on two breast cancer datasets and a skin squamous cell carcinoma dataset demonstrates its superior performance in predicting spatial gene expression. Moreover, mclSTExp has shown promise in interpreting cancer-specific overexpressed genes, elucidating immune-related genes, and identifying specialized spatial domains annotated by pathologists. Our source code is available at https://github.com/shizhiceng/mclSTExp.         _ Less","","arXiv","https://arxiv.org/abs/2407.08216","1","0","origin_of_life"
"Higher-Order Spatial Information for Self-Supervised Place Cell Learning","Abstract:                Mammals navigate novel environments and exhibit resilience to sparse environmental sensory cues via place and grid cells, which encode position in space. While the efficiency of grid_         _ More           Mammals navigate novel environments and exhibit resilience to sparse environmental sensory cues via place and grid cells, which encode position in space. While the efficiency of grid cell coding has been extensively studied, the computational role of place cells is less well understood. This gap arises partially because spatial information measures have, until now, been limited to single place cells. We derive and implement a higher-order spatial information measure, allowing for the study of the emergence of multiple place cells in a self-supervised manner. We show that emergent place cells have many desirable features, including high-accuracy spatial decoding. This is the first work in which higher-order spatial information measures that depend solely on place cells' firing rates have been derived and which focuses on the emergence of multiple place cells via self-supervised learning. By quantifying the spatial information of multiple place cells, we enhance our understanding of place cell formation and capabilities in recurrent neural networks, thereby improving the potential navigation capabilities of artificial systems in novel environments without objective location information.         _ Less","","arXiv","https://arxiv.org/abs/2407.06195","2","0","origin_of_life"
"Multi-Texture Synthesis through Signal Responsive Neural Cellular Automata","Abstract:                _texture. In this work, we train a single NCA for the evolution of multiple textures, based on individual examples. Our solution provides texture information in the state of each cell, in the form of an internally coded genomic signal, which enables the NCA to generate the expected texture. Such a neural cellular automaton not only maintains its regenerative_         _ More           Neural Cellular Automata (NCA) have proven to be effective in a variety of fields, with numerous biologically inspired applications. One of the fields, in which NCAs perform well is the generation of textures, modelling global patterns from local interactions governed by uniform and coherent rules. This paper aims to enhance the usability of NCAs in texture synthesis by addressing a shortcoming of current NCA architectures for texture generation, which requires separately trained NCA for each individual texture. In this work, we train a single NCA for the evolution of multiple textures, based on individual examples. Our solution provides texture information in the state of each cell, in the form of an internally coded genomic signal, which enables the NCA to generate the expected texture. Such a neural cellular automaton not only maintains its regenerative capability but also allows for interpolation between learned textures and supports grafting techniques. This demonstrates the ability to edit generated textures and the potential for them to merge and coexist within the same automaton. We also address questions related to the influence of the genomic information and the cost function on the evolution of the NCA.         _ Less","","arXiv","https://arxiv.org/abs/2407.05991","1","1","multiple"
"AI-Driven Mobility Management for High-Speed Railway Communications: Compressed Measurements and Proactive Handover","Abstract:                _the signaling overhead, and reduces the system throughput, making it difficult to meet the growing and stringent needs of HSR applications. In this article, we explore artificial intelligence (AI)-based beam-level and cell-level mobility management suitable for HSR communications. Particularly, we propose a compressed_         _ More           High-speed railway (HSR) communications are pivotal for ensuring rail safety, operations, maintenance, and delivering passenger information services. The high speed of trains creates rapidly time-varying wireless channels, increases the signaling overhead, and reduces the system throughput, making it difficult to meet the growing and stringent needs of HSR applications. In this article, we explore artificial intelligence (AI)-based beam-level and cell-level mobility management suitable for HSR communications. Particularly, we propose a compressed spatial multi-beam measurements scheme via compressive sensing for beam-level mobility management in HSR communications. In comparison to traditional down-sampling spatial beam measurements, this method leads to improved spatial-temporal beam prediction accuracy with the same measurement overhead. Moreover, we propose a novel AI-based proactive handover scheme to predict handover events and reduce radio link failure (RLF) rates in HSR communications. Compared with the traditional event A3-based handover mechanism, the proposed approach significantly reduces the RLF rates which saves 50% beam measurement overhead.         _ Less","","arXiv","https://arxiv.org/abs/2407.04336","1","0","origin_of_life"
"An Organism Starts with a Single Pix-Cell: A Neural Cellular Diffusion for High-Resolution Image Synthesis","Abstract:                _remains largely untapped. In this paper, we introduce a novel family of models termed Generative Cellular Automata (GeCA), inspired by the evolution of an organism from a single cell. GeCAs are evaluated as an effective augmentation tool for retinal disease classification across two imaging modalities: Fundus and Optical Coherence Tomography (OCT). In the co_         _ More           Generative modeling seeks to approximate the statistical properties of real data, enabling synthesis of new data that closely resembles the original distribution. Generative Adversarial Networks (GANs) and Denoising Diffusion Probabilistic Models (DDPMs) represent significant advancements in generative modeling, drawing inspiration from game theory and thermodynamics, respectively. Nevertheless, the exploration of generative modeling through the lens of biological evolution remains largely untapped. In this paper, we introduce a novel family of models termed Generative Cellular Automata (GeCA), inspired by the evolution of an organism from a single cell. GeCAs are evaluated as an effective augmentation tool for retinal disease classification across two imaging modalities: Fundus and Optical Coherence Tomography (OCT). In the context of OCT imaging, where data is scarce and the distribution of classes is inherently skewed, GeCA significantly boosts the performance of 11 different ophthalmological conditions, achieving a 12% increase in the average F1 score compared to conventional baselines. GeCAs outperform both diffusion methods that incorporate UNet or state-of-the art variants with transformer-based denoising models, under similar parameter constraints. Code is available at: https://github.com/xmed-lab/GeCA.         _ Less","","arXiv","https://arxiv.org/abs/2407.03018","0","1","synthetic_biology"
"SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images","Abstract:                _patients. We evaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas (TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal clear cell carcinoma (KIRC). Our experimental results indicate that SCMIL outperforms current state-of-the-art methods for survival prediction, offering more clinically meaningful and interpretable_         _ More           Cancer survival prediction is a challenging task that involves analyzing of the tumor microenvironment within Whole Slide Image (WSI). Previous methods cannot effectively capture the intricate interaction features among instances within the local area of WSI. Moreover, existing methods for cancer survival prediction based on WSI often fail to provide better clinically meaningful predictions. To overcome these challenges, we propose a Sparse Context-aware Multiple Instance Learning (SCMIL) framework for predicting cancer survival probability distributions. SCMIL innovatively segments patches into various clusters based on their morphological features and spatial location information, subsequently leveraging sparse self-attention to discern the relationships between these patches with a context-aware perspective. Considering many patches are irrelevant to the task, we introduce a learnable patch filtering module called SoftFilter, which ensures that only interactions between task-relevant patches are considered. To enhance the clinical relevance of our prediction, we propose a register-based mixture density network to forecast the survival probability distribution for individual patients. We evaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas (TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal clear cell carcinoma (KIRC). Our experimental results indicate that SCMIL outperforms current state-of-the-art methods for survival prediction, offering more clinically meaningful and interpretable outcomes. Our code is accessible at https://github.com/yang-ze-kang/SCMIL.         _ Less","","arXiv","https://arxiv.org/abs/2407.00664","1","0","origin_of_life"
"Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques","Abstract:                _Many studies have focused on specific features without exploring more comprehensive approaches. In our case, we formulate a deep learning technique for malaria-infected cell classification using traditional CNNs and transfer learning models notably VGG19, InceptionV3, and Xception. The models were trained using NIH datasets and tested using different perfor_         _ More           Malaria parasites pose a significant global health burden, causing widespread suffering and mortality. Detecting malaria infection accurately is crucial for effective treatment and control. However, existing automated detection techniques have shown limitations in terms of accuracy and generalizability. Many studies have focused on specific features without exploring more comprehensive approaches. In our case, we formulate a deep learning technique for malaria-infected cell classification using traditional CNNs and transfer learning models notably VGG19, InceptionV3, and Xception. The models were trained using NIH datasets and tested using different performance metrics such as accuracy, precision, recall, and F1-score. The test results showed that deep CNNs achieved the highest accuracy -- 97%, followed by Xception with an accuracy of 95%. A machine learning model SVM achieved an accuracy of 83%, while an Inception-V3 achieved an accuracy of 94%. Furthermore, the system can be accessed through a web interface, where users can upload blood smear images for malaria detection.         _ Less","","arXiv","https://arxiv.org/abs/2407.00120","1","1","multiple"
"Gaussian process-based online health monitoring and fault analysis of lithium-ion battery systems from field data","Abstract:                _separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232_         _ More           Health monitoring, fault analysis, and detection are critical for the safe and sustainable operation of battery systems. We apply Gaussian process resistance models on lithium iron phosphate battery field data to effectively separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232 cells and 131 million data rows. We develop probabilistic fault detection rules using recursive spatiotemporal Gaussian processes. These processes allow the quick processing of over a million data points, enabling advanced online monitoring and furthering the understanding of battery pack failure in the field. The analysis underlines that often, only a single cell shows abnormal behavior or a knee point, consistent with weakest-link failure for cells connected in series, amplified by local resistive heating. The results further the understanding of how batteries degrade and fail in the field and demonstrate the potential of efficient online monitoring based on data. We open-source the code and publish the large data set upon completion of the review of this article.         _ Less","","arXiv","https://arxiv.org/abs/2406.19015","1","1","multiple"
"A Diagnostic Model for Acute Lymphoblastic Leukemia Using Metaheuristics and Deep Learning Methods","Abstract:                Acute lymphoblastic leukemia (ALL) severity is determined by the presence and ratios of blast cells (abnormal white blood_         _ More           Acute lymphoblastic leukemia (ALL) severity is determined by the presence and ratios of blast cells (abnormal white blood cells) in both bone marrow and peripheral blood. Manual diagnosis of this disease is a tedious and time-consuming operation, making it difficult for professionals to accurately examine blast cell characteristics. To address this difficulty, researchers use deep learning and machine learning. In this paper, a ResNet-based feature extractor is utilized to detect ALL, along with a variety of feature selectors and classifiers. To get the best results, a variety of transfer learning models, including the Resnet, VGG, EfficientNet, and DensNet families, are used as deep feature extractors. Following extraction, different feature selectors are used, including Genetic algorithm, PCA, ANOVA, Random Forest, Univariate, Mutual information, Lasso, XGB, Variance, and Binary ant colony. After feature qualification, a variety of classifiers are used, with MLP outperforming the others. The recommended technique is used to categorize ALL and HEM in the selected dataset which is C-NMC 2019. This technique got an impressive 90.71% accuracy and 95.76% sensitivity for the relevant classifications, and its metrics on this dataset outperformed others.         _ Less","","arXiv","https://arxiv.org/abs/2406.18568","1","0","origin_of_life"
"Causal Learning in Biomedical Applications: A Benchmark","Abstract:                Learning causal relationships between a set of variables is a challenging problem in computer science. Many existing artificial benchmark datasets are based on sampling from causal models and thus contain residual information that the ${R} ^2$-sortability can identify. Here, we present a benchmark for methods in causal learning using time series. The present_         _ More           Learning causal relationships between a set of variables is a challenging problem in computer science. Many existing artificial benchmark datasets are based on sampling from causal models and thus contain residual information that the ${R} ^2$-sortability can identify. Here, we present a benchmark for methods in causal learning using time series. The presented dataset is not ${R}^2$-sortable and is based on a real-world scenario of the Krebs cycle that is used in cells to release energy. We provide four scenarios of learning, including short and long time series, and provide guidance so that testing is unified between possible users.         _ Less","","arXiv","https://arxiv.org/abs/2406.15189","1","0","origin_of_life"
"Development and Validation of Fully Automatic Deep Learning-Based Algorithms for Immunohistochemistry Reporting of Invasive Breast Ductal Carcinoma","Abstract:                _removing artifacts and scores based on Allred standard. The system is developed using 3 million pathologist-annotated image patches from 300 slides, fifty thousand in-house cell annotations, and forty thousand pixels marking of HER2 membrane. We have conducted multicentric trials at four centers with three different types of digital scanners in terms of perc_         _ More           Immunohistochemistry (IHC) analysis is a well-accepted and widely used method for molecular subtyping, a procedure for prognosis and targeted therapy of breast carcinoma, the most common type of tumor affecting women. There are four molecular biomarkers namely progesterone receptor (PR), estrogen receptor (ER), antigen Ki67, and human epidermal growth factor receptor 2 (HER2) whose assessment is needed under IHC procedure to decide prognosis as well as predictors of response to therapy. However, IHC scoring is based on subjective microscopic examination of tumor morphology and suffers from poor reproducibility, high subjectivity, and often incorrect scoring in low-score cases. In this paper, we present, a deep learning-based semi-supervised trained, fully automatic, decision support system (DSS) for IHC scoring of invasive ductal carcinoma. Our system automatically detects the tumor region removing artifacts and scores based on Allred standard. The system is developed using 3 million pathologist-annotated image patches from 300 slides, fifty thousand in-house cell annotations, and forty thousand pixels marking of HER2 membrane. We have conducted multicentric trials at four centers with three different types of digital scanners in terms of percentage agreement with doctors. And achieved agreements of 95, 92, 88 and 82 percent for Ki67, HER2, ER, and PR stain categories, respectively. In addition to overall accuracy, we found that there is 5 percent of cases where pathologist have changed their score in favor of algorithm score while reviewing with detailed algorithmic analysis. Our approach could improve the accuracy of IHC scoring and subsequent therapy decisions, particularly where specialist expertise is unavailable. Our system is highly modular. The proposed algorithm modules can be used to develop DSS for other cancer types.         _ Less","","arXiv","https://arxiv.org/abs/2406.10893","1","2","synthetic_biology"
"Ab Initio Structure Solutions from Nanocrystalline Powder Diffraction Data","Abstract:                _on diffusion processes that is trained on 45,229 known structures. The model factors both the measured diffraction pattern as well as relevant statistical priors on the unit cell of atomic cluster structures. Conditioned only on the chemical formula and the information-scarce finite-size broadened powder diffraction pattern, we find that our model, PXRDnet,_         _ More           A major challenge in materials science is the determination of the structure of nanometer sized objects. Here we present a novel approach that uses a generative machine learning model based on diffusion processes that is trained on 45,229 known structures. The model factors both the measured diffraction pattern as well as relevant statistical priors on the unit cell of atomic cluster structures. Conditioned only on the chemical formula and the information-scarce finite-size broadened powder diffraction pattern, we find that our model, PXRDnet, can successfully solve simulated nanocrystals as small as 10 angstroms across 200 materials of varying symmetry and complexity, including structures from all seven crystal systems. We show that our model can successfully and verifiably determine structural candidates four out of five times, with average error among these candidates being only 7% (as measured by post-Rietveld refinement R-factor). Furthermore, PXRDnet is capable of solving structures from noisy diffraction patterns gathered in real-world experiments. We suggest that data driven approaches, bootstrapped from theoretical simulation, will ultimately provide a path towards determining the structure of previously unsolved nano-materials.         _ Less","","arXiv","https://arxiv.org/abs/2406.10796","1","0","origin_of_life"
"AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images","Abstract:                _support to clinical experts, as manual annotation is time-consuming and prone to human errors. However, automating nuclei segmentation presents challenges due to uncertain cell boundaries, intricate staining, and diverse structures. In this paper, we present a segmentation approach that combines the U-Net architecture with a DenseNet-121 backbone, harnessing_         _ More           Accurate nuclei segmentation in histopathological images is crucial for cancer diagnosis. Automating this process offers valuable support to clinical experts, as manual annotation is time-consuming and prone to human errors. However, automating nuclei segmentation presents challenges due to uncertain cell boundaries, intricate staining, and diverse structures. In this paper, we present a segmentation approach that combines the U-Net architecture with a DenseNet-121 backbone, harnessing the strengths of both to capture comprehensive contextual and spatial information. Our model introduces the Wavelet-guided channel attention module to enhance cell boundary delineation, along with a learnable weighted global attention module for channel-specific attention. The decoder module, composed of an upsample block and convolution block, further refines segmentation in handling staining patterns. The experimental results conducted on two publicly accessible histopathology datasets, namely Monuseg and TNBC, underscore the superiority of our proposed model, demonstrating its potential to advance histopathological image analysis and cancer diagnosis. The code is made available at: https://github.com/AyushRoy2001/AWGUNET.         _ Less","","arXiv","https://arxiv.org/abs/2406.08425","2","1","origin_of_life"
"Modeling PROTAC Degradation Activity with Machine Learning","Abstract:                PROTACs are a promising therapeutic modality that harnesses the cell's built-in degradation machinery to degrade specific proteins. Despite their potential, developing new PROTACs is challenging and requires significant domain expertise, time, and cost. Meanwhile, machine learning has transformed drug design and development. In this work, we present a st_         _ More           PROTACs are a promising therapeutic modality that harnesses the cell's built-in degradation machinery to degrade specific proteins. Despite their potential, developing new PROTACs is challenging and requires significant domain expertise, time, and cost. Meanwhile, machine learning has transformed drug design and development. In this work, we present a strategy for curating open-source PROTAC data and an open-source deep learning tool for predicting the degradation activity of novel PROTAC molecules. The curated dataset incorporates important information such as $pDC_{50}$, $D_{max}$, E3 ligase type, POI amino acid sequence, and experimental cell type. Our model architecture leverages learned embeddings from pretrained machine learning models, in particular for encoding protein sequences and cell type information. We assessed the quality of the curated data and the generalization ability of our model architecture against new PROTACs and targets via three tailored studies, which we recommend other researchers to use in evaluating their degradation activity models. In each study, three models predict protein degradation in a majority vote setting, reaching a top test accuracy of 80.8% and 0.865 ROC AUC, and a test accuracy of 62.3% and 0.604 ROC AUC when generalizing to novel protein targets. Our results are not only comparable to state-of-the-art models for protein degradation prediction, but also part of an open-source implementation which is easily reproducible and less computationally complex than existing approaches.         _ Less","","arXiv","https://arxiv.org/abs/2406.02637","1","0","origin_of_life"
"COVID-19: post infection implications in different age groups, mechanism, diagnosis, effective prevention, treatment, and recommendations","Abstract:                _the gold standard for detecting COVID-19, though it requires specialized equipment, skilled personnel, and considerable time to produce results. To address these limitations, artificial intelligence in imaging and microfluidics technologies offers promising alternatives for diagnosing COVID-19 efficiently. Pharmacological and non-pharmacological strategies a_         _ More           SARS-CoV-2, the highly contagious pathogen responsible for the COVID-19 pandemic, has persistent effects that begin four weeks after initial infection and last for an undetermined duration. These chronic effects are more harmful than acute ones. This review explores the long-term impact of the virus on various human organs, including the pulmonary, cardiovascular, neurological, reproductive, gastrointestinal, musculoskeletal, endocrine, and lymphoid systems, particularly in older adults. Regarding diagnosis, RT-PCR is the gold standard for detecting COVID-19, though it requires specialized equipment, skilled personnel, and considerable time to produce results. To address these limitations, artificial intelligence in imaging and microfluidics technologies offers promising alternatives for diagnosing COVID-19 efficiently. Pharmacological and non-pharmacological strategies are effective in mitigating the persistent impacts of COVID-19. These strategies enhance immunity in post-COVID-19 patients by reducing cytokine release syndrome, improving T cell response, and increasing the circulation of activated natural killer and CD8 T cells in blood and tissues. This, in turn, alleviates symptoms such as fever, nausea, fatigue, muscle weakness, and pain. Vaccines, including inactivated viral, live attenuated viral, protein subunit, viral vectored, mRNA, DNA, and nanoparticle vaccines, significantly reduce the adverse long-term effects of the virus. However, no vaccine has been reported to provide lifetime protection against COVID-19. Consequently, protective measures such as physical distancing, mask usage, and hand hygiene remain essential strategies. This review offers a comprehensive understanding of the persistent effects of COVID-19 on individuals of varying ages, along with insights into diagnosis, treatment, vaccination, and future preventative measures against the spread of SARS-CoV-2.         _ Less","","arXiv","https://arxiv.org/abs/2406.01636","2","2","multiple"
"Molecular Modelling of Aqueous Batteries","Abstract:                _play an increasingly important role for the development of sustainable and safety-prioritised energy storage solutions. Compared to conventional lithium-ion batteries, the cell chemistry in aqueous batteries share many common features with those of electrolyzer and pseudo-capacitor systems because of the involvement of aqueous electrolyte and proton activity_         _ More           Aqueous batteries play an increasingly important role for the development of sustainable and safety-prioritised energy storage solutions. Compared to conventional lithium-ion batteries, the cell chemistry in aqueous batteries share many common features with those of electrolyzer and pseudo-capacitor systems because of the involvement of aqueous electrolyte and proton activity. This imposes the needs for a better understanding of the corresponding ion solvation, intercalation and electron transfer processes at atomistic scale. Therefore, this chapter provides an up-to-date overview of molecular modelling techniques and their applications in aqueous batteries. In particular, we emphasize on the dynamical and reactive description of aqueous battery systems brought in by density functional theory-based molecular dynamics simulation (DFTMD) and its machine-learning (ML) accelerated counterpart. Moreover, we also cover the recent advancement of generative artificial intelligence (AI) in molecular and materials design of aqueous batteries. Case studies presented here include popular aqueous battery systems, such as water-in-salt electrolytes, proton-coupled cathode materials, Zn-ion batteries as well as organic redox flow batteries.         _ Less","","arXiv","https://arxiv.org/abs/2406.00468","1","1","multiple"
"Emergence of bidirectional cell laning from collective contact guidance","Abstract:                Directed collective cell migration is central in morphogenesis, wound healing and cancer progression1,2. Although it is well-accepted that the molecular anisotropy of the micro-environment guides this migration3,4, its impact on the pattern of the_         _ More           Directed collective cell migration is central in morphogenesis, wound healing and cancer progression1,2. Although it is well-accepted that the molecular anisotropy of the micro-environment guides this migration3,4, its impact on the pattern of the cell flows remains largely unexplored. Studying confluent human bronchial epithelial cells (HBECs) in vitro, we show that subcellular microgrooves elicit a polar mode of collective migration in millimeter-long bidirectional lanes that are much wider than a cell size, even though cell flows are highly disordered on featureless surfaces 5. This directed flocking-like transition6,7 can be accounted for by a hydrodynamic theory of active polar fluids and corresponding numerical simulations. This model further predicts that anisotropic friction resulting from the grooves lowers the threshold of the transition, which we confirm experimentally. Therefore, microscopic anisotropy of the environment not only directs the collective motion of the cells in the easy direction, but also shapes the cell migration pattern. Flow patterns induced by collective contact guidance are thus markedly different from those induced by supracellular confinement8, demonstrating that all length-scales of the micro-environment must be considered in a comprehensive description of collective migration. Furthermore, artificial microtopographies designed from theoretical considerations can provide a rational strategy to direct cells to specific geometries and functions, which has broad implications, for instance, for tissue engineering strategies in organoid morphogenesis.         _ Less","","arXiv","https://arxiv.org/abs/2405.18807","2","1","origin_of_life"
"Cognitive Evolutionary Learning to Select Feature Interactions for Recommender Systems","Abstract:                _features, and interactions under task guidance. Inspired by the evolution and functioning of natural organisms, we propose a novel \\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive ability refers to a property of organisms that allows them to react and survive in diverse environments. It consists of three stages, i.e., DNA search, g_         _ More           Feature interaction selection is a fundamental problem in commercial recommender systems. Most approaches equally enumerate all features and interactions by the same pre-defined operation under expert guidance. Their recommendation is unsatisfactory sometimes due to the following issues: (1)~They cannot ensure the learning abilities of models because their architectures are poorly adaptable to tasks and data; (2)~Useless features and interactions can bring unnecessary noise and complicate the training process. In this paper, we aim to adaptively evolve the model to select appropriate operations, features, and interactions under task guidance. Inspired by the evolution and functioning of natural organisms, we propose a novel \\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive ability refers to a property of organisms that allows them to react and survive in diverse environments. It consists of three stages, i.e., DNA search, genome search, and model functioning. Specifically, if we regard the relationship between models and tasks as the relationship between organisms and natural environments, interactions of feature pairs can be analogous to double-stranded DNA, of which relevant features and interactions can be analogous to genomes. Along this line, we diagnose the fitness of the model on operations, features, and interactions to simulate the survival rates of organisms for natural selection. We show that CELL can adaptively evolve into different models for different tasks and data, which enables practitioners to access off-the-shelf models. Extensive experiments on four real-world datasets demonstrate that CELL significantly outperforms state-of-the-art baselines. Also, we conduct synthetic experiments to ascertain that CELL can consistently discover the pre-defined interaction patterns for feature pairs.         _ Less","","arXiv","https://arxiv.org/abs/2405.18708","0","1","synthetic_biology"
"CAVACHON: a hierarchical variational autoencoder to integrate multi-modal single-cell data","Abstract:                Paired single-cell sequencing technologies enable the simultaneous measurement of complementary modalities of molecular data at single-_         _ More           Paired single-cell sequencing technologies enable the simultaneous measurement of complementary modalities of molecular data at single-cell resolution. Along with the advances in these technologies, many methods based on variational autoencoders have been developed to integrate these data. However, these methods do not explicitly incorporate prior biological relationships between the data modalities, which could significantly enhance modeling and interpretation. We propose a novel probabilistic learning framework that explicitly incorporates conditional independence relationships between multi-modal data as a directed acyclic graph using a generalized hierarchical variational autoencoder. We demonstrate the versatility of our framework across various applications pertinent to single-cell multi-omics data integration. These include the isolation of common and distinct information from different modalities, modality-specific differential analysis, and integrated cell clustering. We anticipate that the proposed framework can facilitate the construction of highly flexible graphical models that can capture the complexities of biological hypotheses and unravel the connections between different biological data types, such as different modalities of paired single-cell multi-omics data. The implementation of the proposed framework can be found in the repository https://github.com/kuijjerlab/CAVACHON.         _ Less","","arXiv","https://arxiv.org/abs/2405.18655","1","0","origin_of_life"
"BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments","Abstract:                _of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisi_         _ More           Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent, using Claude 3.5 Sonnet, achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.         _ Less","","arXiv","https://arxiv.org/abs/2405.17631","0","1","synthetic_biology"
"Time Elastic Neural Networks","Abstract:                _smooth and fast.While maintaining good accuracy, we get a drastic gain in scalability by first reducing the required number of reference time series, i.e. the number of teNN cells required. Secondly, we demonstrate that, during the training process, the teNN succeeds in reducing the number of neurons required within each_         _ More           We introduce and detail an atypical neural network architecture, called time elastic neural network (teNN), for multivariate time series classification. The novelty compared to classical neural network architecture is that it explicitly incorporates time warping ability, as well as a new way of considering attention. In addition, this architecture is capable of learning a dropout strategy, thus optimizing its own architecture.Behind the design of this architecture, our overall objective is threefold: firstly, we are aiming at improving the accuracy of instance based classification approaches that shows quite good performances as far as enough training data is available. Secondly we seek to reduce the computational complexity inherent to these methods to improve their scalability. Ideally, we seek to find an acceptable balance between these first two criteria. And finally, we seek to enhance the explainability of the decision provided by this kind of neural architecture.The experiment demonstrates that the stochastic gradient descent implemented to train a teNN is quite effective. To the extent that the selection of some critical meta-parameters is correct, convergence is generally smooth and fast.While maintaining good accuracy, we get a drastic gain in scalability by first reducing the required number of reference time series, i.e. the number of teNN cells required. Secondly, we demonstrate that, during the training process, the teNN succeeds in reducing the number of neurons required within each cell. Finally, we show that the analysis of the activation and attention matrices as well as the reference time series after training provides relevant information to interpret and explain the classification results.The comparative study that we have carried out and which concerns around thirty diverse and multivariate datasets shows that the teNN obtains results comparable to those of the state of the art, in particular similar to those of a network mixing LSTM and CNN architectures for example.         _ Less","","arXiv","https://arxiv.org/abs/2405.17516","2","1","origin_of_life"
"Enhancing Feature Diversity Boosts Channel-Adaptive Vision Transformers","Abstract:                _from each channel. Many of our improvements are architecture agnostic and can be incorporated into new architectures as they are developed. Experiments on both satellite and cell microscopy datasets, CHAMMI, JUMP-CP, and So2Sat, report DiChaViT yields a 1.5 - 5.0% gain over the state-of-the-art. Our code is publicly available at https://github.com/chaudatasc_         _ More           Multi-Channel Imaging (MCI) contains an array of challenges for encoding useful feature representations not present in traditional images. For example, images from two different satellites may both contain RGB channels, but the remaining channels can be different for each imaging source. Thus, MCI models must support a variety of channel configurations at test time. Recent work has extended traditional visual encoders for MCI, such as Vision Transformers (ViT), by supplementing pixel information with an encoding representing the channel configuration. However, these methods treat each channel equally, i.e., they do not consider the unique properties of each channel type, which can result in needless and potentially harmful redundancies in the learned features. For example, if RGB channels are always present, the other channels can focus on extracting information that cannot be captured by the RGB channels. To this end, we propose DiChaViT, which aims to enhance the diversity in the learned features of MCI-ViT models. This is achieved through a novel channel sampling strategy that encourages the selection of more distinct channel sets for training. Additionally, we employ regularization and initialization techniques to increase the likelihood that new information is learned from each channel. Many of our improvements are architecture agnostic and can be incorporated into new architectures as they are developed. Experiments on both satellite and cell microscopy datasets, CHAMMI, JUMP-CP, and So2Sat, report DiChaViT yields a 1.5 - 5.0% gain over the state-of-the-art. Our code is publicly available at https://github.com/chaudatascience/diverse_channel_vit.         _ Less","","arXiv","https://arxiv.org/abs/2405.16419","1","0","origin_of_life"
"GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases","Abstract:                _and generating more reliable analytical narratives. To demonstrate its practical utility, we apply GeneAgent to seven novel gene sets derived from mouse B2905 melanoma cell lines, with expert evaluations showing that GeneAgent offers novel insights into gene functions and subsequently expedites knowledge discovery.         _ More           Gene set knowledge discovery is essential for advancing human functional genomics. Recent studies have shown promising performance by harnessing the power of Large Language Models (LLMs) on this task. Nonetheless, their results are subject to several limitations common in LLMs such as hallucinations. In response, we present GeneAgent, a first-of-its-kind language agent featuring self-verification capability. It autonomously interacts with various biological databases and leverages relevant domain knowledge to improve accuracy and reduce hallucination occurrences. Benchmarking on 1,106 gene sets from different sources, GeneAgent consistently outperforms standard GPT-4 by a significant margin. Moreover, a detailed manual review confirms the effectiveness of the self-verification module in minimizing hallucinations and generating more reliable analytical narratives. To demonstrate its practical utility, we apply GeneAgent to seven novel gene sets derived from mouse B2905 melanoma cell lines, with expert evaluations showing that GeneAgent offers novel insights into gene functions and subsequently expedites knowledge discovery.         _ Less","","arXiv","https://arxiv.org/abs/2405.16205","1","1","multiple"
"BloodCell-Net: A lightweight convolutional neural network for the classification of all microscopic blood cell images of the human body","Abstract:                Blood cell classification and counting are vital for the diagnosis of various blood-related diseases, such as anemia, leukemia, and thrombocytopenia. The manual process of blood_         _ More           Blood cell classification and counting are vital for the diagnosis of various blood-related diseases, such as anemia, leukemia, and thrombocytopenia. The manual process of blood cell classification and counting is time-consuming, prone to errors, and labor-intensive. Therefore, we have proposed a DL based automated system for blood cell classification and counting from microscopic blood smear images. We classify total of nine types of blood cells, including Erythrocyte, Erythroblast, Neutrophil, Basophil, Eosinophil, Lymphocyte, Monocyte, Immature Granulocytes, and Platelet. Several preprocessing steps like image resizing, rescaling, contrast enhancement and augmentation are utilized. To segment the blood cells from the entire microscopic images, we employed the U-Net model. This segmentation technique aids in extracting the region of interest (ROI) by removing complex and noisy background elements. Both pixel-level metrics such as accuracy, precision, and sensitivity, and object-level evaluation metrics like Intersection over Union (IOU) and Dice coefficient are considered to comprehensively evaluate the performance of the U-Net model. The segmentation model achieved impressive performance metrics, including 98.23% accuracy, 98.40% precision, 98.25% sensitivity, 95.97% Intersection over Union (IOU), and 97.92% Dice coefficient. Subsequently, a watershed algorithm is applied to the segmented images to separate overlapped blood cells and extract individual cells. We have proposed a BloodCell-Net approach incorporated with custom light weight convolutional neural network (LWCNN) for classifying individual blood cells into nine types. Comprehensive evaluation of the classifier's performance is conducted using metrics including accuracy, precision, recall, and F1 score. The classifier achieved an average accuracy of 97.10%, precision of 97.19%, recall of 97.01%, and F1 score of 97.10%.         _ Less","","arXiv","https://arxiv.org/abs/2405.14875","1","1","multiple"
"Enhancing Maritime Trajectory Forecasting via H3 Index and Causal Language Modelling (CLM)","Abstract:                The prediction of ship trajectories is a growing field of study in artificial intelligence. Traditional methods rely on the use of LSTM, GRU networks, and even Transformer architectures for the prediction of spatio-temporal series. This study proposes a viable alternative for predicting these trajectories using only GNSS positions. It considers this spatio-t_         _ More           The prediction of ship trajectories is a growing field of study in artificial intelligence. Traditional methods rely on the use of LSTM, GRU networks, and even Transformer architectures for the prediction of spatio-temporal series. This study proposes a viable alternative for predicting these trajectories using only GNSS positions. It considers this spatio-temporal problem as a natural language processing problem. The latitude/longitude coordinates of AIS messages are transformed into cell identifiers using the H3 index. Thanks to the pseudo-octal representation, it becomes easier for language models to learn the spatial hierarchy of the H3 index. The method is compared with a classical Kalman filter, widely used in the maritime domain, and introduces the Fr_chet distance as the main evaluation metric. We show that it is possible to predict ship trajectories quite precisely up to 8 hours ahead with 30 minutes of context, using solely GNSS positions, without relying on any additional information such as speed, course, or external conditions - unlike many traditional methods. We demonstrate that this alternative works well enough to predict trajectories worldwide.         _ Less","","arXiv","https://arxiv.org/abs/2405.09596","1","0","origin_of_life"
"Growing Artificial Neural Networks for Control: the Role of Neuronal Diversity","Abstract:                _evolution complex neural structures grow from a handful of cellular ingredients. As genomes in nature are bounded in size, this complexity is achieved by a growth process where cells communicate locally to decide whether to differentiate, proliferate and connect with other_         _ More           In biological evolution complex neural structures grow from a handful of cellular ingredients. As genomes in nature are bounded in size, this complexity is achieved by a growth process where cells communicate locally to decide whether to differentiate, proliferate and connect with other cells. This self-organisation is hypothesized to play an important part in the generalisation, and robustness of biological neural networks. Artificial neural networks (ANNs), on the other hand, are traditionally optimized in the space of weights. Thus, the benefits and challenges of growing artificial neural networks remain understudied. Building on the previously introduced Neural Developmental Programs (NDP), in this work we present an algorithm for growing ANNs that solve reinforcement learning tasks. We identify a key challenge: ensuring phenotypic complexity requires maintaining neuronal diversity, but this diversity comes at the cost of optimization stability. To address this, we introduce two mechanisms: (a) equipping neurons with an intrinsic state inherited upon neurogenesis; (b) lateral inhibition, a mechanism inspired by biological growth, which controlls the pace of growth, helping diversity persist. We show that both mechanisms contribute to neuronal diversity and that, equipped with them, NDPs achieve comparable results to existing direct and developmental encodings in complex locomotion tasks         _ Less","","arXiv","https://arxiv.org/abs/2405.08510","0","2","synthetic_biology"
"LangCell: Language-Cell Pre-training for Cell Identity Understanding","Abstract:        Cell identity encompasses various semantic aspects of a_         _ More   Cell identity encompasses various semantic aspects of a cell, including cell type, pathway information, disease information, and more, which are essential for biologists to gain insights into its biological characteristics. Understanding cell identity from the transcriptomic data, such as annotating cell types, has become an important task in bioinformatics. As these semantic aspects are determined by human experts, it is impossible for AI models to effectively carry out cell identity understanding tasks without the supervision signals provided by single-cell and label pairs. The single-cell pre-trained language models (PLMs) currently used for this task are trained only on a single modality, transcriptomics data, lack an understanding of cell identity knowledge. As a result, they have to be fine-tuned for downstream tasks and struggle when lacking labeled data with the desired semantic labels. To address this issue, we propose an innovative solution by constructing a unified representation of single-cell data and natural language during the pre-training phase, allowing the model to directly incorporate insights related to cell identity. More specifically, we introduce $\\textbf{LangCell}$, the first $\\textbf{Lang}$uage-$\\textbf{Cell}$ pre-training framework. LangCell utilizes texts enriched with cell identity information to gain a profound comprehension of cross-modal knowledge. Results from experiments conducted on different benchmarks show that LangCell is the only single-cell PLM that can work effectively in zero-shot cell identity understanding scenarios, and also significantly outperforms existing models in few-shot and fine-tuning cell identity understanding scenarios.         _ Less","","arXiv","https://arxiv.org/abs/2405.06708","1","0","origin_of_life"
"Are Biological Systems More Intelligent Than Artificial Intelligence?","Abstract:                Is a biological self-organising system more `intelligent' than an artificial intelligence? If so, why? We frame intelligence as adaptability, and explore this question using a mathematical formalism of enactive causal learning. We extend it to formalise the multilayer, multiscale, bottom-up distributed computational architecture of biological self-organi_         _ More           Is a biological self-organising system more `intelligent' than an artificial intelligence? If so, why? We frame intelligence as adaptability, and explore this question using a mathematical formalism of enactive causal learning. We extend it to formalise the multilayer, multiscale, bottom-up distributed computational architecture of biological self-organisation. We then show that this architecture allows for more efficient adaptation than the static top-down interpreters typically used in computers. To put it provocatively, biology is more intelligent because cells adapt to provide a helpful inductive bias, and static interpreters do not. We call this multilayer-causal-learning. However it inherits a flaw of biological self-organisation. Cells become cancerous when isolated from the collective informational structure, reverting to primitive transcriptional behaviour. We show that, in the context of our formalism, failure states like cancer occur when systems are too tightly constrained by the abstraction layer in which they exist. This suggests control should be distributed (bottom-up rather than top-down) to ensure graceful degradation. We speculate about what this implies for systems in general, from machine learning hardware to human organisational and economic systems. Our result shows how we can design more robust systems and, though theoretical in nature, it lays a foundation for future empirical research.         _ Less","","arXiv","https://arxiv.org/abs/2405.02325","1","2","synthetic_biology"
"Multi-Stream Cellular Test-Time Adaptation of Real-Time Models Evolving in Dynamic Environments","Abstract:                _To address this limitation, we propose a novel Multi-Stream Cellular Test-Time Adaptation (MSC-TTA) setup where models adapt on the fly to a dynamic environment divided into cells. Then, we propose a real-time adaptive student-teacher method that leverages the multiple streams available in each_         _ More           In the era of the Internet of Things (IoT), objects connect through a dynamic network, empowered by technologies like 5G, enabling real-time data sharing. However, smart objects, notably autonomous vehicles, face challenges in critical local computations due to limited resources. Lightweight AI models offer a solution but struggle with diverse data distributions. To address this limitation, we propose a novel Multi-Stream Cellular Test-Time Adaptation (MSC-TTA) setup where models adapt on the fly to a dynamic environment divided into cells. Then, we propose a real-time adaptive student-teacher method that leverages the multiple streams available in each cell to quickly adapt to changing data distributions. We validate our methodology in the context of autonomous vehicles navigating across cells defined based on location and weather conditions. To facilitate future benchmarking, we release a new multi-stream large-scale synthetic semantic segmentation dataset, called DADE, and show that our multi-stream approach outperforms a single-stream baseline. We believe that our work will open research opportunities in the IoT and 5G eras, offering solutions for real-time model adaptation.         _ Less","","arXiv","https://arxiv.org/abs/2404.17930","0","1","synthetic_biology"
"Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond","Abstract:                Fined-grained anomalous cell detection from affected tissues is critical for clinical diagnosis and pathological research. Single-_         _ More           Fined-grained anomalous cell detection from affected tissues is critical for clinical diagnosis and pathological research. Single-cell sequencing data provide unprecedented opportunities for this task. However, current anomaly detection methods struggle to handle domain shifts prevalent in multi-sample and multi-domain single-cell sequencing data, leading to suboptimal performance. Moreover, these methods fall short of distinguishing anomalous cells into pathologically distinct subtypes. In response, we propose ACSleuth, a novel, reconstruction deviation-guided generative framework that integrates the detection, domain adaptation, and fine-grained annotating of anomalous cells into a methodologically cohesive workflow. Notably, we present the first theoretical analysis of using reconstruction deviations output by generative models for anomaly detection in lieu of domain shifts. This analysis informs us to develop a novel and superior maximum mean discrepancy-based anomaly scorer in ACSleuth. Extensive benchmarks over various single-cell data and other types of tabular data demonstrate ACSleuth's superiority over the state-of-the-art methods in identifying and subtyping anomalies in multi-sample and multi-domain contexts. Our code is available at https://github.com/Catchxu/ACsleuth.         _ Less","","arXiv","https://arxiv.org/abs/2404.17454","0","1","synthetic_biology"
"Cell Phone Image-Based Persian Rice Detection and Classification Using Deep Learning Techniques","Abstract:                _grain classification and comprehensive analysis of bulk rice samples, addressing two crucial aspects of rice quality assessment. Utilizing images captured with consumer-grade cell phones reflects a realistic scenario in which individuals can leverage this technology for assistance with grocery shopping and meal preparation. The dataset, comprising various ri_         _ More           This study introduces an innovative approach to classifying various types of Persian rice using image-based deep learning techniques, highlighting the practical application of everyday technology in food categorization. Recognizing the diversity of Persian rice and its culinary significance, we leveraged the capabilities of convolutional neural networks (CNNs), specifically by fine-tuning a ResNet model for accurate identification of different rice varieties and employing a U-Net architecture for precise segmentation of rice grains in bulk images. This dual-methodology framework allows for both individual grain classification and comprehensive analysis of bulk rice samples, addressing two crucial aspects of rice quality assessment. Utilizing images captured with consumer-grade cell phones reflects a realistic scenario in which individuals can leverage this technology for assistance with grocery shopping and meal preparation. The dataset, comprising various rice types photographed under natural conditions without professional lighting or equipment, presents a challenging yet practical classification problem. Our findings demonstrate the feasibility of using non-professional images for food classification and the potential of deep learning models, like ResNet and U-Net, to adapt to the nuances of everyday objects and textures. This study contributes to the field by providing insights into the applicability of image-based deep learning in daily life, specifically for enhancing consumer experiences and knowledge in food selection. Furthermore, it opens avenues for extending this approach to other food categories and practical applications, emphasizing the role of accessible technology in bridging the gap between sophisticated computational methods and everyday tasks.         _ Less","","arXiv","https://arxiv.org/abs/2404.13555","1","1","multiple"
"Predictive Handover Strategy in 6G and Beyond: A Deep and Transfer Learning Approach","Abstract:                _due to smaller coverage areas and the higher signal attenuation. To address these challenges, we propose a deep learning based algorithm for predicting the future serving cell utilizing sequential user equipment measurements to minimize the handover failures and interruption time. Our algorithm enables network operators to dynamically adjust handover trigger_         _ More           Next-generation cellular networks will evolve into more complex and virtualized systems, employing machine learning for enhanced optimization and leveraging higher frequency bands and denser deployments to meet varied service demands. This evolution, while bringing numerous advantages, will also pose challenges, especially in mobility management, as it will increase the overall number of handovers due to smaller coverage areas and the higher signal attenuation. To address these challenges, we propose a deep learning based algorithm for predicting the future serving cell utilizing sequential user equipment measurements to minimize the handover failures and interruption time. Our algorithm enables network operators to dynamically adjust handover triggering events or incorporate UAV base stations for enhanced coverage and capacity, optimizing network objectives like load balancing and energy efficiency through transfer learning techniques. Our framework complies with the O-RAN specifications and can be deployed in a Near-Real-Time RAN Intelligent Controller as an xApp leveraging the E2SM-KPM service model. The evaluation results demonstrate that our algorithm achieves a 92% accuracy in predicting future serving cells with high probability. Finally, by utilizing transfer learning, our algorithm significantly reduces the retraining time by 91% and 77% when new handover trigger decisions or UAV base stations are introduced to the network dynamically.         _ Less","","arXiv","https://arxiv.org/abs/2404.08113","0","1","synthetic_biology"
"Late Breaking Results: Fast System Technology Co-Optimization Framework for Emerging Technology Based on Graph Neural Networks","Abstract:                _architectures. We focus on accelerating the technology level of STCO using AI techniques, by employing graph neural network (GNN)-based approaches for both TCAD simulation and cell library characterization, which are interconnected through a unified compact model, collectively achieving over a 100X speedup over traditional methods. These advancements enable_         _ More           This paper proposes a fast system technology co-optimization (STCO) framework that optimizes power, performance, and area (PPA) for next-generation IC design, addressing the challenges and opportunities presented by novel materials and device architectures. We focus on accelerating the technology level of STCO using AI techniques, by employing graph neural network (GNN)-based approaches for both TCAD simulation and cell library characterization, which are interconnected through a unified compact model, collectively achieving over a 100X speedup over traditional methods. These advancements enable comprehensive STCO iterations with runtime speedups ranging from 1.9X to 14.1X and supports both emerging and traditional technologies.         _ Less","","arXiv","https://arxiv.org/abs/2404.06939","1","1","multiple"
"ASAP: Interpretable Analysis and Summarization of AI-generated Image Patterns at Scale","Abstract:                _patterns. ASAP enables the at scale interactive analysis of these patterns through multiple, coordinated visualizations. This includes a representation overview with innovative cell glyphs to aid in the exploration and qualitative evaluation of fake patterns across a vast array of images, as well as a pattern view that displays authenticity-indicating patter_         _ More           Generative image models have emerged as a promising technology to produce realistic images. Despite potential benefits, concerns grow about its misuse, particularly in generating deceptive images that could raise significant ethical, legal, and societal issues. Consequently, there is growing demand to empower users to effectively discern and comprehend patterns of AI-generated images. To this end, we developed ASAP, an interactive visualization system that automatically extracts distinct patterns of AI-generated images and allows users to interactively explore them via various views. To uncover fake patterns, ASAP introduces a novel image encoder, adapted from CLIP, which transforms images into compact 'distilled' representations, enriched with information for differentiating authentic and fake images. These representations generate gradients that propagate back to the attention maps of CLIP's transformer block. This process quantifies the relative importance of each pixel to image authenticity or fakeness, exposing key deceptive patterns. ASAP enables the at scale interactive analysis of these patterns through multiple, coordinated visualizations. This includes a representation overview with innovative cell glyphs to aid in the exploration and qualitative evaluation of fake patterns across a vast array of images, as well as a pattern view that displays authenticity-indicating patterns in images and quantifies their impact. ASAP supports the analysis of cutting-edge generative models with the latest architectures, including GAN-based models like proGAN and diffusion models like the latent diffusion model. We demonstrate ASAP's usefulness through two usage scenarios using multiple fake image detection benchmark datasets, revealing its ability to identify and understand hidden patterns in AI-generated images, especially in detecting fake human faces produced by diffusion-based techniques.         _ Less","","arXiv","https://arxiv.org/abs/2404.02990","2","1","origin_of_life"
"New methods for drug synergy prediction: a mini-review","Abstract:                _scenarios and evaluation protocols that the papers deal with. Our finding is that the best methods accurately solve the synergy prediction scenarios involving known drugs or cell lines while the scenarios involving new drugs or cell lines still fall short of an accurate prediction level.         _ More           In this mini-review, we explore the new prediction methods for drug combination synergy relying on high-throughput combinatorial screens. The fast progress of the field is witnessed in the more than thirty original machine learning methods published since 2021, a clear majority of them based on deep learning techniques. We aim to put these papers under a unifying lens by highlighting the core technologies, the data sources, the input data types and synergy scores used in the methods, as well as the prediction scenarios and evaluation protocols that the papers deal with. Our finding is that the best methods accurately solve the synergy prediction scenarios involving known drugs or cell lines while the scenarios involving new drugs or cell lines still fall short of an accurate prediction level.         _ Less","","arXiv","https://arxiv.org/abs/2404.02484","1","1","multiple"
"Enhancing Sum-Rate Performance in Constrained Multicell Networks: A Low-Information Exchange Approach","Abstract:                _beyond, the reality is that many deployed base stations are equipped with a limited number of antennas rather than supporting massive MIMO configurations. Furthermore, while the cell-less network concept, which eliminates cell boundaries, is under investigation, practical deployments often grapple with significantly li_         _ More           Despite the extensive research on massive MIMO systems for 5G telecommunications and beyond, the reality is that many deployed base stations are equipped with a limited number of antennas rather than supporting massive MIMO configurations. Furthermore, while the cell-less network concept, which eliminates cell boundaries, is under investigation, practical deployments often grapple with significantly limited backhaul connection capacities between base stations. This letter explores techniques to maximize the sum-rate performance within the constraints of these more realistically equipped multicell networks. We propose an innovative approach that dramatically reduces the need for information exchange between base stations to a mere few bits, in stark contrast to conventional methods that require the exchange of hundreds of bits. Our proposed method not only addresses the limitations imposed by current network infrastructure but also showcases significantly improved performance under these constrained conditions.         _ Less","","arXiv","https://arxiv.org/abs/2404.02477","1","0","origin_of_life"
"Img2Loc: Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation","Abstract:                _a challenging problem in computer vision and information retrieval.Traditional methods typically employ either classification, which dividing the Earth surface into grid cells and classifying images accordingly, or retrieval, which identifying locations by matching images with a database of image-location pairs. However, classification-based approaches are l_         _ More           Geolocating precise locations from images presents a challenging problem in computer vision and information retrieval.Traditional methods typically employ either classification, which dividing the Earth surface into grid cells and classifying images accordingly, or retrieval, which identifying locations by matching images with a database of image-location pairs. However, classification-based approaches are limited by the cell size and cannot yield precise predictions, while retrieval-based systems usually suffer from poor search quality and inadequate coverage of the global landscape at varied scale and aggregation levels. To overcome these drawbacks, we present Img2Loc, a novel system that redefines image geolocalization as a text generation task. This is achieved using cutting-edge large multi-modality models like GPT4V or LLaVA with retrieval augmented generation. Img2Loc first employs CLIP-based representations to generate an image-based coordinate query database. It then uniquely combines query results with images itself, forming elaborate prompts customized for LMMs. When tested on benchmark datasets such as Im2GPS3k and YFCC4k, Img2Loc not only surpasses the performance of previous state-of-the-art models but does so without any model training.         _ Less","","arXiv","https://arxiv.org/abs/2403.19584","1","0","origin_of_life"
"MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering","Abstract:                _Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extra_         _ More           In today's fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks are retrieved based on a given question. The retrieved content is then used to construct few-shot prompts as inputs to an LLM, such as ChatGPT. To tackle the challenge of answering complex questions, the second step leverages Chain-of-thought (CoT) prompting to decompose the complex question into a sequential chain of questions and reasoning thoughts in a multi-hop manner. Retrieval-Augmented Generation (RAG) enhances this process by retrieving relevant tables and contexts of hyperlinks that are relevant to the resulting reasoning thoughts and questions. These additional contexts are then used to supplement the prompt used in the first step, resulting in more accurate answers from an LLM. Empirical results from OTT-QA demonstrate that our abstractive QA approach significantly improves the accuracy of extractive Table QA methods.         _ Less","","arXiv","https://arxiv.org/abs/2403.19116","1","0","origin_of_life"
"Deep Learning Segmentation and Classification of Red Blood Cells Using a Large Multi-Scanner Dataset","Abstract:                Digital pathology has recently been revolutionized by advancements in artificial intelligence, deep learning, and high-performance computing. With its advanced tools, digital pathology can help improve and speed up the diagnostic process, reduce human errors, and streamline the reporting step. In this paper, we report a new large red blood_         _ More           Digital pathology has recently been revolutionized by advancements in artificial intelligence, deep learning, and high-performance computing. With its advanced tools, digital pathology can help improve and speed up the diagnostic process, reduce human errors, and streamline the reporting step. In this paper, we report a new large red blood cell (RBC) image dataset and propose a two-stage deep learning framework for RBC image segmentation and classification. The dataset is a highly diverse dataset of more than 100K RBCs containing eight different classes. The dataset, which is considerably larger than any publicly available hematopathology dataset, was labeled independently by two hematopathologists who also manually created masks for RBC cell segmentation. Subsequently, in the proposed framework, first, a U-Net model was trained to achieve automatic RBC image segmentation. Second, an EfficientNetB0 model was trained to classify RBC images into one of the eight classes using a transfer learning approach with a 5X2 cross-validation scheme. An IoU of 98.03% and an average classification accuracy of 96.5% were attained on the test set. Moreover, we have performed experimental comparisons against several prominent CNN models. These comparisons show the superiority of the proposed model with a good balance between performance and computational cost.         _ Less","","arXiv","https://arxiv.org/abs/2403.18468","0","1","synthetic_biology"
"Interpretable cancer cell detection with phonon microscopy using multi-task conditional neural networks for inter-batch calibration","Abstract:                Advances in artificial intelligence (AI) show great potential in revealing underlying information from phonon microscopy (high-frequency ultrasound) data to identify cancerous_         _ More           Advances in artificial intelligence (AI) show great potential in revealing underlying information from phonon microscopy (high-frequency ultrasound) data to identify cancerous cells. However, this technology suffers from the 'batch effect' that comes from unavoidable technical variations between each experiment, creating confounding variables that the AI model may inadvertently learn. We therefore present a multi-task conditional neural network framework to simultaneously achieve inter-batch calibration, by removing confounding variables, and accurate cell classification of time-resolved phonon-derived signals. We validate our approach by training and validating on different experimental batches, achieving a balanced precision of 89.22% and an average cross-validated precision of 89.07% for classifying background, healthy and cancerous regions. Classification can be performed in 0.5 seconds with only simple prior batch information required for multiple batch corrections. Further, we extend our model to reconstruct denoised signals, enabling physical interpretation of salient features indicating disease state including sound velocity, sound attenuation and cell-adhesion to substrate.         _ Less","","arXiv","https://arxiv.org/abs/2403.17992","1","0","origin_of_life"
"Synthetic active liquid crystals powered by acoustic waves","Abstract:                _particles that can transform energy from the environment into a mechanical motion. Current experimental realizations of the active nematics are of biological origin and include cell layers, suspensions of elongated bacteria in liquid crystal, and combinations of bio-filaments with molecular motors. Here, we report the realization of a fully synthetic active_         _ More           Active nematics are materials composed of mobile, elongated particles that can transform energy from the environment into a mechanical motion. Current experimental realizations of the active nematics are of biological origin and include cell layers, suspensions of elongated bacteria in liquid crystal, and combinations of bio-filaments with molecular motors. Here, we report the realization of a fully synthetic active nematic system comprised of a lyotropic chromonic liquid crystal energized by ultrasonic waves. This artificial active liquid crystal is free from biological degradation and variability, exhibits stable material properties, and enables precise and rapid activity control over a significantly extended range. We demonstrate that the energy of the acoustic field is converted into microscopic extensile stresses disrupting long-range nematic order and giving rise to an undulation instability, development of active turbulence, and proliferation of topological defects. We reveal the emergence of unconventional free-standing persistent vortices in the nematic director field at high activity levels. The results provide a foundation for the design of externally energized active nematic fluids with stable material properties and tunable topological defects dynamics crucial for the realization of reconfigurable microfluidic systems.         _ Less","","arXiv","https://arxiv.org/abs/2403.17268","1","0","origin_of_life"
"On machine learning analysis of atomic force microscopy images for image classification, sample surface recognition","Abstract:                _discuss ML methods other than popular deep-learning neural networks. The described approach has already been successfully used to analyze and classify the surfaces of biological cells. It can be applied to recognize medical images, specific material processing, in forensic studies, even to identify the authenticity of arts. A general template for ML analysis_         _ More           Atomic force microscopy (AFM or SPM) imaging is one of the best matches with machine learning (ML) analysis among microscopy techniques. The digital format of AFM images allows for direct utilization in ML algorithms without the need for additional processing. Additionally, AFM enables the simultaneous imaging of distributions of over a dozen different physicochemical properties of sample surfaces, a process known as multidimensional imaging. While this wealth of information can be challenging to analyze using traditional methods, ML provides a seamless approach to this task. However, the relatively slow speed of AFM imaging poses a challenge in applying deep learning methods broadly used in image recognition. This Prospective is focused on ML recognition/classification when using a relatively small number of AFM images, small database. We discuss ML methods other than popular deep-learning neural networks. The described approach has already been successfully used to analyze and classify the surfaces of biological cells. It can be applied to recognize medical images, specific material processing, in forensic studies, even to identify the authenticity of arts. A general template for ML analysis specific to AFM is suggested, with a specific example of the identification of cell phenotype. Special attention is given to the analysis of the statistical significance of the obtained results, an important feature that is often overlooked in papers dealing with machine learning. A simple method for finding statistical significance is also described.         _ Less","","arXiv","https://arxiv.org/abs/2403.16230","1","0","origin_of_life"
"Reactor Optimization Benchmark by Reinforcement Learning","Abstract:                _This paper introduces a novel benchmark problem within the OpenNeoMC framework designed specifically for reinforcement learning. The benchmark involves optimizing a unit cell of a research reactor with two varying parameters (fuel density and water spacing) to maximize neutron flux while maintaining reactor criticality. The test case features distinct local_         _ More           Neutronic calculations for reactors are a daunting task when using Monte Carlo (MC) methods. As high-performance computing has advanced, the simulation of a reactor is nowadays more readily done, but design and optimization with multiple parameters is still a computational challenge. MC transport simulations, coupled with machine learning techniques, offer promising avenues for enhancing the efficiency and effectiveness of nuclear reactor optimization. This paper introduces a novel benchmark problem within the OpenNeoMC framework designed specifically for reinforcement learning. The benchmark involves optimizing a unit cell of a research reactor with two varying parameters (fuel density and water spacing) to maximize neutron flux while maintaining reactor criticality. The test case features distinct local optima, representing different physical regimes, thus posing a challenge for learning algorithms. Through extensive simulations utilizing evolutionary and neuroevolutionary algorithms, we demonstrate the effectiveness of reinforcement learning in navigating complex optimization landscapes with strict constraints. Furthermore, we propose acceleration techniques within the OpenNeoMC framework, including model updating and cross-section usage by RAM utilization, to expedite simulation times. Our findings emphasize the importance of machine learning integration in reactor optimization and contribute to advancing methodologies for addressing intricate optimization challenges in nuclear engineering. The sources of this work are available at our GitHub repository: https://github.com/Scientific-Computing-Lab-NRCN/RLOpenNeoMC         _ Less","","arXiv","https://arxiv.org/abs/2403.14273","0","1","synthetic_biology"
"Autonomous Engulfment of Active Colloids by Giant Lipid Vesicles","Abstract:                The ability to design artificial micro/nanomachines able to perform sophisticated tasks crucially depends on the understanding of their interaction with biosystems and their compatibility with the biological environment. Here, Janus colloids fuelled only by glucose and light were designed, which can autonomously interact with_         _ More           The ability to design artificial micro/nanomachines able to perform sophisticated tasks crucially depends on the understanding of their interaction with biosystems and their compatibility with the biological environment. Here, Janus colloids fuelled only by glucose and light were designed, which can autonomously interact with cell-like compartments and trigger endocytosis. The crucial role played by the far field hydrodynamic interaction arising from the puller/pusher swimming mode and adhesion is evidenced. It is shown that a large contact time between the active particle and the lipid membrane is required to observe the engulfment of a particle inside a floppy giant lipid vesicle. Active Janus colloids showing relatively small velocities and a puller type swimming mode are able to target giant vesicles, deform their membranes and subsequently get stably engulfed. An instability arising from the unbound membrane segment is responsible for the transition between partial and complete stable engulfment. These experiments shed light on the physical criteria required for autonomous active particle engulfment in giant vesicles, which can serve as general principles in disciplines ranging from drug delivery and microbial infection to nanomedecine.         _ Less","","arXiv","https://arxiv.org/abs/2403.10234","1","1","multiple"
"PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency","Abstract:                _language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a p_         _ More           Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large language models (LLM) on in-context learning, achieving significant results. Nevertheless, they face challenges when dealing with verbose database information and complex user intentions. This paper presents a two-stage framework to enhance the performance of current LLM-based natural language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information. In the second stage, with the linked schema, we simplify the prompt's schema information and instruct the LLM to produce the final SQL. Finally, as the post-refinement module, we propose using cross-consistency across different LLMs rather than self-consistency within a particular LLM. Our methods achieve new SOTA results on the Spider benchmark, with an execution accuracy of 87.6%.         _ Less","","arXiv","https://arxiv.org/abs/2403.09732","1","0","origin_of_life"
"Electrochemical Communication in Bacterial Biofilms: A Study on Potassium Stimulation and Signal Transmission","Abstract:                _coordinates collective actions at the population level through the utilization of electrochemical signals. In this work, we investigate the response of bacterial biofilms to artificial potassium concentration stimulation. We introduce signal inputs at a specific location within the biofilm and observe their transmission to other regions, facilitated by inter_         _ More           Electrochemical communication is a mechanism that enables intercellular interaction among bacteria within communities. Bacteria achieves synchronization and coordinates collective actions at the population level through the utilization of electrochemical signals. In this work, we investigate the response of bacterial biofilms to artificial potassium concentration stimulation. We introduce signal inputs at a specific location within the biofilm and observe their transmission to other regions, facilitated by intermediary cells that amplify and relay the signal. We analyze the output signals when biofilm regions are subjected to different input signal types and explore their impact on biofilm growth. Furthermore, we investigate how the temporal gap between input pulses influences output signal characteristics, demonstrating that an appropriate gap yields distinct and well-defined output signals. Our research sheds light on the potential of bacterial biofilms as communication nodes in electrochemical communication networks.         _ Less","","arXiv","https://arxiv.org/abs/2403.08926","0","2","synthetic_biology"
"Wet TinyML: Chemical Neural Network Using Gene Regulation and Cell Plasticity","Abstract:                In our earlier work, we introduced the concept of Gene Regulatory Neural Network (GRNN), which utilizes natural neural network-like structures inherent in biological cells to perform computing tasks using chemical inputs. We define this form of chemical-based neural network as Wet TinyML. The GRNN structures are based on the gene regulatory network and have_         _ More           In our earlier work, we introduced the concept of Gene Regulatory Neural Network (GRNN), which utilizes natural neural network-like structures inherent in biological cells to perform computing tasks using chemical inputs. We define this form of chemical-based neural network as Wet TinyML. The GRNN structures are based on the gene regulatory network and have weights associated with each link based on the estimated interactions between the genes. The GRNNs can be used for conventional computing by employing an application-based search process similar to the Network Architecture Search. This study advances this concept by incorporating cell plasticity, to further exploit natural cell's adaptability, in order to diversify the GRNN search that can match larger spectrum as well as dynamic computing tasks. As an example application, we show that through the directed cell plasticity, we can extract the mathematical regression evolution enabling it to match to dynamic system applications. We also conduct energy analysis by comparing the chemical energy of the GRNN to its silicon counterpart, where this analysis includes both artificial neural network algorithms executed on von Neumann architecture as well as neuromorphic processors. The concept of Wet TinyML can pave the way for the new emergence of chemical-based, energy-efficient and miniature Biological AI.         _ Less","","arXiv","https://arxiv.org/abs/2403.08549","1","1","multiple"
"Automatic driving lane change safety prediction model based on LSTM","Abstract:                _model can alleviate the shortcomings of current automatic driving trajectory planning, and the output trajectory not only ensures high accuracy but also improves safety. The cell state simulation algorithm simulates the trackability of the trajectory generated by this model. The research results show that compared with the traditional model-based method, the_         _ More           Autonomous driving technology can improve traffic safety and reduce traffic accidents. In addition, it improves traffic flow, reduces congestion, saves energy and increases travel efficiency. In the relatively mature automatic driving technology, the automatic driving function is divided into several modules: perception, decision-making, planning and control, and a reasonable division of labor can improve the stability of the system. Therefore, autonomous vehicles need to have the ability to predict the trajectory of surrounding vehicles in order to make reasonable decision planning and safety measures to improve driving safety. By using deep learning method, a safety-sensitive deep learning model based on short term memory (LSTM) network is proposed. This model can alleviate the shortcomings of current automatic driving trajectory planning, and the output trajectory not only ensures high accuracy but also improves safety. The cell state simulation algorithm simulates the trackability of the trajectory generated by this model. The research results show that compared with the traditional model-based method, the trajectory prediction method based on LSTM network has obvious advantages in predicting the trajectory in the long time domain. The intention recognition module considering interactive information has higher prediction and accuracy, and the algorithm results show that the trajectory is very smooth based on the premise of safe prediction and efficient lane change. And autonomous vehicles can efficiently and safely complete lane changes.         _ Less","","arXiv","https://arxiv.org/abs/2403.06993","1","0","origin_of_life"
"From Pixel to Cancer: Cellular Automata in Computed Tomography","Abstract:                AI for cancer detection encounters the bottleneck of data scarcity, annotation difficulty, and low prevalence of early tumors. Tumor synthesis seeks to create artificial tumors in medical images, which can greatly diversify the data and annotations for AI training. However, current tumor synthesis approaches are not applicable across different organs due to_         _ More           AI for cancer detection encounters the bottleneck of data scarcity, annotation difficulty, and low prevalence of early tumors. Tumor synthesis seeks to create artificial tumors in medical images, which can greatly diversify the data and annotations for AI training. However, current tumor synthesis approaches are not applicable across different organs due to their need for specific expertise and design. This paper establishes a set of generic rules to simulate tumor development. Each cell (pixel) is initially assigned a state between zero and ten to represent the tumor population, and a tumor can be developed based on three rules to describe the process of growth, invasion, and death. We apply these three generic rules to simulate tumor development--from pixel to cancer--using cellular automata. We then integrate the tumor state into the original computed tomography (CT) images to generate synthetic tumors across different organs. This tumor synthesis approach allows for sampling tumors at multiple stages and analyzing tumor-organ interaction. Clinically, a reader study involving three expert radiologists reveals that the synthetic tumors and their developing trajectories are convincingly realistic. Technically, we analyze and simulate tumor development at various stages using 9,262 raw, unlabeled CT images sourced from 68 hospitals worldwide. The performance in segmenting tumors in the liver, pancreas, and kidneys exceeds prevailing literature benchmarks, underlining the immense potential of tumor synthesis, especially for earlier cancer detection.   The code and models are available at https://github.com/MrGiovanni/Pixel2Cancer         _ Less","","arXiv","https://arxiv.org/abs/2403.06459","0","1","synthetic_biology"
"Predicting Single-cell Drug Sensitivity by Adaptive Weighted Feature for Adversarial Multi-source Domain Adaptation","Abstract:                The development of single-cell sequencing technology had promoted the generation of a large amount of single-_         _ More           The development of single-cell sequencing technology had promoted the generation of a large amount of single-cell transcriptional profiles, providing valuable opportunities to explore drug-resistant cell subpopulations in a tumor. However, the drug sensitivity data in single-cell level is still scarce to date, pressing an urgent and highly challenging task for computational prediction of the drug sensitivity to individual cells. This paper proposed scAdaDrug, a multi-source adaptive weighting model to predict single-cell drug sensitivity. We used an autoencoder to extract domain-invariant features related to drug sensitivity from multiple source domains by exploiting adversarial domain adaptation. Especially, we introduced an adaptive weight generator to produce importance-aware and mutual independent weights, which could adaptively modulate the embedding of each sample in dimension-level for both source and target domains. Extensive experimental results showed that our model achieved state-of-the-art performance in predicting drug sensitivity on sinle-cell datasets, as well as on cell line and patient datasets.         _ Less","","arXiv","https://arxiv.org/abs/2403.05260","0","1","synthetic_biology"
"A Learnable Prior Improves Inverse Tumor Growth Modeling","Abstract:                _with this DL-based prior. We showcase the effectiveness of integrating a rapid deep-learning algorithm with a high-precision evolution strategy in estimating brain tumor cell concentrations from magnetic resonance images. The DL-Prior plays a pivotal role, significantly constraining the effective sampling-parameter space. This reduction results in a fivefold_         _ More           Biophysical modeling, particularly involving partial differential equations (PDEs), offers significant potential for tailoring disease treatment protocols to individual patients. However, the inverse problem-solving aspect of these models presents a substantial challenge, either due to the high computational requirements of model-based approaches or the limited robustness of deep learning (DL) methods. We propose a novel framework that leverages the unique strengths of both approaches in a synergistic manner. Our method incorporates a DL ensemble for initial parameter estimation, facilitating efficient downstream evolutionary sampling initialized with this DL-based prior. We showcase the effectiveness of integrating a rapid deep-learning algorithm with a high-precision evolution strategy in estimating brain tumor cell concentrations from magnetic resonance images. The DL-Prior plays a pivotal role, significantly constraining the effective sampling-parameter space. This reduction results in a fivefold convergence acceleration and a Dice-score of 95%.         _ Less","","arXiv","https://arxiv.org/abs/2403.04500","0","2","synthetic_biology"
"Understanding Biology in the Age of Artificial Intelligence","Abstract:                Modern life sciences research is increasingly relying on artificial intelligence approaches to model biological systems, primarily centered around the use of machine learning (ML) models. Although ML is undeniably useful for identifying patterns in large, complex data sets, its widespread application in biological sciences represents a significant deviation_         _ More           Modern life sciences research is increasingly relying on artificial intelligence approaches to model biological systems, primarily centered around the use of machine learning (ML) models. Although ML is undeniably useful for identifying patterns in large, complex data sets, its widespread application in biological sciences represents a significant deviation from traditional methods of scientific inquiry. As such, the interplay between these models and scientific understanding in biology is a topic with important implications for the future of scientific research, yet it is a subject that has received little attention. Here, we draw from an epistemological toolkit to contextualize recent applications of ML in biological sciences under modern philosophical theories of understanding, identifying general principles that can guide the design and application of ML systems to model biological phenomena and advance scientific knowledge. We propose that conceptions of scientific understanding as information compression, qualitative intelligibility, and dependency relation modelling provide a useful framework for interpreting ML-mediated understanding of biological systems. Through a detailed analysis of two key application areas of ML in modern biological research - protein structure prediction and single cell RNA-sequencing - we explore how these features have thus far enabled ML systems to advance scientific understanding of their target phenomena, how they may guide the development of future ML models, and the key obstacles that remain in preventing ML from achieving its potential as a tool for biological discovery. Consideration of the epistemological features of ML applications in biology will improve the prospects of these methods to solve important problems and advance scientific understanding of living systems.         _ Less","","arXiv","https://arxiv.org/abs/2403.04106","1","0","origin_of_life"
"Action potentials in vitro: theory and experiment","Abstract:                Action potential generation underlies some of the most consequential dynamical systems on Earth, from brains to hearts. It is therefore interesting to develop synthetic cell-free systems, based on the same molecular mechanisms, which may allow for the exploration of parameter regions and phenomena not attainable, or not apparent, in the live_         _ More           Action potential generation underlies some of the most consequential dynamical systems on Earth, from brains to hearts. It is therefore interesting to develop synthetic cell-free systems, based on the same molecular mechanisms, which may allow for the exploration of parameter regions and phenomena not attainable, or not apparent, in the live cell. We previously constructed such a synthetic system, based on biological components, which fires action potentials. We call it 'Artificial Axon'. The system is minimal in that it relies on a single ion channel species for its dynamics. Here we characterize the Artificial Axon as a dynamical system in time, using a simplified Hodgkin-Huxley model adapted to our experimental context. We construct a phase diagram in parameter space identifying regions corresponding to different temporal behavior, such as Action Potential (AP) trains, single shot APs, or damped oscillations. The main new result is the finding that our system with a single ion channel species, with inactivation, is dynamically equivalent to the system of two channel species without inactivation (the Morris-Lecar system), which exists in nature. We discuss the transitions and bifurcations occurring crossing phase boundaries in the phase diagram, and obtain criteria for the channels' properties necessary to obtain the desired dynamical behavior. In the second part of the paper we present new experimental results obtained with a system of two AAs connected by excitatory and/or inhibitory electronic 'synapses'. We discuss the feasibility of constructing an autonomous oscillator with this system.         _ Less","","arXiv","https://arxiv.org/abs/2403.03369","0","2","synthetic_biology"
"A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning","Abstract:                Defocus blur is a persistent problem in microscope imaging that poses harm to pathology interpretation and medical intervention in cell microscopy and microscope surgery. To address this problem, a unified framework including the multi-pyramid transformer (MPT) and extended frequency contrastive regularization (EFCR) is proposed to tackle two outstanding cha_         _ More           Defocus blur is a persistent problem in microscope imaging that poses harm to pathology interpretation and medical intervention in cell microscopy and microscope surgery. To address this problem, a unified framework including the multi-pyramid transformer (MPT) and extended frequency contrastive regularization (EFCR) is proposed to tackle two outstanding challenges in microscopy deblur: longer attention span and data deficiency. The MPT employs an explicit pyramid structure at each network stage that integrates the cross-scale window attention (CSWA), the intra-scale channel attention (ISCA), and the feature-enhancing feed-forward network (FEFN) to capture long-range cross-scale spatial interaction and global channel context. The EFCR addresses the data deficiency problem by exploring latent deblur signals from different frequency bands. It also enables deblur knowledge transfer to learn cross-domain information from extra data, improving deblur performance for labeled and unlabeled data. Extensive experiments and downstream task validation show the framework achieves state-of-the-art performance across multiple datasets. Project page: https://github.com/PieceZhang/MPT-CataBlur.         _ Less","","arXiv","https://arxiv.org/abs/2403.02611","1","0","origin_of_life"
"Oriented artificial nanofibers and laser induced periodic surface structures as substrates for Schwann cells alignment","Abstract:                _patients' quality of life, there is an urgent need for conduits that effectively support the healing of large defects in nerve pathways through specific guidance of nerve cells. This paper describes two specific methods for achieving directed growth of Schwann_         _ More           People with injuries to the peripheral nervous system, due to its poor functional regeneration, suffer from paralysis of the facial muscles, fingers and hands, or toes and feet, often for the rest of their lives. Therefore, to improve patients' quality of life, there is an urgent need for conduits that effectively support the healing of large defects in nerve pathways through specific guidance of nerve cells. This paper describes two specific methods for achieving directed growth of Schwann cells, a type of glial cells that can support the regeneration of the nerve pathway by guiding the neuronal axons in the direction of their alignment. One method implies the exposure of a poly(ethylene terephthalate) (PET) foil to a KrF* laser beam, that renders a nanorippled surface topography. The other method uses aligned polyamide-6 (PA-6) nanofibers produced via electrospinning on a very fast rotating structured collector, which enables easy nanofiber detachment, without additional effort. Schwann cells growth on these substrates was inspected after one week of cultivation by means of scanning electron microscope (SEM). For both methods we show that Schwann cells grow in a certain direction, predetermined by nanoripples and nanofibers orientation. In contrast, cells cultivated onto unstructured surfaces or randomly oriented nanofibers, show an omnidirectional growth behavior.         _ Less","","arXiv","https://arxiv.org/abs/2403.01973","0","1","synthetic_biology"
"PreRoutGNN for Timing Prediction with Order Preserving Partition: Global Circuit Pre-training, Local Delay Learning and Attentional Cell Modeling","Abstract:                Pre-routing timing prediction has been recently studied for evaluating the quality of a candidate cell placement in chip design. It involves directly estimating the timing metrics for both pin-level (slack, slew) and edge-level (net delay,_         _ More           Pre-routing timing prediction has been recently studied for evaluating the quality of a candidate cell placement in chip design. It involves directly estimating the timing metrics for both pin-level (slack, slew) and edge-level (net delay, cell delay), without time-consuming routing. However, it often suffers from signal decay and error accumulation due to the long timing paths in large-scale industrial circuits. To address these challenges, we propose a two-stage approach. First, we propose global circuit training to pre-train a graph auto-encoder that learns the global graph embedding from circuit netlist. Second, we use a novel node updating scheme for message passing on GCN, following the topological sorting sequence of the learned graph embedding and circuit graph. This scheme residually models the local time delay between two adjacent pins in the updating sequence, and extracts the lookup table information inside each cell via a new attention mechanism. To handle large-scale circuits efficiently, we introduce an order preserving partition scheme that reduces memory consumption while maintaining the topological dependencies. Experiments on 21 real world circuits achieve a new SOTA R2 of 0.93 for slack prediction, which is significantly surpasses 0.59 by previous SOTA method. Code will be available at: https://github.com/Thinklab-SJTU/EDA-AI.         _ Less","","arXiv","https://arxiv.org/abs/2403.00012","1","0","origin_of_life"
"Properties of Hagen-Poiseuille flows in channel networks","Abstract:                _supporting out-of-equilibrium laminar fluxes. Adaptive Hagen-Poiseuille flows show saturation effects on the fluxes in contractile veins, as observed in animal and artificial contractile veins.         _ More           We derive the main properties of adaptive Hagen-Poiseuille flows in elastic microchannel networks akin to biological veins in organisms. We show that adaptive Hagen-Poiseuille flows successfully simulate key features of \\textit{Physarum polycephalum} networks, replicating physiological out-of-equilibrium phenomena like peristalsis and shuttle streaming, associated with the mechanism of nutrient transport in \\textit{Physarum}. A new topological steady state has been identified for asynchronous adaptation, supporting out-of-equilibrium laminar fluxes. Adaptive Hagen-Poiseuille flows show saturation effects on the fluxes in contractile veins, as observed in animal and artificial contractile veins.         _ Less","","arXiv","https://arxiv.org/abs/2402.19185","0","1","synthetic_biology"
"StaPep: an open-source tool for the structure prediction and feature extraction of hydrocarbon-stapled peptides","Abstract:                _dataset of 201 hydrocarbon-stapled peptides and 384 linear peptides with sequence information and experimental membrane permeability, to showcase StaPep's application in artificial intelligence projects.A machine learning-based predictor utilizing above calculated features was developed with AUC of 0.85, for identifying_         _ More           Many tools exist for extracting structural and physiochemical descriptors from linear peptides to predict their properties, but similar tools for hydrocarbon-stapled peptides are lacking.Here, we present StaPep, a Python-based toolkit designed for generating 2D/3D structures and calculating 21 distinct features for hydrocarbon-stapled peptides.The current version supports hydrocarbon-stapled peptides containing 2 non-standard amino acids (norleucine and 2-aminoisobutyric acid) and 6 nonnatural anchoring residues (S3, S5, S8, R3, R5 and R8).Then we established a hand-curated dataset of 201 hydrocarbon-stapled peptides and 384 linear peptides with sequence information and experimental membrane permeability, to showcase StaPep's application in artificial intelligence projects.A machine learning-based predictor utilizing above calculated features was developed with AUC of 0.85, for identifying cell-penetrating hydrocarbon-stapled peptides.StaPep's pipeline spans data retrieval, cleaning, structure generation, molecular feature calculation, and machine learning model construction for hydrocarbon-stapled peptides.The source codes and dataset are freely available on Github: https://github.com/dahuilangda/stapep_package.         _ Less","","arXiv","https://arxiv.org/abs/2402.17997","1","0","origin_of_life"
"Performance of high-order Godunov-type methods in simulations of astrophysical low Mach number flows","Abstract:                _tool for simulating different classes of astrophysical flows. Their accuracy is mostly determined by the spatial interpolant used to reconstruct the pair of Riemann states at cell interfaces and by the Riemann solver that computes the interface fluxes. In most Godunov-type methods, these two steps can be treated independently, so that many different schemes_         _ More           High-order Godunov methods for gas dynamics have become a standard tool for simulating different classes of astrophysical flows. Their accuracy is mostly determined by the spatial interpolant used to reconstruct the pair of Riemann states at cell interfaces and by the Riemann solver that computes the interface fluxes. In most Godunov-type methods, these two steps can be treated independently, so that many different schemes can in principle be built from the same numerical framework. In this work, we use our fully compressible Seven-League Hydro (SLH) code to test the accuracy of six reconstruction methods and three approximate Riemann solvers on two- and three-dimensional (2D and 3D) problems involving subsonic flows only. We consider Mach numbers in the range from $10^{-3}$ to $10^{-1}$ in a well-posed, 2D, Kelvin--Helmholtz instability problem and a 3D turbulent convection zone that excites internal gravity waves in an overlying stable layer. We find that (i) there is a spread of almost four orders of magnitude in computational cost per fixed accuracy between the methods tested in this study, with the most performant method being a combination of a 'low-dissipation' Riemann solver and a sextic reconstruction scheme, (ii) the low-dissipation solver always outperforms conventional Riemann solvers on a fixed grid when the reconstruction scheme is kept the same, (iii) in simulations of turbulent flows, increasing the order of spatial reconstruction reduces the characteristic dissipation length scale achieved on a given grid even if the overall scheme is only second order accurate, (iv) reconstruction methods based on slope-limiting techniques tend to generate artificial, high-frequency acoustic waves during the evolution of the flow, (v) unlimited reconstruction methods introduce oscillations in the thermal stratification near the convective boundary, where the entropy gradient is steep.         _ Less","","arXiv","https://arxiv.org/abs/2402.16706","0","1","synthetic_biology"
"Effective Phonon Dispersion and Low field transport in AlxGa1-xN alloys using supercells: An ab-initio approach","Abstract:                _supercells. Though traditional methods like Virtual Crystal Approximation (VCA) are computationally efficient, the local disorder in the system is not accurately captured as artificial translational symmetry is imposed on the system. However, in the case of supercells, the error introduced by self-image interaction between the impurities is reduced and trans_         _ More           To investigate the transport properties in random alloys, it is important to model the alloy disorder using supercells. Though traditional methods like Virtual Crystal Approximation (VCA) are computationally efficient, the local disorder in the system is not accurately captured as artificial translational symmetry is imposed on the system. However, in the case of supercells, the error introduced by self-image interaction between the impurities is reduced and translational symmetry is explicitly imposed over larger length scales. In this work, we have investigated the Effective Phonon Dispersion (EPD) and transport properties, from first principle calculations using supercells in AlxGa1-xN alloy systems. Using our in-house developed code, the EPD of AlGaN is obtained and the individual modes are identified. Next, we discuss our in-house developed method to calculate low-field transport properties in supercells. First to validate our methods we have solved the Boltzmann Transport Equation using Rode method to compare the phonon limited mobility in the 4 atom GaN primitive cell and 12 atom GaN supercell. Using the same technique, we have investigated the low field transport in random AlxGa1-xN alloy systems. Our calculations show that along with alloy scattering, electron-phonon scattering may also play an important role at room temperature and high-temperature device operation. This technique opens up the path for calculating phonon-limited transport properties in random alloy systems.         _ Less","","arXiv","https://arxiv.org/abs/2402.16203","1","0","origin_of_life"
"AI-Enabled Lung Cancer Prognosis","Abstract:                _mortality, claiming approximately 1.79 million lives globally in 2020, with an estimated 2.21 million new cases diagnosed within the same period. Among these, Non-Small Cell Lung Cancer (NSCLC) is the predominant subtype, characterized by a notably bleak prognosis and low overall survival rate of approximately 25% over five years across all disease stages. H_         _ More           Lung cancer is the primary cause of cancer-related mortality, claiming approximately 1.79 million lives globally in 2020, with an estimated 2.21 million new cases diagnosed within the same period. Among these, Non-Small Cell Lung Cancer (NSCLC) is the predominant subtype, characterized by a notably bleak prognosis and low overall survival rate of approximately 25% over five years across all disease stages. However, survival outcomes vary considerably based on the stage at diagnosis and the therapeutic interventions administered. Recent advancements in artificial intelligence (AI) have revolutionized the landscape of lung cancer prognosis. AI-driven methodologies, including machine learning and deep learning algorithms, have shown promise in enhancing survival prediction accuracy by efficiently analyzing complex multi-omics data and integrating diverse clinical variables. By leveraging AI techniques, clinicians can harness comprehensive prognostic insights to tailor personalized treatment strategies, ultimately improving patient outcomes in NSCLC. Overviewing AI-driven data processing can significantly help bolster the understanding and provide better directions for using such systems.         _ Less","","arXiv","https://arxiv.org/abs/2402.09476","2","3","synthetic_biology"
"Quasineutral multistability in an epidemiological-like model for defective-helper betacoronavirus infection in cell cultures","Abstract:                _captured in mathematical models. Here, we develop and investigate an epidemiological-like mathematical model specifically designed to study the dynamics of betacoronavirus in cell cultures experiments. The dynamics of the model is governed by several degenerate normally hyperbolic invariant manifolds given by quasineutral planes - i.e. filled by equilibrium_         _ More           It is well known that, during replication, RNA viruses spontaneously generate defective viral genomes (DVGs). DVGs are unable to complete an infectious cycle autonomously, and depend on coinfection with a helper wild-type virus (HV) for their replication and/or transmission. The study of the dynamics arising from a HV and its DVGs has been a longstanding question in virology. It has been shown that DVGs can modulate HV replication and, depending on the strength of interference, result in HV extinctions or self-sustained persistent fluctuations. Extensive experimental work has provided mechanistic explanations for DVG generation and compelling evidences of HV-DVGs virus coevolution. Some of these observations have been captured in mathematical models. Here, we develop and investigate an epidemiological-like mathematical model specifically designed to study the dynamics of betacoronavirus in cell cultures experiments. The dynamics of the model is governed by several degenerate normally hyperbolic invariant manifolds given by quasineutral planes - i.e. filled by equilibrium points. Three different quasineutral planes have been identified depending on parameters and involving: (i) persistence of HV and DVGs; (\\emph{ii}) persistence of non-infected cells and DVG-infected cells; and (iii) persistence of DVG-infected cells and DVGs. Sensitivity analyses indicate that model dynamics largely depend on the maximum burst size ($B$), and both the production rate ($_$) and replicative advantage ($_$) of DVGs. Finally, the model has been fitted to single-passage experimental data using artificial intelligence and key virological parameters have been estimated.         _ Less","","arXiv","https://arxiv.org/abs/2402.08620","0","1","synthetic_biology"
"Topological Neural Networks: Mitigating the Bottlenecks of Graph Neural Networks via Higher-Order Interactions","Abstract:                _bottlenecks while accounting also for higher-order interactions. Inspired by Graph Attention Networks, two topological attention networks are proposed: Simplicial and Cell Attention Networks. The rationale behind these architecture is to leverage the extended notion of neighbourhoods provided by the arrangement of groups of nodes within a simplicial or_         _ More           The irreducible complexity of natural phenomena has led Graph Neural Networks to be employed as a standard model to perform representation learning tasks on graph-structured data. While their capacity to capture local and global patterns is remarkable, the implications associated with long-range and higher-order dependencies pose considerable challenges to such models. This work starts with a theoretical framework to reveal the impact of network's width, depth, and graph topology on the over-squashing phenomena in message-passing neural networks. Then, the work drifts towards, higher-order interactions and multi-relational inductive biases via Topological Neural Networks. Such models propagate messages through higher-dimensional structures, providing shortcuts or additional routes for information flow. With this construction, the underlying computational graph is no longer coupled with the input graph structure, thus mitigating the aforementioned bottlenecks while accounting also for higher-order interactions. Inspired by Graph Attention Networks, two topological attention networks are proposed: Simplicial and Cell Attention Networks. The rationale behind these architecture is to leverage the extended notion of neighbourhoods provided by the arrangement of groups of nodes within a simplicial or cell complex to design anisotropic aggregations able to measure the importance of the information coming from different regions of the domain. By doing so, they capture dependencies that conventional Graph Neural Networks might miss. Finally, a multi-way communication scheme is introduced with Enhanced Cellular Isomorphism Networks, which augment topological message passing schemes to enable a direct interactions among groups of nodes arranged in ring-like structures.         _ Less","","arXiv","https://arxiv.org/abs/2402.06908","1","0","origin_of_life"
"Biological computation through recurrence","Abstract:                _stimuli and the internal dynamic state of the network. In this article we review our current understanding of how recurrent networks can be used by biological systems, from cells to brains, for complex information processing. Rather than focusing on sophisticated, artificial recurrent architectures such as long short-t_         _ More           One of the defining features of living systems is their adaptability to changing environmental conditions. This requires organisms to extract temporal and spatial features of their environment, and use that information to compute the appropriate response. In the last two decades, a growing body or work, mainly coming from the machine learning and computational neuroscience fields, has shown that such complex information processing can be performed by recurrent networks. In those networks, temporal computations emerge from the interaction between incoming stimuli and the internal dynamic state of the network. In this article we review our current understanding of how recurrent networks can be used by biological systems, from cells to brains, for complex information processing. Rather than focusing on sophisticated, artificial recurrent architectures such as long short-term memory (LSTM) networks, here we concentrate on simpler network structures and learning algorithms that can be expected to have been found by evolution. We also review studies showing evidence of naturally occurring recurrent networks in living organisms. Lastly, we discuss some relevant evolutionary aspects concerning the emergence of this natural computation paradigm.         _ Less","","arXiv","https://arxiv.org/abs/2402.05243","3","3","multiple"
"Graphene field-effect transistors for sensing ion-channel coupled receptors: towards biohybrid nanoelectronics for chemical detection","Abstract:                _Here we have demonstrated their ability to sense targeted biomolecules, by combining them with ion channels-coupled receptors (ICCRs). These receptors have been naturally or artificially expressed within living cell membranes to generate ion fluxes in presence of chemicals of interest. Here, we have successfully combin_         _ More           Graphene field effect transistors (G-FETs) have appeared as suitable candidates for sensing charges and have thus attracted large interest for ion and chemical detections. In particular, their high sensitivity, chemical robustness, transparency and bendability offer a unique combination for interfacing living and soft matters. Here we have demonstrated their ability to sense targeted biomolecules, by combining them with ion channels-coupled receptors (ICCRs). These receptors have been naturally or artificially expressed within living cell membranes to generate ion fluxes in presence of chemicals of interest. Here, we have successfully combined those biosensors with G-FET array which converts the bio-activation of the ICCRs into readable electronic signals. This hybrid bioelectronic device leverages the advantages of the biological receptor and the graphene field effect transistor enabling the selective detection of biomolecules, which is a current shortcoming of electronic sensors. Additionally, the G-FET allows to discriminate the polarity of the ion fluxes which otherwise remains hidden from conventional electrophysiological recordings. The multisite recording ability offered by the G-FET array rises numerous possibilities for multiscale sensing and high throughput screening of cellular solutions or analytes, which is of both fundamental and applied interests in health and environment monitoring.         _ Less","","arXiv","https://arxiv.org/abs/2402.04378","0","1","synthetic_biology"
"A structure-preserving reconstruction scheme for compressible single- and multi-phase flows based on artificial neural networks","Abstract:                _perceptron for offline training, culminating in a simple two-hidden-layer neural network. This network identifies the reconstruction schemes employed within the target cell. Our innovative deepMTBVD indicator stands out due to its problem-independent nature, relying solely on the relative values of neighboring cells. T_         _ More           In the present study, we introduce an advanced reconstruction indicator, deepMTBVD, which is an evolution of the MUSCL-THINC-BVD algorithm\\cite{RN2, RN12}. This novel indicator is developed by employing a deep learning neural network to train on numerical results derived from 1D Euler equations, thereby enhancing the capability to discern the most suitable reconstruction scheme. In particular, we have designed a multilayer perceptron for offline training, culminating in a simple two-hidden-layer neural network. This network identifies the reconstruction schemes employed within the target cell. Our innovative deepMTBVD indicator stands out due to its problem-independent nature, relying solely on the relative values of neighboring cells. This approach eliminates the need to pre-construct MUSCL and THINC schemes at each time step, thereby reducing the computational effort. Without further modifications, the deepMTBVD seamlessly lends itself to direct application in the compressible multiphase model and straightforward to multi-dimensional cases on Cartesian grids. Numerical results demonstrate that deepMTBVD performs as well as the MUSCL-THINC-BVD scheme in accurately capturing shock waves, contact discontinuities, material interfaces, and vertical solutions with enhanced sharpness and reduced oscillations in smooth regions. Compared with the MUSCL scheme, the deepMTBVD exhibits lower numerical dissipation and superior resolution of complex flow structures, thereby enhancing the overall quality of the solution.         _ Less","","arXiv","https://arxiv.org/abs/2402.03002","0","1","synthetic_biology"
"Investigating the influence of particle size and shape on froth flotation based benefication of lithium-rich minerals in slags","Abstract:                _in the future. Slags obtained from pyrometallurgical recycling represent a promising resource of valuable materials, among them lithium and rare earth elements found in artificial minerals particulate phases. This study investigates the flotation separation of engineered_         _ More           The demand for lithium, as well as other critical resources, needed for electrochemical energy storage is expected to grow significantly in the future. Slags obtained from pyrometallurgical recycling represent a promising resource of valuable materials, among them lithium and rare earth elements found in artificial minerals particulate phases. This study investigates the flotation separation of engineered artificial minerals (EnAMs) in slags, such as lithium aluminate and gehlenite as valuable and gangue phases, respectively. Flotation experiments are carried out in a Partridge-Smith cell using oleic acid (OA) as a benchmark surfactant. Particle characterization is performed using SEM-based Mineral Liberation Analysis (MLA), which provides particle discrete information. From this information, bivariate Tromp functions based on non-parametric kernel density estimation are computed to characterize the separation behavior with respect to particle descriptors. This approach enables investigating the influence of particle size and shape on separation behavior of EnAMs. Furthermore, these results allow for the optimization of flotation experiments for enriching Li-bearing EnAMs.         _ Less","","arXiv","https://arxiv.org/abs/2402.02818","1","0","origin_of_life"
"FDNet: Frequency Domain Denoising Network For Cell Segmentation in Astrocytes Derived From Induced Pluripotent Stem Cells","Abstract:        Artificially generated induced pluripotent stem_         _ More   Artificially generated induced pluripotent stem cells (iPSCs) from somatic cells play an important role for disease modeling and drug screening of neurodegenerative diseases. Astrocytes differentiated from iPSCs are important targets to investigate neuronal metabolism. The astrocyte differentiation progress can be monitored through the variations of morphology observed from microscopy images at different differentiation stages, then determined by molecular biology techniques upon maturation. However, the astrocytes usually ``perfectly'' blend into the background and some of them are covered by interference information (i.e., dead cells, media sediments, and cell debris), which makes astrocytes difficult to observe. Due to the lack of annotated datasets, the existing state-of-the-art deep learning approaches cannot be used to address this issue. In this paper, we introduce a new task named astrocyte segmentation with a novel dataset, called IAI704, which contains 704 images and their corresponding pixel-level annotation masks. Moreover, a novel frequency domain denoising network, named FDNet, is proposed for astrocyte segmentation. In detail, our FDNet consists of a contextual information fusion module (CIF), an attention block (AB), and a Fourier transform block (FTB). CIF and AB fuse multi-scale feature embeddings to localize the astrocytes. FTB transforms feature embeddings into the frequency domain and conducts a high-pass filter to eliminate interference information. Experimental results demonstrate the superiority of our proposed FDNet over the state-of-the-art substitutes in astrocyte segmentation, shedding insights for iPSC differentiation progress prediction.         _ Less","","arXiv","https://arxiv.org/abs/2402.02724","1","1","multiple"
"Adversarial Attacks and Defenses in 6G Network-Assisted IoT Systems","Abstract:                The Internet of Things (IoT) and massive IoT systems are key to sixth-generation (6G) networks due to dense connectivity, ultra-reliability, low latency, and high throughput. Artificial intelligence, including deep learning and machine learning, offers solutions for optimizing and deploying cutting-edge technologies for future radio communications. However,_         _ More           The Internet of Things (IoT) and massive IoT systems are key to sixth-generation (6G) networks due to dense connectivity, ultra-reliability, low latency, and high throughput. Artificial intelligence, including deep learning and machine learning, offers solutions for optimizing and deploying cutting-edge technologies for future radio communications. However, these techniques are vulnerable to adversarial attacks, leading to degraded performance and erroneous predictions, outcomes unacceptable for ubiquitous networks. This survey extensively addresses adversarial attacks and defense methods in 6G network-assisted IoT systems. The theoretical background and up-to-date research on adversarial attacks and defenses are discussed. Furthermore, we provide Monte Carlo simulations to validate the effectiveness of adversarial attacks compared to jamming attacks. Additionally, we examine the vulnerability of 6G IoT systems by demonstrating attack strategies applicable to key technologies, including reconfigurable intelligent surfaces, massive multiple-input multiple-output (MIMO)/cell-free massive MIMO, satellites, the metaverse, and semantic communications. Finally, we outline the challenges and future developments associated with adversarial attacks and defenses in 6G IoT systems.         _ Less","","arXiv","https://arxiv.org/abs/2401.14780","1","1","multiple"
"Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network","Abstract:                The brain extracellular space (ECS), an irregular, extremely tortuous nanoscale space located between cells or between cells and blood vessels, is crucial for nerve cell survival. It plays a pivotal role in high-level brain functions such as memory, emotion, and sensation. Howeve_         _ More           The brain extracellular space (ECS), an irregular, extremely tortuous nanoscale space located between cells or between cells and blood vessels, is crucial for nerve cell survival. It plays a pivotal role in high-level brain functions such as memory, emotion, and sensation. However, the specific form of molecular transport within the ECS remain elusive. To address this challenge, this paper proposes a novel approach to quantitatively analyze the molecular transport within the ECS by solving an inverse problem derived from the advection-diffusion equation (ADE) using a physics-informed neural network (PINN). PINN provides a streamlined solution to the ADE without the need for intricate mathematical formulations or grid settings. Additionally, the optimization of PINN facilitates the automatic computation of the diffusion coefficient governing long-term molecule transport and the velocity of molecules driven by advection. Consequently, the proposed method allows for the quantitative analysis and identification of the specific pattern of molecular transport within the ECS through the calculation of the Peclet number. Experimental validation on two datasets of magnetic resonance images (MRIs) captured at different time points showcases the effectiveness of the proposed method. Notably, our simulations reveal identical molecular transport patterns between datasets representing rats with tracer injected into the same brain region. These findings highlight the potential of PINN as a promising tool for comprehensively exploring molecular transport within the ECS.         _ Less","","arXiv","https://arxiv.org/abs/2401.12435","1","1","multiple"
"An Ultra-Sensitive Visible-IR Range Fiber Based Plasmonic Refractive Index Sensor","Abstract:                _RIU. In addition, a novel artificial neural network (ANN) model is proposed to be integrated into the practical setup in order to accurately predict the RIs by carefully examining the simulation data. The mean square error (MSE) and accuracy ($R^2$) values for the ANN model are found about 0.0097 and 0.9987, respectively, indicating the high prediction capa_         _ More           Photonic crystal fiber (PCF)-based plasmonic sensors have gained considerable attention because of their highly sensitive performance and broad range of sensing regimes. In this work, a relatively simple ultra-sensitive PCF-based surface plasmon resonance (SPR) sensor has been proposed for detecting different analyte refractive indices (RIs) ranging from 1.33 to 1.43 over a wide range of wavelength spectrum spanning 0.55 $_$m to 3.50 $_$m. The comprehensive finite-element simulations indicate that it is possible to achieve remarkable sensing performances such as wavelength sensitivity (WS) and figure of merit (FOM) as high as 123,000 nm/RIU and 683 RIU$^{-1}$, respectively, and extremely low values of wavelength resolution (WR) of 8.13 x 10$^{-8}$ RIU. In addition, a novel artificial neural network (ANN) model is proposed to be integrated into the practical setup in order to accurately predict the RIs by carefully examining the simulation data. The mean square error (MSE) and accuracy ($R^2$) values for the ANN model are found about 0.0097 and 0.9987, respectively, indicating the high prediction capability of the proposed ANN model. Due to its exceptional sensitivity and precise detection capabilities, the proposed device has the potential to serve as a viable option for sensing analyte refractive index (RI). Additionally, the sensor could be utilized for identifying cancerous cells and detecting urinary tract infections in humans.         _ Less","","arXiv","https://arxiv.org/abs/2401.10968","1","1","multiple"
"MATE-Pred: Multimodal Attention-based TCR-Epitope interaction Predictor","Abstract:                An accurate binding affinity prediction between T-cell receptors and epitopes contributes decisively to develop successful immunotherapy strategies. Some state-of-the-art computational methods implement deep learning techniques by integrating evolutionary features to convert the amino acid residues of_         _ More           An accurate binding affinity prediction between T-cell receptors and epitopes contributes decisively to develop successful immunotherapy strategies. Some state-of-the-art computational methods implement deep learning techniques by integrating evolutionary features to convert the amino acid residues of cell receptors and epitope sequences into numerical values, while some other methods employ pre-trained language models to summarize the embedding vectors at the amino acid residue level to obtain sequence-wise representations.   Here, we propose a highly reliable novel method, MATE-Pred, that performs multi-modal attention-based prediction of T-cell receptors and epitopes binding affinity. The MATE-Pred is compared and benchmarked with other deep learning models that leverage multi-modal representations of T-cell receptors and epitopes. In the proposed method, the textual representation of proteins is embedded with a pre-trained bi-directional encoder model and combined with two additional modalities: a) a comprehensive set of selected physicochemical properties; b) predicted contact maps that estimate the 3D distances between amino acid residues in the sequences.   The MATE-Pred demonstrates the potential of multi-modal model in achieving state-of-the-art performance (+8.4\\% MCC, +5.5\\% AUC compared to baselines) and efficiently capturing contextual, physicochemical, and structural information from amino acid residues. The performance of MATE-Pred projects its potential application in various drug discovery regimes.         _ Less","","arXiv","https://arxiv.org/abs/2401.08619","2","2","multiple"
"Predicting heteropolymer interactions: demixing and hypermixing of disordered protein sequences","Abstract:        Cells contain multiple condensates which spontaneously form due to the heterotypic interactions between their components. Although the proteins and disordered region sequences that are responsible for condensate formation have been extensively studied, the rule of interactions between the components that allow demixing, i.e., the coexistence of multiple cond_         _ More   Cells contain multiple condensates which spontaneously form due to the heterotypic interactions between their components. Although the proteins and disordered region sequences that are responsible for condensate formation have been extensively studied, the rule of interactions between the components that allow demixing, i.e., the coexistence of multiple condensates, is yet to be elucidated. Here we construct an effective theory of the interaction between heteropolymers by fitting it to the molecular dynamics simulation results obtained for more than 200 sequences sampled from the disordered regions of human proteins. We find that the sum of amino acid pair interactions across two heteropolymers predicts the Boyle temperature qualitatively well, which can be quantitatively improved by the dimer pair approximation, where we incorporate the effect of neighboring amino acids in the sequences. The improved theory, combined with the finding of a metric that captures the effective interaction strength between distinct sequences, allowed the selection of up to three disordered region sequences that demix with each other in multicomponent simulations, as well as the generation of artificial sequences that demix with a given sequence.The theory points to a generic sequence design strategy to demix or hypermix thanks to the low dimensional nature of the space of the interactions that we identify. As a consequence of the geometric arguments in the space of interactions, we find that the number of distinct sequences that can demix with each other is strongly constrained, irrespective of the choice of the coarse-grained model. Altogether, we construct a theoretical basis for methods to estimate the effective interaction between heteropolymers, which can be utilized in predicting phase separation properties as well as rules of assignment in the localization and functions of disordered proteins.         _ Less","","arXiv","https://arxiv.org/abs/2401.07826","1","0","origin_of_life"
"Supersonic turbulence simulations with GPU-based high-order Discontinuous Galerkin hydrodynamics","Abstract:                _to retain its accuracy and stability for highly supersonic turbulence, characterized by a network of shocks. We find that our new implementation, which regularizes shocks at sub-cell resolution with_         _ More           We investigate the numerical performance of a Discontinuous Galerkin (DG) hydrodynamics implementation when applied to the problem of driven, isothermal supersonic turbulence. While the high-order element-based spectral approach of DG is known to efficiently produce accurate results for smooth problems (exponential convergence with expansion order), physical discontinuities in solutions, like shocks, prove challenging and may significantly diminish DG's applicability to practical astrophysical applications. We consider whether DG is able to retain its accuracy and stability for highly supersonic turbulence, characterized by a network of shocks. We find that our new implementation, which regularizes shocks at sub-cell resolution with artificial viscosity, still performs well compared to standard second-order schemes for moderately high Mach number turbulence, provided we also employ an additional projection of the primitive variables onto the polynomial basis to regularize the extrapolated values at cell interfaces. However, the accuracy advantage of DG diminishes significantly in the highly supersonic regime. Nevertheless, in turbulence simulations with a wide dynamic range that start with supersonic Mach numbers and can resolve the sonic point, the low numerical dissipation of DG schemes still proves advantageous in the subsonic regime. Our results thus support the practical applicability of DG schemes for demanding astrophysical problems that involve strong shocks and turbulence, such as star formation in the interstellar medium. We also discuss the substantial computational cost of DG when going to high order, which needs to be weighted against the resulting accuracy gain. For problems containing shocks, this favours the use of comparatively low DG order.         _ Less","","arXiv","https://arxiv.org/abs/2401.06841","1","0","origin_of_life"
"Large language models in bioinformatics: applications and perspectives","Abstract:                Large language models (LLMs) are a class of artificial intelligence models based on deep learning, which have great performance in various tasks, especially in natural language processing (NLP). Large language models typically consist of_         _ More           Large language models (LLMs) are a class of artificial intelligence models based on deep learning, which have great performance in various tasks, especially in natural language processing (NLP). Large language models typically consist of artificial neural networks with numerous parameters, trained on large amounts of unlabeled input using self-supervised or semi-supervised learning. However, their potential for solving bioinformatics problems may even exceed their proficiency in modeling human language. In this review, we will present a summary of the prominent large language models used in natural language processing, such as BERT and GPT, and focus on exploring the applications of large language models at different omics levels in bioinformatics, mainly including applications of large language models in genomics, transcriptomics, proteomics, drug discovery and single cell analysis. Finally, this review summarizes the potential and prospects of large language models in solving bioinformatic problems.         _ Less","","arXiv","https://arxiv.org/abs/2401.04155","1","1","multiple"
"Multi-Modal Cognitive Maps based on Neural Networks trained on Successor Representations","Abstract:                _complex is heavily involved in episodic and relational memory processing, as well as spatial navigation and is thought to built cognitive maps via place and grid cells. To make use of the promising properties of cognitive maps, we set up a multi-modal neural network using successor representations which is able to model place_         _ More           Cognitive maps are a proposed concept on how the brain efficiently organizes memories and retrieves context out of them. The entorhinal-hippocampal complex is heavily involved in episodic and relational memory processing, as well as spatial navigation and is thought to built cognitive maps via place and grid cells. To make use of the promising properties of cognitive maps, we set up a multi-modal neural network using successor representations which is able to model place cell dynamics and cognitive map representations. Here, we use multi-modal inputs consisting of images and word embeddings. The network learns the similarities between novel inputs and the training database and therefore the representation of the cognitive map successfully. Subsequently, the prediction of the network can be used to infer from one modality to another with over $90\\%$ accuracy. The proposed method could therefore be a building block to improve current AI systems for better understanding of the environment and the different modalities in which objects appear. The association of specific modalities with certain encounters can therefore lead to context awareness in novel situations when similar encounters with less information occur and additional information can be inferred from the learned cognitive map. Cognitive maps, as represented by the entorhinal-hippocampal complex in the brain, organize and retrieve context from memories, suggesting that large language models (LLMs) like ChatGPT could harness similar architectures to function as a high-level processing center, akin to how the hippocampus operates within the cortex hierarchy. Finally, by utilizing multi-modal inputs, LLMs can potentially bridge the gap between different forms of data (like images and words), paving the way for context-awareness and grounding of abstract concepts through learned associations, addressing the grounding problem in AI.         _ Less","","arXiv","https://arxiv.org/abs/2401.01364","1","0","origin_of_life"
"Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge","Abstract:                Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit_         _ More           Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery. This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption, draining only 180mW for a complete inference on an input image. The latency is comparable to the ones observed in the state-of-the-art, with 780us/img. To the authors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD. In this case, the accelerator requires 18,268 logic cells and 51 BRAM, with an overall power consumption of 430mW and a latency of 54 us for a complete inference on input data. This underscores the significance of Spiker+ in the hardware-accelerated SNN landscape, making it an excellent solution to deploy configurable and tunable SNN architectures in resource and power-constrained edge applications.         _ Less","","arXiv","https://arxiv.org/abs/2401.01141","1","1","multiple"
"Multidimensional nanoarchitectures for improved indoor light harvesting in dye-sensitized solar cells","Abstract:                Dye Sensitized Solar Cells (DSSCs) have recently regained attention for indoor light harvesting and powering wireless devices. Advantages such as cost-effectiveness, flexibility, wide angular response, and lightweight design have driven the fostering of the implementation of advanced photonic architectures, dedicated photosensitizers and compatibility with w_         _ More           Dye Sensitized Solar Cells (DSSCs) have recently regained attention for indoor light harvesting and powering wireless devices. Advantages such as cost-effectiveness, flexibility, wide angular response, and lightweight design have driven the fostering of the implementation of advanced photonic architectures, dedicated photosensitizers and compatibility with wearable carriers. However, to fully exploit their potential, crucial aspects require further attention, in particular the improvement of spectral compatibility and low-light harvesting mechanisms, as well as the development of efficient photoanodes through high-yield scalable methods. In this article, we propose the use of nanocomposite photoanodes integrating mesoporous TiO2 (m-TiO2) nanoparticles, ITO nanotubes (NTs) and TiO2 anatase shells (ITO@TiO2 NTs) prepared by step-by-step method relying on mild temperature conditions and avoiding toxic precursors. These photoanodes outperform previous attempts to implement low-dimensional ITO and ITO@TiO2 nanowires and nanotubes for outdoor light conversion, demonstrating an outstanding PCE under low artificial light intensity of 24 % for at 0.014 mWcm-2, a 166 % increase compared to the conventional architectures. Advanced microstructural, optical, and electrochemical characterizations have revealed that the strong scattering effect of the light in the visible range coupled with enhanced charge collection at low-intensity illumination are the essential mechanisms responsible for such enhanced energy conversion. Remarkably, our devices retain up to 90% of the normal incidence efficiency even under glancing illumination, while conventional reference devices show a drop down to 50%.         _ Less","","arXiv","https://arxiv.org/abs/2312.16663","0","1","synthetic_biology"
"Astrocyte Regulated Neuromorphic Central Pattern Generator Control of Legged Robotic Locomotion","Abstract:                _Generators (CPGs) for bionics robotic control algorithms - inspired from neural circuits governing the collaboration of the limb muscles in animal movement. Implementation of artificial CPGs on neuromorphic hardware platforms can potentially enable adaptive and energy-efficient edge robotics applications in resource constrained environments. However, underly_         _ More           Neuromorphic computing systems, where information is transmitted through action potentials in a bio-plausible fashion, is gaining increasing interest due to its promise of low-power event-driven computing. Application of neuromorphic computing in robotic locomotion research have largely focused on Central Pattern Generators (CPGs) for bionics robotic control algorithms - inspired from neural circuits governing the collaboration of the limb muscles in animal movement. Implementation of artificial CPGs on neuromorphic hardware platforms can potentially enable adaptive and energy-efficient edge robotics applications in resource constrained environments. However, underlying rewiring mechanisms in CPG for gait emergence process is not well understood. This work addresses the missing gap in literature pertaining to CPG plasticity and underscores the critical homeostatic functionality of astrocytes - a cellular component in the brain that is believed to play a major role in multiple brain functions. This paper introduces an astrocyte regulated Spiking Neural Network (SNN)-based CPG for learning locomotion gait through Reward-Modulated STDP for quadruped robots, where the astrocytes help build inhibitory connections among the artificial motor neurons in different limbs. The SNN-based CPG is simulated on a multi-object physics simulation platform resulting in the emergence of a trotting gait while running the robot on flat ground. $23.3\\times$ computational power savings is observed in comparison to a state-of-the-art reinforcement learning based robot control algorithm. Such a neuroscience-algorithm co-design approach can potentially enable a quantum leap in the functionality of neuromorphic systems incorporating glial cell functionality.         _ Less","","arXiv","https://arxiv.org/abs/2312.15805","2","0","origin_of_life"
"Artificial Hair Sensor Placement Optimization on Airfoils for Angle of Attack Prediction","Abstract:                Arrays of bioinspired artificial hair-cell airflow velocity sensors can enable flight-by-feel of small, unmanned aircraft. Natural fliers - bats, insects, and birds - have hundred or thousands of velocity sensors distributed across their wings. Aircraft designers do not have this luxury due to size, weight, and power c_         _ More           Arrays of bioinspired artificial hair-cell airflow velocity sensors can enable flight-by-feel of small, unmanned aircraft. Natural fliers - bats, insects, and birds - have hundred or thousands of velocity sensors distributed across their wings. Aircraft designers do not have this luxury due to size, weight, and power constraints. The challenge is to identify the best locations for a small set of sensors to extract relevant information from the flow field for the prediction of flight control parameters. In this paper, we introduce the data-reducing Sparse Sensor Placement Optimization for Prediction algorithm which locates near-optimal sensor placement on airfoils and wings. For two or more sensors this algorithm finds a set of sensor locations (design point) which predicts angle of attack to within 0.10 degrees and ranks within the top 1% of all possible design points found by brute force search. We demonstrate this algorithm on several variations of airfoil sections of infinite and finite wings in clean and noisy data, evaluate model sensitivities, and show that the algorithm can be used to identify an appropriate number of sensors for a given accuracy requirement. Applications for this algorithm are explored for aircraft design and flight-by-feel control.         _ Less","","arXiv","https://arxiv.org/abs/2312.14228","1","0","origin_of_life"
"Light-weight CNN-based VVC Inter Partitioning Acceleration","Abstract:                _method to speed up inter partitioning in VVC. Our method operates at the Coding Tree Unit (CTU) level, by splitting each CTU into a fixed grid of 8x8 blocks. Then each cell in this grid is associated with information about the partitioning depth within that area. A lightweight network for predicting this grid is employed during the rate-distortion optimizati_         _ More           The Versatile Video Coding (VVC) standard has been finalized by Joint Video Exploration Team (JVET) in 2020. Compared to the High Efficiency Video Coding (HEVC) standard, VVC offers about 50% compression efficiency gain, in terms of Bjontegaard Delta-Rate (BD-rate), at the cost of about 10x more encoder complexity. In this paper, we propose a Convolutional Neural Network (CNN)-based method to speed up inter partitioning in VVC. Our method operates at the Coding Tree Unit (CTU) level, by splitting each CTU into a fixed grid of 8x8 blocks. Then each cell in this grid is associated with information about the partitioning depth within that area. A lightweight network for predicting this grid is employed during the rate-distortion optimization to limit the Quaternary Tree (QT)-split search and avoid partitions that are unlikely to be selected. Experiments show that the proposed method can achieve acceleration ranging from 17% to 30% in the RandomAccess Group Of Picture 32 (RAGOP32) mode of VVC Test Model (VTM)10 with a reasonable efficiency drop ranging from 0.37% to 1.18% in terms of BD-rate increase.         _ Less","","arXiv","https://arxiv.org/abs/2312.10567","1","0","origin_of_life"
"scBiGNN: Bilevel Graph Representation Learning for Cell Type Classification from Single-cell RNA Sequencing Data","Abstract:                Single-cell RNA sequencing (scRNA-seq) technology provides high-throughput gene expression data to study the cellular heterogeneity and dynamics of complex organisms. Graph neural networks (GNNs) have been widely used for automatic_         _ More           Single-cell RNA sequencing (scRNA-seq) technology provides high-throughput gene expression data to study the cellular heterogeneity and dynamics of complex organisms. Graph neural networks (GNNs) have been widely used for automatic cell type classification, which is a fundamental problem to solve in scRNA-seq analysis. However, existing methods do not sufficiently exploit both gene-gene and cell-cell relationships, and thus the true potential of GNNs is not realized. In this work, we propose a bilevel graph representation learning method, named scBiGNN, to simultaneously mine the relationships at both gene and cell levels for more accurate single-cell classification. Specifically, scBiGNN comprises two GNN modules to identify cell types. A gene-level GNN is established to adaptively learn gene-gene interactions and cell representations via the self-attention mechanism, and a cell-level GNN builds on the cell-cell graph that is constructed from the cell representations generated by the gene-level GNN. To tackle the scalability issue for processing a large number of cells, scBiGNN adopts an Expectation Maximization (EM) framework in which the two modules are alternately trained via the E-step and M-step to learn from each other. Through this interaction, the gene- and cell-level structural information is integrated to gradually enhance the classification performance of both GNN modules. Experiments on benchmark datasets demonstrate that our scBiGNN outperforms a variety of existing methods for cell type classification from scRNA-seq data.         _ Less","","arXiv","https://arxiv.org/abs/2312.10310","1","0","origin_of_life"
"Preserving large-scale features in simulations of elastic turbulence","Abstract:                _definiteness, which triggers numerical instabilities. While efforts to tackle these issues have produced a plethora of specialized techniques -- tensor decompositions, artificial diffusion, and shock-capturing advection schemes -- we still lack an unambiguous route to accurate and efficient simulations. In this work, we show that even when a simulation is nu_         _ More           Simulations of elastic turbulence, the chaotic flow of highly elastic and inertialess polymer solutions, are plagued by numerical difficulties: The chaotically advected polymer conformation tensor develops extremely large gradients and can loose its positive definiteness, which triggers numerical instabilities. While efforts to tackle these issues have produced a plethora of specialized techniques -- tensor decompositions, artificial diffusion, and shock-capturing advection schemes -- we still lack an unambiguous route to accurate and efficient simulations. In this work, we show that even when a simulation is numerically stable, maintaining positive-definiteness and displaying the expected chaotic fluctuations, it can still suffer from errors significant enough to distort the large-scale dynamics and flow-structures. Focusing on two-dimensional simulations of the Oldroyd-B and FENE-P equations, we first compare two decompositions of the conformation tensor: symmetric square root (SSR) and Cholesky with a logarithmic transformation (Cholesky-log). While both simulations yield chaotic flows, only the Cholesky-log preserves the pattern of the forcing, i.e., its vortical cells remain ordered in a lattice as opposed to the vortices of the SSR simulations which shrink, expand and reorient constantly. To identify the accurate simulation, we appeal to a hitherto overlooked mathematical bound on the determinant of the conformation tensor, which unequivocally rejects the SSR simulation. Importantly, the accuracy of the Cholesky-log simulation is shown to arise from the logarithmic transformation. We then consider local artificial diffusion, a potential low-cost alternative to high-order advection schemes, and find unfortunately that it significantly modifies the dynamics. We end with an example, showing how the spurious large-scale motions identified here contaminate predictions of scalar mixing.         _ Less","","arXiv","https://arxiv.org/abs/2312.09165","1","0","origin_of_life"
"Morphological Profiling for Drug Discovery in the Era of Deep Learning","Abstract:                _profiling is a valuable tool in phenotypic drug discovery. The advent of high-throughput automated imaging has enabled the capturing of a wide range of morphological features of cells or organisms in response to perturbations at the single-_         _ More           Morphological profiling is a valuable tool in phenotypic drug discovery. The advent of high-throughput automated imaging has enabled the capturing of a wide range of morphological features of cells or organisms in response to perturbations at the single-cell resolution. Concurrently, significant advances in machine learning and deep learning, especially in computer vision, have led to substantial improvements in analyzing large-scale high-content images at high-throughput. These efforts have facilitated understanding of compound mechanism-of-action (MOA), drug repurposing, characterization of cell morphodynamics under perturbation, and ultimately contributing to the development of novel therapeutics. In this review, we provide a comprehensive overview of the recent advances in the field of morphological profiling. We summarize the image profiling analysis workflow, survey a broad spectrum of analysis strategies encompassing feature engineering- and deep learning-based approaches, and introduce publicly available benchmark datasets. We place a particular emphasis on the application of deep learning in this pipeline, covering cell segmentation, image representation learning, and multimodal learning. Additionally, we illuminate the application of morphological profiling in phenotypic drug discovery and highlight potential challenges and opportunities in this field.         _ Less","","arXiv","https://arxiv.org/abs/2312.07899","4","4","multiple"
"Context-Aware Iteration Policy Network for Efficient Optical Flow Estimation","Abstract:                _this by learning contextual information to realize whether flow improvement is bottlenecked or minimal. On the one hand, we use iteration embedding and historical hidden cell, which include previous iterations information, to convey how flow has changed from previous iterations. On the other hand, we use the incremental loss to make the policy network implic_         _ More           Existing recurrent optical flow estimation networks are computationally expensive since they use a fixed large number of iterations to update the flow field for each sample. An efficient network should skip iterations when the flow improvement is limited. In this paper, we develop a Context-Aware Iteration Policy Network for efficient optical flow estimation, which determines the optimal number of iterations per sample. The policy network achieves this by learning contextual information to realize whether flow improvement is bottlenecked or minimal. On the one hand, we use iteration embedding and historical hidden cell, which include previous iterations information, to convey how flow has changed from previous iterations. On the other hand, we use the incremental loss to make the policy network implicitly perceive the magnitude of optical flow improvement in the subsequent iteration. Furthermore, the computational complexity in our dynamic network is controllable, allowing us to satisfy various resource preferences with a single trained model. Our policy network can be easily integrated into state-of-the-art optical flow networks. Extensive experiments show that our method maintains performance while reducing FLOPs by about 40%/20% for the Sintel/KITTI datasets.         _ Less","","arXiv","https://arxiv.org/abs/2312.07180","1","0","origin_of_life"
"Macroscopically Self-Aligned and Chiralized Carbon Nanotubes: From Filtration to Innovation","Abstract:                _1D properties of ordered CNT assemblies. We also focus on a newly discovered class of CNT architectures, combining CNT alignment and twisting mechanisms to create artificial radial and chiral CNT films at wafer scales. Finally, we summarize recent developments related to aligned and chiral CNT films in optoelectronics, highlighting their unique roles in sola_         _ More           Because of their natural one-dimensional (1D) structure combined with intricate chiral variations, carbon nanotubes (CNTs) exhibit various exceptional physical properties, such as ultrahigh electrical and thermal conductivity, exceptional mechanical strength, and chirality-dependent metallicity. These properties make CNTs highly promising for diverse applications, including field-effect transistors, sensors, photodetectors, and thermoelectric devices. While CNTs excel individually at the nanoscale, their 1D and chiral nature can be lost on a macroscopic scale when they are randomly assembled. Therefore, the alignment and organization of CNTs in macroscopic structures is crucial for harnessing their full potential. In this review, we explore recent advancements in understanding CNT alignment mechanisms, improving CNT aligning methods, and demonstrating macroscopically 1D properties of ordered CNT assemblies. We also focus on a newly discovered class of CNT architectures, combining CNT alignment and twisting mechanisms to create artificial radial and chiral CNT films at wafer scales. Finally, we summarize recent developments related to aligned and chiral CNT films in optoelectronics, highlighting their unique roles in solar cells, thermal emitters, and optical modulators.         _ Less","","arXiv","https://arxiv.org/abs/2312.00984","1","1","multiple"
"Removing Biases from Molecular Representations via Information Maximization","Abstract:                High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing w_         _ More           High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing with batch effects, which can introduce systematic errors and non-biological associations in the data. We propose InfoCORE, an Information maximization approach for COnfounder REmoval, to effectively deal with batch effects and obtain refined molecular representations. InfoCORE establishes a variational lower bound on the conditional mutual information of the latent representations given a batch identifier. It adaptively reweighs samples to equalize their implied batch distribution. Extensive experiments on drug screening data reveal InfoCORE's superior performance in a multitude of tasks including molecular property prediction and molecule-phenotype retrieval. Additionally, we show results for how InfoCORE offers a versatile framework and resolves general distribution shifts and issues of data fairness by minimizing correlation with spurious features or removing sensitive attributes. The code is available at https://github.com/uhlerlab/InfoCORE.         _ Less","","arXiv","https://arxiv.org/abs/2312.00718","1","0","origin_of_life"
"Single-Cell Deep Clustering Method Assisted by Exogenous Gene Information: A Novel Approach to Identifying Cell Types","Abstract:                In recent years, the field of single-cell data analysis has seen a marked advancement in the development of clustering methods. Despite advancements, most of these algorithms still concentrate on analyzing the provided single-_         _ More           In recent years, the field of single-cell data analysis has seen a marked advancement in the development of clustering methods. Despite advancements, most of these algorithms still concentrate on analyzing the provided single-cell matrix data. However, in medical applications, single-cell data often involves a wealth of exogenous information, including gene networks. Overlooking this aspect could lead to information loss and clustering results devoid of significant clinical relevance. An innovative single-cell deep clustering method, incorporating exogenous gene information, has been proposed to overcome this limitation. This model leverages exogenous gene network information to facilitate the clustering process, generating discriminative representations. Specifically, we have developed an attention-enhanced graph autoencoder, which is designed to efficiently capture the topological features between cells. Concurrently, we conducted a random walk on an exogenous Protein-Protein Interaction (PPI) network, thereby acquiring the gene's topological features. Ultimately, during the clustering process, we integrated both sets of information and reconstructed the features of both cells and genes to generate a discriminative representation. Extensive experiments have validated the effectiveness of our proposed method. This research offers enhanced insights into the characteristics and distribution of cells, thereby laying the groundwork for early diagnosis and treatment of diseases.         _ Less","","arXiv","https://arxiv.org/abs/2311.17104","1","0","origin_of_life"
"Single-cell Multi-view Clustering via Community Detection with Unknown Number of Clusters","Abstract:                Single-cell multi-view clustering enables the exploration of cellular heterogeneity within the same_         _ More           Single-cell multi-view clustering enables the exploration of cellular heterogeneity within the same cell from different views. Despite the development of several multi-view clustering methods, two primary challenges persist. Firstly, most existing methods treat the information from both single-cell RNA (scRNA) and single-cell Assay of Transposase Accessible Chromatin (scATAC) views as equally significant, overlooking the substantial disparity in data richness between the two views. This oversight frequently leads to a degradation in overall performance. Additionally, the majority of clustering methods necessitate manual specification of the number of clusters by users. However, for biologists dealing with cell data, precisely determining the number of distinct cell types poses a formidable challenge. To this end, we introduce scUNC, an innovative multi-view clustering approach tailored for single-cell data, which seamlessly integrates information from different views without the need for a predefined number of clusters. The scUNC method comprises several steps: initially, it employs a cross-view fusion network to create an effective embedding, which is then utilized to generate initial clusters via community detection. Subsequently, the clusters are automatically merged and optimized until no further clusters can be merged. We conducted a comprehensive evaluation of scUNC using three distinct single-cell datasets. The results underscored that scUNC outperforms the other baseline methods.         _ Less","","arXiv","https://arxiv.org/abs/2311.17103","2","1","origin_of_life"
"Gene regulatory interactions limit the gene expression diversity","Abstract:                The diversity of expressed genes plays a critical role in cellular specialization, adaptation to environmental changes, and overall cell functionality. This diversity varies dramatically across_         _ More           The diversity of expressed genes plays a critical role in cellular specialization, adaptation to environmental changes, and overall cell functionality. This diversity varies dramatically across cell types and is orchestrated by intricate, dynamic, and cell type-specific gene regulatory networks (GRNs). Despite extensive research on GRNs, their governing principles, as well as the underlying forces that have shaped them, remain largely unknown. Here, we investigated whether there is a tradeoff between the diversity of expressed genes and the intensity of GRN interactions. We have developed a computational framework that evaluates GRN interaction intensity from scRNA-seq data and used it to analyze simulated and real scRNA-seq data collected from different tissues in humans, mice, fruit flies, and C. elegans. We find a significant tradeoff between diversity and interaction intensity, driven by stability constraints, where the GRN could be stable up to a critical level of complexity - a product of gene expression diversity and interaction intensity. Furthermore, we analyzed hematopoietic stem cell differentiation data and find that the overall complexity of unstable transition states cells is higher than that of stem cells and fully differentiated cells. Our results suggest that GRNs are shaped by stability constraints which limit the diversity of gene expression.         _ Less","","arXiv","https://arxiv.org/abs/2311.15503","0","1","synthetic_biology"
"SkyCharge: Deploying Unmanned Aerial Vehicles for Dynamic Load Optimization in Solar Small Cell 5G Networks","Abstract:                _user load transfer approach using airborne base stations (BS) mounted on drones for reliable and secure power redistribution across the micro-grid network comprising green small cell BSs. Depending on the user density and the availability of an aerial BS, the energy requirement of a_         _ More           The power requirements posed by the fifth-generation and beyond cellular networks are an important constraint in network deployment and require energy-efficient solutions. In this work, we propose a novel user load transfer approach using airborne base stations (BS) mounted on drones for reliable and secure power redistribution across the micro-grid network comprising green small cell BSs. Depending on the user density and the availability of an aerial BS, the energy requirement of a cell with an energy deficit is accommodated by migrating the aerial BS from a high-energy to a low-energy cell. The proposed hybrid drone-based framework integrates long short-term memory with unique cost functions using an evolutionary neural network for drones and BSs and efficiently manages energy and load redistribution. The proposed algorithm reduces power outages at BSs and maintains consistent throughput stability, thereby demonstrating its capability to boost the reliability and robustness of wireless communication systems.         _ Less","","arXiv","https://arxiv.org/abs/2311.12944","0","1","synthetic_biology"
"Orchard: building large cancer phylogenies using stochastic combinatorial search","Abstract:                Phylogenies depicting the evolutionary history of genetically heterogeneous subpopulations of cells from the same cancer, i.e., cancer phylogenies, offer valuable insights about cancer development and guide treatment strategies. Many methods exist that reconstruct cancer phylogenies using point mutations detected with bulk DNA sequencing. However, these meth_         _ More           Phylogenies depicting the evolutionary history of genetically heterogeneous subpopulations of cells from the same cancer, i.e., cancer phylogenies, offer valuable insights about cancer development and guide treatment strategies. Many methods exist that reconstruct cancer phylogenies using point mutations detected with bulk DNA sequencing. However, these methods become inaccurate when reconstructing phylogenies with more than 30 mutations, or, in some cases, fail to recover a phylogeny altogether. Here, we introduce Orchard, a cancer phylogeny reconstruction algorithm that is fast and accurate using up to 1000 mutations. Orchard samples without replacement from a factorized approximation of the posterior distribution over phylogenies, a novel result derived in this paper. Each factor in this approximate posterior corresponds to a conditional distribution for adding a new mutation to a partially built phylogeny. Orchard optimizes each factor sequentially, generating a sequence of incrementally larger phylogenies that ultimately culminate in a complete tree containing all mutations. Our evaluations demonstrate that Orchard outperforms state-of-the-art cancer phylogeny reconstruction methods in reconstructing more plausible phylogenies across 90 simulated cancers and 14 B-progenitor acute lymphoblastic leukemias (B-ALLs). Remarkably, Orchard accurately reconstructs cancer phylogenies using up to 1,000 mutations. Additionally, we demonstrate that the large and accurate phylogenies reconstructed by Orchard are useful for identifying patterns of somatic mutations and genetic variations among distinct cancer cell subpopulations.         _ Less","","arXiv","https://arxiv.org/abs/2311.12917","0","1","synthetic_biology"
"Now and Future of Artificial Intelligence-based Signet Ring Cell Diagnosis: A Survey","Abstract:                Since signet ring cells (SRCs) are associated with high peripheral metastasis rate and dismal survival, they play an important role in determining surgical approaches and prognosis, while they are easily missed by even experienced pathologists. Although automatic diagnosis SRCs based on deep learning has received increasing attention to assist pathologists i_         _ More           Since signet ring cells (SRCs) are associated with high peripheral metastasis rate and dismal survival, they play an important role in determining surgical approaches and prognosis, while they are easily missed by even experienced pathologists. Although automatic diagnosis SRCs based on deep learning has received increasing attention to assist pathologists in improving the diagnostic efficiency and accuracy, the existing works have not been systematically overviewed, which hindered the evaluation of the gap between algorithms and clinical applications. In this paper, we provide a survey on SRC analysis driven by deep learning from 2008 to August 2023. Specifically, the biological characteristics of SRCs and the challenges of automatic identification are systemically summarized. Then, the representative algorithms are analyzed and compared via dividing them into classification, detection, and segmentation. Finally, for comprehensive consideration to the performance of existing methods and the requirements for clinical assistance, we discuss the open issues and future trends of SRC analysis. The retrospect research will help researchers in the related fields, particularly for who without medical science background not only to clearly find the outline of SRC analysis, but also gain the prospect of intelligent diagnosis, resulting in accelerating the practice and application of intelligent algorithms.         _ Less","","arXiv","https://arxiv.org/abs/2311.10118","3","3","multiple"
"Harnessing Transformers: A Leap Forward in Lung Cancer Image Detection","Abstract:                _the role of Transfer Learning (TL) and transformers in cancer detection based on image analysis. With the enormous evolution of cancer patients, the identification of cancer cells in a patient's body has emerged as a trend in the field of Artificial Intelligence (AI). This process involves analyzing medical images,_         _ More           This paper discusses the role of Transfer Learning (TL) and transformers in cancer detection based on image analysis. With the enormous evolution of cancer patients, the identification of cancer cells in a patient's body has emerged as a trend in the field of Artificial Intelligence (AI). This process involves analyzing medical images, such as Computed Tomography (CT) scans and Magnetic Resonance Imaging (MRIs), to identify abnormal growths that may help in cancer detection. Many techniques and methods have been realized to improve the quality and performance of cancer classification and detection, such as TL, which allows the transfer of knowledge from one task to another with the same task or domain. TL englobes many methods, particularly those used in image analysis, such as transformers and Convolutional Neural Network (CNN) models trained on the ImageNet dataset. This paper analyzes and criticizes each method of TL based on image analysis and compares the results of each method, showing that transformers have achieved the best results with an accuracy of 97.41% for colon cancer detection and 94.71% for Histopathological Lung cancer. Future directions for cancer detection based on image analysis are also discussed.         _ Less","","arXiv","https://arxiv.org/abs/2311.09942","0","2","synthetic_biology"
"Cross-domain feature disentanglement for interpretable modeling of tumor microenvironment impact on drug response","Abstract:                High-throughput screening technology has facilitated the generation of large-scale drug responses across hundreds of cancer cell lines. However, there exists significant discrepancy between in vitro_         _ More           High-throughput screening technology has facilitated the generation of large-scale drug responses across hundreds of cancer cell lines. However, there exists significant discrepancy between in vitro cell lines and actual tumors in vivo in terms of their response to drug treatments, because of tumors comprise of complex cellular compositions and histopathology structure, known as tumor microenvironment (TME), which greatly influences the drug cytotoxicity against tumor cells. To date, no study has focused on modeling the impact of the TME on clinical drug response. This paper proposed a domain adaptation network for feature disentanglement to separate representations of cancer cells and TME of a tumor in patients. Two denoising autoencoders were separately used to extract features from cell lines (source domain) and tumors (target domain) for partial domain alignment and feature decoupling. The specific encoder was enforced to extract information only about TME. Moreover, to ensure generalizability to novel drugs, we applied a graph attention network to learn the latent representation of drugs, allowing us to linearly model the drug perturbation on cellular state in latent space. We calibrated our model on a benchmark dataset and demonstrated its superior performance in predicting clinical drug response and dissecting the influence of the TME on drug efficacy.         _ Less","","arXiv","https://arxiv.org/abs/2311.09264","1","1","multiple"
"High-mobility compensated semimetals, orbital magnetization, and umklapp scattering in bilayer graphene moire superlattices","Abstract:                Twist-controlled moire superlattices (MS) have emerged as a versatile platform in which to realize artificial systems with complex electronic spectra. Bernal-stacked bilayer graphene (BLG) and hexagonal boron nitride (hBN) form an interesting example of the MS that has recently featured a set of unexpected behaviors, such as unconventional ferroelectricity a_         _ More           Twist-controlled moire superlattices (MS) have emerged as a versatile platform in which to realize artificial systems with complex electronic spectra. Bernal-stacked bilayer graphene (BLG) and hexagonal boron nitride (hBN) form an interesting example of the MS that has recently featured a set of unexpected behaviors, such as unconventional ferroelectricity and electronic ratchet effect. Yet, the understanding of the BLG/hBN MS electronic properties has, at present, remained fairly limited. Here we develop a multi-messenger approach that combines standard magnetotransport techniques with low-energy sub-THz excitation to get insights into the properties of this MS. We show that BLG/hBN lattice alignment results in the emergence of compensated semimetals at some integer fillings of the moire bands separated by van Hove singularities where Lifshitz transition occurs. A particularly pronounced semimetal develops when 8 electrons reside in the moire unit cell, where coexisting high-mobility electron and hole systems feature a strong magnetoresistance reaching 2350 % already at B=0.25 T. Next, by measuring the THz-driven Nernst effect in remote bands, we observe valley splitting, pointing to an orbital magnetization characterized by a strongly enhanced effective g-factor of 340. Last, using THz photoresistance measurements, we show that the high-temperature conductivity of the BLG/hBN MS is limited by electron-electron umklapp processes. Our multi-facet analysis introduces THz-driven magnetotransport as a convenient tool to probe the band structure and interaction effects in vdW materials and provides a comprehension of the BLG/hBN MS.         _ Less","","arXiv","https://arxiv.org/abs/2311.05124","1","0","origin_of_life"
"Astrocytes as a mechanism for meta-plasticity and contextually-guided network function","Abstract:                Astrocytes are a ubiquitous and enigmatic type of non-neuronal cell and are found in the brain of all vertebrates. While traditionally viewed as being supportive of neurons, it is increasingly recognized that astrocytes may play a more direct and active role in brain function and neural computation. On account of their sensitivity to a host of physiological_         _ More           Astrocytes are a ubiquitous and enigmatic type of non-neuronal cell and are found in the brain of all vertebrates. While traditionally viewed as being supportive of neurons, it is increasingly recognized that astrocytes may play a more direct and active role in brain function and neural computation. On account of their sensitivity to a host of physiological covariates and ability to modulate neuronal activity and connectivity on slower time scales, astrocytes may be particularly well poised to modulate the dynamics of neural circuits in functionally salient ways. In the current paper, we seek to capture these features via actionable abstractions within computational models of neuron-astrocyte interaction. Specifically, we engage how nested feedback loops of neuron-astrocyte interaction, acting over separated time-scales may endow astrocytes with the capability to enable learning in context-dependent settings, where fluctuations in task parameters may occur much more slowly than within-task requirements. We pose a general model of neuron-synapse-astrocyte interaction and use formal analysis to characterize how astrocytic modulation may constitute a form of meta-plasticity, altering the ways in which synapses and neurons adapt as a function of time. We then embed this model in a bandit-based reinforcement learning task environment, and show how the presence of time-scale separated astrocytic modulation enables learning over multiple fluctuating contexts. Indeed, these networks learn far more reliably versus dynamically homogeneous networks and conventional non-network-based bandit algorithms. Our results indicate how the presence of neuron-astrocyte interaction in the brain may benefit learning over different time-scales and the conveyance of task-relevant contextual information onto circuit dynamics.         _ Less","","arXiv","https://arxiv.org/abs/2311.03508","1","1","multiple"
"Machine learning regression analyses of intensity modulation two-photon spectroscopy (Mlim) in perovskite microcrystals","Abstract:                Perovskite thin films hold great promise for optoelectronic applications, such as solar cells and light emitting diodes. A challenge is that defects are unavoidably formed in the material. Thorough understanding of the defect formation and their dynamics has proven challenging based on traditional spectroscopy. Here we integrated the functional intensity mod_         _ More           Perovskite thin films hold great promise for optoelectronic applications, such as solar cells and light emitting diodes. A challenge is that defects are unavoidably formed in the material. Thorough understanding of the defect formation and their dynamics has proven challenging based on traditional spectroscopy. Here we integrated the functional intensity modulation two-photon spectroscopy with artificial intelligence - enhance data analyses to obtain a deep understanding of defect-related trap states within perovskite microcrystals. We introduce a novel charge carrier recombination dynamics model that comprehensively includes exciton and electron-hole pair photoluminescence (PL) emissions, as well as the trapping and detrapping equilibrium dynamics. By varying parameters in the dynamic model, a large pool of the temperature dependent intensity modulation PL spectra can be simulated by solving the ordinary differential equations in the charge carrier dynamics model. Then, tree-based supervised machine learning methods and ensemble technique -- regression chain have been used to optimize the Machine learning intensity modulation spectroscopy (Mlim), which helps to determine the parameters of the charge carrier dynamics model based on the temperature dependent intensity modulated PL spectra in perovskite. And the reliability of the Mlim predicted trap property parameters is confirmed by directly comparing the Mlim-retrieved intensity modulation spectra with experimental data. Besides, our approach unravels valuable insights into PL emissions, including those from excitons and free electron-hole pairs, but also provides details of trapping, detrapping, and nonradiative depopulation processes, offering a comprehensive understanding of perovskite material photophysics. This study suggests that Mlim applications hold promise for studying various photoactive devices.         _ Less","","arXiv","https://arxiv.org/abs/2311.02788","2","1","origin_of_life"
"scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks","Abstract:                Despite the breakthroughs in biomarker discovery facilitated by differential gene analysis, challenges remain, particularly at the single-cell level. Traditional methodologies heavily rely on user-supplied_         _ More           Despite the breakthroughs in biomarker discovery facilitated by differential gene analysis, challenges remain, particularly at the single-cell level. Traditional methodologies heavily rely on user-supplied cell annotations, focusing on individually expressed data, often neglecting the critical interactions between biological conditions, such as healthy versus diseased states. In response, here we introduce scBeacon, an innovative framework built upon a deep contrastive siamese network. scBeacon pioneers an unsupervised approach, adeptly identifying matched cell populations across varied conditions, enabling a refined differential gene analysis. By utilizing a VQ-VAE framework, a contrastive siamese network, and a greedy iterative strategy, scBeacon effectively pinpoints differential genes that hold potential as key biomarkers. Comprehensive evaluations on a diverse array of datasets validate scBeacon's superiority over existing single-cell differential gene analysis tools. Its precision and adaptability underscore its significant role in enhancing diagnostic accuracy in biomarker discovery. With the emphasis on the importance of biomarkers in diagnosis, scBeacon is positioned to be a pivotal asset in the evolution of personalized medicine and targeted treatments.         _ Less","","arXiv","https://arxiv.org/abs/2311.02594","1","2","synthetic_biology"
"AI-based Self-healing Solutions Applied to Cellular Networks: An Overview","Abstract:                In this article, we provide an overview of machine learning (ML) methods, both classical and deep variants, that are used to implement self-healing for cell outages in cellular networks. Self-healing is a promising approach to network management, which aims to detect and compensate for_         _ More           In this article, we provide an overview of machine learning (ML) methods, both classical and deep variants, that are used to implement self-healing for cell outages in cellular networks. Self-healing is a promising approach to network management, which aims to detect and compensate for cell outages in an autonomous way. This technology aims to decrease the expenses associated with the installation and maintenance of existing 4G and 5G, i.e. emerging 6G networks by simplifying operational tasks through its ability to heal itself. We provide an overview of the basic concepts and taxonomy for SON, self-healing, and ML techniques, in network management. Moreover, we review the state-of-the-art in literature for cell outages, with a particular emphasis on ML-based approaches.         _ Less","","arXiv","https://arxiv.org/abs/2311.02390","2","2","multiple"
"The Moving Discontinuous Galerkin Method with Interface Condition Enforcement for the Simulation of Hypersonic, Viscous Flows","Abstract:                _we develop an optimization solver based on the Levenberg-Marquardt algorithm that features an anisotropic, locally adaptive penalty method to enhance robustness and prevent cell degeneration in the computation of hypersonic, viscous flows. Specifically, we incorporate an anisotropic grid regularization based on the mesh-implied metric that inhibits grid mot_         _ More           The moving discontinuous Galerkin method with interface condition enforcement (MDG-ICE) is a high-order, r-adaptive method that treats the grid as a variable and weakly enforces the conservation law, constitutive law, and corresponding interface conditions in order to implicitly fit high-gradient flow features. In this paper, we develop an optimization solver based on the Levenberg-Marquardt algorithm that features an anisotropic, locally adaptive penalty method to enhance robustness and prevent cell degeneration in the computation of hypersonic, viscous flows. Specifically, we incorporate an anisotropic grid regularization based on the mesh-implied metric that inhibits grid motion in directions with small element length scales, an element shape regularization that inhibits nonlinear deformations of the high-order elements, and a penalty regularization that penalizes degenerate elements. Additionally, we introduce a procedure for locally scaling the regularization operators in an adaptive, elementwise manner in order to maintain grid validity. We apply the proposed MDG-ICE formulation to two- and three-dimensional test cases involving viscous shocks and/or boundary layers, including Mach 17.6 hypersonic viscous flow over a circular cylinder and Mach 5 hypersonic viscous flow over a sphere, which are very challenging test cases for conventional numerical schemes on simplicial grids. Even without artificial dissipation, the computed solutions are free from spurious oscillations and yield highly symmetric surface heat-flux profiles.         _ Less","","arXiv","https://arxiv.org/abs/2311.00701","1","0","origin_of_life"
"Phase separation dependent active motion of Janus lipid vesicles","Abstract:                _systems have emerged as promising contenders for the future of microdevices. While conventional designs have extensively exploited the use of hard colloids, the advancement of cell-inspired architectures represents a pivotal path towards realizing self-regulating and highly functional_         _ More           Active colloidal systems have emerged as promising contenders for the future of microdevices. While conventional designs have extensively exploited the use of hard colloids, the advancement of cell-inspired architectures represents a pivotal path towards realizing self-regulating and highly functional artificial microswimmers. In this work, we fabricate and actuate Janus lipid vesicles demonstrating reconfigurable motion under an AC electric field. The giant unilamellar vesicles (GUVs) undergo spontaneous phase separation at room temperature leading to Janus-like GUVs with two distinct lipid phases. We report self-propulsion of the Janus GUVs via induced charge electroosmosis, in between parallel electrodes. Remarkably, the fluid nature of the lipid membrane affected by the electric field leads to asymmetry-symmetry transient states resulting in run-and-tumble events supported by structure domain analysis. We characterise an enhanced rotational diffusivity associated with tumble events, decoupled from thermal reorientation. Lastly, we identify cargo-release capabilities and a variety of shape-encoded dynamic modes in these vesicles. This cell-inspired architecture provides an alternative route for creating motile artificial cells and programmable microswimmers.         _ Less","","arXiv","https://arxiv.org/abs/2311.00685","1","2","synthetic_biology"
"Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests","Abstract:                _contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and_         _ More           Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a 'bag' of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to 'positive' labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and other works derived from these models will share the same issue. In any context in which these models are being used, this creates the potential for learning incorrect models, which creates risk of operational failure. We identify and demonstrate this problem via a proposed 'algorithmic unit test', where we create synthetic datasets that can be solved by a MIL respecting model, and which clearly reveal learning that violates MIL assumptions. The five evaluated methods each fail one or more of these tests. This provides a model-agnostic way to identify violations of modeling assumptions, which we hope will be useful for future development and evaluation of MIL models.         _ Less","","arXiv","https://arxiv.org/abs/2310.17867","1","0","origin_of_life"
"Manipulating Plasma Excitations with Terahertz Light Pulses in Superconducting Cuprates","Abstract:                _that has been theoretically understood as a sum-frequency process involving a two-plasmon excitation. However, recent experiments in cuprates with two planes per unit cell challenge this interpretation, due to the lack of resonant response at the temperature where the driving frequency matches the plasma energy scale, as observed instead in single-layer cup_         _ More           Layered cuprates offer a preferential playground for optical non-linearity thanks to the emergence, below Tc, of soft out-of-plane Josephson plasmons. The hallmark of such a non-linearity is the observation of Third Harmonic Generation, that has been theoretically understood as a sum-frequency process involving a two-plasmon excitation. However, recent experiments in cuprates with two planes per unit cell challenge this interpretation, due to the lack of resonant response at the temperature where the driving frequency matches the plasma energy scale, as observed instead in single-layer cuprates. Here we show that such an apparent discrepancy in bilayer systems can be resolved by taking into account the combined effect of light polarization and Josephson-coupling anisotropy on setting the energy range where three-dimensional layered plasma modes can be resonantly excited. Our results offer a novel perspective on the possibility to tune on demand high-harmonic generation by artificially designing Josephson heterostructures.         _ Less","","arXiv","https://arxiv.org/abs/2310.16815","1","0","origin_of_life"
"Skin Lesion Segmentation Improved by Transformer-based Networks with Inter-scale Dependency Modeling","Abstract:                Melanoma, a dangerous type of skin cancer resulting from abnormal skin cell growth, can be treated if detected early. Various approaches using Fully Convolutional Networks (FCNs) have been proposed, with the U-Net architecture being prominent To aid in its diagnosis through automatic skin lesion segmentation. However, the symmetrical U-Net model's relian_         _ More           Melanoma, a dangerous type of skin cancer resulting from abnormal skin cell growth, can be treated if detected early. Various approaches using Fully Convolutional Networks (FCNs) have been proposed, with the U-Net architecture being prominent To aid in its diagnosis through automatic skin lesion segmentation. However, the symmetrical U-Net model's reliance on convolutional operations hinders its ability to capture long-range dependencies crucial for accurate medical image segmentation. Several Transformer-based U-Net topologies have recently been created to overcome this limitation by replacing CNN blocks with different Transformer modules to capture local and global representations. Furthermore, the U-shaped structure is hampered by semantic gaps between the encoder and decoder. This study intends to increase the network's feature re-usability by carefully building the skip connection path. Integrating an already calculated attention affinity within the skip connection path improves the typical concatenation process utilized in the conventional skip connection path. As a result, we propose a U-shaped hierarchical Transformer-based structure for skin lesion segmentation and an Inter-scale Context Fusion (ISCF) method that uses attention correlations in each stage of the encoder to adaptively combine the contexts from each stage to mitigate semantic gaps. The findings from two skin lesion segmentation benchmarks support the ISCF module's applicability and effectiveness. The code is publicly available at \\url{https://github.com/saniaesk/skin-lesion-segmentation}         _ Less","","arXiv","https://arxiv.org/abs/2310.13604","0","1","synthetic_biology"
"Zero-shot Learning of Drug Response Prediction for Preclinical Drug Screening","Abstract:                Conventional deep learning methods typically employ supervised learning for drug response prediction (DRP). This entails dependence on labeled response data from drugs for model training. However, practical applications in the preclinical drug screening phase demand that DRP models predict responses for novel compounds, often with unknown drug responses. This presents a challenge, rendering superv_         _ More           Conventional deep learning methods typically employ supervised learning for drug response prediction (DRP). This entails dependence on labeled response data from drugs for model training. However, practical applications in the preclinical drug screening phase demand that DRP models predict responses for novel compounds, often with unknown drug responses. This presents a challenge, rendering supervised deep learning methods unsuitable for such scenarios. In this paper, we propose a zero-shot learning solution for the DRP task in preclinical drug screening. Specifically, we propose a Multi-branch Multi-Source Domain Adaptation Test Enhancement Plug-in, called MSDA. MSDA can be seamlessly integrated with conventional DRP methods, learning invariant features from the prior response data of similar drugs to enhance real-time predictions of unlabeled compounds. We conducted experiments using the GDSCv2 and CellMiner datasets. The results demonstrate that MSDA efficiently predicts drug responses for novel compounds, leading to a general performance improvement of 5-10\\% in the preclinical drug screening phase. The significance of this solution resides in its potential to accelerate the drug discovery process, improve drug candidate assessment, and facilitate the success of drug discovery.         _ Less","","arXiv","https://arxiv.org/abs/2310.12996","0","1","synthetic_biology"
"Moire synaptic transistor for homogeneous-architecture reservoir computing","Abstract:                _in the single electronic device have been desired to implement the reservoir and the readout layer of reservoir computing system. Two-dimensional moire material, with an artificial lattice constant many times larger than the atomic length scale, is one type of most studied_         _ More           Reservoir computing has been considered as a promising intelligent computing paradigm for effectively processing complex temporal information. Exploiting tunable and reproducible dynamics in the single electronic device have been desired to implement the reservoir and the readout layer of reservoir computing system. Two-dimensional moire material, with an artificial lattice constant many times larger than the atomic length scale, is one type of most studied artificial quantum materials in community of material science and condensed-matter physics over the past years. These materials are featured with gate-tunable periodic potential and electronic correlation, thus varying the electric field allows the electrons in the moire potential per unit cell to exhibit distinct and reproducible dynamics, showing great promise in robust reservoir computing. Here, we report that a moire synaptic transistor can be used to implement the reservoir computing system with a homogeneous reservoir-readout architecture. The synaptic transistor is fabricated based on a h-BN/bilayer graphene/h-BN moire heterostructure, exhibiting ferroelectricity-like hysteretic gate voltage dependence of resistance. Varying the magnitude of the gate voltage enables the moire transistor to be switched between long-term memory and short-term memory with nonlinear dynamics. By employing the short- and long-term memory as the reservoir nodes and weights of the readout layer, respectively, we construct a full-moire physical neural network and demonstrate that the classification accuracy of 90.8% can be achieved for the MNIST handwritten digit database. Our work would pave the way towards the development of neuromorphic computing based on the moire materials.         _ Less","","arXiv","https://arxiv.org/abs/2310.11743","1","0","origin_of_life"
"Role of Morphogenetic Competency on Evolution","Abstract:                _morphospace, and assess how the degree and manner of problem solving competency during morphogenesis effects evolutionary dynamics. To this end, we evolve populations of artificial embryos using a standard genetic algorithm in silico._         _ More           The relationship between intelligence and evolution is bidirectional: while evolution can help evolve intelligences, the degree of intelligence itself can impact evolution (Baldwin, 1896). In the field of Evolutionary Computation, the inverse relationship (impact of intelligence on evolution) is approached from the perspective of organism level behaviour (Hinton, 1996). We extend these ideas to the developmental (cellular morphogenetic) level in the context of an expanded view of intelligence as not only the ability of a system to navigate the three-dimensional world, but also as the ability to navigate other arbitrary spaces (transcriptional, anatomical, physiological, etc.). Here, we specifically focus on the intelligence of a minimal model of a system navigating anatomical morphospace, and assess how the degree and manner of problem solving competency during morphogenesis effects evolutionary dynamics. To this end, we evolve populations of artificial embryos using a standard genetic algorithm in silico. Artificial embryos were cellular collectives given the capacity to undergo morphogenetic rearrangement (e.g., regulative development) prior to selection within an evolutionary cycle. Results from our model indicates that morphogenetic competency significantly alters evolutionary dynamics, with evolution preferring to improve anatomical intelligence rather than perfect the structural genes. These observations hint that evolution in the natural world may be leveraging the problem solving competencies of cells at multiple scales to boost evolvability and robustness to novel conditions. We discuss implications of our results for the Developmental Biology and Artificial Life communities.         _ Less","","arXiv","https://arxiv.org/abs/2310.09318","0","1","synthetic_biology"
"Pain Forecasting using Self-supervised Learning and Patient Phenotyping: An attempt to prevent Opioid Addiction","Abstract:                Sickle Cell Disease (SCD) is a chronic genetic disorder characterized by recurrent acute painful episodes. Opioids are often used to manage these painful episodes; the extent of their use in managing pain in this disorder is an issue of debate. The risk of addiction and side effects of these opioid treatments can often lead to more pain episodes in the futur_         _ More           Sickle Cell Disease (SCD) is a chronic genetic disorder characterized by recurrent acute painful episodes. Opioids are often used to manage these painful episodes; the extent of their use in managing pain in this disorder is an issue of debate. The risk of addiction and side effects of these opioid treatments can often lead to more pain episodes in the future. Hence, it is crucial to forecast future patient pain trajectories to help patients manage their SCD to improve their quality of life without compromising their treatment. It is challenging to obtain many pain records to design forecasting models since it is mainly recorded by patients' self-report. Therefore, it is expensive and painful (due to the need for patient compliance) to solve pain forecasting problems in a purely supervised manner. In light of this challenge, we propose to solve the pain forecasting problem using self-supervised learning methods. Also, clustering such time-series data is crucial for patient phenotyping, anticipating patients' prognoses by identifying 'similar' patients, and designing treatment guidelines tailored to homogeneous patient subgroups. Hence, we propose a self-supervised learning approach for clustering time-series data, where each cluster comprises patients who share similar future pain profiles. Experiments on five years of real-world datasets show that our models achieve superior performance over state-of-the-art benchmarks and identify meaningful clusters that can be translated into actionable information for clinical decision-making.         _ Less","","arXiv","https://arxiv.org/abs/2310.06075","1","0","origin_of_life"
"Cell Tracking-by-detection using Elliptical Bounding Boxes","Abstract:        Cell detection and tracking are paramount for bio-analysis. Recent approaches rely on the tracking-by-model evolution paradigm, which usually consists of training end-to-end deep learning models to detect and track the_         _ More   Cell detection and tracking are paramount for bio-analysis. Recent approaches rely on the tracking-by-model evolution paradigm, which usually consists of training end-to-end deep learning models to detect and track the cells on the frames with promising results. However, such methods require extensive amounts of annotated data, which is time-consuming to obtain and often requires specialized annotators. This work proposes a new approach based on the classical tracking-by-detection paradigm that alleviates the requirement of annotated data. More precisely, it approximates the cell shapes as oriented ellipses and then uses generic-purpose oriented object detectors to identify the cells in each frame. We then rely on a global data association algorithm that explores temporal cell similarity using probability distance metrics, considering that the ellipses relate to two-dimensional Gaussian distributions. Our results show that our method can achieve detection and tracking results competitively with state-of-the-art techniques that require considerably more extensive data annotation. Our code is available at: https://github.com/LucasKirsten/Deep-Cell-Tracking-EBB.         _ Less","","arXiv","https://arxiv.org/abs/2310.04895","1","1","multiple"
"scHyena: Foundation Model for Full-Length Single-Cell RNA-Seq Analysis in Brain","Abstract:                Single-cell RNA sequencing (scRNA-seq) has made significant strides in unraveling the intricate cellular diversity within complex tissues. This is particularly critical in the brain, presenting a greater diversity of_         _ More           Single-cell RNA sequencing (scRNA-seq) has made significant strides in unraveling the intricate cellular diversity within complex tissues. This is particularly critical in the brain, presenting a greater diversity of cell types than other tissue types, to gain a deeper understanding of brain function within various cellular contexts. However, analyzing scRNA-seq data remains a challenge due to inherent measurement noise stemming from dropout events and the limited utilization of extensive gene expression information. In this work, we introduce scHyena, a foundation model designed to address these challenges and enhance the accuracy of scRNA-seq analysis in the brain. Specifically, inspired by the recent Hyena operator, we design a novel Transformer architecture called singe-cell Hyena (scHyena) that is equipped with a linear adaptor layer, the positional encoding via gene-embedding, and a {bidirectional} Hyena operator. This enables us to process full-length scRNA-seq data without losing any information from the raw data. In particular, our model learns generalizable features of cells and genes through pre-training scHyena using the full length of scRNA-seq data. We demonstrate the superior performance of scHyena compared to other benchmark methods in downstream tasks, including cell type classification and scRNA-seq imputation.         _ Less","","arXiv","https://arxiv.org/abs/2310.02713","1","0","origin_of_life"
"A Robust Machine Learning Approach for Path Loss Prediction in 5G Networks with Nested Cross Validation","Abstract:                _error and stable results for ML deployment. First, we acquire a publicly available dataset obtained through a comprehensive measurement campaign conducted in an urban macro-cell scenario located in Beijing, China. The dataset includes crucial information such as longitude, latitude, elevation, altitude, clutter height, and distance, which are utilized as ess_         _ More           The design and deployment of fifth-generation (5G) wireless networks pose significant challenges due to the increasing number of wireless devices. Path loss has a landmark importance in network performance optimization, and accurate prediction of the path loss, which characterizes the attenuation of signal power during transmission, is critical for effective network planning, coverage estimation, and optimization. In this sense, we utilize machine learning (ML) methods, which overcome conventional path loss prediction models drawbacks, for path loss prediction in a 5G network system to facilitate more accurate network planning, resource optimization, and performance improvement in wireless communication systems. To this end, we utilize a novel approach, nested cross validation scheme, with ML to prevent overfitting, thereby getting better generalization error and stable results for ML deployment. First, we acquire a publicly available dataset obtained through a comprehensive measurement campaign conducted in an urban macro-cell scenario located in Beijing, China. The dataset includes crucial information such as longitude, latitude, elevation, altitude, clutter height, and distance, which are utilized as essential features to predict the path loss in the 5G network system. We deploy Support Vector Regression (SVR), CatBoost Regression (CBR), eXtreme Gradient Boosting Regression (XGBR), Artificial Neural Network (ANN), and Random Forest (RF) methods to predict the path loss, and compare the prediction results in terms of Mean Absolute Error (MAE) and Mean Square Error (MSE). As per obtained results, XGBR outperforms the rest of the methods. It outperforms CBR with a slight performance differences by 0.4 % and 1 % in terms of MAE and MSE metrics, respectively. On the other hand, it outperforms the rest of the methods with clear performance differences.         _ Less","","arXiv","https://arxiv.org/abs/2310.01030","2","1","origin_of_life"
"Channel Vision Transformers: An Image Is Worth 1 x 16 x 16 Words","Abstract:                _a learnable channel embedding that is added to the patch tokens, similar to positional embeddings. We evaluate the performance of ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat (satellite imaging). Our results show that ChannelViT outperforms ViT on classification tasks and generalizes well, even when a subset of input channels is used_         _ More           Vision Transformer (ViT) has emerged as a powerful architecture in the realm of modern computer vision. However, its application in certain imaging fields, such as microscopy and satellite imaging, presents unique challenges. In these domains, images often contain multiple channels, each carrying semantically distinct and independent information. Furthermore, the model must demonstrate robustness to sparsity in input channels, as they may not be densely available during training or testing. In this paper, we propose a modification to the ViT architecture that enhances reasoning across the input channels and introduce Hierarchical Channel Sampling (HCS) as an additional regularization technique to ensure robustness when only partial channels are presented during test time. Our proposed model, ChannelViT, constructs patch tokens independently from each input channel and utilizes a learnable channel embedding that is added to the patch tokens, similar to positional embeddings. We evaluate the performance of ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat (satellite imaging). Our results show that ChannelViT outperforms ViT on classification tasks and generalizes well, even when a subset of input channels is used during testing. Across our experiments, HCS proves to be a powerful regularizer, independent of the architecture employed, suggesting itself as a straightforward technique for robust ViT training. Lastly, we find that ChannelViT generalizes effectively even when there is limited access to all channels during training, highlighting its potential for multi-channel imaging under real-world conditions with sparse sensors. Our code is available at https://github.com/insitro/ChannelViT.         _ Less","","arXiv","https://arxiv.org/abs/2309.16108","1","0","origin_of_life"
"FATHER: FActory on THE Road","Abstract:                In most factories today the robotic cells are deployed on well enforced bases to avoid any external impact on the accuracy of production. In contrast to that, we evaluate a futuristic concept where the whole robotic_         _ More           In most factories today the robotic cells are deployed on well enforced bases to avoid any external impact on the accuracy of production. In contrast to that, we evaluate a futuristic concept where the whole robotic cell could work in a moving platform. Imagine a trailer of a truck moving along the motorway while exposed to heavy physical impacts due to maneuvering. The key question here is how the robotic cell behaves and how the productivity is affected. We propose a system architecture (FATHER) and show some solutions including network related information and artificial intelligence to make the proposed futuristic concept feasible to implement.         _ Less","","arXiv","https://arxiv.org/abs/2309.13168","1","0","origin_of_life"
"A review of troubled cell indicators for discontinuous Galerkin method","Abstract:                In this paper, eight different troubled cell indicators (shock detectors) are reviewed for the solution of nonlinear hyperbolic conservation laws using discontinuous Galerkin (DG) method and a WENO limiter on both structured and unstructured meshes. Extensive simulations using one-dimensional and two-dimensional problems (2D Riemann problem and the double Ma_         _ More           In this paper, eight different troubled cell indicators (shock detectors) are reviewed for the solution of nonlinear hyperbolic conservation laws using discontinuous Galerkin (DG) method and a WENO limiter on both structured and unstructured meshes. Extensive simulations using one-dimensional and two-dimensional problems (2D Riemann problem and the double Mach reflection) for various orders on the hyperbolic system of Euler equations are used to compare these troubled cell indicators. They are evaluated based on the percentage of cells flagged as troubled cells for various orders and various grid sizes. CPU time taken to test a single cell for discontinuity is also compared. For one-dimensional problems, the performance of Fu and Shu indicator and the modified KXRCF indicator is better than other indicators. For two-dimensional problems, the performance of the artificial neural network (ANN) indicator of Ray and Hesthaven is quite good and the Fu and Shu and the modified KXRCF indicators are also good. These three indicators are suitable candidates for applications of DGM using WENO limiters though it should be noted that the ANN indicator is quite expensive and requires a lot of training.         _ Less","","arXiv","https://arxiv.org/abs/2309.11973","1","1","multiple"
"Improving diagnosis and prognosis of lung cancer using vision transformers: A scoping review","Abstract:                Vision transformer-based methods are advancing the field of medical artificial intelligence and cancer imaging, including lung cancer applications. Recently, many researchers have developed vision transformer-based AI methods for lung cancer diagnosis and prognosis. This scoping review aims to identify the recent developments on vision transformer-based AI m_         _ More           Vision transformer-based methods are advancing the field of medical artificial intelligence and cancer imaging, including lung cancer applications. Recently, many researchers have developed vision transformer-based AI methods for lung cancer diagnosis and prognosis. This scoping review aims to identify the recent developments on vision transformer-based AI methods for lung cancer imaging applications. It provides key insights into how vision transformers complemented the performance of AI and deep learning methods for lung cancer. Furthermore, the review also identifies the datasets that contributed to advancing the field. Of the 314 retrieved studies, this review included 34 studies published from 2020 to 2022. The most commonly addressed task in these studies was the classification of lung cancer types, such as lung squamous cell carcinoma versus lung adenocarcinoma, and identifying benign versus malignant pulmonary nodules. Other applications included survival prediction of lung cancer patients and segmentation of lungs. The studies lacked clear strategies for clinical transformation. SWIN transformer was a popular choice of the researchers; however, many other architectures were also reported where vision transformer was combined with convolutional neural networks or UNet model. It can be concluded that vision transformer-based models are increasingly in popularity for developing AI methods for lung cancer applications. However, their computational complexity and clinical relevance are important factors to be considered for future research work. This review provides valuable insights for researchers in the field of AI and healthcare to advance the state-of-the-art in lung cancer diagnosis and prognosis. We provide an interactive dashboard on lung-cancer.onrender.com/.         _ Less","","arXiv","https://arxiv.org/abs/2309.02783","2","1","origin_of_life"
"Recurrence-Free Survival Prediction for Anal Squamous Cell Carcinoma Chemoradiotherapy using Planning CT-based Radiomics Model","Abstract:                Objectives: Approximately 30% of non-metastatic anal squamous cell carcinoma (ASCC) patients will experience recurrence after chemoradiotherapy (CRT), and currently available clinical variables are poor predictors of treatment response. We aimed to develop a model leveraging information extracted from radiation pretreatment planning CT to predict recurrence-_         _ More           Objectives: Approximately 30% of non-metastatic anal squamous cell carcinoma (ASCC) patients will experience recurrence after chemoradiotherapy (CRT), and currently available clinical variables are poor predictors of treatment response. We aimed to develop a model leveraging information extracted from radiation pretreatment planning CT to predict recurrence-free survival (RFS) in ASCC patients after CRT. Methods: Radiomics features were extracted from planning CT images of 96 ASCC patients. Following pre-feature selection, the optimal feature set was selected via step-forward feature selection with a multivariate Cox proportional hazard model. The RFS prediction was generated from a radiomics-clinical combined model based on an optimal feature set with five repeats of five-fold cross validation. The risk stratification ability of the proposed model was evaluated with Kaplan-Meier analysis. Results: Shape- and texture-based radiomics features significantly predicted RFS. Compared to a clinical-only model, radiomics-clinical combined model achieves better performance in the testing cohort with higher C-index (0.80 vs 0.73) and AUC (0.84 vs 0.79 for 1-year RFS, 0.84 vs 0.78 for 2-year RFS, and 0.86 vs 0.83 for 3-year RFS), leading to distinctive high- and low-risk of recurrence groups (p<0.001). Conclusions: A treatment planning CT based radiomics and clinical combined model had improved prognostic performance in predicting RFS for ASCC patients treated with CRT as compared to a model using clinical features only.         _ Less","","arXiv","https://arxiv.org/abs/2309.02562","1","0","origin_of_life"
"AI driven B-cell Immunotherapy Design","Abstract:                _strength, sensitivity, and specificity of the paratope-epitope interaction, which demands resource-intensive experimental techniques for characterisation. In recent years, artificial intelligence and machine learning methods have made significant strides, revolutionising the prediction of protein structures and their complexes. The past decade has also witne_         _ More           Antibodies, a prominent class of approved biologics, play a crucial role in detecting foreign antigens. The effectiveness of antigen neutralisation and elimination hinges upon the strength, sensitivity, and specificity of the paratope-epitope interaction, which demands resource-intensive experimental techniques for characterisation. In recent years, artificial intelligence and machine learning methods have made significant strides, revolutionising the prediction of protein structures and their complexes. The past decade has also witnessed the evolution of computational approaches aiming to support immunotherapy design. This review focuses on the progress of machine learning-based tools and their frameworks in the domain of B-cell immunotherapy design, encompassing linear and conformational epitope prediction, paratope prediction, and antibody design. We mapped the most commonly used data sources, evaluation metrics, and method availability and thoroughly assessed their significance and limitations, discussing the main challenges ahead.         _ Less","","arXiv","https://arxiv.org/abs/2309.01122","2","2","multiple"
"Depth analysis of battery performance based on a data-driven approach","Abstract:                Capacity attenuation is one of the most intractable issues in the current of application of the cells. The disintegration mechanism is well known to be very complex across the system. It is a great challenge to fully comprehend this process and predict the process accurately. Thus, the machine learning (ML) technology is employed to predict the specific capa_         _ More           Capacity attenuation is one of the most intractable issues in the current of application of the cells. The disintegration mechanism is well known to be very complex across the system. It is a great challenge to fully comprehend this process and predict the process accurately. Thus, the machine learning (ML) technology is employed to predict the specific capacity change of the cell throughout the cycle and grasp this intricate procedure. Different from the previous work, according to the WOA-ELM model proposed in this work (R2 = 0.9999871), the key factors affecting the specific capacity of the battery are determined, and the defects in the machine learning black box are overcome by the interpretable model. Their connection with the structural damage of electrode materials and battery failure during battery cycling is comprehensively explained, revealing their essentiality to battery performance, which is conducive to superior research on contemporary batteries and modification.         _ Less","","arXiv","https://arxiv.org/abs/2308.15833","1","1","multiple"
"Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification","Abstract:                _neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, GCNs underperform in multi-class histopathologic_         _ More           Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, GCNs underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integrate the two asymmetric branches. Notably, we collect a private clinically acquired dataset termed LUAD7C, including seven subtypes of lung adenocarcinoma, which is rare and more challenging. We evaluated our approach on the private LUAD7C and public colorectal cancer datasets, showcasing its superior performance, explainability, and generalizability in multi-class histopathological image classification.         _ Less","","arXiv","https://arxiv.org/abs/2308.12737","1","0","origin_of_life"
"A mathematical model for meniscus cartilage regeneration","Abstract:                We propose a continuous model for meniscus cartilage regeneration triggered by two populations of cells migrating and (de)differentiating within an artificial scaffold with a known structure. The described biological processes are influenced by a fluid flow and therewith induced deformations of the scaffold. Numerical_         _ More           We propose a continuous model for meniscus cartilage regeneration triggered by two populations of cells migrating and (de)differentiating within an artificial scaffold with a known structure. The described biological processes are influenced by a fluid flow and therewith induced deformations of the scaffold. Numerical simulations are done for the corresponding dynamics within a bioreactor which was designed for performing the biological experiments.         _ Less","","arXiv","https://arxiv.org/abs/2308.11255","1","0","origin_of_life"
"A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks","Abstract:                _and histopathological characteristics. There are more than 35 different histological forms of breast lesions that can be classified and diagnosed histologically according to cell morphology, growth, and architecture patterns. Recently, deep learning, in the field of artificial intelligence, has drawn a lot of attentio_         _ More           Breast cancer is one of the most common cancers affecting women worldwide. They include a group of malignant neoplasms with a variety of biological, clinical, and histopathological characteristics. There are more than 35 different histological forms of breast lesions that can be classified and diagnosed histologically according to cell morphology, growth, and architecture patterns. Recently, deep learning, in the field of artificial intelligence, has drawn a lot of attention for the computerized representation of medical images. Searchable digital atlases can provide pathologists with patch matching tools allowing them to search among evidently diagnosed and treated archival cases, a technology that may be regarded as computational second opinion. In this study, we indexed and analyzed the WHO breast taxonomy (Classification of Tumours 5th Ed.) spanning 35 tumour types. We visualized all tumour types using deep features extracted from a state-of-the-art deep learning model, pre-trained on millions of diagnostic histopathology images from the TCGA repository. Furthermore, we test the concept of a digital 'atlas' as a reference for search and matching with rare test cases. The patch similarity search within the WHO breast taxonomy data reached over 88% accuracy when validating through 'majority vote' and more than 91% accuracy when validating using top-n tumour types. These results show for the first time that complex relationships among common and rare breast lesions can be investigated using an indexed digital archive.         _ Less","","arXiv","https://arxiv.org/abs/2308.11162","0","1","synthetic_biology"
"Exploring Unsupervised Cell Recognition with Prior Self-activation Maps","Abstract:                The success of supervised deep learning models on cell recognition tasks relies on detailed annotations. Many previous works have managed to reduce the dependency on labels. However, considering the large number of_         _ More           The success of supervised deep learning models on cell recognition tasks relies on detailed annotations. Many previous works have managed to reduce the dependency on labels. However, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. To this end, we explored label-free methods for cell recognition. Prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. To be specific, an activation network is trained with self-supervised learning. The gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. Afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. We evaluated our method on two histological datasets: MoNuSeg (cell segmentation) and BCData (multi-class cell detection). Compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. Our simple but effective framework can also achieve multi-class cell detection which can not be done by existing unsupervised methods. The results show the potential of PSMs that might inspire other research to deal with the hunger for labels in medical area.         _ Less","","arXiv","https://arxiv.org/abs/2308.11144","1","0","origin_of_life"
"Exciton Superposition across Moir_ States in a Semiconducting Moir_ Superlattice","Abstract:                Moir_ superlattices of semiconducting transition metal dichalcogenides (TMDCs) enable unprecedented spatial control of electron wavefunctions in an artificial lattice with periodicities more than ten times larger than that of atomic crystals, leading to emerging quantum states with fascinating electronic and optical properties. The breaking of translational_         _ More           Moir_ superlattices of semiconducting transition metal dichalcogenides (TMDCs) enable unprecedented spatial control of electron wavefunctions in an artificial lattice with periodicities more than ten times larger than that of atomic crystals, leading to emerging quantum states with fascinating electronic and optical properties. The breaking of translational symmetry further introduces a new degree of freedom inside each moir_ unit cell: high symmetry points of energy minima called moir_ sites, behaving as spatially separated quantum dots. The superposition of a quasiparticle wavefunction between different moir_ sites will enable a new platform for quantum information processing but is hindered by the suppressed electron tunneling between moir_ sites. Here we demonstrate the superposition between two moir_ sites by constructing an angle-aligned trilayer WSe2/monolayer WS2 moir_ heterojunction. The two moir_ sites with energy minimum allow the formation of two different interlayer excitons, with the hole residing in either moir_ site of the first WSe2 layer interfacing the WS2 layer and the electron in the third WSe2 layer. An external electric field can drive the hybridization of either of the interlayer excitons with the intralayer excitons in the third WSe2 layer, realizing the continuous tuning of interlayer exciton hopping between two moir_ sites. Therefore, a superposition of the two interlayer excitons localized at different moir_ sites can be realized, which can be resolved in the electric-field-dependent optical reflectance spectra, distinctly different from that of the natural trilayer WSe2 in which the moir_ modulation is absent. Our study illustrates a strategy of harnessing the new moir_ site degree of freedom for quantum information science, a new direction of twistronics.         _ Less","","arXiv","https://arxiv.org/abs/2308.11054","1","1","multiple"
"Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders","Abstract:                _image obfuscation. The segmentation task further diversifies when considering the study of histopathology slides for autoimmune diseases like dermatomyositis. The analysis of cell inflammation and interaction in these cases has been less studied due to constraints in data acquisition pipelines. Despite the progressive strides in medical science, we lack a co_         _ More           The task of medical image segmentation presents unique challenges, necessitating both localized and holistic semantic understanding to accurately delineate areas of interest, such as critical tissues or aberrant features. This complexity is heightened in medical image segmentation due to the high degree of inter-class similarities, intra-class variations, and possible image obfuscation. The segmentation task further diversifies when considering the study of histopathology slides for autoimmune diseases like dermatomyositis. The analysis of cell inflammation and interaction in these cases has been less studied due to constraints in data acquisition pipelines. Despite the progressive strides in medical science, we lack a comprehensive collection of autoimmune diseases. As autoimmune diseases globally escalate in prevalence and exhibit associations with COVID-19, their study becomes increasingly essential. While there is existing research that integrates artificial intelligence in the analysis of various autoimmune diseases, the exploration of dermatomyositis remains relatively underrepresented. In this paper, we present a deep-learning approach tailored for Medical image segmentation. Our proposed method outperforms the current state-of-the-art techniques by an average of 12.26% for U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the dermatomyositis dataset. Furthermore, we probe the importance of optimizing loss function weights and benchmark our methodology on three challenging medical image segmentation tasks         _ Less","","arXiv","https://arxiv.org/abs/2308.10488","1","1","multiple"
"SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM","Abstract:                _spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. F_         _ More           Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve as a solid baseline to promote the advancement of spatiotemporal prediction accuracy. The codes are publicly available at https://github.com/SongTang-x/SwinLSTM.         _ Less","","arXiv","https://arxiv.org/abs/2308.09891","1","0","origin_of_life"
"3D particle-in-cell simulations of negative and positive streamers in C4F7N-CO2 mixtures","Abstract:                _are considered to be more environmentally friendly than the insulating gas SF6 that is widely used in high voltage technology. Simulations are performed using a 3D particle-in-cell model. Negative streamers can propagate when the background field is close to the critical field. We relate this to their short conductive channels, due to rapid electron attachme_         _ More           We investigate negative and positive streamers in C4F7N-CO2 mixtures through simulations. These mixtures are considered to be more environmentally friendly than the insulating gas SF6 that is widely used in high voltage technology. Simulations are performed using a 3D particle-in-cell model. Negative streamers can propagate when the background field is close to the critical field. We relate this to their short conductive channels, due to rapid electron attachment, which limits their field enhancement. Positive streamers also require a background field close to the critical field, and in addition a source of free electrons ahead of them. In our simulations these electrons are provided through an artificial stochastic background ionization process as no efficient photoionization process is known for these gases. In 3D, we can only simulate the early inception stage of positive discharges, due to the extremely high electric fields and electron densities that occur. Qualitative 2D Cartesian simulations show that the growth of these discharges is highly irregular, resulting from incoming negative streamers that connect to existing channels. The inclusion of a stochastic background ionization process also has an interesting effect on negative discharges: new streamers can be generated behind previous ones, thereby forming a chain of negative streamers.         _ Less","","arXiv","https://arxiv.org/abs/2308.08901","0","1","synthetic_biology"
"A Comprehensive Overview of Computational Nuclei Segmentation Methods in Digital Pathology","Abstract:                _to high variance in appearance, sourcing either from the acquisition devices or the H\\&E staining process. Nuclei segmentation is an important task, as it detects the nuclei cells over background tissue and gives rise to the topology, size, and count of nuclei which are determinant factors for cancer detection. Yet, it is a fairly time consuming task for_         _ More           In the cancer diagnosis pipeline, digital pathology plays an instrumental role in the identification, staging, and grading of malignant areas on biopsy tissue specimens. High resolution histology images are subject to high variance in appearance, sourcing either from the acquisition devices or the H\\&E staining process. Nuclei segmentation is an important task, as it detects the nuclei cells over background tissue and gives rise to the topology, size, and count of nuclei which are determinant factors for cancer detection. Yet, it is a fairly time consuming task for pathologists, with reportedly high subjectivity. Computer Aided Diagnosis (CAD) tools empowered by modern Artificial Intelligence (AI) models enable the automation of nuclei segmentation. This can reduce the subjectivity in analysis and reading time. This paper provides an extensive review, beginning from earlier works use traditional image processing techniques and reaching up to modern approaches following the Deep Learning (DL) paradigm. Our review also focuses on the weak supervision aspect of the problem, motivated by the fact that annotated data is scarce. At the end, the advantages of different models and types of supervision are thoroughly discussed. Furthermore, we try to extrapolate and envision how future research lines will potentially be, so as to minimize the need for labeled data while maintaining high performance. Future methods should emphasize efficient and explainable models with a transparent underlying process so that physicians can trust their output.         _ Less","","arXiv","https://arxiv.org/abs/2308.08112","3","3","multiple"
"NNPP: A Learning-Based Heuristic Model for Accelerating Optimal Path Planning on Uneven Terrain","Abstract:                _distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the digital elevation model. Subsequently, the start and goal locations are encoded using a Gaussian distribution a_         _ More           Intelligent autonomous path planning is essential for enhancing the exploration efficiency of mobile robots operating in uneven terrains like planetary surfaces and off-road environments.In this paper, we propose the NNPP model for computing the heuristic region, enabling foundation algorithms like Astar to find the optimal path solely within this reduced search space, effectively decreasing the search time. The NNPP model learns semantic information about start and goal locations, as well as map representations, from numerous pre-annotated optimal path demonstrations, and produces a probabilistic distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the digital elevation model. Subsequently, the start and goal locations are encoded using a Gaussian distribution and different location encoding parameters are analyzed for their effect on model performance. After training, the NNPP model is able to \\textcolor{revision}{accelerate} path planning on novel maps.         _ Less","","arXiv","https://arxiv.org/abs/2308.04792","1","0","origin_of_life"
"ALFA -- Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals","Abstract:                _a synthetic dataset created by applying histopathology-specific jitters to the MHIST dataset (defining different domains with varied distribution shifts), and a Renal Cell Carcinoma dataset derived from four image repositories from TCGA, collectively indicate that our proposed model is adept at managing varying levels of image granularity. Thus, it shows im_         _ More           We propose an exhaustive methodology that leverages all levels of feature abstraction, targeting an enhancement in the generalizability of image classification to unobserved hospitals. Our approach incorporates augmentation-based self-supervision with common distribution shifts in histopathology scenarios serving as the pretext task. This enables us to derive invariant features from training images without relying on training labels, thereby covering different abstraction levels. Moving onto the subsequent abstraction level, we employ a domain alignment module to facilitate further extraction of invariant features across varying training hospitals. To represent the highly specific features of participating hospitals, an encoder is trained to classify hospital labels, independent of their diagnostic labels. The features from each of these encoders are subsequently disentangled to minimize redundancy and segregate the features. This representation, which spans a broad spectrum of semantic information, enables the development of a model demonstrating increased robustness to unseen images from disparate distributions. Experimental results from the PACS dataset (a domain generalization benchmark), a synthetic dataset created by applying histopathology-specific jitters to the MHIST dataset (defining different domains with varied distribution shifts), and a Renal Cell Carcinoma dataset derived from four image repositories from TCGA, collectively indicate that our proposed model is adept at managing varying levels of image granularity. Thus, it shows improved generalizability when faced with new, out-of-distribution hospital images.         _ Less","","arXiv","https://arxiv.org/abs/2308.03936","1","0","origin_of_life"
"An unsupervised machine-learning-based shock sensor for high-order supersonic flow solvers","Abstract:                _coupled to the sensor to provide examples of possible applications. The Sedov blast and double Mach reflection cases demonstrate that our proposed sensor can enhance hybrid sub-cell flux-differencing formulations by providing accurate information of the nodes that require low-order blending. Besides, supersonic test cases including high Reynolds numbers show_         _ More           We present a novel unsupervised machine-learning sock sensor based on Gaussian Mixture Models (GMMs). The proposed GMM sensor demonstrates remarkable accuracy in detecting shocks and is robust across diverse test cases with significantly less parameter tuning than other options. We compare the GMM-based sensor with state-of-the-art alternatives. All methods are integrated into a high-order compressible discontinuous Galerkin solver, where two stabilization approaches are coupled to the sensor to provide examples of possible applications. The Sedov blast and double Mach reflection cases demonstrate that our proposed sensor can enhance hybrid sub-cell flux-differencing formulations by providing accurate information of the nodes that require low-order blending. Besides, supersonic test cases including high Reynolds numbers showcase the sensor performance when used to introduce entropy-stable artificial viscosity to capture shocks, demonstrating the same effectiveness as fine-tuned state-of-the-art sensors. The adaptive nature and ability to function without extensive training datasets make this GMM-based sensor suitable for complex geometries and varied flow configurations. Our study reveals the potential of unsupervised machine-learning methods, exemplified by this GMM sensor, to improve the robustness and efficiency of advanced CFD codes.         _ Less","","arXiv","https://arxiv.org/abs/2308.00086","1","0","origin_of_life"
"Opportunities and challenges for deep learning in cell dynamics research","Abstract:                With the growth of artificial intelligence (AI), there has been an increase in the adoption of computer vision and deep learning (DL) techniques for the evaluation of microscopy images and movies. This adoption has not only addressed hurdles in quantitative analysis of dynamic_         _ More           With the growth of artificial intelligence (AI), there has been an increase in the adoption of computer vision and deep learning (DL) techniques for the evaluation of microscopy images and movies. This adoption has not only addressed hurdles in quantitative analysis of dynamic cell biological processes, but it has also started supporting advances in drug development, precision medicine and genome-phenome mapping. Here we survey existing AI-based techniques and tools, and open-source datasets, with a specific focus on the computational tasks of segmentation, classification, and tracking of cellular and subcellular structures and dynamics. We summarise long-standing challenges in microscopy video analysis from the computational perspective and review emerging research frontiers and innovative applications for deep learning-guided automation for cell dynamics research.         _ Less","","arXiv","https://arxiv.org/abs/2307.10500","2","3","synthetic_biology"
"Automated Knowledge Modeling for Cancer Clinical Practice Guidelines","Abstract:                _Cancer Network (NCCN) CPGs in Oncology and generating a structured model containing the retrieved knowledge. The proposed method was tested using two versions of NCCN Non-Small Cell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful extraction and modeling of knowledge. Three enrichment strategies using Cancer staging information, Unified M_         _ More           Clinical Practice Guidelines (CPGs) for cancer diseases evolve rapidly due to new evidence generated by active research. Currently, CPGs are primarily published in a document format that is ill-suited for managing this developing knowledge. A knowledge model of the guidelines document suitable for programmatic interaction is required. This work proposes an automated method for extraction of knowledge from National Comprehensive Cancer Network (NCCN) CPGs in Oncology and generating a structured model containing the retrieved knowledge. The proposed method was tested using two versions of NCCN Non-Small Cell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful extraction and modeling of knowledge. Three enrichment strategies using Cancer staging information, Unified Medical Language System (UMLS) Metathesaurus & National Cancer Institute thesaurus (NCIt) concepts, and Node classification are also presented to enhance the model towards enabling programmatic traversal and querying of cancer care guidelines. The Node classification was performed using a Support Vector Machine (SVM) model, achieving a classification accuracy of 0.81 with 10-fold cross-validation.         _ Less","","arXiv","https://arxiv.org/abs/2307.10231","2","1","origin_of_life"
"Reciprocal microswimming in fluctuating and confined environments","Abstract:                From bacteria and sperm cells to_         _ More           From bacteria and sperm cells to artificial microrobots, self-propelled microscopic objects at low Reynolds numbers often perceive fluctuating mechanical and chemical stimuli and contact exterior wall boundaries both in nature and the laboratory. In this study, we theoretically investigate the fundamental features of microswimmers by focusing on their reciprocal deformation. Although the scallop theorem prohibits the net locomotion of reciprocal microswimmers, by analyzing a two-sphere swimmer model, we show that in a fluctuating and geometrically confined environment, reciprocal deformations can afford a statistically average displacement. After designing the shape gait, a reciprocal swimmer can migrate in any direction, even in the statistical sense, while the statistical average of passive rigid particles statistically diffuses in a particular direction in the presence of external boundaries. To elucidate this symmetry breakdown, by introducing an impulse response function, we derive a general formula for predicting the nonzero net displacement of a reciprocal swimmer. Using this theory, we determine the relation between the shape gait and net locomotion as well as the net diffusion constant increase and decrease owing to a reciprocal deformation. Based on these findings and a theoretical formulation, we provide a fundamental basis for environment-coupled statistical locomotion. Thus, this study is valuable for understanding biophysical phenomena in fluctuating environments, designing artificial microrobots, and conducting laboratory experiments.         _ Less","","arXiv","https://arxiv.org/abs/2307.10049","1","0","origin_of_life"
"Integration of Large Language Models and Federated Learning","Abstract:                As the parameter size of Large Language Models (LLMs) continues to expand, there is an urgent need to address the scarcity of high-quality data. In response, existing research has attempted to make a breakthrough by incorporating Federated Learning (FL) into LLMs. Conversely, considering the outstanding performance of LLMs in task generalization, researchers have also tried applying LLMs within FL_         _ More           As the parameter size of Large Language Models (LLMs) continues to expand, there is an urgent need to address the scarcity of high-quality data. In response, existing research has attempted to make a breakthrough by incorporating Federated Learning (FL) into LLMs. Conversely, considering the outstanding performance of LLMs in task generalization, researchers have also tried applying LLMs within FL to tackle challenges in relevant domains. The complementarity between LLMs and FL has already ignited widespread research interest. In this paper, we aim to deeply explore the integration of LLMs and FL. We propose a research framework, dividing the fusion of LLMs and FL into three parts: the combination of LLM sub-technologies with FL, the integration of FL sub-technologies with LLMs, and the overall merger of LLMs and FL. We first provide a comprehensive review of the current state of research in the domain of LLMs combined with FL, including their typical applications, integration advantages, challenges faced, and future directions for resolution. Subsequently, we discuss the practical applications of the combination of LLMs and FL in critical scenarios such as healthcare, finance, and education, and provide new perspectives and insights into future research directions for LLMs and FL.         _ Less","","arXiv","https://arxiv.org/abs/2307.08925","2","2","multiple"
"Heterogeneous graphs model spatial relationships between biological entities for breast cancer diagnosis","Abstract:                _neural networks (GNNs) offer a promising solution by coding the spatial relationships within images. Prior studies have investigated the modeling of histopathological images as cell and tissue graphs, but they have not fully tapped into the potential of extracting interrelationships between these biological entities. In this paper, we present a novel approac_         _ More           The heterogeneity of breast cancer presents considerable challenges for its early detection, prognosis, and treatment selection. Convolutional neural networks often neglect the spatial relationships within histopathological images, which can limit their accuracy. Graph neural networks (GNNs) offer a promising solution by coding the spatial relationships within images. Prior studies have investigated the modeling of histopathological images as cell and tissue graphs, but they have not fully tapped into the potential of extracting interrelationships between these biological entities. In this paper, we present a novel approach using a heterogeneous GNN that captures the spatial and hierarchical relations between cell and tissue graphs to enhance the extraction of useful information from histopathological images. We also compare the performance of a cross-attention-based network and a transformer architecture for modeling the intricate relationships within tissue and cell graphs. Our model demonstrates superior efficiency in terms of parameter count and achieves higher accuracy compared to the transformer-based state-of-the-art approach on three publicly available breast cancer datasets -- BRIGHT, BreakHis, and BACH.         _ Less","","arXiv","https://arxiv.org/abs/2307.08132","1","0","origin_of_life"
"Data-Driven Design for Metamaterials and Multiscale Systems: A Review","Abstract:                Metamaterials are artificial materials designed to exhibit effective material parameters that go beyond those found in nature. Composed of unit_         _ More           Metamaterials are artificial materials designed to exhibit effective material parameters that go beyond those found in nature. Composed of unit cells with rich designability that are assembled into multiscale systems, they hold great promise for realizing next-generation devices with exceptional, often exotic, functionalities. However, the vast design space and intricate structure-property relationships pose significant challenges in their design. A compelling paradigm that could bring the full potential of metamaterials to fruition is emerging: data-driven design. In this review, we provide a holistic overview of this rapidly evolving field, emphasizing the general methodology instead of specific domains and deployment contexts. We organize existing research into data-driven modules, encompassing data acquisition, machine learning-based unit cell design, and data-driven multiscale optimization. We further categorize the approaches within each module based on shared principles, analyze and compare strengths and applicability, explore connections between different modules, and identify open research questions and opportunities.         _ Less","","arXiv","https://arxiv.org/abs/2307.05506","2","2","multiple"
"Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data","Abstract:                Renal cell carcinoma represents a significant global health challenge with a low survival rate. This research aimed to devise a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal_         _ More           Renal cell carcinoma represents a significant global health challenge with a low survival rate. This research aimed to devise a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework comprises three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments are performed, with varying numbers of clinical variables determined by different thresholds of the Spearman and importance scores. Our findings demonstrate that the proposed strategy surpasses the current literature on renal cancer prognosis based on CT scans and clinical factors. The best-performing experiment yielded a concordance index of 0.84 and an area under the curve value of 0.8 on the test cohort, which suggests strong predictive power. The multimodal deep-learning approach developed in this study shows promising results in estimating survival probabilities for renal cell carcinoma patients using CT imaging and clinical data. This may have potential implications in identifying patients who require urgent treatment, potentially improving patient outcomes. The code created for this project is available for the public on: \\href{https://github.com/Balasingham-AI-Group/Survival_CTplusClinical}{GitHub}         _ Less","","arXiv","https://arxiv.org/abs/2307.03575","1","1","multiple"
"On the gain of entrainment in a class of weakly contractive bilinear control systems with applications to the master equation and the ribosome flow model","Abstract:                We consider a class of bilinear weakly contractive systems that entrain to periodic excitations. Entrainment is important in many natural and artificial processes. For example, in order to function properly synchronous generators must entrain to the frequency of the electrical grid, and biological organisms must entrain to the 24h solar day. A dynamical syst_         _ More           We consider a class of bilinear weakly contractive systems that entrain to periodic excitations. Entrainment is important in many natural and artificial processes. For example, in order to function properly synchronous generators must entrain to the frequency of the electrical grid, and biological organisms must entrain to the 24h solar day. A dynamical system has a positive gain of entrainment (GOE) if entrainment also yields a larger output, on average. This property is important in many applications from the periodic operation of bioreactors to the periodic production of proteins during the cell cycle division process. We derive a closed-form formula for the GOE to first-order in the control perturbation. This is used to show that in the class of systems that we consider the GOE is always a higher-order phenomenon. We demonstrate the theoretical results using two applications: the master equation and a model from systems biology called the ribosome flow model, both with time-varying and periodic transition rates.         _ Less","","arXiv","https://arxiv.org/abs/2307.03568","0","1","synthetic_biology"
"Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings","Abstract:                _environment. The entorhinal-hippocampal plays a critical role in this function, as it is deeply engaged in memory processing and constructing cognitive maps using place and grid cells. Comprehending and leveraging this ability could significantly augment the field of_         _ More           The human brain possesses the extraordinary capability to contextualize the information it receives from our environment. The entorhinal-hippocampal plays a critical role in this function, as it is deeply engaged in memory processing and constructing cognitive maps using place and grid cells. Comprehending and leveraging this ability could significantly augment the field of artificial intelligence. The multi-scale successor representation serves as a good model for the functionality of place and grid cells and has already shown promise in this role. Here, we introduce a model that employs successor representations and neural networks, along with word embedding vectors, to construct a cognitive map of three separate concepts. The network adeptly learns two different scaled maps and situates new information in proximity to related pre-existing representations. The dispersion of information across the cognitive map varies according to its scale - either being heavily concentrated, resulting in the formation of the three concepts, or spread evenly throughout the map. We suggest that our model could potentially improve current AI models by providing multi-modal context information to any input, based on a similarity metric for the input and pre-existing knowledge representations.         _ Less","","arXiv","https://arxiv.org/abs/2307.01577","1","0","origin_of_life"
"Microelectronic Morphogenesis: Progress towards Artificial Organisms","Abstract:                _Electronic information that controls morphology is inheritable like its biological counterpart, genetic information, and is set to open new vistas of technology leading to artificial organisms when coupled with modular design and self-assembly that can make reversible microscopic electrical connections. Three core capabilities of_         _ More           Microelectronic morphogenesis is the creation and maintenance of complex functional structures by microelectronic information within shape-changing materials. Only recently has in-built information technology begun to be used to reshape materials and their functions in three dimensions to form smart microdevices and microrobots. Electronic information that controls morphology is inheritable like its biological counterpart, genetic information, and is set to open new vistas of technology leading to artificial organisms when coupled with modular design and self-assembly that can make reversible microscopic electrical connections. Three core capabilities of cells in organisms, self-maintenance (homeostatic metabolism utilizing free energy), self-containment (distinguishing self from non-self), and self-reproduction (cell division with inherited properties), once well out of reach for technology, are now within the grasp of information-directed materials. Construction-aware electronics can be used to proof-read and initiate game-changing error correction in microelectronic self-assembly. Furthermore, non-contact communication and electronically supported learning enable one to implement guided self-assembly and enhance functionality. This article reviews the fundamental breakthroughs that have opened the pathway to this prospective path, analyzes the extent and way in which the core properties of life can be addressed and discusses the potential and indeed necessity of such technology for sustainable high technology in society.         _ Less","","arXiv","https://arxiv.org/abs/2306.17288","2","4","synthetic_biology"
"CLANet: A Comprehensive Framework for Cross-Batch Cell Line Identification Using Brightfield Images","Abstract:        Cell line authentication plays a crucial role in the biomedical field, ensuring researchers work with accurately identified_         _ More   Cell line authentication plays a crucial role in the biomedical field, ensuring researchers work with accurately identified cells. Supervised deep learning has made remarkable strides in cell line identification by studying cell morphological features through cell imaging. However, batch effects, a significant issue stemming from the different times at which data is generated, lead to substantial shifts in the underlying data distribution, thus complicating reliable differentiation between cell lines from distinct batch cultures. To address this challenge, we introduce CLANet, a pioneering framework for cross-batch cell line identification using brightfield images, specifically designed to tackle three distinct batch effects. We propose a cell cluster-level selection method to efficiently capture cell density variations, and a self-supervised learning strategy to manage image quality variations, thus producing reliable patch representations. Additionally, we adopt multiple instance learning(MIL) for effective aggregation of instance-level features for cell line identification. Our innovative time-series segment sampling module further enhances MIL's feature-learning capabilities, mitigating biases from varying incubation times across batches. We validate CLANet using data from 32 cell lines across 93 experimental batches from the AstraZeneca Global Cell Bank. Our results show that CLANet outperforms related approaches (e.g. domain adaptation, MIL), demonstrating its effectiveness in addressing batch effects in cell line identification.         _ Less","","arXiv","https://arxiv.org/abs/2306.16538","1","2","synthetic_biology"
"Microscopic conductivity of passive films on ferritic stainless steel for hydrogen fuel cells","Abstract:                Hydrogen fuel cells offer a clean and sustainable energy conversion solution. The bipolar separator plate, a critical component in fuel_         _ More           Hydrogen fuel cells offer a clean and sustainable energy conversion solution. The bipolar separator plate, a critical component in fuel cells, plays a vital role in preventing reactant gas cross-contamination and facilitating efficient ion transport in a fuel cell. High chromium ferritic stainless steel with an artificially formed thin chromium oxide passive film has recently gained attention due to its superior electrical conductivity and corrosion resistance, making it a suitable material for separators. In this study, we investigate the microscopic electrical conductivity of the intrinsic passive oxide film on such ferritic stainless steel. Through advanced surface characterization techniques such as current sensing atomic force microscopy and scanning tunneling microscopy/spectroscopy, we discover highly conductive regions within the film that vary depending on location. These findings provide valuable insights into the behavior of the passive oxide film in fuel cells. By understanding the microscopic electrical properties, we can enhance the design and performance of separator materials in hydrogen fuel cells. Ultimately, this research contributes to a broader understanding of separator materials and supports the wider application of hydrogen fuel cells.         _ Less","","arXiv","https://arxiv.org/abs/2306.14513","0","1","synthetic_biology"
"WBCAtt: A White Blood Cell Dataset Annotated with Detailed Morphological Attributes","Abstract:                _samples at a microscopic level plays a fundamental role in clinical diagnostics, influencing a wide range of medical conditions. For instance, an in-depth study of White Blood Cells (WBCs), a crucial component of our blood, is essential for diagnosing blood-related diseases such as leukemia and anemia. While multiple datasets containing WBC images have been_         _ More           The examination of blood samples at a microscopic level plays a fundamental role in clinical diagnostics, influencing a wide range of medical conditions. For instance, an in-depth study of White Blood Cells (WBCs), a crucial component of our blood, is essential for diagnosing blood-related diseases such as leukemia and anemia. While multiple datasets containing WBC images have been proposed, they mostly focus on cell categorization, often lacking the necessary morphological details to explain such categorizations, despite the importance of explainable artificial intelligence (XAI) in medical domains. This paper seeks to address this limitation by introducing comprehensive annotations for WBC images. Through collaboration with pathologists, a thorough literature review, and manual inspection of microscopic images, we have identified 11 morphological attributes associated with the cell and its components (nucleus, cytoplasm, and granules). We then annotated ten thousand WBC images with these attributes. Moreover, we conduct experiments to predict these attributes from images, providing insights beyond basic WBC classification. As the first public dataset to offer such extensive annotations, we also illustrate specific applications that can benefit from our attribute annotations. Overall, our dataset paves the way for interpreting WBC recognition models, further advancing XAI in the fields of pathology and hematology.         _ Less","","arXiv","https://arxiv.org/abs/2306.13531","2","2","multiple"
"Modeling of a Liquid Leaf Target TNSA Experiment using Particle-In-Cell Simulations and Deep Learning","Abstract:                _for use as a possible laser-driven neutron source. To aid in this research, we develop a surrogate model for liquid leaf target laser-ion acceleration experiments, based on artificial neural networks. The model is trained using data from Particle-In-Cell (PIC) simulations. The fast inference speed of our deep learning_         _ More           Liquid leaf targets show promise as high repetition rate targets for laser-based ion acceleration using the Target Normal Sheath Acceleration (TNSA) mechanism and are currently under development. In this work, we discuss the effects of different ion species and investigate how they can be leveraged for use as a possible laser-driven neutron source. To aid in this research, we develop a surrogate model for liquid leaf target laser-ion acceleration experiments, based on artificial neural networks. The model is trained using data from Particle-In-Cell (PIC) simulations. The fast inference speed of our deep learning model allows us to optimize experimental parameters for maximum ion energy and laser-energy conversion efficiency. An analysis of parameter influence on our model output, using Sobol and PAWN indices, provides deeper insights into the laser-plasma system.         _ Less","","arXiv","https://arxiv.org/abs/2306.13316","0","1","synthetic_biology"
"Semi-supervised Cell Recognition under Point Supervision","Abstract:        Cell recognition is a fundamental task in digital histopathology image analysis. Point-based_         _ More   Cell recognition is a fundamental task in digital histopathology image analysis. Point-based cell recognition (PCR) methods normally require a vast number of annotations, which is extremely costly, time-consuming and labor-intensive. Semi-supervised learning (SSL) can provide a shortcut to make full use of cell information in gigapixel whole slide images without exhaustive labeling. However, research into semi-supervised point-based cell recognition (SSPCR) remains largely overlooked. Previous SSPCR works are all built on density map-based PCR models, which suffer from unsatisfactory accuracy, slow inference speed and high sensitivity to hyper-parameters. To address these issues, end-to-end PCR models are proposed recently. In this paper, we develop a SSPCR framework suitable for the end-to-end PCR models for the first time. Overall, we use the current models to generate pseudo labels for unlabeled images, which are in turn utilized to supervise the models training. Besides, we introduce a co-teaching strategy to overcome the confirmation bias problem that generally exists in self-training. A distribution alignment technique is also incorporated to produce high-quality, unbiased pseudo labels for unlabeled data. Experimental results on four histopathology datasets concerning different types of staining styles show the effectiveness and versatility of the proposed framework. Code is available at \\textcolor{magenta}{\\url{https://github.com/windygooo/SSPCR}         _ Less","","arXiv","https://arxiv.org/abs/2306.08240","1","0","origin_of_life"
"CIN++: Enhancing Topological Message Passing","Abstract:                _modeling higher-order structures and group interactions. Cellular Isomorphism Networks (CINs) recently addressed most of these challenges with a message passing scheme based on cell complexes. Despite their advantages, CINs make use only of boundary and upper messages which do not consider a direct interaction between the rings present in the underlying comp_         _ More           Graph Neural Networks (GNNs) have demonstrated remarkable success in learning from graph-structured data. However, they face significant limitations in expressive power, struggling with long-range interactions and lacking a principled approach to modeling higher-order structures and group interactions. Cellular Isomorphism Networks (CINs) recently addressed most of these challenges with a message passing scheme based on cell complexes. Despite their advantages, CINs make use only of boundary and upper messages which do not consider a direct interaction between the rings present in the underlying complex. Accounting for these interactions might be crucial for learning representations of many real-world complex phenomena such as the dynamics of supramolecular assemblies, neural activity within the brain, and gene regulation processes. In this work, we propose CIN++, an enhancement of the topological message passing scheme introduced in CINs. Our message passing scheme accounts for the aforementioned limitations by letting the cells to receive also lower messages within each layer. By providing a more comprehensive representation of higher-order and long-range interactions, our enhanced topological message passing scheme achieves state-of-the-art results on large-scale and long-range chemistry benchmarks.         _ Less","","arXiv","https://arxiv.org/abs/2306.03561","1","1","multiple"
"Comparing a composite model versus chained models to locate a nearest visual object","Abstract:                Extracting information from geographic images and text is crucial for autonomous vehicles to determine in advance the best cell stations to connect to along their future path. Multiple artificial neural network models can address this challenge; however, there is no definitive guidance on the selection of an appropriat_         _ More           Extracting information from geographic images and text is crucial for autonomous vehicles to determine in advance the best cell stations to connect to along their future path. Multiple artificial neural network models can address this challenge; however, there is no definitive guidance on the selection of an appropriate model for such use cases. Therefore, we experimented two architectures to solve such a task: a first architecture with chained models where each model in the chain addresses a sub-task of the task; and a second architecture with a single model that addresses the whole task. Our results showed that these two architectures achieved the same level performance with a root mean square error (RMSE) of 0.055 and 0.056; The findings further revealed that when the task can be decomposed into sub-tasks, the chain architecture exhibits a twelve-fold increase in training speed compared to the composite model. Nevertheless, the composite model significantly alleviates the burden of data labeling.         _ Less","","arXiv","https://arxiv.org/abs/2306.01551","1","0","origin_of_life"
"Determinantal Point Process Attention Over Grid Cell Code Supports Out of Distribution Generalization","Abstract:                _provide a proof of concept by evaluating performance on two challenging cognitive tasks. First we draw on the fact that the mammalian brain represents metric spaces using grid cell code (e.g., in the entorhinal cortex): abstract representations of relational structure, organized in recurring motifs that cover the representational space. Second, we propose an_         _ More           Deep neural networks have made tremendous gains in emulating human-like intelligence, and have been used increasingly as ways of understanding how the brain may solve the complex computational problems on which this relies. However, these still fall short of, and therefore fail to provide insight into how the brain supports strong forms of generalization of which humans are capable. One such case is out-of-distribution (OOD) generalization-successful performance on test examples that lie outside the distribution of the training set. Here, we identify properties of processing in the brain that may contribute to this ability. We describe a two-part algorithm that draws on specific features of neural computation to achieve OOD generalization, and provide a proof of concept by evaluating performance on two challenging cognitive tasks. First we draw on the fact that the mammalian brain represents metric spaces using grid cell code (e.g., in the entorhinal cortex): abstract representations of relational structure, organized in recurring motifs that cover the representational space. Second, we propose an attentional mechanism that operates over the grid cell code using Determinantal Point Process (DPP), that we call DPP attention (DPP-A) -- a transformation that ensures maximum sparseness in the coverage of that space. We show that a loss function that combines standard task-optimized error with DPP-A can exploit the recurring motifs in the grid cell code, and can be integrated with common architectures to achieve strong OOD generalization performance on analogy and arithmetic tasks. This provides both an interpretation of how the grid cell code in the mammalian brain may contribute to generalization performance, and at the same time a potential means for improving such capabilities in artificial neural networks.         _ Less","","arXiv","https://arxiv.org/abs/2305.18417","1","0","origin_of_life"
"EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds","Abstract:                _system employing a novel framework for studying emergent intelligence in organisms resembling slime molds. EINCASM evolves neural cellular automata with NEAT to maximize cell growth constrained by nutrient and energy costs. These organisms capitalize physically simulated fluid to transport nutrients and chemical-like signals to orchestrate growth and adaptat_         _ More           This paper presents EINCASM, a prototype system employing a novel framework for studying emergent intelligence in organisms resembling slime molds. EINCASM evolves neural cellular automata with NEAT to maximize cell growth constrained by nutrient and energy costs. These organisms capitalize physically simulated fluid to transport nutrients and chemical-like signals to orchestrate growth and adaptation to complex, changing environments. Our framework builds the foundation for studying how the presence of puzzles, physics, communication, competition and dynamic open-ended environments contribute to the emergence of intelligent behavior. We propose preliminary tests for intelligence in such organisms and suggest future work for more powerful systems employing EINCASM to better understand intelligence in distributed dynamical systems.         _ Less","","arXiv","https://arxiv.org/abs/2305.13425","1","2","synthetic_biology"
"Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study","Abstract:                _this data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities of LLMs through seven distinct tasks, e.g., cell lookup, row retrieval and size detection. Specially, we perform a series of evaluations on the recent most advanced LLM models, GPT-3.5 and GPT-4 and observe that performance varie_         _ More           Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, the understanding of their capability to process structured data like tables remains an under-explored area. While tables can be serialized as input for LLMs, there is a lack of comprehensive studies on whether LLMs genuinely comprehend this data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities of LLMs through seven distinct tasks, e.g., cell lookup, row retrieval and size detection. Specially, we perform a series of evaluations on the recent most advanced LLM models, GPT-3.5 and GPT-4 and observe that performance varied with different input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we propose $\\textit{self-augmentation}$ for effective structural prompting, such as critical value / range identification using internal knowledge of LLMs. When combined with carefully chosen input choices, these structural prompting methods lead to promising improvements in LLM performance on a variety of tabular tasks, e.g., TabFact($\\uparrow2.31\\%$), HybridQA($\\uparrow2.13\\%$), SQA($\\uparrow2.72\\%$), Feverous($\\uparrow0.84\\%$), and ToTTo($\\uparrow5.68\\%$). We believe that our open source benchmark and proposed prompting methods can serve as a simple yet generic selection for future research. The code and data of this paper will be temporality released at https://anonymous.4open.science/r/StructuredLLM-76F3/README.md and will be replaced with an official one at https://github.com/microsoft/TableProvider later.         _ Less","","arXiv","https://arxiv.org/abs/2305.13062","1","1","multiple"
"Real-time Evolution of Multicellularity with Artificial Gene Regulation","Abstract:                This paper presents a real-time simulation involving ''protozoan-like'' cells that evolve by natural selection in a physical 2D ecosystem. Selection pressure is exerted via the requirements to collect mass and energy from the surroundings in order to reproduce by_         _ More           This paper presents a real-time simulation involving ''protozoan-like'' cells that evolve by natural selection in a physical 2D ecosystem. Selection pressure is exerted via the requirements to collect mass and energy from the surroundings in order to reproduce by cell-division. Cells do not have fixed morphologies from birth; they can use their resources in construction projects that produce functional nodes on their surfaces such as photoreceptors for light sensitivity or flagella for motility. Importantly, these nodes act as modular components that connect to the cell's control system via IO channels, meaning that the evolutionary process can replace one function with another while utilising pre-developed control pathways on the other side of the channel. A notable type of node function is the adhesion receptors that allow cells to bind together into multicellular structures in which individuals can share resource and signal to one another. The control system itself is modelled as an artificial neural network that doubles as a gene regulatory network, thereby permitting the co-evolution of form and function in a single data structure and allowing cell specialisation within multicellular groups.         _ Less","","arXiv","https://arxiv.org/abs/2305.12249","0","1","synthetic_biology"
"Color Deconvolution applied to Domain Adaptation in HER2 histopathological images","Abstract:                Breast cancer early detection is crucial for improving patient outcomes. The Institut Catal_ de la Salut (ICS) has launched the DigiPatICS project to develop and implement artificial intelligence algorithms to assist with the diagnosis of cancer. In this paper, we propose a new approach for facing the color normalization problem in HER2-stained histopatholog_         _ More           Breast cancer early detection is crucial for improving patient outcomes. The Institut Catal_ de la Salut (ICS) has launched the DigiPatICS project to develop and implement artificial intelligence algorithms to assist with the diagnosis of cancer. In this paper, we propose a new approach for facing the color normalization problem in HER2-stained histopathological images of breast cancer tissue, posed as an style transfer problem. We combine the Color Deconvolution technique with the Pix2Pix GAN network to present a novel approach to correct the color variations between different HER2 stain brands. Our approach focuses on maintaining the HER2 score of the cells in the transformed images, which is crucial for the HER2 analysis. Results demonstrate that our final model outperforms the state-of-the-art image style transfer methods in maintaining the cell classes in the transformed images and is as effective as them in generating realistic images.         _ Less","","arXiv","https://arxiv.org/abs/2305.07404","0","1","synthetic_biology"
"Spectrum Breathing: Protecting Over-the-Air Federated Learning Against Interference","Abstract:                Federated Learning (FL) is a widely embraced paradigm for distilling artificial intelligence from distributed mobile data. However, the deployment of FL in mobile networks can be compromised by exposure to interference from neighboring_         _ More           Federated Learning (FL) is a widely embraced paradigm for distilling artificial intelligence from distributed mobile data. However, the deployment of FL in mobile networks can be compromised by exposure to interference from neighboring cells or jammers. Existing interference mitigation techniques require multi-cell cooperation or at least interference channel state information, which is expensive in practice. On the other hand, power control that treats interference as noise may not be effective due to limited power budgets, and also that this mechanism can trigger countermeasures by interference sources. As a practical approach for protecting FL against interference, we propose Spectrum Breathing, which cascades stochastic-gradient pruning and spread spectrum to suppress interference without bandwidth expansion. The cost is higher learning latency by exploiting the graceful degradation of learning speed due to pruning. We synchronize the two operations such that their levels are controlled by the same parameter, Breathing Depth. To optimally control the parameter, we develop a martingale-based approach to convergence analysis of Over-the-Air FL with spectrum breathing, termed AirBreathing FL. We show a performance tradeoff between gradient-pruning and interference-induced error as regulated by the breathing depth. Given receive SIR and model size, the optimization of the tradeoff yields two schemes for controlling the breathing depth that can be either fixed or adaptive to channels and the learning process. As shown by experiments, in scenarios where traditional Over-the-Air FL fails to converge in the presence of strong interference, AirBreahing FL with either fixed or adaptive breathing depth can ensure convergence where the adaptive scheme achieves close-to-ideal performance.         _ Less","","arXiv","https://arxiv.org/abs/2305.05933","1","0","origin_of_life"
"Cellular blood flow modelling with HemoCell","Abstract:                _empirical descriptions of bulk rheology are available for decades, their validity is limited to the experimental conditions they were observed under. These are typically artificial scenarios (e.g., perfectly straight glass tube or in pure shear with no gradients). Such conditions make experimental measurements simpler, however, they do not exist in real syst_         _ More           Many of the intriguing properties of blood originate from its cellular nature. Bulk effects, such as viscosity, depend on the local shear rates and on the size of the vessels. While empirical descriptions of bulk rheology are available for decades, their validity is limited to the experimental conditions they were observed under. These are typically artificial scenarios (e.g., perfectly straight glass tube or in pure shear with no gradients). Such conditions make experimental measurements simpler, however, they do not exist in real systems (i.e., in a real human circulatory system). Therefore, as we strive to increase our understanding on the cardiovascular system and improve the accuracy of our computational predictions, we need to incorporate a more comprehensive description of the cellular nature of blood. This, however, presents several computational challenges that can only be addressed by high performance computing. In this chapter we describe HemoCell , an open-source high performance cellular blood flow simulation, which implements validated mechanical models for red blood cells and is capable of reproducing the emergent transport characteristics of such a complex cellular system. We discuss the accuracy, the range of validity, and demonstrate applications on a series of human diseases.         _ Less","","arXiv","https://arxiv.org/abs/2305.02752","1","1","multiple"
"An Artificial Life Simulation Library Based on Genetic Algorithm, 3-Character Genetic Code and Biological Hierarchy","Abstract:                _of evolutionary operators, suggesting that GA may be a suitable model for studying real-life evolutionary processes. This paper describes the design of a Python library for artificial life simulation, Digital Organism Simulation Environment (DOSE), based on GA and biological hierarchy starting from genetic sequence to population. A 3-character instruction se_         _ More           Genetic algorithm (GA) is inspired by biological evolution of genetic organisms by optimizing the genotypic combinations encoded within each individual with the help of evolutionary operators, suggesting that GA may be a suitable model for studying real-life evolutionary processes. This paper describes the design of a Python library for artificial life simulation, Digital Organism Simulation Environment (DOSE), based on GA and biological hierarchy starting from genetic sequence to population. A 3-character instruction set that does not take any operand is introduced as genetic code for digital organism. This mimics the 3-nucleotide codon structure in naturally occurring DNA. In addition, the context of a 3-dimensional world composing of ecological cells is introduced to simulate a physical ecosystem. Using DOSE, an experiment to examine the changes in genetic sequences with respect to mutation rates is presented.         _ Less","","arXiv","https://arxiv.org/abs/2304.13520","0","1","synthetic_biology"
"Federated Deep Reinforcement Learning for THz-Beam Search with Limited CSI","Abstract:                _(DDPG)-based DRL to obtain THz beamforming policy with limited channel state information (CSI). They update their DDPG models with hidden information in order to mitigate inter-cell interference. We demonstrate that the cell network can achieve higher throughput as more THz CSI and hidden neurons of DDPG are adopted. W_         _ More           Terahertz (THz) communication with ultra-wide available spectrum is a promising technique that can achieve the stringent requirement of high data rate in the next-generation wireless networks, yet its severe propagation attenuation significantly hinders its implementation in practice. Finding beam directions for a large-scale antenna array to effectively overcome severe propagation attenuation of THz signals is a pressing need. This paper proposes a novel approach of federated deep reinforcement learning (FDRL) to swiftly perform THz-beam search for multiple base stations (BSs) coordinated by an edge server in a cellular network. All the BSs conduct deep deterministic policy gradient (DDPG)-based DRL to obtain THz beamforming policy with limited channel state information (CSI). They update their DDPG models with hidden information in order to mitigate inter-cell interference. We demonstrate that the cell network can achieve higher throughput as more THz CSI and hidden neurons of DDPG are adopted. We also show that FDRL with partial model update is able to nearly achieve the same performance of FDRL with full model update, which indicates an effective means to reduce communication load between the edge server and the BSs by partial model uploading. Moreover, the proposed FDRL outperforms conventional non-learning-based and existing non-FDRL benchmark optimization methods.         _ Less","","arXiv","https://arxiv.org/abs/2304.13109","1","0","origin_of_life"
"Cell-free layer development and spatial organization of healthy and rigid red blood cells in a microfluidic bifurcation","Abstract:                Bifurcations and branches in the microcirculation dramatically affect blood flow as they determine the spatiotemporal organization of red blood cells (RBCs). Such changes in vessel geometries can further influence the formation of a_         _ More           Bifurcations and branches in the microcirculation dramatically affect blood flow as they determine the spatiotemporal organization of red blood cells (RBCs). Such changes in vessel geometries can further influence the formation of a cell-free layer (CFL) close to the vessel walls. Biophysical cell properties, such as their deformability, which is impaired in various diseases, are often thought to impact blood flow and affect the distribution of flowing RBCs. This study investigates the flow behavior of healthy and artificially hardened RBCs in a bifurcating microfluidic T-junction. We determine the RBC distribution across the channel width at multiple positions before and after the bifurcation. Thus, we reveal distinct focusing profiles in the feeding mother channel for rigid and healthy RBCs that dramatically impact the cell organization in the successive daughter channels. Moreover, we experimentally show how the characteristic asymmetric CFLs in the daughter vessels develop along their flow direction. Complimentary numerical simulations indicate that the buildup of the CFL is faster for healthy than for rigid RBCs. Our results provide fundamental knowledge to understand the partitioning of rigid RBC as a model of cells with pathologically impaired deformability in complex in vitro networks.         _ Less","","arXiv","https://arxiv.org/abs/2304.08203","1","0","origin_of_life"
"Artificial intelligence based prediction on lung cancer risk factors using deep learning","Abstract:                _1%. Hence physicians can use our convolution neural network models for predicting lung cancer risk factors in the real world. Moreover, this investigation reveals that squamous cell carcinoma, normal, adenocarcinoma, and large cell carcinoma are the most significant risk factors. In addition, the remaining attributes a_         _ More           In this proposed work, we identified the significant research issues on lung cancer risk factors. Capturing and defining symptoms at an early stage is one of the most difficult phases for patients. Based on the history of patients records, we reviewed a number of current research studies on lung cancer and its various stages. We identified that lung cancer is one of the significant research issues in predicting the early stages of cancer disease. This research aimed to develop a model that can detect lung cancer with a remarkably high level of accuracy using the deep learning approach (convolution neural network). This method considers and resolves significant gaps in previous studies. We compare the accuracy levels and loss values of our model with VGG16, InceptionV3, and Resnet50. We found that our model achieved an accuracy of 94% and a minimum loss of 0.1%. Hence physicians can use our convolution neural network models for predicting lung cancer risk factors in the real world. Moreover, this investigation reveals that squamous cell carcinoma, normal, adenocarcinoma, and large cell carcinoma are the most significant risk factors. In addition, the remaining attributes are also crucial for achieving the best performance.         _ Less","","arXiv","https://arxiv.org/abs/2304.05065","1","1","multiple"
"Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT","Abstract:                _(SII) to address the complexities of information extraction at the device level in materials science. We accomplished this task by tuning GPT-3 on an existing perovskite solar cell FAIR (Findable, Accessible, Interoperable, Reusable) dataset with 91.8% F1-score and extended the dataset with data published since its release. The produced data is formatted and_         _ More           The amount of data has growing significance in exploring cutting-edge materials and a number of datasets have been generated either by hand or automated approaches. However, the materials science field struggles to effectively utilize the abundance of data, especially in applied disciplines where materials are evaluated based on device performance rather than their properties. This article presents a new natural language processing (NLP) task called structured information inference (SII) to address the complexities of information extraction at the device level in materials science. We accomplished this task by tuning GPT-3 on an existing perovskite solar cell FAIR (Findable, Accessible, Interoperable, Reusable) dataset with 91.8% F1-score and extended the dataset with data published since its release. The produced data is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature empowers materials scientists to develop models by selecting high-quality review articles within their domain. Additionally, we designed experiments to predict the electrical performance of solar cells and design materials or devices with targeted parameters using large language models (LLMs). Our results demonstrate comparable performance to traditional machine learning methods without feature selection, highlighting the potential of LLMs to acquire scientific knowledge and design new materials akin to materials scientists.         _ Less","","arXiv","https://arxiv.org/abs/2304.02213","2","1","origin_of_life"
"Towards an Hybrid Hodgkin-Huxley Action Potential Generation Model","Abstract:                _laboratory measurements that are often very expensive and produce little data because they involve a time-space-independent measurement of the voltage in a single channel of the cell membrane. In this work, we investigate the possibility of finding the Hodgkin-Huxley model's parametric functions using only two simple measurements (the membrane voltage as_         _ More           Mathematical models for the generation of the action potential can improve the understanding of physiological mechanisms that are consequence of the electrical activity in neurons. In such models, some equations involving empirically obtained functions of the membrane potential are usually defined. The best known of these models, the Hodgkin-Huxley model, is an example of this paradigm since it defines the conductances of ion channels in terms of the opening and closing rates of each type of gate present in the channels. These functions need to be derived from laboratory measurements that are often very expensive and produce little data because they involve a time-space-independent measurement of the voltage in a single channel of the cell membrane. In this work, we investigate the possibility of finding the Hodgkin-Huxley model's parametric functions using only two simple measurements (the membrane voltage as a function of time and the injected current that triggered that voltage) and applying Deep Learning methods to estimate these functions. This would result in an hybrid model of the action potential generation composed by the original Hodgkin-Huxley equations and an Artificial Neural Network that requires a small set of easy-to-perform measurements to be trained. Experiments were carried out using data generated from the original Hodgkin-Huxley model, and results show that a simple two-layer artificial neural network (ANN) architecture trained on a minimal amount of data can learn to model some of the fundamental proprieties of the action potential generation by estimating the model's rate functions.         _ Less","","arXiv","https://arxiv.org/abs/2304.01346","0","1","synthetic_biology"
"Nonuniform magnetic domain-wall synapses enabled by population coding","Abstract:                Traditional artificial intelligence implemented in software is usually executed on accurate digital computers. Nevertheless, the nanoscale devices for the implementation of neuromorphic computing may not be ideally identical, and the performance is reduced by nonuniform devices. In biological brains, information is usually encoded by a cluster of neurons suc_         _ More           Traditional artificial intelligence implemented in software is usually executed on accurate digital computers. Nevertheless, the nanoscale devices for the implementation of neuromorphic computing may not be ideally identical, and the performance is reduced by nonuniform devices. In biological brains, information is usually encoded by a cluster of neurons such that the variability of nerve cells does not influence the accuracy of human cognition and movement. Here, we introduce the population encoding strategy in neuromorphic computing and demonstrate that this strategy can overcome the problems caused by nonuniform devices. Using magnetic memristor device based on current-induced domain-wall motion as an example, we show that imperfect storage devices can be applied in a hardware network to perform principal component analysis (PCA), and the accuracy of unsupervised classification is comparable to that of conventional PCA using ideally accurate synaptic weights. Our results pave the way for hardware implementation of neuromorphic computing and lower the criteria for the uniformity of nanoscale devices.         _ Less","","arXiv","https://arxiv.org/abs/2303.11572","1","0","origin_of_life"
"EGFR mutation prediction using F18-FDG PET-CT based radiomics features in non-small cell lung cancer","Abstract:                _mutation status is highly relevant for the proper treatment of this patients. Purpose: The aim of this study was to predict the mutational status of the EGFR in non-small cell lung cancer patients using radiomics features extracted from PET-CT images. Methods: Retrospective study that involve 34 patients with lung cancer confirmed by histology and EGFR statu_         _ More           Lung cancer is the leading cause of cancer death in the world. Accurate determination of the EGFR (epidermal growth factor receptor) mutation status is highly relevant for the proper treatment of this patients. Purpose: The aim of this study was to predict the mutational status of the EGFR in non-small cell lung cancer patients using radiomics features extracted from PET-CT images. Methods: Retrospective study that involve 34 patients with lung cancer confirmed by histology and EGFR status mutation assessment. A total of 2.205 radiomics features were extracted from manual segmentation of the PET-CT images using pyradiomics library. Both computed tomography and positron emission tomography images were used. All images were acquired with intravenous iodinated contrast and F18-FDG. Preprocessing includes resampling, normalization, and discretization of the pixel intensity. Three methods were used for the feature selection process: backward selection (set 1), forward selection (set 2), and feature importance analysis of random forest model (set 3). Nine machine learning methods were used for radiomics model building. Results: 35.2% of patients had EGFR mutation, without significant differences in age, gender, tumor size and SUVmax. After the feature selection process 6, 7 and 17 radiomics features were selected, respectively in each group. The best performances were obtained by Ridge Regression in set 1: AUC of 0.826 (95% CI, 0.811 - 0.839), Random Forest in set 2: AUC of 0.823 (95% CI, 0.808 - 0.838) and Neural Network in set 3: AUC of 0.821 (95% CI, 0.808 - 0.835). Conclusion: The radiomics features analysis has the potential of predicting clinically relevant mutations in lung cancer patients through a non-invasive methodology.         _ Less","","arXiv","https://arxiv.org/abs/2303.08569","0","1","synthetic_biology"
"Electrostatic theory of the acidity of the solution in the lumina of viruses and virus-like particles","Abstract:                _material. The large shifts up to a full pH unit that we predict must have consequences for applications of virus capsids as nanocontainers in bionanotechnology and artificial cell organelles.         _ More           Recently, Maassen et al. measured an appreciable pH difference between the bulk solution and the solution in the lumen of virus-like particles, self-assembled in an aqueous buffer solution containing the coat proteins of a simple plant virus and polyanions. [Maassen, S. J.; et al. Small 2018, 14, 1802081] They attribute this to the Donnan effect, caused by an imbalance between the number of negative charges on the encapsulated polyelectrolyte molecules and the number of positive charges on the RNA binding domains of the coat proteins that make up the virus shell or capsid. By applying Poisson-Boltzmann theory, we confirm this conclusion and show that simple Donnan theory is accurate even for the smallest of viruses and virus-like particles. This, in part, is due to the additional screening caused by the presence of a large number of immobile charges in the cavity of the shell. The presence of a net charge on the outer surface of the capsid we find in practice to not have a large effect on the pH shift. Hence, Donnan theory can indeed be applied to connect the local pH and the amount of encapsulated material. The large shifts up to a full pH unit that we predict must have consequences for applications of virus capsids as nanocontainers in bionanotechnology and artificial cell organelles.         _ Less","","arXiv","https://arxiv.org/abs/2303.03722","0","1","synthetic_biology"
"Cell-sized confinements alter molecular diffusion in concentrated polymer solutions due to length-dependent wetting of polymers","Abstract:                Living cells are characterized by the micrometric confinement of various macromolecules at high concentrations. Using droplets containing binary polymer blends as_         _ More           Living cells are characterized by the micrometric confinement of various macromolecules at high concentrations. Using droplets containing binary polymer blends as artificial cells, we previously showed that cell-sized confinement causes phase separation of the binary polymer solutions because of the length-dependent wetting of the polymers. Here we demonstrate that the wetting-induced heterogeneity of polymers also emerges in single-component polymer solutions. The resulting heterogeneity leads to a slower transport of small molecules at the center of cell-sized droplets than that in bulk solutions. This heterogeneous distribution is observed when longer polymers with lower wettability are localized at the droplet center. Molecular simulations support this wetting-induced heterogeneous distribution by polymer length. Our results suggest that cell-sized confinement functions as a structural regulator for polydisperse polymer solutions that specifically manipulate the diffusion of molecules, particularly those with sizes close to the correlation length of the polymer chains.         _ Less","","arXiv","https://arxiv.org/abs/2303.02818","0","1","synthetic_biology"
"Multi-Agent Reinforcement Learning with Common Policy for Antenna Tilt Optimization","Abstract:                This paper presents a method for optimizing wireless networks by adjusting cell parameters that affect both the performance of the_         _ More           This paper presents a method for optimizing wireless networks by adjusting cell parameters that affect both the performance of the cell being optimized and the surrounding cells. The method uses multiple reinforcement learning agents that share a common policy and take into account information from neighboring cells to determine the state and reward. In order to avoid impairing network performance during the initial stages of learning, agents are pre-trained in an earlier phase of offline learning. During this phase, an initial policy is obtained using feedback from a static network simulator and considering a wide variety of scenarios. Finally, agents can intelligently tune the cell parameters of a test network by suggesting small incremental changes, slowly guiding the network toward an optimal configuration. The agents propose optimal changes using the experience gained with the simulator in the pre-training phase, but they can also continue to learn from current network readings after each change. The results show how the proposed approach significantly improves the performance gains already provided by expert system-based methods when applied to remote antenna tilt optimization. The significant gains of this approach have truly been observed when compared with a similar method in which the state and reward do not incorporate information from neighboring cells.         _ Less","","arXiv","https://arxiv.org/abs/2302.12899","1","0","origin_of_life"
"Improving the Data Efficiency of Multi-Objective Quality-Diversity through Gradient Assistance and Crowding Exploration","Abstract:                _and high-performing solutions. Recently, Multi-Objective MAP-Elites (MOME) extended the QD paradigm to the multi-objective setting by maintaining a Pareto front in each cell of a map-elites grid. MOME achieved a global performance that competed with NSGA-II and SPEA2, two well-established Multi-Objective Evolutionary Algorithms (MOEA), while also acquiring a_         _ More           Quality-Diversity (QD) algorithms have recently gained traction as optimisation methods due to their effectiveness at escaping local optima and capability of generating wide-ranging and high-performing solutions. Recently, Multi-Objective MAP-Elites (MOME) extended the QD paradigm to the multi-objective setting by maintaining a Pareto front in each cell of a map-elites grid. MOME achieved a global performance that competed with NSGA-II and SPEA2, two well-established Multi-Objective Evolutionary Algorithms (MOEA), while also acquiring a diverse repertoire of solutions. However, MOME is limited by non-directed genetic search mechanisms which struggle in high-dimensional search spaces. In this work, we present Multi-Objective MAP-Elites with Policy-Gradient Assistance and Crowding-based Exploration (MOME-PGX): a new QD algorithm that extends MOME to improve its data efficiency and performance. MOME-PGX uses gradient-based optimisation to efficiently drive solutions towards higher performance. It also introduces crowding-based mechanisms to create an improved exploration strategy and to encourage uniformity across Pareto fronts. We evaluate MOME-PGX in four simulated robot locomotion tasks and demonstrate that it converges faster and to a higher performance than all other baselines. We show that MOME-PGX is between 4.3 and 42 times more data-efficient than MOME and doubles the performance of MOME, NSGA-II and SPEA2 in challenging environments.         _ Less","","arXiv","https://arxiv.org/abs/2302.12668","0","1","synthetic_biology"
"Molecular Modeling of Aquaporins and Artificial Transmembrane Channels: a mini-review and perspective for plants","Abstract:                _that are found from archaea, eubacteria, and fungi kingdoms to plants and animals. These proteins play a major role in water and small solutes transport across biological cell membranes and maintain the osmotic balance of living_         _ More           Aquaporins (AQPs) are a family of transmembrane channels that are found from archaea, eubacteria, and fungi kingdoms to plants and animals. These proteins play a major role in water and small solutes transport across biological cell membranes and maintain the osmotic balance of living cells. In this sense, many works in recent years have been devoted to understanding their behavior, including in plants, where 5 major groups of AQPs have been identified, whose physiological function details still have open questions waiting for an answer. In this direction, we observed in the literature very few Molecular Modeling studies focusing on plant AQPs. It creates a gap in the proper depiction of AQPs since Molecular Simulations allow us to get information that is usually inaccessible by experiments. Likewise, many efforts have been made to create artificial nanochannels with improved properties. It has the potential to help humanity (and plants) to face water stress -- a current problem that will be worsened by Climate Change. In this short review, we will revisit and discuss important computational studies about plant aquaporins and artificial transmembrane channels. With this, we aim to show how the Molecular Modeling community can (and should) help to understand plants' AQPs properties and function and how we can create new nanotechnology-based artificial channels.         _ Less","","arXiv","https://arxiv.org/abs/2302.12145","2","1","origin_of_life"
"Stress and Adaptation: Applying Anna Karenina Principle in Deep Learning for Image Classification","Abstract:                _a wide range: from the surface of endangered corals exposed to harsh weather to the lungs of patients suffering from fatal diseases of AIDs. In our paper, we have generated artificial perturbations to our model by hot-swapping the activation and loss functions during the training. In this paper, we build a model to classify cancer_         _ More           Image classification with deep neural networks has reached state-of-art with high accuracy. This success is attributed to good internal representation features that bypasses the difficulties of the non-convex optimization problems. We have little understanding of these internal representations, let alone quantifying them. Recent research efforts have focused on alternative theories and explanations of the generalizability of these deep networks. We propose the alternative perturbation of deep models during their training induces changes that lead to transitions to different families. The result is an Anna Karenina Principle AKP for deep learning, in which less generalizable models unhappy families vary more in their representation than more generalizable models happy families paralleling Leo Tolstoy dictum that all happy families look alike, each unhappy family is unhappy in its own way. Anna Karenina principle has been found in systems in a wide range: from the surface of endangered corals exposed to harsh weather to the lungs of patients suffering from fatal diseases of AIDs. In our paper, we have generated artificial perturbations to our model by hot-swapping the activation and loss functions during the training. In this paper, we build a model to classify cancer cells from non-cancer ones. We give theoretical proof that the internal representations of generalizable happy models are similar in the asymptotic limit. Our experiments verify similar representations of generalizable models.         _ Less","","arXiv","https://arxiv.org/abs/2302.11380","0","1","synthetic_biology"
"Adaptive Discretization using Voronoi Trees for Continuous POMDPs","Abstract:                _the action space for each sampled belief using a hierarchical partition called Voronoi tree, which is a Binary Space Partitioning that implicitly maintains the partition of a cell as the Voronoi diagram of two points sampled from the_         _ More           Solving continuous Partially Observable Markov Decision Processes (POMDPs) is challenging, particularly for high-dimensional continuous action spaces. To alleviate this difficulty, we propose a new sampling-based online POMDP solver, called Adaptive Discretization using Voronoi Trees (ADVT). It uses Monte Carlo Tree Search in combination with an adaptive discretization of the action space as well as optimistic optimization to efficiently sample high-dimensional continuous action spaces and compute the best action to perform. Specifically, we adaptively discretize the action space for each sampled belief using a hierarchical partition called Voronoi tree, which is a Binary Space Partitioning that implicitly maintains the partition of a cell as the Voronoi diagram of two points sampled from the cell. ADVT uses the estimated diameters of the cells to form an upper-confidence bound on the action value function within the cell, guiding the Monte Carlo Tree Search expansion and further discretization of the action space. This enables ADVT to better exploit local information with respect to the action value function, allowing faster identification of the most promising regions in the action space, compared to existing solvers. Voronoi trees keep the cost of partitioning and estimating the diameter of each cell low, even in high-dimensional spaces where many sampled points are required to cover the space well. ADVT additionally handles continuous observation spaces, by adopting an observation progressive widening strategy, along with a weighted particle representation of beliefs. Experimental results indicate that ADVT scales substantially better to high-dimensional continuous action spaces, compared to state-of-the-art methods.         _ Less","","arXiv","https://arxiv.org/abs/2302.10439","1","0","origin_of_life"
"Growing Steerable Neural Cellular Automata","Abstract:                _(NCA) models have shown remarkable capacity for pattern formation and complex global behaviors stemming from local coordination. However, in the original implementation of NCA, cells are incapable of adjusting their own orientation, and it is the responsibility of the model designer to orient them externally. A recent isotropic variant of NCA (Growing Isotro_         _ More           Neural Cellular Automata (NCA) models have shown remarkable capacity for pattern formation and complex global behaviors stemming from local coordination. However, in the original implementation of NCA, cells are incapable of adjusting their own orientation, and it is the responsibility of the model designer to orient them externally. A recent isotropic variant of NCA (Growing Isotropic Neural Cellular Automata) makes the model orientation-independent - cells can no longer tell up from down, nor left from right - by removing its dependency on perceiving the gradient of spatial states in its neighborhood. In this work, we revisit NCA with a different approach: we make each cell responsible for its own orientation by allowing it to 'turn' as determined by an adjustable internal state. The resulting Steerable NCA contains cells of varying orientation embedded in the same pattern. We observe how, while Isotropic NCA are orientation-agnostic, Steerable NCA have chirality: they have a predetermined left-right symmetry. We therefore show that we can train Steerable NCA in similar but simpler ways than their Isotropic variant by: (1) breaking symmetries using only two seeds, or (2) introducing a rotation-invariant training objective and relying on asynchronous cell updates to break the up-down symmetry of the system.         _ Less","","arXiv","https://arxiv.org/abs/2302.10197","1","0","origin_of_life"
"Explainable artificial intelligence toward usable and trustworthy computer-aided early diagnosis of multiple sclerosis from Optical Coherence Tomography","Abstract:                _of 216 eyes from 111 healthy controls and 100 eyes from 59 patients with relapsing-remitting MS were enrolled. The feature set was obtained from the thickness of the ganglion cell layer (GCL) and the retinal nerve fiber layer (RNFL). Measurements were acquired by the novel Posterior Pole protocol from Spectralis Optical Coherence Tomography (OCT) device. We_         _ More           Background: Several studies indicate that the anterior visual pathway provides information about the dynamics of axonal degeneration in Multiple Sclerosis (MS). Current research in the field is focused on the quest for the most discriminative features among patients and controls and the development of machine learning models that yield computer-aided solutions widely usable in clinical practice. However, most studies are conducted with small samples and the models are used as black boxes. Clinicians should not trust machine learning decisions unless they come with comprehensive and easily understandable explanations. Materials and methods: A total of 216 eyes from 111 healthy controls and 100 eyes from 59 patients with relapsing-remitting MS were enrolled. The feature set was obtained from the thickness of the ganglion cell layer (GCL) and the retinal nerve fiber layer (RNFL). Measurements were acquired by the novel Posterior Pole protocol from Spectralis Optical Coherence Tomography (OCT) device. We compared two black-box methods (gradient boosting and random forests) with a glass-box method (explainable boosting machine). Explainability was studied using SHAP for the black-box methods and the scores of the glass-box method. Results: The best-performing models were obtained for the GCL layer. Explainability pointed out to the temporal location of the GCL layer that is usually broken or thinning in MS and the relationship between low thickness values and high probability of MS, which is coherent with clinical knowledge. Conclusions: The insights on how to use explainability shown in this work represent a first important step toward a trustworthy computer-aided solution for the diagnosis of MS with OCT.         _ Less","","arXiv","https://arxiv.org/abs/2302.06613","2","1","origin_of_life"
"Between Generating Noise and Generating Images: Noise in the Correct Frequency Improves the Quality of Synthetic Histopathology Images for Digital Pathology","Abstract:        Artificial intelligence and machine learning techniques have the promise to revolutionize the field of digital pathology. However, these models demand considerable amounts of data, while the availability of unbiased training data is limited. Synthetic images can augment existing datasets, to improve and validate AI algorithms. Yet, controlling the exact dist_         _ More   Artificial intelligence and machine learning techniques have the promise to revolutionize the field of digital pathology. However, these models demand considerable amounts of data, while the availability of unbiased training data is limited. Synthetic images can augment existing datasets, to improve and validate AI algorithms. Yet, controlling the exact distribution of cellular features within them is still challenging. One of the solutions is harnessing conditional generative adversarial networks that take a semantic mask as an input rather than a random noise. Unlike other domains, outlining the exact cellular structure of tissues is hard, and most of the input masks depict regions of cell types. However, using polygon-based masks introduce inherent artifacts within the synthetic images - due to the mismatch between the polygon size and the single-cell size. In this work, we show that introducing random single-pixel noise with the appropriate spatial frequency into a polygon semantic mask can dramatically improve the quality of the synthetic images. We used our platform to generate synthetic images of immunohistochemistry-treated lung biopsies. We test the quality of the images using a three-fold validation procedure. First, we show that adding the appropriate noise frequency yields 87% of the similarity metrics improvement that is obtained by adding the actual single-cell features. Second, we show that the synthetic images pass the Turing test. Finally, we show that adding these synthetic images to the train set improves AI performance in terms of PD-L1 semantic segmentation performances. Our work suggests a simple and powerful approach for generating synthetic data on demand to unbias limited datasets to improve the algorithms' accuracy and validate their robustness.         _ Less","","arXiv","https://arxiv.org/abs/2302.06549","0","1","synthetic_biology"
"DEPAS: De-novo Pathology Semantic Masks using a Generative Model","Abstract:                The integration of artificial intelligence into digital pathology has the potential to automate and improve various tasks, such as image analysis and diagnostic decision-making. Yet, the inherent variability of tissues, together with the need for image labeling, lead to biased datasets that limit the generalizability of algorithms trained on them. One of the_         _ More           The integration of artificial intelligence into digital pathology has the potential to automate and improve various tasks, such as image analysis and diagnostic decision-making. Yet, the inherent variability of tissues, together with the need for image labeling, lead to biased datasets that limit the generalizability of algorithms trained on them. One of the emerging solutions for this challenge is synthetic histological images. However, debiasing real datasets require not only generating photorealistic images but also the ability to control the features within them. A common approach is to use generative methods that perform image translation between semantic masks that reflect prior knowledge of the tissue and a histological image. However, unlike other image domains, the complex structure of the tissue prevents a simple creation of histology semantic masks that are required as input to the image translation model, while semantic masks extracted from real images reduce the process's scalability. In this work, we introduce a scalable generative model, coined as DEPAS, that captures tissue structure and generates high-resolution semantic masks with state-of-the-art quality. We demonstrate the ability of DEPAS to generate realistic semantic maps of tissue for three types of organs: skin, prostate, and lung. Moreover, we show that these masks can be processed using a generative image translation model to produce photorealistic histology images of two types of cancer with two different types of staining techniques. Finally, we harness DEPAS to generate multi-label semantic masks that capture different cell types distributions and use them to produce histological images with on-demand cellular features. Overall, our work provides a state-of-the-art solution for the challenging task of generating synthetic histological images while controlling their semantic information in a scalable way.         _ Less","","arXiv","https://arxiv.org/abs/2302.06513","1","0","origin_of_life"
"Self-reconfiguring colloidal active matter","Abstract:        Cells and microorganisms employ dynamic shape changes to enable steering and avoidance for efficient spatial exploration and collective organization. In contrast, active colloids, their_         _ More   Cells and microorganisms employ dynamic shape changes to enable steering and avoidance for efficient spatial exploration and collective organization. In contrast, active colloids, their synthetic counterparts, currently lack similar abilities and strategies. Through physical interactions alone, here we create active colloidal molecules that spontaneously reconfigure their structure, unlike traditional active particles. We find that self-reconfiguration decouples reorientational dynamics from rotational diffusivity and bestows our active molecules additional reorientation capabilities. During encounters with neighbors, rapid conformational changes lead to self-steering and avoidance. At higher area fractions, reconfiguration-induced avoidance fully inhibits characteristic dynamic clustering, motility-induced phase separation and flocking; instead, the system retains a homogeneous structure comprising well-separated active units. Self-reconfiguring systems therefore present an exciting path towards autonomous motion beyond that of classical synthetic active matter.         _ Less","","arXiv","https://arxiv.org/abs/2501.00672","1","0","origin_of_life"
"Wetting-Layer-Assisted Synthesis of Inverted CdSe/PbSe Quantum Dots and their Photophysical and Photo-Electrical Properties","Abstract:                _(QDs) based on narrow-gap PbSe and wide-gap CdSe have been studied with an eye on their prospective applications in near-infrared (NIR) light sources, photodetectors, and solar cells. The most common structural motif is a spherical QD comprising a PbSe core enclosed into a CdSe shell. However, the potential barrier created by the CdSe shell complicates extra_         _ More           Heterostructured quantum dots (QDs) based on narrow-gap PbSe and wide-gap CdSe have been studied with an eye on their prospective applications in near-infrared (NIR) light sources, photodetectors, and solar cells. The most common structural motif is a spherical QD comprising a PbSe core enclosed into a CdSe shell. However, the potential barrier created by the CdSe shell complicates extraction of band-edge charge carriers from the QD. Therefore, conventional PbSe/CdSe QDs are not suitable for applications in practical photoconversion devices. Here we report inverted CdSe/PbSe core/shell QDs that overcome this drawback. In these structures, both photocarriers (electron and hole) exhibit a significant degree of shell localization and are therefore free to move within the QD solid and be extracted into an external circuit. To create such QDs, we employ a novel synthetic method in which a thin, atomically controlled wetting layer is used to homogenize the surface of the CdSe core and thus promote directionally uniform growth of the PbSe shell. Unlike noninverted QDs, inverted core/shell structures exhibit highly efficient photocarrier transport, making them excellent candidates for applications in practical photoconversion including photovoltaics, photodetection, and photochemistry.         _ Less","","arXiv","https://arxiv.org/abs/2412.17939","0","1","synthetic_biology"
"AFM Cantilever Magnetometry for Measuring Femto-Nm Torques Generated by Single Magnetic Particles for Cell Actuation","Abstract:                _scheme. In this work, we developed a method using a commercially available Atomic Force Microscopy setup and cantilevers to quantify the torque generated by a single synthetic antiferromagnetic (SAF) nanoplatelet with high perpendicular magnetic anisotropy. Specifically, we measured 1.6$\\pm$0.6$\\cdot$10$^{-15}$ Nm torque while applying 373$\\pm$5 mT field at_         _ More           Particles with high anisotropy in their magnetic properties and shape are of increasing interest for mechanobiology, where transducing a remotely applied magnetic field vector to a local mechanical response is crucial. An outstanding challenge is quantifying the mechanical torque of a single nanoparticle, typically in the range of atto- to femto-Newton-meters (Nm). The magneto-mechanical torque manifests due to a misalignment of the external magnetic field vector with the built-in magnetic anisotropy axis, as opposed to a magnetic force, and complicates the measurement scheme. In this work, we developed a method using a commercially available Atomic Force Microscopy setup and cantilevers to quantify the torque generated by a single synthetic antiferromagnetic (SAF) nanoplatelet with high perpendicular magnetic anisotropy. Specifically, we measured 1.6$\\pm$0.6$\\cdot$10$^{-15}$ Nm torque while applying 373$\\pm$5 mT field at 12$\\pm$2 degrees to the built-in anisotropy axis exerted by a single circular SAF nanoplatelet with 1.88 $_$m diameter and 72 nm thickness, naively translating to a $\\approx$ 1.7 nN maximum force at the nanoplatelet apex. This measured torque and derived force of the SAF nanoplatelets is strong enough for most applications in mechanobiology; for example, it can be used to rupture (cancer) cell membranes. Moreover, SAF nanoplatelets open a route for easy tuning of the built-in magnetic anisotropy and size, reducing the torque and allowing for small mechanical stimuli for ion channel activation. This work presents a straightforward and widely applicable method for characterizing magnetic particles' mechanical transduction, which is applied to SAF nanoplatelets with a high PMA.         _ Less","","arXiv","https://arxiv.org/abs/2412.17516","0","1","synthetic_biology"
"Synthetic pulsar lightcurves from global kinetic simulations and comparison with the Fermi-LAT catalog","Abstract:                _of pulsar magnetospheres to the test, in light of the most recent gamma-ray observations in the GeV and TeV bands. To this end, we present of a new series of global particle-in-cell simulations of an inclined pulsar magnetosphere. High-quality synthetic pulse profiles in the synchrotron and inverse Compton channels are_         _ More           Rotation-powered pulsars represent the main class of identified gamma-ray sources in the Galaxy. The wealth of observational data collected by the AGILE and Fermi gamma-ray space telescopes in the GeV range, and by ground-based Cherenkov telescopes in the TeV band provide invaluable insights into how relativistic plasmas dissipate and accelerate particles. Decoding the information contained in the gamma-ray pulses profile is an important step to understand how pulsars work. In this study, we aim at putting an ab initio plasma model of pulsar magnetospheres to the test, in light of the most recent gamma-ray observations in the GeV and TeV bands. To this end, we present of a new series of global particle-in-cell simulations of an inclined pulsar magnetosphere. High-quality synthetic pulse profiles in the synchrotron and inverse Compton channels are reconstructed to study in greater details their morphology and their energy dependence. We also perform a fit of observed lightcurves with the model, using the third Fermi-LAT gamma-ray pulsar catalog. Reconnection in the wind current sheet powers synchrotron and inverse Compton emission. The modeled pulse profiles reproduce some of the salient features of observed gamma-ray pulsars, including the mysterious Vela-like lightcurves, such as: the generic double-peaked structure, the presence of a bridge or third peak in between the main pulses, the pulse narrowing with increasing energy. The bolometric synchrotron radiative efficiency is strictly limited by the reconnection rate. Our global kinetic simulations are able to match observed pulse profiles. Such direct comparisons will help drive and focus future simulation developments.         _ Less","","arXiv","https://arxiv.org/abs/2412.02307","1","0","origin_of_life"
"PINNs4Drops: Convolutional feature-enhanced physics-informed neural networks for reconstructing two-phase flows","Abstract:                Two-phase flow phenomena play a key role in many engineering applications, including hydrogen fuel cells, spray cooling techniques and combustion. Specialized techniques like shadowgraphy and particle image velocimetry can reveal gas-liquid interface evolution and internal velocity fields; however, they are largely limited to planar measurements, while flow_         _ More           Two-phase flow phenomena play a key role in many engineering applications, including hydrogen fuel cells, spray cooling techniques and combustion. Specialized techniques like shadowgraphy and particle image velocimetry can reveal gas-liquid interface evolution and internal velocity fields; however, they are largely limited to planar measurements, while flow dynamics are inherently three-dimensional (3D). Deep learning techniques based on convolutional neural networks provide a powerful approach for volumetric reconstruction based on the experimental data by leveraging spatial structure of images and extracting context-rich features. Building on this foundation, Physics-informed neural networks (PINNs) offer a complementary and promising alternative integrating prior knowledge in the form of governing equations into the networks training process. This integration enables accurate predictions even with limited data. By combining the strengths of both approaches, we propose a novel convolutional feature-enhanced PINNs framework, designed for the spatio-temporal reconstruction of two-phase flows from color-coded shadowgraphy images. The proposed approach is first validated on synthetic data generated through direct numerical simulation, demonstrating high spatial accuracy in reconstructing the three-dimensional gas-liquid interface, along with the inferred velocity and pressure fields. Subsequently, we apply this method to interface reconstruction for an impinging droplet using planar experimental data, highlighting the practical applicability and significant potential of the proposed approach to real-world fluid dynamics analysis.         _ Less","","arXiv","https://arxiv.org/abs/2411.15949","0","1","synthetic_biology"
"Enhancing Table Representations with LLM-powered Synthetic Data Generation","Abstract:                _for improving table management, discovery, and analysis. However, existing approaches to tabular data representation often face limitations, primarily due to their focus on cell-level tasks and the lack of high-quality training data. To address these challenges, we first formulate a clear definition of table similarity in the context of data transformation a_         _ More           In the era of data-driven decision-making, accurate table-level representations and efficient table recommendation systems are becoming increasingly crucial for improving table management, discovery, and analysis. However, existing approaches to tabular data representation often face limitations, primarily due to their focus on cell-level tasks and the lack of high-quality training data. To address these challenges, we first formulate a clear definition of table similarity in the context of data transformation activities within data-driven enterprises. This definition serves as the foundation for synthetic data generation, which require a well-defined data generation process. Building on this, we propose a novel synthetic data generation pipeline that harnesses the code generation and data manipulation capabilities of Large Language Models (LLMs) to create a large-scale synthetic dataset tailored for table-level representation learning. Through manual validation and performance comparisons on the table recommendation task, we demonstrate that the synthetic data generated by our pipeline aligns with our proposed definition of table similarity and significantly enhances table representations, leading to improved recommendation performance.         _ Less","","arXiv","https://arxiv.org/abs/2411.03356","1","0","origin_of_life"
"Collective behavior of 'flexicles'","Abstract:                In recent years the functionality of synthetic active microparticles has edged even closer to that of their biological counterparts. However, we still lack the understanding needed to recreate at the microscale key features of autonomous behavior exhibited by microorganisms or swarms of macroscopic robots. In this study, we propose a model for a three-dimens_         _ More           In recent years the functionality of synthetic active microparticles has edged even closer to that of their biological counterparts. However, we still lack the understanding needed to recreate at the microscale key features of autonomous behavior exhibited by microorganisms or swarms of macroscopic robots. In this study, we propose a model for a three-dimensional deformable cellular composite particle consisting of self-propelled rod-shaped colloids confined within a flexible vesicle - a superstructure we call a 'flexicle'. Using molecular dynamics simulations, we investigate the collective behavior of dense systems comprised of many flexicles. We show that individual flexicles exhibit shape changes upon collisions with other flexicles that lead to rearrangement of the internal active rods that slow the flexicle motion significantly. This shape deformability gives rise to a diverse set of motility-induced phase separation phenomena and the spontaneous flow of flexicles akin to the migration of cells in dense tissues. Our findings establish a foundation for designing responsive cell-like active particles and developing strategies for controlling swarm migration and other autonomous swarm behaviors at cellular and colloidal scales.         _ Less","","arXiv","https://arxiv.org/abs/2410.19172","1","1","multiple"
"Gumbel Rao Monte Carlo based Bi-Modal Neural Architecture Search for Audio-Visual Deepfake Detection","Abstract:                Deepfakes pose a critical threat to biometric authentication systems by generating highly realistic synthetic media. Existing multimodal deepfake detectors often struggle to adapt to diverse data and rely on simple fusion methods. To address these challenges, we propose Gumbel-Rao Monte Carlo Bi-modal Neural Architecture Search (GRMC-BMNAS), a novel architec_         _ More           Deepfakes pose a critical threat to biometric authentication systems by generating highly realistic synthetic media. Existing multimodal deepfake detectors often struggle to adapt to diverse data and rely on simple fusion methods. To address these challenges, we propose Gumbel-Rao Monte Carlo Bi-modal Neural Architecture Search (GRMC-BMNAS), a novel architecture search framework that employs Gumbel-Rao Monte Carlo sampling to optimize multimodal fusion. It refines the Straight through Gumbel Softmax (STGS) method by reducing variance with Rao-Blackwellization, stabilizing network training. Using a two-level search approach, the framework optimizes the network architecture, parameters, and performance. Crucial features are efficiently identified from backbone networks, while within the cell structure, a weighted fusion operation integrates information from various sources. By varying parameters such as temperature and number of Monte carlo samples yields an architecture that maximizes classification performance and better generalisation capability. Experimental results on the FakeAVCeleb and SWAN-DF datasets demonstrate an impressive AUC percentage of 95.4\\%, achieved with minimal model parameters.         _ Less","","arXiv","https://arxiv.org/abs/2410.06543","1","0","origin_of_life"
"Mind the kinematics simulation of planet-disk interactions: time evolution and numerical resolution","Abstract:                _to study non-axisymmetric kinematic perturbations at 2 scale heights induced by Jovian planets in protoplanetary disks, followed by examinations of detectable signals in synthetic CO emission line observations at millimeter wavelengths. We advocate for using residual velocity or channel maps, generated by subtracting an azimuthally averaged background of the_         _ More           Planet-disk interactions can produce kinematic signatures in protoplanetary disks. While recent observations have detected non-Keplerian gas motions in disks, their origins are still being debated. To explore this, we conduct 3D hydrodynamic simulations using the code FARGO3D to study non-axisymmetric kinematic perturbations at 2 scale heights induced by Jovian planets in protoplanetary disks, followed by examinations of detectable signals in synthetic CO emission line observations at millimeter wavelengths. We advocate for using residual velocity or channel maps, generated by subtracting an azimuthally averaged background of the disk, to identify planet-induced kinematic perturbations. We investigate the effects of two basic simulation parameters, simulation duration and numerical resolution, on the simulation results. Our findings suggest that a short simulation (e.g., 100 orbits) is insufficient to establish a steady velocity pattern given our chosen viscosity ($_=10^{-3}$), and displays plenty of fluctuations on orbital timescale. Such transient features could be detected in observations. By contrast, a long simulation (e.g., 1,000 orbits) is required to reach steady state in kinematic structures. At 1,000 orbits, the strongest and detectable velocity structures are found in the spiral wakes close to the planet. Through numerical convergence tests, we find hydrodynamics results converge in spiral regions at a resolution of 14 cells per disk scale height (CPH) or higher. Meanwhile, synthetic observations produced from hydrodynamic simulations at different resolutions are indistinguishable with 0.1$^{\\prime\\prime}$ angular resolution and 10 hours of integration time on ALMA.         _ Less","","arXiv","https://arxiv.org/abs/2410.05482","0","1","synthetic_biology"
"Deciphering the Interface Laws of Turing Mixtures and Foams","Abstract:                _arise from distinct physical processes in active systems. It allows the design of specific pattern morphologies with potential applications as spatial control strategies in synthetic cells.         _ More           For cellular functions like division and polarization, protein pattern formation driven by NTPase cycles is a central spatial control strategy. Operating far from equilibrium, no general theory links microscopic reaction networks and parameters to the pattern type and dynamics. We discover a generic mechanism giving rise to an effective interfacial tension organizing the macroscopic structure of non-equilibrium steady-state patterns. Namely, maintaining protein-density interfaces by cyclic protein attachment and detachment produces curvature-dependent protein redistribution which straightens the interface. We develop a non-equilibrium Neumann angle law and Plateau vertex conditions for interface junctions and mesh patterns, thus introducing the concepts of ``Turing mixtures'' and ``Turing foams''. In contrast to liquid foams and mixtures, these non-equilibrium patterns can select an intrinsic wavelength by interrupting an equilibrium-like coarsening process. Data from in vitro experiments with the E. coli Min protein system verifies the vertex conditions and supports the wavelength dynamics. Our study uncovers interface laws with correspondence to thermodynamic relations that arise from distinct physical processes in active systems. It allows the design of specific pattern morphologies with potential applications as spatial control strategies in synthetic cells.         _ Less","","arXiv","https://arxiv.org/abs/2409.20070","1","2","synthetic_biology"
"Integrating Optimal Transport and Structural Inference Models for GRN Inference from Single-cell Data","Abstract:                _transport (OT) with a deep-learning structural inference model. Advances in next-generation sequencing enable detailed yet destructive gene expression assays at the single-cell level, resulting in the loss of_         _ More           We introduce a novel gene regulatory network (GRN) inference method that integrates optimal transport (OT) with a deep-learning structural inference model. Advances in next-generation sequencing enable detailed yet destructive gene expression assays at the single-cell level, resulting in the loss of cell evolutionary trajectories. Due to technological and cost constraints, single-cell experiments often feature cells sampled at irregular and sparse time points with a small sample size. Although trajectory-based structural inference models can accurately reveal the underlying interaction graph from observed data, their efficacy depends on the inputs of thousands of regularly sampled trajectories. The irregularly-sampled nature of single-cell data precludes the direct use of these powerful models for reconstructing GRNs. Optimal transport, a classical mathematical framework that minimize transportation costs between distributions, has shown promise in multi-omics data integration and cell fate prediction. Utilizing OT, our method constructs mappings between consecutively sampled cells to form cell-level trajectories, which are given as input to a structural inference model that recovers the GRN from single-cell data. Through case studies in two synthetic datasets, we demonstrate the feasibility of our proposed method and its promising performance over eight state-of-the-art GRN inference methods.         _ Less","","arXiv","https://arxiv.org/abs/2409.15080","0","1","synthetic_biology"
"Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles","Abstract:                _this work, we study if causal language modeling can learn a complex task such as solving Sudoku puzzles. To solve a Sudoku, the model is first required to search over all empty cells of the puzzle to decide on a_         _ More           Causal language modeling using the Transformer architecture has yielded remarkable capabilities in Large Language Models (LLMs) over the last few years. However, the extent to which fundamental search and reasoning capabilities emerged within LLMs remains a topic of ongoing debate. In this work, we study if causal language modeling can learn a complex task such as solving Sudoku puzzles. To solve a Sudoku, the model is first required to search over all empty cells of the puzzle to decide on a cell to fill and then apply an appropriate strategy to fill the decided cell. Sometimes, the application of a strategy only results in thinning down the possible values in a cell rather than concluding the exact value of the cell. In such cases, multiple strategies are applied one after the other to fill a single cell. We observe that Transformer models trained on this synthetic task can indeed learn to solve Sudokus (our model solves $94.21\\%$ of the puzzles fully correctly) when trained on a logical sequence of steps taken by a solver. We find that training Transformers with the logical sequence of steps is necessary and without such training, they fail to learn Sudoku. We also extend our analysis to Zebra puzzles (known as Einstein puzzles) and show that the model solves $92.04 \\%$ of the puzzles fully correctly. In addition, we study the internal representations of the trained Transformer and find that through linear probing, we can decode information about the set of possible values in any given cell from them, pointing to the presence of a strong reasoning engine implicit in the Transformer weights.         _ Less","","arXiv","https://arxiv.org/abs/2409.10502","1","0","origin_of_life"
"Light-induced cortical excitability reveals programmable shape dynamics in starfish oocytes","Abstract:                _deformable surfaces are a key component for many vital cellular functions. In particular, these waves play a major role in force generation and long-range signal transmission in cells that dynamically change shape, as encountered during_         _ More           Chemo-mechanical waves on active deformable surfaces are a key component for many vital cellular functions. In particular, these waves play a major role in force generation and long-range signal transmission in cells that dynamically change shape, as encountered during cell division or morphogenesis. Reconstituting and controlling such chemically controlled cell deformations is a crucial but unsolved challenge for the development of synthetic cells. Here, we develop an optogenetic method to elucidate the mechanism responsible for coordinating surface contraction waves that occur in oocytes of the starfish Patiria miniata during meiotic cell division. Using spatiotemporally-patterned light stimuli as a control input, we create chemo-mechanical cortical excitations that are decoupled from meiotic cues and drive diverse shape deformations ranging from local pinching to surface contraction waves and cell lysis. We develop a quantitative model that entails the hierarchy of chemical and mechanical dynamics, which allows to relate the variety of mechanical responses to optogenetic stimuli. Our framework systematically predicts and explains transitions of programmed shape dynamics. Finally, we qualitatively map the observed shape dynamics to elucidate how the versatility of intracellular protein dynamics can give rise to a broad range of mechanical phenomenologies. More broadly, our results pave the way toward real-time control over dynamical deformations in living organisms and can advance the design of synthetic cells and life-like cellular functions.         _ Less","","arXiv","https://arxiv.org/abs/2409.08651","1","1","multiple"
"Collective chemotactic search strategies","Abstract:                Chemotactic biological or synthetic active matter shapes its environment by secretions of chemical signals from its self-propelled constituents, like cells, organisms or active colloids. From this indirect interaction collective effects emerge that can be used by the agents to migrate collectively, to form patterns or_         _ More           Chemotactic biological or synthetic active matter shapes its environment by secretions of chemical signals from its self-propelled constituents, like cells, organisms or active colloids. From this indirect interaction collective effects emerge that can be used by the agents to migrate collectively, to form patterns or to search for targets more efficiently. Here, we use paradigmatic models to study the efficiency of collective search strategies of a large group of motile agents that release during their movement repulsive auto-chemotactic signals forcing them to move away from high concentrations of the chemical clue. We show that the repulsive chemotactic interactions improve the search efficiency, measured by the mean first passage time to find a randomly located target, by orders of magnitude depending on the strength of the chemotactic coupling. The mechanism for this improvement relies on two factors: the increase of the persistence length due to the agent's self-interaction with its own chemotactic field and by a more homogeneous distribution of the agents due to their mutual indirect repulsion mediated by the chemotactic field. At stronger particle-field coupling the chemotactic searchers self-organize into ballistically moving bands reminiscent of search-chains formed in search and rescue operations, whose efficiency depends on the number of searchers involved. Our comprehensive study of collective search strategies of large groups of interacting agents is not only relevant for chemotactic active matter but also for a wide range of fields like ethology, information engineering, robotics, and social engineering.         _ Less","","arXiv","https://arxiv.org/abs/2409.04262","2","1","origin_of_life"
"LLOT: application of Laplacian Linear Optimal Transport in spatial transcriptome reconstruction","Abstract:                Single-cell RNA sequencing (scRNA-seq) allows transcriptional profiling, and_         _ More           Single-cell RNA sequencing (scRNA-seq) allows transcriptional profiling, and cell-type annotation of individual cells. However, sample preparation in typical scRNA-seq experiments often homogenizes the samples, thus spatial locations of individual cells are often lost. Although spatial transcriptomic techniques, such as in situ hybridization (ISH) or Slide-seq, can be used to measure gene expression in specific locations in samples, it remains a challenge to measure or infer expression level for every gene at a single-cell resolution in every location in tissues. Existing computational methods show promise in reconstructing these missing data by integrating scRNA-seq data with spatial expression data such as those obtained from spatial transcriptomics. Here we describe Laplacian Linear Optimal Transport (LLOT), an interpretable method to integrate single-cell and spatial transcriptomics data to reconstruct missing information at a whole-genome and single-cell resolution. LLOT iteratively corrects platform effects and employs Laplacian Optimal Transport to decompose each spot in spatial transcriptomics data into a spatially-smooth probabilistic mixture of single cells. We benchmarked LLOT against several other methods on datasets of Drosophila embryo, mouse cerebellum and synthetic datasets generated by scDesign3 in the paper, and another three datasets in the supplementary. The results showed that LLOT consistently outperformed others in reconstructing spatial expressions.         _ Less","","arXiv","https://arxiv.org/abs/2408.15149","1","0","origin_of_life"
"CHOTA: A Higher Order Accuracy Metric for Cell Tracking","Abstract:                The evaluation of cell tracking results steers the development of tracking methods, significantly impacting biomedical research. This is quantitatively achieved by means of evaluation metrics. Unfortunately, current metrics favor local correctness and weakly reward global coherence, impeding high-level biological analysis. To also foster global coherence, we_         _ More           The evaluation of cell tracking results steers the development of tracking methods, significantly impacting biomedical research. This is quantitatively achieved by means of evaluation metrics. Unfortunately, current metrics favor local correctness and weakly reward global coherence, impeding high-level biological analysis. To also foster global coherence, we propose the CHOTA metric (Cell-specific Higher Order Tracking Accuracy) which unifies the evaluation of all relevant aspects of cell tracking: cell detections and local associations, global coherence, and lineage tracking. We achieve this by introducing a new definition of the term 'trajectory' that includes the entire cell lineage and by including this into the well-established HOTA metric from general multiple object tracking. Furthermore, we provide a detailed survey of contemporary cell tracking metrics to compare our novel CHOTA metric and to show its advantages. All metrics are extensively evaluated on state-of-the-art real-data cell tracking results and synthetic results that simulate specific tracking errors. We show that CHOTA is sensitive to all tracking errors and gives a good indication of the biologically relevant capability of a method to reconstruct the full lineage of cells. It introduces a robust and comprehensive alternative to the currently used metrics in cell tracking. Python code is available at https://github.com/CellTrackingChallenge/py-ctcmetrics .         _ Less","","arXiv","https://arxiv.org/abs/2408.11571","2","2","multiple"
"Deep Generative Classification of Blood Cell Morphology","Abstract:                Accurate classification of haematological cells is critical for diagnosing blood disorders, but presents significant challenges for machine automation owing to the complexity of_         _ More           Accurate classification of haematological cells is critical for diagnosing blood disorders, but presents significant challenges for machine automation owing to the complexity of cell morphology, heterogeneities of biological, pathological, and imaging characteristics, and the imbalance of cell type frequencies. We introduce CytoDiffusion, a diffusion-based classifier that effectively models blood cell morphology, combining accurate classification with robust anomaly detection, resistance to distributional shifts, interpretability, data efficiency, and superhuman uncertainty quantification. Our approach outperforms state-of-the-art discriminative models in anomaly detection (AUC 0.990 vs. 0.918), resistance to domain shifts (85.85% vs. 74.38% balanced accuracy), and performance in low-data regimes (95.88% vs. 94.95% balanced accuracy). Notably, our model generates synthetic blood cell images that are nearly indistinguishable from real images, as demonstrated by an authenticity test in which expert haematologists achieved only 52.3% accuracy (95% CI: [50.5%, 54.2%]) in distinguishing real from generated images. Furthermore, we enhance model explainability through the generation of directly interpretable counterfactual heatmaps. Our comprehensive evaluation framework, encompassing these multiple performance dimensions, establishes a new benchmark for medical image analysis in haematology, ultimately enabling improved diagnostic accuracy in clinical settings. Our code is available at https://github.com/CambridgeCIA/CytoDiffusion.         _ Less","","arXiv","https://arxiv.org/abs/2408.08982","1","1","multiple"
"Direct measurement of topological invariants through temporal adiabatic evolution of bulk states in the synthetic Brillouin zone","Abstract:                _coupling circuits between acoustic cavities to mimic the Hamiltonians in the Brillouin zone, with which excitation and adiabatic evolution of bulk states are realized in a unit cell. By extracting the Berry phases of the bulk band, topological invariants, including the Zak phase for the SSH model and the Chern number for the AAH model, are obtained convincin_         _ More           Mathematically, topological invariants arise from the parallel transport of eigenstates on the energy bands, which, in physics, correspond to the adiabatic dynamical evolution of transient states. It determines the presence of boundary states, while lacking direct measurements. Here, we develop time-varying programmable coupling circuits between acoustic cavities to mimic the Hamiltonians in the Brillouin zone, with which excitation and adiabatic evolution of bulk states are realized in a unit cell. By extracting the Berry phases of the bulk band, topological invariants, including the Zak phase for the SSH model and the Chern number for the AAH model, are obtained convincingly. The bulk state evolution also provides insight into the topological charges of our newly developed non-Abelian models, which are also verified by observing the adiabatic eigenframe rotation. Our work not only provides a general recipe for telling various topological invariants but also sheds light on transient acoustic wave manipulations.         _ Less","","arXiv","https://arxiv.org/abs/2408.02984","0","1","synthetic_biology"
"The appeal of the gamma family distribution to protect the confidentiality of contingency tables","Abstract:                _information that are potentially useful for researchers. For such data sources to be made available, however, strict guarantees of privacy would be required. To achieve this, synthetic data methods can be used. Such methods, when protecting the confidentiality of tabular data (contingency tables), often utilise the Poisson or Poisson-mixture distributions, s_         _ More           Administrative databases, such as the English School Census (ESC), are rich sources of information that are potentially useful for researchers. For such data sources to be made available, however, strict guarantees of privacy would be required. To achieve this, synthetic data methods can be used. Such methods, when protecting the confidentiality of tabular data (contingency tables), often utilise the Poisson or Poisson-mixture distributions, such as the negative binomial (NBI). These distributions, however, are either equidispersed (in the case of the Poisson) or overdispersed (e.g. in the case of the NBI), which results in excessive noise being applied to large low-risk counts. This paper proposes the use of the (discretized) gamma family (GAF) distribution, which allows noise to be applied in a more bespoke fashion. Specifically, it allows less noise to be applied as cell counts become larger, providing an optimal balance in relation to the risk-utility trade-off. We illustrate the suitability of the GAF distribution on an administrative-type data set that is reminiscent of the ESC.         _ Less","","arXiv","https://arxiv.org/abs/2408.02513","1","0","origin_of_life"
"Asymmetries in asymptotic giant branch stars and their winds. I. From 3D RHD models to synthetic observables","Abstract:                _to the metal enrichment of the interstellar medium. In this paper, we adapted models from advanced RHD simulations as input for radiative transfer software to create synthetic observables. A major goal is to describe an AGB star's non-sphericity and to simulate its effects on the surrounding dusty envelope. We developed tools to translate models of an AG_         _ More           [Abridged] AGB stars are significant contributors to the metal enrichment of the interstellar medium. In this paper, we adapted models from advanced RHD simulations as input for radiative transfer software to create synthetic observables. A major goal is to describe an AGB star's non-sphericity and to simulate its effects on the surrounding dusty envelope. We developed tools to translate models of an AGB star and its dust-driven wind from simulations with CO5BOLD into the format used by RADMC-3D. We preserved the asymmetric shape of the star by including it as a `dust species' and by using temperature data computed in CO5BOLD. Circumstellar dust is included using Mg2SiO4 opacity data with spatially dependent grain sizes. We compared images and SEDs created with RADMC-3D of a model with similar output made with a spherically symmetric star. Our CO5BOLD model features substantial and clumpy dust formation just above 3.4 au from the grid centre, and large-scale structures due to giant convection cells are visible on the stellar surface. With the properties of VLTI as a basis, we have created simple synthetic observables. Such optical interferometers should be able to detect these dust clouds. We find that it is important to include asymmetric stellar models since they even affect the SEDs. Effects on flux levels can be linked to the clumpiness of the circumstellar dust and the angle-dependent illumination resulting from temperature variations on the stellar surface causes shifts in the wavelengths of the flux maximum. The methods presented here are an important step towards producing realistic synthetic observables and testing predictions of advanced 3D RHD models. Taking the angle-dependence of SEDs as a proxy for temporal variations in unresolved data, we conclude that not all variability observed in AGB stars should be interpreted as global changes in the sense of spherical models.         _ Less","","arXiv","https://arxiv.org/abs/2407.17317","1","0","origin_of_life"
"Can Generative AI Replace Immunofluorescent Staining Processes? A Comparison Study of Synthetically Generated CellPainting Images from Brightfield","Abstract:        Cell imaging assays utilizing fluorescence stains are essential for observing sub-cellular organelles and their responses to perturbations. Immunofluorescent staining process is routinely in labs, however the recent innovations in generative AI is challenging the idea of IF staining are required. This is especially true when the availability and cost of spec_         _ More   Cell imaging assays utilizing fluorescence stains are essential for observing sub-cellular organelles and their responses to perturbations. Immunofluorescent staining process is routinely in labs, however the recent innovations in generative AI is challenging the idea of IF staining are required. This is especially true when the availability and cost of specific fluorescence dyes is a problem to some labs. Furthermore, staining process takes time and leads to inter-intra technician and hinders downstream image and data analysis, and the reusability of image data for other projects. Recent studies showed the use of generated synthetic immunofluorescence (IF) images from brightfield (BF) images using generative AI algorithms in the literature. Therefore, in this study, we benchmark and compare five models from three types of IF generation backbones, CNN, GAN, and diffusion models, using a publicly available dataset. This paper not only serves as a comparative study to determine the best-performing model but also proposes a comprehensive analysis pipeline for evaluating the efficacy of generators in IF image synthesis. We highlighted the potential of deep learning-based generators for IF image synthesis, while also discussed potential issues and future research directions. Although generative AI shows promise in simplifying cell phenotyping using only BF images with IF staining, further research and validations are needed to address the key challenges of model generalisability, batch effects, feature relevance and computational costs.         _ Less","","arXiv","https://arxiv.org/abs/2407.09507","1","1","multiple"
"Surface parameterisation and spectral synthesis of rapidly rotating stars. Vega as a testbed","Abstract:                _radius, the effective temperature, and gravity, as a function of the colatitude for rapid rotators with radiative envelopes, and a subsequent method to build the corresponding synthetic spectrum.   The structure of the star is computed using a semi-analytical approach, which is easy to implement from a computational point of view and which reproduces very ac_         _ More           Spectral synthesis is a powerful tool with which to find the fundamental parameters of stars. Models are usually restricted to single values of temperature and gravity, and assume spherical symmetry. This approximation breaks down for rapidly rotating stars.This paper presents a joint formalism to allow a computation of the stellar structure, namely, the photospheric radius, the effective temperature, and gravity, as a function of the colatitude for rapid rotators with radiative envelopes, and a subsequent method to build the corresponding synthetic spectrum.   The structure of the star is computed using a semi-analytical approach, which is easy to implement from a computational point of view and which reproduces very accurately the results of much more complex codes. Once R, T, and g are computed, the suite of code atlas and synthe, by R. Kurucz are used to synthesise spectra for a mesh of cells in which the star is divided. The appropriate limb-darkening coefficients are also computed, and the final output spectrum is built for a given inclination of the rotation axis with respect to the line of sight. All the geometrical transformations required are described in detail.   The combined formalism has been applied to Vega, a rapidly rotating star almost seen pole-on, as a testbed. The structure reproduces the results from interferometric studies and the synthetic spectrum matches the peculiar shape of the spectral lines well.   Contexts where this formalism can be applied are outlined.         _ Less","","arXiv","https://arxiv.org/abs/2406.18392","1","0","origin_of_life"
"'Minus-One' Data Prediction Generates Synthetic Census Data with Good Crosstabulation Fidelity","Abstract:                _L predicts each question's response based on the same respondent's answers to all the other questions. Draws from the resulting probability distribution become synthetic responses. Applying this methodology to the PUMS subset of Census ACS data, and with a learned L akin to multiple parallel logistic regression, we generate_         _ More           We propose to capture relevant statistical associations in a dataset of categorical survey responses by a method, here termed MODP, that 'learns' a probabilistic prediction function L. Specifically, L predicts each question's response based on the same respondent's answers to all the other questions. Draws from the resulting probability distribution become synthetic responses. Applying this methodology to the PUMS subset of Census ACS data, and with a learned L akin to multiple parallel logistic regression, we generate synthetic responses whose crosstabulations (two-point conditionals) are found to have a median accuracy of ~5% across all crosstabulation cells, with cell counts ranging over four orders of magnitude. We investigate and attempt to quantify the degree to which the privacy of the original data is protected.         _ Less","","arXiv","https://arxiv.org/abs/2406.05264","1","1","multiple"
"Federated Learning-based Collaborative Wideband Spectrum Sensing and Scheduling for UAVs in UTM Systems","Abstract:                _utilize detected 'spectrum holes'. Our overall framework consists of three main stages. Firstly, in the model training stage, we explore dataset generation in a multi-cell environment and training a machine learning (ML) model using the federated learning (FL) architecture. Unlike the existing studies on FL for wireless that presume datasets are read_         _ More           In this paper, we propose a data-driven framework for collaborative wideband spectrum sensing and scheduling for networked unmanned aerial vehicles (UAVs), which act as the secondary users (SUs) to opportunistically utilize detected 'spectrum holes'. Our overall framework consists of three main stages. Firstly, in the model training stage, we explore dataset generation in a multi-cell environment and training a machine learning (ML) model using the federated learning (FL) architecture. Unlike the existing studies on FL for wireless that presume datasets are readily available for training, we propose a novel architecture that directly integrates wireless dataset generation, which involves capturing I/Q samples from over-the-air signals in a multi-cell environment, into the FL training process. Secondly, in the collaborative spectrum inference stage, we propose a collaborative spectrum fusion strategy that is compatible with the unmanned aircraft system traffic management (UTM) ecosystem. Finally, in the spectrum scheduling stage, we leverage reinforcement learning (RL) solutions to dynamically allocate the detected spectrum holes to the secondary users. To evaluate the proposed methods, we establish a comprehensive simulation framework that generates a near-realistic synthetic dataset using MATLAB LTE toolbox by incorporating base-station~(BS) locations in a chosen area of interest, performing ray-tracing, and emulating the primary users channel usage in terms of I/Q samples. This evaluation methodology provides a flexible framework to generate large spectrum datasets that could be used for developing ML/AI-based spectrum management solutions for aerial devices.         _ Less","","arXiv","https://arxiv.org/abs/2406.01727","1","1","multiple"
"Calibration of stochastic, agent-based neuron growth models with Approximate Bayesian Computation","Abstract:                _information of single neurons with so-called morphometrics and resort to statistical distances to measure discrepancies between populations thereof. We conduct experiments on synthetic as well as experimental data. We find that ABC utilizing Sequential Monte Carlo sampling and the Wasserstein distance finds accurate posterior parameter distributions for repr_         _ More           Understanding how genetically encoded rules drive and guide complex neuronal growth processes is essential to comprehending the brain's architecture, and agent-based models (ABMs) offer a powerful simulation approach to further develop this understanding. However, accurately calibrating these models remains a challenge. Here, we present a novel application of Approximate Bayesian Computation (ABC) to address this issue. ABMs are based on parametrized stochastic rules that describe the time evolution of small components -- the so-called agents -- discretizing the system, leading to stochastic simulations that require appropriate treatment. Mathematically, the calibration defines a stochastic inverse problem. We propose to address it in a Bayesian setting using ABC. We facilitate the repeated comparison between data and simulations by quantifying the morphological information of single neurons with so-called morphometrics and resort to statistical distances to measure discrepancies between populations thereof. We conduct experiments on synthetic as well as experimental data. We find that ABC utilizing Sequential Monte Carlo sampling and the Wasserstein distance finds accurate posterior parameter distributions for representative ABMs. We further demonstrate that these ABMs capture specific features of pyramidal cells of the hippocampus (CA1). Overall, this work establishes a robust framework for calibrating agent-based neuronal growth models and opens the door for future investigations using Bayesian techniques for model building, verification, and adequacy assessment.         _ Less","","arXiv","https://arxiv.org/abs/2405.13905","1","2","synthetic_biology"
"Generating forces in confinement via polymerization","Abstract:                Understanding how to produce forces using biomolecular building blocks is essential for the development of adaptive synthetic cells and living materials. Here we ask whether a dynamic polymer system can generate deformation forces in soft compartments by pure self-assembly, motivated by the fact that biological polymer_         _ More           Understanding how to produce forces using biomolecular building blocks is essential for the development of adaptive synthetic cells and living materials. Here we ask whether a dynamic polymer system can generate deformation forces in soft compartments by pure self-assembly, motivated by the fact that biological polymer networks like the cytoskeleton can exert forces, move objects, and deform membranes by simply growing, even in the absence of molecular motors. We address this question by investigating polymer force generation by varying the release rate, the structure, and the interactions of self-assembling monomers. First, we develop a toy computational model of polymerization in a soft elastic shell that reveals the emergence of spontaneous bundling which enhances shell deformation. We then extend our model to account more explicitly for monomer binding dynamics. We find that the rate at which monomers are released into the interior of the shell is a crucial parameter for achieving deformation through polymer growth. Finally, we demonstrate that the introduction of multivalent particles that can join polymers can either improve or impede polymer performance, depending on the amount and on the structure of the multivalent particles. Our results provide guidance for the experimental realization of polymer systems that can perform work at the nanoscale, for example through rationally designed self-assembling proteins or nucleic acids.         _ Less","","arXiv","https://arxiv.org/abs/2405.13270","2","3","synthetic_biology"
"Segmentation of dense and multi-species bacterial colonies using models trained on synthetic microscopy images","Abstract:                _techniques make collective behaviors in clinically relevant systems challenging to quantify. Here, novel experimental and image analysis techniques for high-fidelity single-cell segmentation of bacterial colonies are developed. Machine learning-based segmentation models are trained solely using_         _ More           The spread of microbial infections is governed by the self-organization of bacteria on surfaces. Limitations of live imaging techniques make collective behaviors in clinically relevant systems challenging to quantify. Here, novel experimental and image analysis techniques for high-fidelity single-cell segmentation of bacterial colonies are developed. Machine learning-based segmentation models are trained solely using synthetic microscopy images that are processed to look realistic using state-of-the-art image-to-image translation methods, requiring no biophysical modeling. Accurate single-cell segmentation is achieved for densely packed single-species colonies and multi-species colonies of common pathogenic bacteria, even under suboptimal imaging conditions and for both brightfield and confocal laser scanning microscopy. The resulting data provide quantitative insights into the self-organization of bacteria on soft surfaces. Thanks to their high adaptability and relatively simple implementation, these methods promise to greatly facilitate quantitative descriptions of bacterial infections in varied environments.         _ Less","","arXiv","https://arxiv.org/abs/2405.12407","0","1","synthetic_biology"
"Mathematical Modeling of $^{18}$F-Fluoromisonidazole ($^{18}$F-FMISO) Radiopharmaceutical Transport in Vascularized Solid Tumors","Abstract:                _this study, two tumor geometries with heterogeneous and uniform distributions of capillary networks were employed to incorporate varying degrees of microvascular density. The synthetic image of the heterogeneous and vascularized tumor was generated by simulating the angiogenesis process. The proposed multi-scale spatiotemporal model accounts for intricate ph_         _ More           $^{18}$F-Fluoromisonidazole ($^{18}$F-FMISO) is a highly promising positron emission tomography radiopharmaceutical for identifying hypoxic regions in solid tumors. This research employs spatiotemporal multi-scale mathematical modeling to explore how different levels of angiogenesis influence the transport of radiopharmaceuticals within tumors. In this study, two tumor geometries with heterogeneous and uniform distributions of capillary networks were employed to incorporate varying degrees of microvascular density. The synthetic image of the heterogeneous and vascularized tumor was generated by simulating the angiogenesis process. The proposed multi-scale spatiotemporal model accounts for intricate physiological and biochemical factors within the tumor microenvironment, such as the transvascular transport of the radiopharmaceutical agent, its movement into the interstitial space by diffusion and convection mechanisms, and ultimately its uptake by tumor cells. Results showed that both quantitative and semi-quantitative metrics of $^{18}$F-FMISO uptake differ spatially and temporally at different stages during tumor growth. The presence of a high microvascular density in uniformly vascularized tumor increases cellular uptake, as it allows for more efficient release and rapid distribution of radiopharmaceutical molecules. This results in enhanced uptake compared to the heterogeneous vascularized tumor. In both heterogeneous and uniform distribution of microvessels in tumors, the diffusion transport mechanism has a more pronounced than convection. The findings of this study shed light on the transport phenomena behind $^{18}$F-FMISO radiopharmaceutical distribution and its delivery in the tumor microenvironment, aiding oncologists in their routine decision-making processes.         _ Less","","arXiv","https://arxiv.org/abs/2405.04418","0","1","synthetic_biology"
"Scaling of phase count in multicomponent liquids","Abstract:                Mixtures with many components can segregate into coexisting phases, e.g., in biological cells and synthetic materials such as metallic glass. The interactions between components dictate what phases form in equilibrium, but quantifying this relationship has proven difficult. We derive scaling relations for the number of_         _ More           Mixtures with many components can segregate into coexisting phases, e.g., in biological cells and synthetic materials such as metallic glass. The interactions between components dictate what phases form in equilibrium, but quantifying this relationship has proven difficult. We derive scaling relations for the number of coexisting phases in multicomponent liquids with random interactions and compositions, which we verify numerically. Our results indicate that interactions only need to increase logarithmically with the number of components for the liquid to segregate into many phases. In contrast, a stability analysis of the homogeneous state predicts a power-law scaling. This discrepancy implies an enormous parameter regime where the number of coexisting phases exceeds the number of unstable modes, generalizing the nucleation and growth regime of binary mixtures to many components.         _ Less","","arXiv","https://arxiv.org/abs/2405.01138","0","1","synthetic_biology"
"SynCellFactory: Generative Data Augmentation for Cell Tracking","Abstract:        Cell tracking remains a pivotal yet challenging task in biomedical research. The full potential of deep learning for this purpose is often untapped due to the limited availability of comprehensive and varied training data sets. In this paper, we present SynCellFactory, a generative_         _ More   Cell tracking remains a pivotal yet challenging task in biomedical research. The full potential of deep learning for this purpose is often untapped due to the limited availability of comprehensive and varied training data sets. In this paper, we present SynCellFactory, a generative cell video augmentation. At the heart of SynCellFactory lies the ControlNet architecture, which has been fine-tuned to synthesize cell imagery with photorealistic accuracy in style and motion patterns. This technique enables the creation of synthetic yet realistic cell videos that mirror the complexity of authentic microscopy time-lapses. Our experiments demonstrate that SynCellFactory boosts the performance of well-established deep learning models for cell tracking, particularly when original training data is sparse.         _ Less","","arXiv","https://arxiv.org/abs/2404.16421","1","1","multiple"
"Cation exchange synthesis of AgBiS$_2$ quantum dots for highly efficient solar cells","Abstract:                _) nanocrystals have emerged as a promising eco-friendly, low-cost solar cell absorber material. Their direct synthesis often relies on the hot-injection method, requiring the application of high temperatures and vacuum for prolonged times. Here, we demonstrate an alternative synthetic approach via a cation exchange rea_         _ More           Silver bismuth sulfide (AgBiS$_2$) nanocrystals have emerged as a promising eco-friendly, low-cost solar cell absorber material. Their direct synthesis often relies on the hot-injection method, requiring the application of high temperatures and vacuum for prolonged times. Here, we demonstrate an alternative synthetic approach via a cation exchange reaction. In the first-step, bis(stearoyl)sulfide is used as an air-stable sulfur precursor for the synthesis of small, monodisperse Ag2S nanocrystals at room-temperature. In a second step, bismuth cations are incorporated into the nanocrystal lattice to form ternary AgBiS$_2$ nanocrystals, without altering their size and shape. When implemented into photovoltaic devices, AgBiS$_2$ nanocrystals obtained by cation exchange reach power conversion efficiencies of up to 7.35%, demonstrating the efficacy of the new synthetic approach for the formation of high-quality, ternary semiconducting nanocrystals.         _ Less","","arXiv","https://arxiv.org/abs/2404.14426","1","0","origin_of_life"
"Measuring Feature Dependency of Neural Networks by Collapsing Feature Dimensions in the Data Manifold","Abstract:                _how the model's performance changes on the modified test data set, with the target feature dimension removed. We test our method on deep neural network models trained on synthetic image data with known ground truth, an Alzheimer's disease prediction task using MRI and hippocampus segmentations from the OASIS-3 dataset, and a_         _ More           This paper introduces a new technique to measure the feature dependency of neural network models. The motivation is to better understand a model by querying whether it is using information from human-understandable features, e.g., anatomical shape, volume, or image texture. Our method is based on the principle that if a model is dependent on a feature, then removal of that feature should significantly harm its performance. A targeted feature is 'removed' by collapsing the dimension in the data distribution that corresponds to that feature. We perform this by moving data points along the feature dimension to a baseline feature value while staying on the data manifold, as estimated by a deep generative model. Then we observe how the model's performance changes on the modified test data set, with the target feature dimension removed. We test our method on deep neural network models trained on synthetic image data with known ground truth, an Alzheimer's disease prediction task using MRI and hippocampus segmentations from the OASIS-3 dataset, and a cell nuclei classification task using the Lizard dataset.         _ Less","","arXiv","https://arxiv.org/abs/2404.12341","1","0","origin_of_life"
"Synthesizing Realistic Data for Table Recognition","Abstract:                _established the inaugural benchmark for real-world complex tables in the Chinese financial announcement domain, using it to assess the performance of models trained on our synthetic data, thereby effectively validating our method's practicality and effectiveness. Furthermore, we applied our synthesis method to augment the FinTabNet dataset, extracted fro_         _ More           To overcome the limitations and challenges of current automatic table data annotation methods and random table data synthesis approaches, we propose a novel method for synthesizing annotation data specifically designed for table recognition. This method utilizes the structure and content of existing complex tables, facilitating the efficient creation of tables that closely replicate the authentic styles found in the target domain. By leveraging the actual structure and content of tables from Chinese financial announcements, we have developed the first extensive table annotation dataset in this domain. We used this dataset to train several recent deep learning-based end-to-end table recognition models. Additionally, we have established the inaugural benchmark for real-world complex tables in the Chinese financial announcement domain, using it to assess the performance of models trained on our synthetic data, thereby effectively validating our method's practicality and effectiveness. Furthermore, we applied our synthesis method to augment the FinTabNet dataset, extracted from English financial announcements, by increasing the proportion of tables with multiple spanning cells to introduce greater complexity. Our experiments show that models trained on this augmented dataset achieve comprehensive improvements in performance, especially in the recognition of tables with multiple spanning cells.         _ Less","","arXiv","https://arxiv.org/abs/2404.11100","1","1","multiple"
"Selecting active matter according to motility in an acoustofluidic setup: Self-propelled particles and sperm cells","Abstract:                Active systems -- including sperm cells, living organisms like bacteria, fish, birds, or active soft matter systems like synthetic ''microswimmers'' -- are characterized by motility, i.e., the ability to propel using their own ''engine''. Motility is the key feature that distinguishes ac_         _ More           Active systems -- including sperm cells, living organisms like bacteria, fish, birds, or active soft matter systems like synthetic ''microswimmers'' -- are characterized by motility, i.e., the ability to propel using their own ''engine''. Motility is the key feature that distinguishes active systems from passive or externally driven systems. In a large ensemble, motility of individual species can vary in a wide range. Selecting active species according to their motility represents an exciting and challenging problem. We propose a new method for selecting active species based on their motility using an acoustofluidic setup where highly motile species escape from the acoustic trap. This is demonstrated in simulations and in experiments with self-propelled Janus particles and human sperm. The immediate application of this method is selecting highly motile sperm for medically assisted reproduction (MAR). Due to the tunable acoustic trap, the proposed method is more flexible than the existing passive microfluidic methods. The proposed selection method based on motility can also be applied to other active systems that require selecting highly motile species or removing immotile species.         _ Less","","arXiv","https://arxiv.org/abs/2404.05422","0","1","synthetic_biology"
"Waveform Design for Joint Communication and SAR Imaging Under Random Signaling","Abstract:                Conventional synthetic aperture radar (SAR) imaging systems typically employ deterministic signal designs, which lack the capability to convey communication information and are thus not suitable for integrated sensing and communication (ISAC) scenarios. In this letter, we propose a joint communication and SAR imaging (JCASAR) system based on orthogonal frequ_         _ More           Conventional synthetic aperture radar (SAR) imaging systems typically employ deterministic signal designs, which lack the capability to convey communication information and are thus not suitable for integrated sensing and communication (ISAC) scenarios. In this letter, we propose a joint communication and SAR imaging (JCASAR) system based on orthogonal frequency-division multiplexing (OFDM) signal with cyclic prefix (CP), which is capable of reconstructing the target profile while serving a communication user. In contrast to traditional matched filters, we propose a least squares (LS) estimator for range profiling. Then the SAR image is obtained followed by range cell migration correction (RCMC) and azimuth processing. By minimizing the mean squared error (MSE) of the proposed LS estimator, we investigate the optimal waveform design for SAR imaging, and JCASAR under random signaling, where power allocation strategies are conceived for Gaussian-distributed ISAC signals, in an effort to strike a flexible performance tradeoff between the communication and SAR imaging tasks. Numerical results are provided to validate the effectiveness of the proposed ISAC waveform design for JCASAR systems.         _ Less","","arXiv","https://arxiv.org/abs/2403.17627","1","0","origin_of_life"
"Debiased Projected Two-Sample Comparisonscfor Single-Cell Expression Data","Abstract:                We study several variants of the high-dimensional mean inference problem motivated by modern single-cell genomics data. By taking advantage of low-dimensional and localized signal structures commonly seen in such data, our proposed methods not only have the usual frequentist validity but also provide useful information on the potential locations of the signa_         _ More           We study several variants of the high-dimensional mean inference problem motivated by modern single-cell genomics data. By taking advantage of low-dimensional and localized signal structures commonly seen in such data, our proposed methods not only have the usual frequentist validity but also provide useful information on the potential locations of the signal if the null hypothesis is rejected. Our method adaptively projects the high-dimensional vector onto a low-dimensional space, followed by a debiasing step using the semiparametric double-machine learning framework. Our analysis shows that debiasing is unnecessary under the global null, but necessary under a ``projected null'' that is of scientific interest. We also propose an ``anchored projection'' to maximize the power while avoiding the degeneracy issue under the null. Experiments on synthetic data and a real single-cell sequencing dataset demonstrate the effectiveness and interpretability of our methods.         _ Less","","arXiv","https://arxiv.org/abs/2403.05679","1","0","origin_of_life"
"Learning Cyclic Causal Models from Incomplete Data","Abstract:                _maximizing the expected log-likelihood of the visible part of the data in each training step, following the principles of the expectation-maximization (EM) framework. Through synthetic experiments and real-world single-cell perturbation data, we demonstrate improved performance when compared to using state-of-the-art i_         _ More           Causal learning is a fundamental problem in statistics and science, offering insights into predicting the effects of unseen treatments on a system. Despite recent advances in this topic, most existing causal discovery algorithms operate under two key assumptions: (i) the underlying graph is acyclic, and (ii) the available data is complete. These assumptions can be problematic as many real-world systems contain feedback loops (e.g., biological systems), and practical scenarios frequently involve missing data. In this work, we propose a novel framework, named MissNODAGS, for learning cyclic causal graphs from partially missing data. Under the additive noise model, MissNODAGS learns the causal graph by alternating between imputing the missing data and maximizing the expected log-likelihood of the visible part of the data in each training step, following the principles of the expectation-maximization (EM) framework. Through synthetic experiments and real-world single-cell perturbation data, we demonstrate improved performance when compared to using state-of-the-art imputation techniques followed by causal learning on partially missing interventional data.         _ Less","","arXiv","https://arxiv.org/abs/2402.15625","0","1","synthetic_biology"
"BioNeRF: Biologically Plausible Neural Radiance Fields for View Synthesis","Abstract:                _into a memory-like structure, improving the storing capacity and extracting more intrinsic and correlated information. BioNeRF also mimics a behavior observed in pyramidal cells concerning contextual information, in which the memory is provided as the context and combined with the inputs of two subsequent neural models, one responsible for producing the volu_         _ More           This paper presents BioNeRF, a biologically plausible architecture that models scenes in a 3D representation and synthesizes new views through radiance fields. Since NeRF relies on the network weights to store the scene's 3-dimensional representation, BioNeRF implements a cognitive-inspired mechanism that fuses inputs from multiple sources into a memory-like structure, improving the storing capacity and extracting more intrinsic and correlated information. BioNeRF also mimics a behavior observed in pyramidal cells concerning contextual information, in which the memory is provided as the context and combined with the inputs of two subsequent neural models, one responsible for producing the volumetric densities and the other the colors used to render the scene. Experimental results show that BioNeRF outperforms state-of-the-art results concerning a quality measure that encodes human perception in two datasets: real-world images and synthetic data.         _ Less","","arXiv","https://arxiv.org/abs/2402.07310","1","0","origin_of_life"
"A shape-driven reentrant jamming transition in confluent monolayers of synthetic cell-mimics","Abstract:                Many critical biological processes, like wound healing, require confluent cell monolayers/bulk tissues to transition from a jammed solid-like to a fluid-like state. Although numerical studies anticipate changes in the_         _ More           Many critical biological processes, like wound healing, require confluent cell monolayers/bulk tissues to transition from a jammed solid-like to a fluid-like state. Although numerical studies anticipate changes in the cell shape alone can lead to unjamming, experimental support for this prediction is not definitive because, in living systems, fluidization due to density changes cannot be ruled out. Additionally, a cell's ability to modulate its motility only compounds difficulties since even in assemblies of rigid active particles, changing the nature of self-propulsion has non-trivial effects on the dynamics. Here, we design and assemble a monolayer of synthetic cell-mimics and examine their collective behaviour. By systematically increasing the persistence time of self-propulsion, we discovered a cell shape-driven, density-independent, re-entrant jamming transition. Notably, we observed cell shape and shape variability were mutually constrained in the confluent limit and followed the same universal scaling as that observed in confluent epithelia. Dynamical heterogeneities, however, did not conform to this scaling, with the fast cells showing suppressed shape variability, which our simulations revealed is due to a transient confinement effect of these cells by their slower neighbors. Our experiments unequivocally establish a morphodynamic link, demonstrating that geometric constraints alone can dictate epithelial jamming/unjamming.         _ Less","","arXiv","https://arxiv.org/abs/2401.13437","0","1","synthetic_biology"
"Learning Dynamics from Multicellular Graphs with Deep Neural Networks","Abstract:                _is a dynamic process that is critical in the development and diseases, including embryo development, organ formation, tumor invasion, and others. Being able to infer collective cell migratory dynamics from their static configuration is valuable for both understanding and predicting these complex processes. However, the identification of structural features t_         _ More           Multicellular self-assembly into functional structures is a dynamic process that is critical in the development and diseases, including embryo development, organ formation, tumor invasion, and others. Being able to infer collective cell migratory dynamics from their static configuration is valuable for both understanding and predicting these complex processes. However, the identification of structural features that can indicate multicellular motion has been difficult, and existing metrics largely rely on physical instincts. Here we show that using a graph neural network (GNN), the motion of multicellular collectives can be inferred from a static snapshot of cell positions, in both experimental and synthetic datasets.         _ Less","","arXiv","https://arxiv.org/abs/2401.12196","1","1","multiple"
"Limited Feedback on Measurements: Sharing a Codebook or a Generative Model?","Abstract:                _data-aided solutions have been shown to achieve higher performance, enabled by the adaptivity of the feedback scheme to the propagation environment of the base station (BS) cell. In particular, a versatile limited feedback scheme utilizing Gaussian mixture models (GMMs) was recently introduced. The scheme supports multi-user communications, exhibits low com_         _ More           Discrete Fourier transform (DFT) codebook-based solutions are well-established for limited feedback schemes in frequency division duplex (FDD) systems. In recent years, data-aided solutions have been shown to achieve higher performance, enabled by the adaptivity of the feedback scheme to the propagation environment of the base station (BS) cell. In particular, a versatile limited feedback scheme utilizing Gaussian mixture models (GMMs) was recently introduced. The scheme supports multi-user communications, exhibits low complexity, supports parallelization, and offers significant flexibility concerning various system parameters. Conceptually, a GMM captures environment knowledge and is subsequently transferred to the mobile terminals (MTs) for online inference of feedback information. Afterward, the BS designs precoders using either directional information or a generative modeling-based approach. A major shortcoming of recent works is that the assessed system performance is only evaluated through synthetic simulation data that is generally unable to fully characterize the features of real-world environments. It raises the question of how the GMM-based feedback scheme performs on real-world measurement data, especially compared to the well-established DFT-based solution. Our experiments reveal that the GMM-based feedback scheme tremendously improves the system performance measured in terms of sum-rate, allowing to deploy systems with fewer pilots or feedback bits.         _ Less","","arXiv","https://arxiv.org/abs/2401.01721","1","0","origin_of_life"
"Geo2SigMap: High-Fidelity RF Signal Mapping Using Geographic Databases","Abstract:                _increased computational complexity. Recently, machine learning (ML) has emerged as a data-driven method for modeling RF signal propagation, which leverages models trained on synthetic datasets to perform RF signal mapping in 'unseen' areas.   In this paper, we present Geo2SigMap, an ML-based framework for efficient and high-fidelity RF signal mapping_         _ More           Radio frequency (RF) signal mapping, which is the process of analyzing and predicting the RF signal strength and distribution across specific areas, is crucial for cellular network planning and deployment. Traditional approaches to RF signal mapping rely on statistical models constructed based on measurement data, which offer low complexity but often lack accuracy, or ray tracing tools, which provide enhanced precision for the target area but suffer from increased computational complexity. Recently, machine learning (ML) has emerged as a data-driven method for modeling RF signal propagation, which leverages models trained on synthetic datasets to perform RF signal mapping in 'unseen' areas.   In this paper, we present Geo2SigMap, an ML-based framework for efficient and high-fidelity RF signal mapping using geographic databases. First, we develop an automated framework that seamlessly integrates three open-source tools: OpenStreetMap (geographic databases), Blender (computer graphics), and Sionna (ray tracing), enabling the efficient generation of large-scale 3D building maps and ray tracing models. Second, we propose a cascaded U-Net model, which is pre-trained on synthetic datasets and employed to generate detailed RF signal maps, leveraging environmental information and sparse measurement data. Finally, we evaluate the performance of Geo2SigMap via a real-world measurement campaign, where three types of user equipment (UE) collect over 45,000 data points related to cellular information from six LTE cells operating in the citizens broadband radio service (CBRS) band. Our results show that Geo2SigMap achieves an average root-mean-square-error (RMSE) of 6.04 dB for predicting the reference signal received power (RSRP) at the UE, representing an average RMSE improvement of 3.59 dB compared to existing methods.         _ Less","","arXiv","https://arxiv.org/abs/2312.14303","1","0","origin_of_life"
"Model-based Deep Learning for Beam Prediction based on a Channel Chart","Abstract:                _be seen as low-dimensional compressed versions of channel state information that can be used for a wide variety of applications, including beam prediction. In non-standalone or cell-free systems, chart locations computed at a given base station can be transmitted to several other base stations (possibly operating at different frequency bands) for them to pre_         _ More           Channel charting builds a map of the radio environment in an unsupervised way. The obtained chart locations can be seen as low-dimensional compressed versions of channel state information that can be used for a wide variety of applications, including beam prediction. In non-standalone or cell-free systems, chart locations computed at a given base station can be transmitted to several other base stations (possibly operating at different frequency bands) for them to predict which beams to use. This potentially yields a dramatic reduction of the overhead due to channel estimation or beam management, since only the base station performing charting requires channel state information, the others directly predicting the beam from the chart location. In this paper, advanced model-based neural network architectures are proposed for both channel charting and beam prediction. The proposed methods are assessed on realistic synthetic channels, yielding promising results.         _ Less","","arXiv","https://arxiv.org/abs/2312.02239","1","0","origin_of_life"
"Extragalactic Magnetism with SOFIA (SALSA Legacy Program). VII. A Tomographic View of Far-infrared and Radio Polarimetric Observations through MHD Simulations of Galaxies","Abstract:                _(FIR) polarization and polarimetric observations are the best methods to measure galactic scale properties of magnetic fields in galaxies beyond the Milky Way. We use synthetic polarimetric observations of a simulated galaxy to identify and quantify the regions, scales, and interstellar medium (ISM) phases probed at FIR and radio wavelengths. Our studied sui_         _ More           The structure of magnetic fields in galaxies remains poorly constrained, despite the importance of magnetism in the evolution of galaxies. Radio synchrotron and far-infrared (FIR) polarization and polarimetric observations are the best methods to measure galactic scale properties of magnetic fields in galaxies beyond the Milky Way. We use synthetic polarimetric observations of a simulated galaxy to identify and quantify the regions, scales, and interstellar medium (ISM) phases probed at FIR and radio wavelengths. Our studied suite of magnetohydrodynamical cosmological zoom-in simulations features high-resolutions (10 pc full-cell size) and multiple magnetization models. Our synthetic observations have a striking resemblance to those of observed galaxies. We find that the total and polarized radio emission extends to approximately double the altitude above the galactic disk (half-intensity disk thickness of $h_\\text{I radio} \\sim h_\\text{PI radio} = 0.23 \\pm 0.03$ kpc) relative to the total FIR and polarized emission that are concentrated in the disk midplane ($h_\\text{I FIR} \\sim h_\\text{PI FIR} = 0.11 \\pm 0.01$ kpc). Radio emission traces magnetic fields at scales of $\\gtrsim 300$ pc, whereas FIR emission probes magnetic fields at the smallest scales of our simulations. These scales are comparable to our spatial resolution and well below the spatial resolution ($<300$ pc) of existing FIR polarimetric measurements. Finally, we confirm that synchrotron emission traces a combination of the warm neutral and cold neutral gas phases, whereas FIR emission follows the densest gas in the cold neutral phase in the simulation. These results are independent of the ISM magnetic field strength. The complementarity we measure between radio and FIR wavelengths motivates future multiwavelength polarimetric observations to advance our knowledge of extragalactic magnetism.         _ Less","","arXiv","https://arxiv.org/abs/2311.06356","0","1","synthetic_biology"
"Tuning ultrasmall theranostic nanoparticles for MRI contrast and radiation dose amplification","Abstract:                _. Safety, efficacy, and theranostic potential of the nanoparticles were evaluated in vitro and in vivo in a human non-small cell lung cancer model. Results: We demonstrated that increasing Bi$^{3+}$ in the nanoparticles is associated with more DNA damage and improves in vivo efficacy with a statistically significant delay in tumor growth and 33% complete reg_         _ More           Background: The introduction of magnetic resonance (MR)-guided radiation treatment planning has opened a new space for theranostic nanoparticles to reduce acute toxicity while improving local control. In this work, second-generation AGuIX nanoparticles (AGuIX-Bi) are synthesized and validated. AGuIX-Bi are shown to maintain MR positive contrast while further amplifying the radiation dose by the replacement of some Gd$^{3+}$ cations with higher Z Bi$^{3+}$. These next-generation nanoparticles are based on the AGuIX platform, which is currently being evaluated in multiple Phase II clinical trials in combination with radiotherapy. Methods: In this clinically scalable methodology, AGuIX is used as an initial chelation platform to exchange Gd$^{3+}$ for Bi$^{3+}$. AGuIX-Bi nanoparticles are synthesized with three ratios of Gd/Bi, each maintaining MR contrast while further amplifying radiation dose relative to Bi$^{3+}$. Safety, efficacy, and theranostic potential of the nanoparticles were evaluated in vitro and in vivo in a human non-small cell lung cancer model. Results: We demonstrated that increasing Bi$^{3+}$ in the nanoparticles is associated with more DNA damage and improves in vivo efficacy with a statistically significant delay in tumor growth and 33% complete regression for the largest Bi/Gd ratio tested. The addition of Bi$^{3+}$ by our synthetic method leads to nanoparticles that present slightly altered pharmacokinetics and lengthening of the period of high tumor accumulation with no observed evidence of toxicity. Conclusions: We confirmed the safety and enhanced efficacy of AGuIX-Bi with radiation therapy at the selected ratio of 30Gd/70Bi. These results provide crucial evidence towards patient translation.         _ Less","","arXiv","https://arxiv.org/abs/2310.01179","0","1","synthetic_biology"
"Treatment-aware Diffusion Probabilistic Model for Longitudinal MRI Generation and Diffuse Glioma Growth Prediction","Abstract:                Diffuse gliomas are malignant brain tumors that grow widespread through the brain. The complex interactions between neoplastic cells and normal tissue, as well as the treatment-induced changes often encountered, make glioma tumor growth modeling challenging. In this paper, we present a novel end-to-end network capable of generating future tumor masks and rea_         _ More           Diffuse gliomas are malignant brain tumors that grow widespread through the brain. The complex interactions between neoplastic cells and normal tissue, as well as the treatment-induced changes often encountered, make glioma tumor growth modeling challenging. In this paper, we present a novel end-to-end network capable of generating future tumor masks and realistic MRIs of how the tumor will look at any future time points for different treatment plans. Our approach is based on cutting-edge diffusion probabilistic models and deep-segmentation neural networks. We included sequential multi-parametric magnetic resonance images (MRI) and treatment information as conditioning inputs to guide the generative diffusion process. This allows for tumor growth estimates at any given time point. We trained the model using real-world postoperative longitudinal MRI data with glioma tumor growth trajectories represented as tumor segmentation maps over time. The model has demonstrated promising performance across a range of tasks, including the generation of high-quality synthetic MRIs with tumor masks, time-series tumor segmentations, and uncertainty estimates. Combined with the treatment-aware generated MRIs, the tumor growth predictions with uncertainty estimates can provide useful information for clinical decision-making.         _ Less","","arXiv","https://arxiv.org/abs/2309.05406","1","1","multiple"
"Causality-oriented robustness: exploiting general additive interventions","Abstract:                _We extend our approach to the semi-supervised domain adaptation setting to further improve prediction performance. Finally, we empirically validate our methods on synthetic simulations and on single-cell data.         _ More           Since distribution shifts are common in real-world applications, there is a pressing need for developing prediction models that are robust against such shifts. Existing frameworks, such as empirical risk minimization or distributionally robust optimization, either lack generalizability for unseen distributions or rely on postulated distance measures. Alternatively, causality offers a data-driven and structural perspective to robust predictions. However, the assumptions necessary for causal inference can be overly stringent, and the robustness offered by such causal models often lacks flexibility. In this paper, we focus on causality-oriented robustness and propose Distributional Robustness via Invariant Gradients (DRIG), a method that exploits general additive interventions in training data for robust predictions against unseen interventions, and naturally interpolates between in-distribution prediction and causality. In a linear setting, we prove that DRIG yields predictions that are robust among a data-dependent class of distribution shifts. Furthermore, we show that our framework includes anchor regression (Rothenh_usler et al.\\ 2021) as a special case, and that it yields prediction models that protect against more diverse perturbations. We extend our approach to the semi-supervised domain adaptation setting to further improve prediction performance. Finally, we empirically validate our methods on synthetic simulations and on single-cell data.         _ Less","","arXiv","https://arxiv.org/abs/2307.10299","0","1","synthetic_biology"
"A Darcy-Cahn-Hilliard model of multiphase fluid-driven fracture","Abstract:                _coupled with damage is developed to describe multiphase-flow and fluid-driven fracturing in porous media. The model is motivated by recent experimental observations in Hele-Shaw cells of the fluid-driven fracturing of a synthetic porous medium with tunable fracture resistance. The model is derived from continuum thermo_         _ More           A Darcy-Cahn-Hilliard model coupled with damage is developed to describe multiphase-flow and fluid-driven fracturing in porous media. The model is motivated by recent experimental observations in Hele-Shaw cells of the fluid-driven fracturing of a synthetic porous medium with tunable fracture resistance. The model is derived from continuum thermodynamics and employs several simplifying assumptions, such as linear poroelasticity and viscous-dominated flow. Two distinct phase fields are used to regularize the interface between an invading and a defending fluid, as well as the ensuing damage. The damage model is a cohesive version of a phase-field model for fracture, in which model parameters allow for control over both nucleation and crack growth. Model-based simulations with finite elements are then performed to calibrate the model against recent experimental results. In particular, an experimentally-inferred phase diagram differentiating two flow regimes of porous invasion and fracturing is recovered. Finally, the model is employed to explore the parameter space beyond experimental capabilities, giving rise to the construction of an expanded phase diagram that suggests a new flow regime.         _ Less","","arXiv","https://arxiv.org/abs/2306.16930","0","1","synthetic_biology"
"Microbial Corrosion Prevention by Citrobacter sp. Biofilms","Abstract:                Microbiologically influenced corrosion (MIC) compromises the integrity of many technologically relevant metals. Protective coatings based on synthetic materials pose potential environmental impacts. Here, we report a MIC resistant coating based on a biofilm matrix of Citrobacter sp. strain MIC21 on underlying copper (Cu) surfaces. Three identical corrosion_         _ More           Microbiologically influenced corrosion (MIC) compromises the integrity of many technologically relevant metals. Protective coatings based on synthetic materials pose potential environmental impacts. Here, we report a MIC resistant coating based on a biofilm matrix of Citrobacter sp. strain MIC21 on underlying copper (Cu) surfaces. Three identical corrosion cells varying in the type of working electrode (annealed Cu, 29.5% coldworked, and 56.2% coldworked Cu) were used. Graphite plate and Ag/AgCl served as counter and reference electrodes, respectively. The working electrolyte was based on lactate-C media along with an inocula consisting of Oleidesulfovibrio alaskensis strain G20 and Citrobacter sp. strain MIC21. Passivating effect of the co-cultured biofilm matrix was observed in the form of an ennoblement effect. Tests based on sequencing, microscopy, and spectroscopy revealed the formation of a compact biofilm matrix dominated by strain MIC21 cells, exopolymers, and insoluble precipitates. This matrix displayed elastic modulus (a measure of rigidity) as high as 0.8 Gpa and increased corrosion resistance by ~10-fold. Interestingly, strain MIC21 has the capacity to inhibit the undesirable growth of aggressive strain G20. Additional corrosion tests also substantiated the passivation effects of strain MIC21. We provide mechanistic insight into the underlying reasons responsible for corrosion prevention behavior of the biofilm matrix.         _ Less","","arXiv","https://arxiv.org/abs/2304.13862","1","1","multiple"
"MA$_2$Z$_4$ Family Heteorstructures: Promises and Prospects","Abstract:                _metal nitride (Mo-N) inner sub-monolayer sandwiched by two silicon nitride (Si-N) outer sub-monolayers - have motivated the computational discovery of an expansive family of synthetic MA2Z4 monolayers with no bulk (3D) material counterpart (where M = transition metals or alkaline earth metals; A = Si, Ge; and N = N, P, As). MA2Z4 monolayers exhibit interesti_         _ More           Recent experimental synthesis of ambient-stable MoSi2N4 monolayer have garnered enormous research interests. The intercalation morphology of MoSi2N4 - composed of a transition metal nitride (Mo-N) inner sub-monolayer sandwiched by two silicon nitride (Si-N) outer sub-monolayers - have motivated the computational discovery of an expansive family of synthetic MA2Z4 monolayers with no bulk (3D) material counterpart (where M = transition metals or alkaline earth metals; A = Si, Ge; and N = N, P, As). MA2Z4 monolayers exhibit interesting electronic, magnetic, optical, spintronic, valleytronic and topological properties, making them a compelling material platform for next-generation device technologies. Furthermore, heterostructure engineering enormously expands the opportunities of MA2Z4. In this review, we summarize the recent rapid progress in the computational design of MA2Z4-based heterostructures based on first-principle density functional theory (DFT) simulations - a central \\emph{work horse} widely used to understand the physics, chemistry and general design rules for specific targeted functions. We systematically classify the MA2Z4-based heterostructures based on their contact types, and review their physical properties, with a focus on their performances in electronics, optoelectronics and energy conversion applications. We review the performance and promises of MA2Z4-based heterostructures for device applications that include electrical contacts, transistors, spintronic devices, photodetectors, solar cells, and photocatalytic water splitting. This review unveils the vast device application potential of MA2Z4-based heterostructures, and paves a roadmap for the future experimental and theoretical development of MA2Z4-based functional heterostructures and devices.         _ Less","","arXiv","https://arxiv.org/abs/2304.02802","1","2","synthetic_biology"
"Evolution of Discrete Symmetries","Abstract:                _symmetries, in the sense of a symmetry that holds only in a finite domain of space, can be either the result of a self-organization process or a structural ingredient into a synthetically prepared physical system. Applying local symmetry operations to extend a given finite chain we show that the resulting one-dimensional lattice consists of a transient follo_         _ More           Symmetries are known to dictate important physical properties and can be used as a design principle in particular in wave physics, including wave structures and the resulting propagation dynamics. Local symmetries, in the sense of a symmetry that holds only in a finite domain of space, can be either the result of a self-organization process or a structural ingredient into a synthetically prepared physical system. Applying local symmetry operations to extend a given finite chain we show that the resulting one-dimensional lattice consists of a transient followed by a subsequent periodic behaviour. Due to the fact that, by construction, the implanted local symmetries strongly overlap the resulting lattice possesses a dense skeleton of such symmetries. We proof this behaviour on the basis of a class of local symmetry operations allowing us to conclude upon the 'asymptotic' properties such as the final period, decomposition of the unit-cell and the length and decomposition of the transient. As an example case, we explore the corresponding tight-binding Hamiltonians. Their energy eigenvalue spectra and eigenstates are analyzed in some detail, showing in particular the strong variability of the localization properties of the eigenstates due to the presence of a plethora of local symmetries.         _ Less","","arXiv","https://arxiv.org/abs/2303.14150","0","2","synthetic_biology"
"Inhomogeneous Galactic Chemical Evolution: Modelling Ultra-Faint Dwarf Galaxies of the Large Magellanic Cloud","Abstract:                _II, both satellites of the Large Magellanic Cloud. Our model is based on the Monte Carlo sampling of the initial mass function as star formation proceeds in different gas cells of the galaxy volume. We account for the chemical enrichment of Supernova bubbles as they spread in the interstellar medium, causing dispersion in the elemental abundances. We recreat_         _ More           Ultra-faint dwarf galaxies are among the oldest and most metal-poor galaxies in the cosmos, observed to contain no gas and a high dark matter mass fraction. Understanding the chemical abundance dispersion in such extreme environments could shed light on the very first generations of stars. We present a novel inhomogeneous chemical evolution model, {\\tt i-GEtool}, that we apply to two ultra-faint dwarf galaxies, Carina II and Reticulum II, both satellites of the Large Magellanic Cloud. Our model is based on the Monte Carlo sampling of the initial mass function as star formation proceeds in different gas cells of the galaxy volume. We account for the chemical enrichment of Supernova bubbles as they spread in the interstellar medium, causing dispersion in the elemental abundances. We recreate the abundance patterns of $_$- and odd-$\\textit{Z}$ elements, predicting two sequences in [C/Fe] and [N/Fe] at all metallicities. Our models underestimate [C/Fe] and [Ti/Fe] because of the large uncertainty in the adopted stellar nucleosynthesis yields. We discuss that the observed C and N abundances had likely been affected by internal mixing processes, which changed the initial surface abundances in the red giants. Our Supernova feedback scheme is responsible for driving galactic outflows, which quench the star formation activity at early times. We predict an average outflow mass-loading factor $\\approx 10^{3}$, which extrapolates towards very low galaxy stellar masses the trend observed at high masses. Finally, by combining our model with the MIST isochrone database, we compare our synthetic colour-magnitude diagrams to observations.         _ Less","","arXiv","https://arxiv.org/abs/2303.12530","2","1","origin_of_life"
"Multi-modal Differentiable Unsupervised Feature Selection","Abstract:                _gates that mask nuisance features and enhance the accuracy of the structure captured by the graph Laplacian. The performance of the new scheme is illustrated using synthetic and real datasets, including an extended biological application to single-cell multi-omics.         _ More           Multi-modal high throughput biological data presents a great scientific opportunity and a significant computational challenge. In multi-modal measurements, every sample is observed simultaneously by two or more sets of sensors. In such settings, many observed variables in both modalities are often nuisance and do not carry information about the phenomenon of interest. Here, we propose a multi-modal unsupervised feature selection framework: identifying informative variables based on coupled high-dimensional measurements. Our method is designed to identify features associated with two types of latent low-dimensional structures: (i) shared structures that govern the observations in both modalities and (ii) differential structures that appear in only one modality. To that end, we propose two Laplacian-based scoring operators. We incorporate the scores with differentiable gates that mask nuisance features and enhance the accuracy of the structure captured by the graph Laplacian. The performance of the new scheme is illustrated using synthetic and real datasets, including an extended biological application to single-cell multi-omics.         _ Less","","arXiv","https://arxiv.org/abs/2303.09381","1","0","origin_of_life"
"Direct Motif Extraction from High Resolution Crystalline STEM Images","Abstract:                During the last decade, automatic data analysis methods concerning different aspects of crystal analysis have been developed, e.g., unsupervised primitive unit cell extraction and automated crystal distortion and defects detection. However, an automatic, unsupervised motif extraction method is still not widely available yet. Here, we propose and demonstrate_         _ More           During the last decade, automatic data analysis methods concerning different aspects of crystal analysis have been developed, e.g., unsupervised primitive unit cell extraction and automated crystal distortion and defects detection. However, an automatic, unsupervised motif extraction method is still not widely available yet. Here, we propose and demonstrate a novel method for the automatic motif extraction in real space from crystalline images based on a variational approach involving the unit cell projection operator. Due to the non-convex nature of the resulting minimization problem, a multi-stage algorithm is used. First, we determine the primitive unit cell in form of two lattice vectors. Second, a motif image is estimated using the unit cell information. Finally, the motif is determined in terms of atom positions inside the unit cell. The method was tested on various synthetic and experimental HAADF STEM images. The results are a representation of the motif in form of an image, atomic positions, primitive unit cell vectors, and a denoised and a modeled reconstruction of the input image. The method was applied to extract the primitive cells of complex $_$-phase structures Nb$_\\text{6.4}$Co$_\\text{6.6}$ and Nb$_\\text{7}$Co$_\\text{6}$, where subtle differences between their interplanar spacings were determined.         _ Less","","arXiv","https://arxiv.org/abs/2303.07438","2","0","origin_of_life"
"Statistics of carrier-cargo complexes","Abstract:                _of cargo particles by carriers engulfing their load. While the such carrier-cargo complexes are important for many applications out of equilibrium, such as drug delivery and synthetic cell encapsulation, we uncover here the basic statistical physics in minimal hard-core-like models for particle uptake. Introducing an e_         _ More           We explore the statistics of assembling soft-matter building blocks to investigate the uptake and encapsulation of cargo particles by carriers engulfing their load. While the such carrier-cargo complexes are important for many applications out of equilibrium, such as drug delivery and synthetic cell encapsulation, we uncover here the basic statistical physics in minimal hard-core-like models for particle uptake. Introducing an exactly solvable equilibrium model in one dimension, we demonstrate that the formation of carrier-cargo complexes can be largely tuned by both the cargo concentration and the carriers' interior size. These findings are intuitively explained by interpreting the internal free space (partition function) of the cargo inside a carrier as its engulfment strength, which can be mapped to an external control parameter (chemical potential) of an additional effective particle species. Assuming a hard carrier membrane, such a mapping can be exactly applied to account for multiple cargo uptake involving various carrier or cargo species and even attractive uptake mechanisms, while soft interactions require certain approximations. We further argue that the Boltzmann occupation law identified within our approach is broken when particle uptake is governed by non-equilibrium forces. Speculating on alternative occupation laws using effective parameters, we put forward a Bose-Einstein-like phase transition associated with polydisperse carrier properties.         _ Less","","arXiv","https://arxiv.org/abs/2303.04005","1","1","multiple"
"Deep Momentum Multi-Marginal Schr_dinger Bridge","Abstract:                _we manage to handle high-dimensional multi-marginal trajectory inference tasks efficiently. Our algorithm outperforms baselines significantly, as evidenced by experiments for synthetic datasets and a real-world single-cell RNA sequence dataset. Additionally, the proposed approach can reasonably reconstruct the evoluti_         _ More           It is a crucial challenge to reconstruct population dynamics using unlabeled samples from distributions at coarse time intervals. Recent approaches such as flow-based models or Schr_dinger Bridge (SB) models have demonstrated appealing performance, yet the inferred sample trajectories either fail to account for the underlying stochasticity or are $\\underline{D}$eep $\\underline{M}$omentum Multi-Marginal $\\underline{S}$chr_dinger $\\underline{B}$ridge(DMSB), a novel computational framework that learns the smooth measure-valued spline for stochastic systems that satisfy position marginal constraints across time. By tailoring the celebrated Bregman Iteration and extending the Iteration Proportional Fitting to phase space, we manage to handle high-dimensional multi-marginal trajectory inference tasks efficiently. Our algorithm outperforms baselines significantly, as evidenced by experiments for synthetic datasets and a real-world single-cell RNA sequence dataset. Additionally, the proposed approach can reasonably reconstruct the evolution of velocity distribution, from position snapshots only, when there is a ground truth velocity that is nevertheless inaccessible.         _ Less","","arXiv","https://arxiv.org/abs/2303.01751","0","1","synthetic_biology"
"Supervised topological data analysis for MALDI mass spectrometry imaging applications","Abstract:                _especially in tumor typing and subtyping. Lung cancer is the primary cause of tumor-related deaths, where the most lethal entities are adenocarcinoma (ADC) and squamous cell carcinoma (SqCC). Distinguishing between these two common subtypes is crucial for therapy decisions and successful patient management.   Results: We propose a new algebraic topological_         _ More           Background: Matrix-assisted laser desorption/ionization mass spectrometry imaging (MALDI MSI) displays significant potential for applications in cancer research, especially in tumor typing and subtyping. Lung cancer is the primary cause of tumor-related deaths, where the most lethal entities are adenocarcinoma (ADC) and squamous cell carcinoma (SqCC). Distinguishing between these two common subtypes is crucial for therapy decisions and successful patient management.   Results: We propose a new algebraic topological framework, which obtains intrinsic information from MALDI data and transforms it to reflect topological persistence. Our framework offers two main advantages. Firstly, topological persistence aids in distinguishing the signal from noise. Secondly, it compresses the MALDI data, saving storage space and optimizes computational time for subsequent classification tasks. We present an algorithm that efficiently implements our topological framework, relying on a single tuning parameter. Afterwards, logistic regression and random forest classifiers are employed on the extracted persistence features, thereby accomplishing an automated tumor (sub-)typing process. To demonstrate the competitiveness of our proposed framework, we conduct experiments on a real-world MALDI dataset using cross-validation. Furthermore, we showcase the effectiveness of the single denoising parameter by evaluating its performance on synthetic MALDI images with varying levels of noise.   Conclusion: Our empirical experiments demonstrate that the proposed algebraic topological framework successfully captures and leverages the intrinsic spectral information from MALDI data, leading to competitive results in classifying lung cancer subtypes. Moreover, the frameworks ability to be fine-tuned for denoising highlights its versatility and potential for enhancing data analysis in MALDI applications.         _ Less","","arXiv","https://arxiv.org/abs/2302.13948","1","0","origin_of_life"
"Taxis of cargo-carrying microswimmers in traveling activity waves","Abstract:                _properties of biological active matter crucially depend on the capacity of constituting entities to perform directed motion, e.g., molecular motors transporting vesicles inside cells or bacteria searching for food. While much effort has been devoted to mimicking biological functions in synthetic systems, such as transp_         _ More           Many fascinating properties of biological active matter crucially depend on the capacity of constituting entities to perform directed motion, e.g., molecular motors transporting vesicles inside cells or bacteria searching for food. While much effort has been devoted to mimicking biological functions in synthetic systems, such as transporting a cargo to a targeted zone, theoretical studies have primarily focused on single active particles subject to various spatial and temporal stimuli. Here we study the behavior of a self-propelled particle carrying a passive cargo in a travelling activity wave and show that this active-passive dimer displays a rich, emergent tactic behavior. For cargoes with low mobility, the dimer always drifts in the direction of the wave propagation. For highly-mobile cargoes, instead, the dimer can also drift against the traveling wave. The transition between these two tactic behaviors is controlled by the ratio between the frictions of the cargo and the microswimmer. In slow activity waves the dimer can perform an active surfing of the wave maxima, with an average drift velocity equal to the wave speed. These analytical predictions, which we confirm by numerical simulations, might be useful for the future efficient design of bio-hybrid microswimmers.         _ Less","","arXiv","https://arxiv.org/abs/2302.08954","1","1","multiple"
"In-the-wild Material Appearance Editing using Perceptual Attributes","Abstract:                _and illumination are not controlled, and inverse rendering is not required. We rely on generative models and devise a novel architecture with Selective Transfer Unit (STU) cells that allow to preserve the high-frequency details from the input image in the edited one. To train our framework we leverage a dataset with pairs of_         _ More           Intuitively editing the appearance of materials from a single image is a challenging task given the complexity of the interactions between light and matter, and the ambivalence of human perception. This problem has been traditionally addressed by estimating additional factors of the scene like geometry or illumination, thus solving an inverse rendering problem and subduing the final quality of the results to the quality of these estimations. We present a single-image appearance editing framework that allows us to intuitively modify the material appearance of an object by increasing or decreasing high-level perceptual attributes describing such appearance (e.g., glossy or metallic). Our framework takes as input an in-the-wild image of a single object, where geometry, material, and illumination are not controlled, and inverse rendering is not required. We rely on generative models and devise a novel architecture with Selective Transfer Unit (STU) cells that allow to preserve the high-frequency details from the input image in the edited one. To train our framework we leverage a dataset with pairs of synthetic images rendered with physically-based algorithms, and the corresponding crowd-sourced ratings of high-level perceptual attributes. We show that our material editing framework outperforms the state of the art, and showcase its applicability on synthetic images, in-the-wild real-world photographs, and video sequences.         _ Less","","arXiv","https://arxiv.org/abs/2302.03619","1","1","multiple"
"Dynamic shapes of floppy vesicles enclosing active Brownian particles with membrane adhesion","Abstract:                Recent advances in micro- and nano-technologies allow the construction of complex active systems from biological and synthetic materials. An interesting example is active vesicles, which consist of a membrane enclosing self-propelled particles, and exhibit several features resembling biological cells. We investigate nu_         _ More           Recent advances in micro- and nano-technologies allow the construction of complex active systems from biological and synthetic materials. An interesting example is active vesicles, which consist of a membrane enclosing self-propelled particles, and exhibit several features resembling biological cells. We investigate numerically the behavior of active vesicles, where the enclosed self-propelled particles can adhere to the membrane. A vesicle is represented by a dynamically triangulated membrane, while the adhesive active particles are modelled as active Brownian particles (ABPs) that interact with the membrane via the Lennard-Jones potential. Phase diagrams of dynamic vesicle shapes as a function of ABP activity and particle volume fraction inside the vesicle are constructed for different strengths of adhesive interactions. At low ABP activity, adhesive interactions dominate over the propulsion forces, such that the vesicle attains near static configurations, with protrusions of membrane-wrapped ABPs having ring-like and sheet-like structures. At moderate particle densities and strong enough activities, active vesicles show dynamic highly-branched tethers filled with string-like arrangements of ABPs, which do not occur in the absence of particle adhesion to the membrane. At large volume fractions of ABPs, vesicles fluctuate for moderate particle activities, and elongate and finally split into two vesicles for large ABP propulsion strengths. We also analyze membrane tension, active fluctuations, and ABP characteristics (e.g., mobility, clustering), and compare them to the case of active vesicles with non-adhesive ABPs. The adhesion of ABPs to the membrane significantly alters the behavior of active vesicles, and provides an additional parameter for controlling their behavior.         _ Less","","arXiv","https://arxiv.org/abs/2301.07952","1","1","multiple"
"A light- and heat-seeking vine-inspired robot with material-level responsiveness","Abstract:                The fields of soft and bio-inspired robotics promise to imbue synthetic systems with capabilities found in the natural world. However, many of these biological capabilities are yet to be realized. For example, vines in nature direct growth via localized responses embedded in the cells of vine body, allowing an organism_         _ More           The fields of soft and bio-inspired robotics promise to imbue synthetic systems with capabilities found in the natural world. However, many of these biological capabilities are yet to be realized. For example, vines in nature direct growth via localized responses embedded in the cells of vine body, allowing an organism without a central brain to successfully search for resources (e.g., light). Yet to date, vine-inspired robots have yet to show such localized embedded responsiveness. Here we present a vine-inspired robotic device with material-level responses embedded in its skin and capable of growing and steering toward either a light or heat stimulus. We present basic modeling of the concept, design details, and experimental results showing its behavior in response to infrared (IR) and visible light. Our simple design concept advances the capabilities of bio-inspired robots and lays the foundation for future growing robots that are capable of seeking light or heat, yet are extremely simple and low-cost. Potential applications include solar tracking, and in the future, firefighting smoldering fires. We envision using similar robots to find hot spots in hard-to-access environments, allowing us to put out potentially long-burning fires faster.         _ Less","","arXiv","https://arxiv.org/abs/2301.07362","0","1","synthetic_biology"
"NODAGS-Flow: Nonlinear Cyclic Causal Structure Learning","Abstract:                _data, called NODAGS-Flow. We perform inference via direct likelihood optimization, employing techniques from residual normalizing flows for likelihood estimation. Through synthetic experiments and an application to single-cell high-content perturbation screening data, we show significant performance improvements with o_         _ More           Learning causal relationships between variables is a well-studied problem in statistics, with many important applications in science. However, modeling real-world systems remain challenging, as most existing algorithms assume that the underlying causal graph is acyclic. While this is a convenient framework for developing theoretical developments about causal reasoning and inference, the underlying modeling assumption is likely to be violated in real systems, because feedback loops are common (e.g., in biological systems). Although a few methods search for cyclic causal models, they usually rely on some form of linearity, which is also limiting, or lack a clear underlying probabilistic model. In this work, we propose a novel framework for learning nonlinear cyclic causal graphical models from interventional data, called NODAGS-Flow. We perform inference via direct likelihood optimization, employing techniques from residual normalizing flows for likelihood estimation. Through synthetic experiments and an application to single-cell high-content perturbation screening data, we show significant performance improvements with our approach compared to state-of-the-art methods with respect to structure recovery and predictive performance.         _ Less","","arXiv","https://arxiv.org/abs/2301.01849","0","1","synthetic_biology"
"Cross-domain Microscopy Cell Counting by Disentangled Transfer Learning","Abstract:                Microscopy images from different imaging conditions, organs, and tissues often have numerous cells with various shapes on a range of backgrounds. As a result, designing a deep learning model to count_         _ More           Microscopy images from different imaging conditions, organs, and tissues often have numerous cells with various shapes on a range of backgrounds. As a result, designing a deep learning model to count cells in a source domain becomes precarious when transferring them to a new target domain. To address this issue, manual annotation costs are typically the norm when training deep learning-based cell counting models across different domains. In this paper, we propose a cross-domain cell counting approach that requires only weak human annotation efforts. Initially, we implement a cell counting network that disentangles domain-specific knowledge from domain-agnostic knowledge in cell images, where they pertain to the creation of domain style images and cell density maps, respectively. We then devise an image synthesis technique capable of generating massive synthetic images founded on a few target-domain images that have been labeled. Finally, we use a public dataset consisting of synthetic cells as the source domain, where no manual annotation cost is present, to train our cell counting network; subsequently, we transfer only the domain-agnostic knowledge to a new target domain of real cell images. By progressively refining the trained model using synthesized target-domain images and several real annotated ones, our proposed cross-domain cell counting method achieves good performance compared to state-of-the-art techniques that rely on fully annotated training images in the target domain. We evaluated the efficacy of our cross-domain approach on two target domain datasets of actual microscopy cells, demonstrating the feasibility of requiring annotations on only a few images in a new domain.         _ Less","","arXiv","https://arxiv.org/abs/2211.14638","0","1","synthetic_biology"
"A Magnetically and Electrically Powered Hybrid Micromotor in Conductive Solutions: Synergistic Propulsion Effects and Label-Free Cargo Transport and Sensing","Abstract:                Electrically powered micro- and nanomotors are promising tools for in-vitro single-cell analysis. In particular, single_         _ More           Electrically powered micro- and nanomotors are promising tools for in-vitro single-cell analysis. In particular, single cells can be trapped, transported and electroporated by a Janus particle (JP) using an externally applied electric field. However, while dielectrophoretic (DEP)-based cargo manipulation can be achieved at high-solution conductivity, electrical propulsion of these micromotors becomes ineffective at solution conductivities exceeding 0.3mS/cm. Here, we successfully extended JP cargo manipulation and transport capabilities to conductive near-physiological (<6mS/cm) solutions by combining magnetic field-based micromotor propulsion and navigation with DEP-based manipulation of various synthetic and biological cargos. Combination of a rotating magnetic field and electric field resulted in enhanced micromotor mobility and steering control through tuning of the electric field frequency. conditions are necessary. In addition, we demonstrated the micromotors ability of identifying apoptotic cell among viable and necrotic cells based their dielectrophoretic difference, thus, enabling to analyze the apoptotic status in the single cell samples for drug discovery, cell therapeutics and immunotherapy. We also demonstrated the ability to trap and transport live cells towards regions containing doxorubicin-loaded liposomes. This hybrid micromotor approach for label-free trapping, transporting and sensing of selected cells within conductive solutions, opens new opportunities in drug delivery and single cell analysis, where close-to-physiological media         _ Less","","arXiv","https://arxiv.org/abs/2211.14055","0","1","synthetic_biology"
"Novel transfer learning schemes based on Siamese networks and synthetic data","Abstract:                _In this contribution, we address an important application area in the domain of biotechnology, the automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation, where data characteristics are very dissimilar to existing domains and trained deep networks cannot easily be adapted by classical transfer learning. We propose a novel tra_         _ More           Transfer learning schemes based on deep networks which have been trained on huge image corpora offer state-of-the-art technologies in computer vision. Here, supervised and semi-supervised approaches constitute efficient technologies which work well with comparably small data sets. Yet, such applications are currently restricted to application domains where suitable deepnetwork models are readily available. In this contribution, we address an important application area in the domain of biotechnology, the automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation, where data characteristics are very dissimilar to existing domains and trained deep networks cannot easily be adapted by classical transfer learning. We propose a novel transfer learning scheme which expands a recently introduced Twin-VAE architecture, which is trained on realistic and synthetic data, and we modify its specialized training procedure to the transfer learning domain. In the specific domain, often only few to no labels exist and annotations are costly. We investigate a novel transfer learning strategy, which incorporates a simultaneous retraining on natural and synthetic data using an invariant shared representation as well as suitable target variables, while it learns to handle unseen data from a different microscopy tech nology. We show the superiority of the variation of our Twin-VAE architecture over the state-of-the-art transfer learning methodology in image processing as well as classical image processing technologies, which persists, even with strongly shortened training times and leads to satisfactory results in this domain. The source code is available at https://github.com/dstallmann/transfer_learning_twinvae, works cross-platform, is open-source and free (MIT licensed) software. We make the data sets available at https://pub.uni-bielefeld.de/record/2960030.         _ Less","","arXiv","https://arxiv.org/abs/2211.11308","0","1","synthetic_biology"
"Data-Driven Occupancy Grid Mapping using Synthetic and Real-World Data","Abstract:                _occupancy grid maps (OGMs) from lidar measurements. Our approach extends previous work such that the estimated environment representation now contains an additional layer for cells occupied by dynamic objects. Earlier solutions could only distinguish between free and occupied_         _ More           In perception tasks of automated vehicles (AVs) data-driven have often outperformed conventional approaches. This motivated us to develop a data-driven methodology to compute occupancy grid maps (OGMs) from lidar measurements. Our approach extends previous work such that the estimated environment representation now contains an additional layer for cells occupied by dynamic objects. Earlier solutions could only distinguish between free and occupied cells. The information whether an obstacle could move plays an important role for planning the behavior of an AV. We present two approaches to generating training data. One approach extends our previous work on using synthetic training data so that OGMs with the three aforementioned cell states are generated. The other approach uses manual annotations from the nuScenes dataset to create training data. We compare the performance of both models in a quantitative analysis on unseen data from the real-world dataset. Next, we analyze the ability of both approaches to cope with a domain shift, i.e. when presented with lidar measurements from a different sensor on a different vehicle. We propose using information gained from evaluation on real-world data to further close the reality gap and create better synthetic data that can be used to train occupancy grid mapping models for arbitrary sensor configurations. Code is available at https://github.com/ika-rwth-aachen/DEviLOG.         _ Less","","arXiv","https://arxiv.org/abs/2211.08278","1","0","origin_of_life"
"An unobtrusive quality supervision approach for medical image annotation","Abstract:                _data and have an automated system to unobtrusively rate their performance during this process. We examine such a system based on whole slide images (WSIs) showing lung fluid cells. We evaluate two methods the generation of_         _ More           Image annotation is one essential prior step to enable data-driven algorithms. In medical imaging, having large and reliably annotated data sets is crucial to recognize various diseases robustly. However, annotator performance varies immensely, thus impacts model training. Therefore, often multiple annotators should be employed, which is however expensive and resource-intensive. Hence, it is desirable that users should annotate unseen data and have an automated system to unobtrusively rate their performance during this process. We examine such a system based on whole slide images (WSIs) showing lung fluid cells. We evaluate two methods the generation of synthetic individual cell images: conditional Generative Adversarial Networks and Diffusion Models (DM). For qualitative and quantitative evaluation, we conduct a user study to highlight the suitability of generated cells. Users could not detect 52.12% of generated images by DM proofing the feasibility to replace the original cells with synthetic cells without being noticed.         _ Less","","arXiv","https://arxiv.org/abs/2211.06146","0","1","synthetic_biology"
"Designing magnetic properties in CrSBr through hydrostatic pressure and ligand substitution","Abstract:                _the A-type antiferromagnetic properties of the layered semiconductor CrSBr through hydrostatic pressure and ligand substitution. Hydrostatic pressure compresses the unit cell, increasing the interlayer exchange energy while lowering the N_el temperature. Ligand substitution, realized_         _ More           The ability to control magnetic properties of materials is crucial for fundamental research and underpins many information technologies. In this context, two-dimensional materials are a particularly exciting platform due to their high degree of tunability and ease of implementation into nanoscale devices. Here we report two approaches for manipulating the A-type antiferromagnetic properties of the layered semiconductor CrSBr through hydrostatic pressure and ligand substitution. Hydrostatic pressure compresses the unit cell, increasing the interlayer exchange energy while lowering the N_el temperature. Ligand substitution, realized synthetically through Cl alloying, anisotropically compresses the unit cell and suppresses the Cr-halogen covalency, reducing the magnetocrystalline anisotropy energy and decreasing the N_el temperature. A detailed structural analysis combined with first-principles calculations reveal that alterations in the magnetic properties are intricately related to changes in direct Cr-Cr exchange interactions and the Cr-anion superexchange pathways. Further, we demonstrate that Cl alloying enables chemical tuning of the interlayer coupling from antiferromagnetic to ferromagnetic, which is unique amongst known two-dimensional magnets. The magnetic tunability, combined with a high ordering temperature, chemical stability, and functional semiconducting properties, make CrSBr an ideal candidate for pre- and post-synthetic design of magnetism in two-dimensional materials.         _ Less","","arXiv","https://arxiv.org/abs/2211.02788","1","0","origin_of_life"
"CausalBench: A Large-scale Benchmark for Network Inference from Single-cell Perturbation Data","Abstract:                _methods in real-world environments is challenging due to the need for observations under both interventional and control conditions. Traditional evaluations conducted on synthetic datasets do not reflect the performance in real-world systems. To address this, we introduce CausalBench, a benchmark suite for evaluating network inference methods on real-world i_         _ More           Causal inference is a vital aspect of multiple scientific disciplines and is routinely applied to high-impact applications such as medicine. However, evaluating the performance of causal inference methods in real-world environments is challenging due to the need for observations under both interventional and control conditions. Traditional evaluations conducted on synthetic datasets do not reflect the performance in real-world systems. To address this, we introduce CausalBench, a benchmark suite for evaluating network inference methods on real-world interventional data from large-scale single-cell perturbation experiments. CausalBench incorporates biologically-motivated performance metrics, including new distribution-based interventional metrics. A systematic evaluation of state-of-the-art causal inference methods using our CausalBench suite highlights how poor scalability of current methods limits performance. Moreover, methods that use interventional information do not outperform those that only use observational data, contrary to what is observed on synthetic benchmarks. Thus, CausalBench opens new avenues in causal network inference research and provides a principled and reliable way to track progress in leveraging real-world interventional data.         _ Less","","arXiv","https://arxiv.org/abs/2210.17283","1","0","origin_of_life"
"Cosmic Ray Acceleration and Nonthermal Radiation at Accretion Shocks in the Outer Regions of Galaxy Clusters","Abstract:                _have not been confirmed, and detailed acceleration physics at such shocks has yet to be understood. In this study, we first establish through two-dimensional particle-in-cell simulations that at strong high-$_$ shocks electrons can be pre-energized via stochastic Fermi acceleration owing to the ion-Weibel instability in the shock transition region, possibly_         _ More           Cosmology models predict that external accretion shocks form in the outer region of galaxy clusters due to supersonic gas infall from filaments and voids in the cosmic web. They are characterized by high sonic and Alfv_nic Mach numbers, $M_s\\sim10-10^2$ and $M_A\\sim10^2-10^3$, and propagate into weakly magnetized plasmas of $_\\equiv P_g/P_B\\gtrsim10^2$. Although strong accretion shocks are expected to be efficient accelerators of cosmic rays (CRs), nonthermal signatures of shock-accelerated CRs around clusters have not been confirmed, and detailed acceleration physics at such shocks has yet to be understood. In this study, we first establish through two-dimensional particle-in-cell simulations that at strong high-$_$ shocks electrons can be pre-energized via stochastic Fermi acceleration owing to the ion-Weibel instability in the shock transition region, possibly followed by injection into diffusive shock acceleration. Hence, we propose that the models derived from conventional thermal leakage injection may be employed for the acceleration of electrons and ions at accretion shocks as well. Applying these analytic models to numerical shock zones identified in structure formation simulations, we estimate nonthermal radiation, such as synchrotron and inverse-Compton (IC) emission due to CR electrons, and $_^0$-decay $_$-rays due to CR protons, around simulated clusters. Our models with the injection parameter, $Q\\approx3.5-3.8$, predict synthetic synchrotron maps, which seem consistent with recent radio observations of the Coma cluster. However, the detection of nonthermal IC X-rays and $_$-rays from accretion shocks would be quite challenging. We suggest that the proposed analytic models may be adopted as generic recipes for CR production at cosmological shocks.         _ Less","","arXiv","https://arxiv.org/abs/2210.16817","1","0","origin_of_life"
"Chemotaxis of sea urchin sperm cells through deep reinforcement learning","Abstract:                _it is still a great challenge to enable microrobots to maneuver in a complex environment. Machine learning algorithms offer a tool to boost mobility and flexibility of a synthetic microswimmer, hence could help us design truly smart microrobots. In this work, we investigate how a model of sea urchin sperm_         _ More           By imitating biological microswimmers, microrobots can be designed to accomplish targeted delivery of cargos and biomedical manipulations at microscale. However, it is still a great challenge to enable microrobots to maneuver in a complex environment. Machine learning algorithms offer a tool to boost mobility and flexibility of a synthetic microswimmer, hence could help us design truly smart microrobots. In this work, we investigate how a model of sea urchin sperm cell can self-learn chemotactic motion in a chemoattractant concentration field. We employ an artificial neural network to act as a decision-making agent and facilitate the sperm cell to discover efficient maneuver strategies through a deep reinforcement learning (DRL) algorithm. Our results show that chemotactic behaviours, very similar to the realistic ones, can be achieved by the DRL utilizing only limited environmental information. In most cases, the DRL algorithm discovers more efficient strategies than the human-devised one. Furthermore, the DRL can even utilize an external disturbance to facilitate the chemotactic motion if the extra flow information is also taken into account by the artificial neural network. Our results provide insights to the chemotactic process of sea urchin sperm cells and also prepare guidance for the intelligent maneuver of microrobots.         _ Less","","arXiv","https://arxiv.org/abs/2209.07407","1","0","origin_of_life"
"Active Learning for Optimal Intervention Design in Causal Models","Abstract:                _are theoretically grounded with information-theoretic bounds and provable consistency results for linear causal models with known causal graph. We apply our approach to both synthetic data and single-_         _ More           Sequential experimental design to discover interventions that achieve a desired outcome is a key problem in various domains including science, engineering and public policy. When the space of possible interventions is large, making an exhaustive search infeasible, experimental design strategies are needed. In this context, encoding the causal relationships between the variables, and thus the effect of interventions on the system, is critical for identifying desirable interventions more efficiently. Here, we develop a causal active learning strategy to identify interventions that are optimal, as measured by the discrepancy between the post-interventional mean of the distribution and a desired target mean. The approach employs a Bayesian update for the causal model and prioritizes interventions using a carefully designed, causally informed acquisition function. This acquisition function is evaluated in closed form, allowing for fast optimization. The resulting algorithms are theoretically grounded with information-theoretic bounds and provable consistency results for linear causal models with known causal graph. We apply our approach to both synthetic data and single-cell transcriptomic data from Perturb-CITE-seq experiments to identify optimal perturbations that induce a specific cell state transition. The causally informed acquisition function generally outperforms existing criteria allowing for optimal intervention design with fewer but carefully selected samples.         _ Less","","arXiv","https://arxiv.org/abs/2209.04744","1","0","origin_of_life"
"Spatio-temporal programming of lyotropic phase transition in nanoporous microfluidic confinements","Abstract:                _transitions. Our results present a programmable physical route to material assembly, and offer a new paradigm for assembling genetic components, biological cargo, and minimal synthetic cells.         _ More           Self-assembly of simple molecules into complex phases can be driven by physical constraints, for instance, due to selective molecular uptake by nanoporous surfaces. Despite the significance of surface-mediated assembly in evolution of life, physical routes to molecular enrichment and assembly have remained overlooked. Here, using a lyotropic chromonic liquid crystal as model biological material, confined within nanoporous microfluidic environments, we study molecular assembly driven by nanoporous substrates. We demonstrate that nanoporous polydimethylsiloxane (PDMS) surfaces, due to selective permeation of water molecules, drive transition of disordered isotropic phase to ordered nematic, and higher order columnar phases under isothermal conditions. Synergistically, by tailoring the wettability, the surface-to-volume ratio, and surface topography of the confinements, we program the lyotropic phase transitions with a high degree of spatial and temporal control. Using a combination of timelapse polarized imaging, quantitative image processing, and a simple mathematical model, we analyze the phase transitions, and construct a master diagram capturing the role of surface wettability and channel geometry on programmable lyotropic phase transitions. Intrinsic PDMS nanoporosity and confinement cross-section, together with the imposed wettability regulate the rate of the N-M phase transition; whereas the microfluidic geometry and embedded topography enable phase transition at targeted locations. We harness the emergent long-range order during N-M transition to actuate elasto-advective transport of embedded micro-cargo, demonstrating particle manipulation concepts governed by tunable phase transitions. Our results present a programmable physical route to material assembly, and offer a new paradigm for assembling genetic components, biological cargo, and minimal synthetic cells.         _ Less","","arXiv","https://arxiv.org/abs/2209.02151","0","3","synthetic_biology"
"Electronic Energy Migration in Microtubules","Abstract:                The repeating arrangement of tubulin dimers confers great mechanical strength to microtubules, which are used as scaffolds for intracellular macromolecular transport in cells and exploited in biohybrid devices. The crystalline order in a microtubule, with lattice constants short enough to allow energy transfer between amino acid chromophores, is similar to_         _ More           The repeating arrangement of tubulin dimers confers great mechanical strength to microtubules, which are used as scaffolds for intracellular macromolecular transport in cells and exploited in biohybrid devices. The crystalline order in a microtubule, with lattice constants short enough to allow energy transfer between amino acid chromophores, is similar to synthetic structures designed for light harvesting. After photoexcitation, can these amino acid chromophores transfer excitation energy along the microtubule like a natural or artificial light-harvesting system? Here, we use tryptophan autofluorescence lifetimes to probe inter-tryptophan energy hopping in tubulin and microtubules. By studying how quencher concentration alters tryptophan autofluorescence lifetimes, we demonstrate that electronic energy can diffuse over 6.6 nm in microtubules. We discover that while diffusion lengths are influenced by tubulin polymerization state (free tubulin versus tubulin in the microtubule lattice), they are not significantly altered by the average number of protofilaments (13 versus 14). We also demonstrate that the presence of the anesthetics etomidate and isoflurane reduce exciton diffusion. Energy transport as explained by conventional F_rster theory (accommodating for interactions between tryptophan and tyrosine residues) does not sufficiently explain our observations. Our studies indicate that microtubules are, unexpectedly, effective light harvesters.         _ Less","","arXiv","https://arxiv.org/abs/2208.10628","0","1","synthetic_biology"
"Novel Deep Learning Approach to Derive Cytokeratin Expression and Epithelium Segmentation from DAPI","Abstract:                _image synthesis. Here, we present dapi2ck, a novel GAN-based approach to synthesize cytokeratin (CK) staining from immunofluorescent (IF) DAPI staining of nuclei in non-small cell lung cancer (NSCLC) images. We use the synthetic CK to segment epithelial regions, which, compared to expert annotations, yield equally good_         _ More           Generative Adversarial Networks (GANs) are state of the art for image synthesis. Here, we present dapi2ck, a novel GAN-based approach to synthesize cytokeratin (CK) staining from immunofluorescent (IF) DAPI staining of nuclei in non-small cell lung cancer (NSCLC) images. We use the synthetic CK to segment epithelial regions, which, compared to expert annotations, yield equally good results as segmentation on stained CK. Considering the limited number of markers in a multiplexed IF (mIF) panel, our approach allows to replace CK by another marker addressing the complexity of the tumor micro-environment (TME) to facilitate patient selection for immunotherapies. In contrast to stained CK, dapi2ck does not suffer from issues like unspecific CK staining or loss of tumoral CK expression.         _ Less","","arXiv","https://arxiv.org/abs/2208.08284","1","1","multiple"
"Orthogonal Gated Recurrent Unit with Neumann-Cayley Transformation","Abstract:                _control gradients. While Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM) architectures address the vanishing gradient problem by using a variety of gates and memory cells, they are still prone to the exploding gradient problem. In this work, we analyze the gradients in GRU and propose the usage of orthogonal matrices to prevent exploding gradien_         _ More           In recent years, using orthogonal matrices has been shown to be a promising approach in improving Recurrent Neural Networks (RNNs) with training, stability, and convergence, particularly, to control gradients. While Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM) architectures address the vanishing gradient problem by using a variety of gates and memory cells, they are still prone to the exploding gradient problem. In this work, we analyze the gradients in GRU and propose the usage of orthogonal matrices to prevent exploding gradient problems and enhance long-term memory. We study where to use orthogonal matrices and we propose a Neumann series-based Scaled Cayley transformation for training orthogonal matrices in GRU, which we call Neumann-Cayley Orthogonal GRU, or simply NC-GRU. We present detailed experiments of our model on several synthetic and real-world tasks, which show that NC-GRU significantly outperforms GRU as well as several other RNNs.         _ Less","","arXiv","https://arxiv.org/abs/2208.06496","1","0","origin_of_life"
"Seamless Iterative Semi-Supervised Correction of Imperfect Labels in Microscopy Images","Abstract:                In-vitro tests are an alternative to animal testing for the toxicity of medical devices. Detecting cells as a first step, a_         _ More           In-vitro tests are an alternative to animal testing for the toxicity of medical devices. Detecting cells as a first step, a cell expert evaluates the growth of cells according to cytotoxicity grade under the microscope. Thus, human fatigue plays a role in error making, making the use of deep learning appealing. Due to the high cost of training data annotation, an approach without manual annotation is needed. We propose Seamless Iterative Semi-Supervised correction of Imperfect labels (SISSI), a new method for training object detection models with noisy and missing annotations in a semi-supervised fashion. Our network learns from noisy labels generated with simple image processing algorithms, which are iteratively corrected during self-training. Due to the nature of missing bounding boxes in the pseudo labels, which would negatively affect the training, we propose to train on dynamically generated synthetic-like images using seamless cloning. Our method successfully provides an adaptive early learning correction technique for object detection. The combination of early learning correction that has been applied in classification and semantic segmentation before and synthetic-like image generation proves to be more effective than the usual semi-supervised approach by > 15% AP and > 20% AR across three different readers. Our code is available at https://github.com/marwankefah/SISSI.         _ Less","","arXiv","https://arxiv.org/abs/2208.03327","0","1","synthetic_biology"
"Implicit Neural Representations for Generative Modeling of Living Cell Shapes","Abstract:                Methods allowing the synthesis of realistic cell shapes could help generate training data sets to improve_         _ More           Methods allowing the synthesis of realistic cell shapes could help generate training data sets to improve cell tracking and segmentation in biomedical images. Deep generative models for cell shape synthesis require a light-weight and flexible representation of the cell shape. However, commonly used voxel-based representations are unsuitable for high-resolution shape synthesis, and polygon meshes have limitations when modeling topology changes such as cell growth or mitosis. In this work, we propose to use level sets of signed distance functions (SDFs) to represent cell shapes. We optimize a neural network as an implicit neural representation of the SDF value at any point in a 3D+time domain. The model is conditioned on a latent code, thus allowing the synthesis of new and unseen shape sequences. We validate our approach quantitatively and qualitatively on C. elegans cells that grow and divide, and lung cancer cells with growing complex filopodial protrusions. Our results show that shape descriptors of synthetic cells resemble those of real cells, and that our model is able to generate topologically plausible sequences of complex cell shapes in 3D+time.         _ Less","","arXiv","https://arxiv.org/abs/2207.06283","0","2","synthetic_biology"
"Multi-scale Attentive Image De-raining Networks via Neural Architecture Search","Abstract:                _formulates a new multi-scale attention search space with multiple flexible modules that are favorite to the image de-raining task. Under the search space, multi-scale attentive cells are built, which are further used to construct a powerful image de-raining network. The internal multiscale attentive architecture of the de-raining network is searched automati_         _ More           Multi-scale architectures and attention modules have shown effectiveness in many deep learning-based image de-raining methods. However, manually designing and integrating these two components into a neural network requires a bulk of labor and extensive expertise. In this article, a high-performance multi-scale attentive neural architecture search (MANAS) framework is technically developed for image deraining. The proposed method formulates a new multi-scale attention search space with multiple flexible modules that are favorite to the image de-raining task. Under the search space, multi-scale attentive cells are built, which are further used to construct a powerful image de-raining network. The internal multiscale attentive architecture of the de-raining network is searched automatically through a gradient-based search algorithm, which avoids the daunting procedure of the manual design to some extent. Moreover, in order to obtain a robust image de-raining model, a practical and effective multi-to-one training strategy is also presented to allow the de-raining network to get sufficient background information from multiple rainy images with the same background scene, and meanwhile, multiple loss functions including external loss, internal loss, architecture regularization loss, and model complexity loss are jointly optimized to achieve robust de-raining performance and controllable model complexity. Extensive experimental results on both synthetic and realistic rainy images, as well as the down-stream vision applications (i.e., objection detection and segmentation) consistently demonstrate the superiority of our proposed method. The code is publicly available at https://github.com/lcai-gz/MANAS.         _ Less","","arXiv","https://arxiv.org/abs/2207.00728","1","0","origin_of_life"
"Self-supervised deep visual servoing for high precision peg-in-hole insertion","Abstract:                Many industrial assembly tasks involve peg-in-hole like insertions with sub-millimeter tolerances which are challenging, even in highly calibrated robot cells. Visual servoing can be employed to increase the robustness towards uncertainties in the system, however, state of the art methods either rely on accurate 3D models for_         _ More           Many industrial assembly tasks involve peg-in-hole like insertions with sub-millimeter tolerances which are challenging, even in highly calibrated robot cells. Visual servoing can be employed to increase the robustness towards uncertainties in the system, however, state of the art methods either rely on accurate 3D models for synthetic renderings or manual involvement in acquisition of training data. We present a novel self-supervised visual servoing method for high precision peg-in-hole insertion, which is fully automated and does not rely on synthetic data. We demonstrate its applicability for insertion of electronic components into a printed circuit board with tight tolerances. We show that peg-in-hole insertion can be drastically sped up by preceding a robust but slow force-based insertion strategy with our proposed visual servoing method, the configuration of which is fully autonomous.         _ Less","","arXiv","https://arxiv.org/abs/2206.08800","1","1","multiple"
"A DNA turbine powered by a transmembrane potential across a nanopore","Abstract:                Rotary motors play key roles in energy transduction, from macroscale windmills to nanoscale turbines such as ATP synthase in cells. Despite our capabilities to construct engines at many scales, developing functional synthetic turbines at the nanoscale has remained challenging. Here, we experimentally demonstrate ration_         _ More           Rotary motors play key roles in energy transduction, from macroscale windmills to nanoscale turbines such as ATP synthase in cells. Despite our capabilities to construct engines at many scales, developing functional synthetic turbines at the nanoscale has remained challenging. Here, we experimentally demonstrate rationally designed nanoscale DNA-origami turbines with three chiral blades. These DNA nanoturbines are 24-27 nm in height and diameter and can utilise transmembrane electrochemical potentials across nanopores to drive DNA bundles into sustained unidirectional rotations of up to 10 revolutions/s. The rotation direction is set by the designed chirality of the turbine. All-atom molecular dynamics simulations show how hydrodynamic flows drive this turbine. At high salt concentrations, the rotation direction of turbines with the same chirality is reversed, which is explained by a change in the anisotropy of the electrophoretic mobility. Our artificial turbines operate autonomously in physiological conditions, converting energy from naturally abundant electrochemical potentials into mechanical work. The results open new possibilities for engineering active robotics at the nanoscale.         _ Less","","arXiv","https://arxiv.org/abs/2206.06612","0","1","synthetic_biology"
"MorphoSim: An efficient and scalable phase-field framework for accurately simulating multicellular morphologies","Abstract:                The phase field model can accurately simulate the evolution of microstructures with complex morphologies, and it has been widely used for cell modeling in the last two decades. However, compared to other cellular models such as the coarse-grained model and the vertex model, its high computational cost caused by three-dimensional spatial discretization hamper_         _ More           The phase field model can accurately simulate the evolution of microstructures with complex morphologies, and it has been widely used for cell modeling in the last two decades. However, compared to other cellular models such as the coarse-grained model and the vertex model, its high computational cost caused by three-dimensional spatial discretization hampered its application and scalability, especially for multicellular organisms. Recently, we built a phase field model coupled with in vivo imaging data to accurately reconstruct the embryonic morphogenesis of Caenorhabditis elegans from 1- to 8-cell stages [Kuang et al, PLoS Comput. Biol., 2022]. In this work, we propose an improved phase field model by using the stabilized numerical scheme and modified volume constriction. Then we present a scalable phase-field framework, MorphoSim, which is 100 times more efficient than the previous one, and can simulate over 100 mechanically interacting cells. Finally, we demonstrate how MorphoSim can be successfully applied to reproduce the assembly, self-repairing, and dissociation of a synthetic artificial multicellular system - the synNotch system.         _ Less","","arXiv","https://arxiv.org/abs/2206.04903","0","1","synthetic_biology"
"Robust boundary formation in a morphogen gradient via cell-cell signaling","Abstract:                Establishing sharp and correctly positioned boundaries in spatial gene expression patterns is a central task, both in developmental and synthetic biology. We consider situations where a global morphogen gradient provides positional information to_         _ More           Establishing sharp and correctly positioned boundaries in spatial gene expression patterns is a central task, both in developmental and synthetic biology. We consider situations where a global morphogen gradient provides positional information to cells, but is insufficient to ensure the required boundary precision, due to different types of noise in the system. In a conceptual model, we quantitatively compare three mechanisms, which combine the global signal with local signaling between neighboring cells, to enhance the boundary formation process. These mechanisms differ with respect to the way in which they combine the signals, by following either an AND, an OR, or a SUM rule. Within our model, we analyze the dynamics of the boundary formation process, and the fuzziness of the resulting boundary. Furthermore, we consider the tunability of the boundary position, and its scaling with system size. We nd that all three mechanisms produce less fuzzy boundaries than the purely gradient-based reference mechanism, even in the regime of high noise in the local signals relative to the noise in the global signal. Among the three mechanisms, the SUM rule produces the most accurate boundary. However, in contrast to the other two mechanisms, it requires noise to exit metastable states and rapidly reach the stable boundary pattern.         _ Less","","arXiv","https://arxiv.org/abs/2206.03805","1","1","multiple"
"Biofabrication for neural tissue engineering applications","Abstract:                _in the nervous system have provided new alternative medical approaches. These methods use external biomaterial supports, known as scaffolds, in order to create platforms for the cells to migrate to the injury site and repair the tissue. The challenge in neural tissue engineering (NTE) remains the fabrication of scaffolds with precisely controlled, tunable to_         _ More           Unlike other tissue types, the nervous tissue extends to a wide and complex environment that provides a plurality of different biochemical and topological stimuli which in turn define the functions of that tissue. As a consequence of such complexity, the traditional transplantation therapeutic methods are quite ineffective; therefore, the restoration of peripheral and central nervous system injuries has been a continuous challenge. Tissue engineering and regenerative medicine in the nervous system have provided new alternative medical approaches. These methods use external biomaterial supports, known as scaffolds, in order to create platforms for the cells to migrate to the injury site and repair the tissue. The challenge in neural tissue engineering (NTE) remains the fabrication of scaffolds with precisely controlled, tunable topography, biochemical cues and surface energy, capable of directing and controlling the function of neuronal cells. At the same time, it has been shown that neural tissue engineering provides the potential to model neurological diseases in vitro, mainly via lab-on-a-chip systems, especially in cases for which it is difficult to obtain suitable animal models. As a consequence of the intense research activity in the field, a variety of synthetic approaches and 3D fabrication methods have been developed for the fabrication of NTE scaffolds, including soft lithography and self-assembly, as well as subtractive (top-down) and additive (bottom-up) manufacturing. This article aims at reviewing the existing research effort in the rapidly growing field related to the development of biomaterial scaffolds and lab-on-a-chip systems for NTE applications. Besides presenting recent advances achieved by NTE strategies, this work also delineates existing limitations and highlights emerging possibilities and future prospects in this field.         _ Less","","arXiv","https://arxiv.org/abs/2205.15633","1","3","synthetic_biology"
"Predictive Rate Selection for Ultra-Reliable Communication using Statistical Radio Maps","Abstract:                _position using a non-parametric model. This prior information is then used to select the transmission rate for some target level of reliability. The approach is tested with synthetic data, simulated from urban micro-cell environments, highlighting how the proposed solution helps to reduce the training estimation phase,_         _ More           This paper proposes exploiting the spatial correlation of wireless channel statistics beyond the conventional received signal strength maps by constructing statistical radio maps to predict any relevant channel statistics to assist communications. Specifically, from stored channel samples acquired by previous users in the network, we use Gaussian processes (GPs) to estimate quantiles of the channel distribution at a new position using a non-parametric model. This prior information is then used to select the transmission rate for some target level of reliability. The approach is tested with synthetic data, simulated from urban micro-cell environments, highlighting how the proposed solution helps to reduce the training estimation phase, which is especially attractive for the tight latency constraints inherent to ultra-reliable low-latency (URLLC) deployments.         _ Less","","arXiv","https://arxiv.org/abs/2205.15030","1","0","origin_of_life"
"Inferring relative surface elastic moduli in thin-wall models of single cells","Abstract:                There is a growing interest in measuring the cell wall mechanical property at different locations in single walled_         _ More           There is a growing interest in measuring the cell wall mechanical property at different locations in single walled cells. We present an inference scheme that maps relative surface elastic modulus distributions along the cell wall based on tracking the location of material marker points along the turgid and relaxed cell wall outline. A primary scheme provides a step-function inference of surface elastic moduli by computing the tensions and elastic stretches between material marker points. We perform stability analysis for the primary scheme against perturbations on the marker-point locations, which may occur due to image acquisition and processing from experiments. The perturbation analysis shows that the primary scheme is more stable to noise when the spacing between the marker points is coarser, and has been confirmed by the numerical experiments where we apply the primary scheme to synthetic cell outlines from simulations of hyper-elastic membrane deformation with random noise on the marker-point locations. To improve the spatial resolution of elastic modulus distribution of the primary scheme with noise, we propose two optimization schemes that convert the step-function inferences of elastic moduli into smooth-curve inferences. The first scheme infers a canonical elastic modulus distribution based on marker-point locations from multiple cell samples of the same cell type. The second scheme is a simplified cost-effective version that infers the elastic moduli based on marker-point locations from a single cell. The numerical experiments show that the first scheme significantly improves the inference precision for the underlying canonical elastic modulus distributions and can even capture some degree of nonlinearity when the underlying elastic modulus gradients are nonlinear. The second cost-effective scheme can predict the trend of the elastic modulus gradients consistently.         _ Less","","arXiv","https://arxiv.org/abs/2205.12044","1","1","multiple"
"Mathematical Characterization of Private and Public Immune Repertoire Sequences","Abstract:                Diverse T and B cell repertoires play an important role in mounting effective immune responses against a wide range of pathogens and malignant_         _ More           Diverse T and B cell repertoires play an important role in mounting effective immune responses against a wide range of pathogens and malignant cells. The number of unique T and B cell clones is characterized by T and B cell receptors (TCRs and BCRs), respectively. Although receptor sequences are generated probabilistically by recombination processes, clinical studies found a high degree of sharing of TCRs and BCRs among different individuals. In this work, we use a general probabilistic model for T/B cell receptor clone abundances to define 'publicness' or 'privateness' and information-theoretic measures for comparing the frequency of sampled sequences observed across different individuals. We derive mathematical formulae to quantify the mean and the variances of clone richness and overlap. Our results can be used to evaluate the effect of different sampling protocols on abundances of clones within an individual as well as the commonality of clones across individuals. Using synthetic and empirical TCR amino acid sequence data, we perform simulations to study expected clonal commonalities across multiple individuals. Based on our formulae, we compare these simulated results with the analytically predicted mean and variances of the repertoire overlap. Complementing the results on simulated repertoires, we derive explicit expressions for the richness and its uncertainty for specific, single-parameter truncated power-law probability distributions. Finally, the information loss associated with grouping together certain receptor sequences, as is done in spectratyping, is also evaluated. Our approach can be, in principle, applied under more general and mechanistically realistic clone generation models.         _ Less","","arXiv","https://arxiv.org/abs/2205.08750","1","0","origin_of_life"
"Bayesian learning of effective chemical master equations in crowded intracellular conditions","Abstract:                Biochemical reactions inside living cells often occur in the presence of crowders -- molecules that do not participate in the reactions but influence the reaction rates through excluded volume effects. However the standard approach to modelling stochastic intracellular reaction kinetics is based on the chemical master equation (CME) whose propensities are de_         _ More           Biochemical reactions inside living cells often occur in the presence of crowders -- molecules that do not participate in the reactions but influence the reaction rates through excluded volume effects. However the standard approach to modelling stochastic intracellular reaction kinetics is based on the chemical master equation (CME) whose propensities are derived assuming no crowding effects. Here, we propose a machine learning strategy based on Bayesian Optimisation utilising synthetic data obtained from spatial cellular automata (CA) simulations (that explicitly model volume-exclusion effects) to learn effective propensity functions for CMEs. The predictions from a small CA training data set can then be extended to the whole range of parameter space describing physiologically relevant levels of crowding by means of Gaussian Process regression. We demonstrate the method on an enzyme-catalyzed reaction and a genetic feedback loop, showing good agreement between the time-dependent distributions of molecule numbers predicted by the effective CME and CA simulations.         _ Less","","arXiv","https://arxiv.org/abs/2205.06268","0","2","synthetic_biology"
"Embedded Multilevel Regression and Poststratification: Model-based Inference with Incomplete Auxiliary Information","Abstract:                _variables' joint distribution; data analysts often only have access to the marginal distributions. To overcome this limitation, we embed the estimation of population cell counts needed for poststratification into the MRP workflow: embedded MRP (EMRP). Under EMRP, we generate synthetic populations of the auxiliary v_         _ More           Health disparity research often evaluates health outcomes across demographic subgroups. Multilevel regression and poststratification (MRP) is a popular approach for small subgroup estimation due to its ability to stabilize estimates by fitting multilevel models and to adjust for selection bias by poststratifying on auxiliary variables, which are population characteristics predictive of the analytic outcome. However, the granularity and quality of the estimates produced by MRP are limited by the availability of the auxiliary variables' joint distribution; data analysts often only have access to the marginal distributions. To overcome this limitation, we embed the estimation of population cell counts needed for poststratification into the MRP workflow: embedded MRP (EMRP). Under EMRP, we generate synthetic populations of the auxiliary variables before implementing MRP. All sources of estimation uncertainty are propagated with a fully Bayesian framework. Through simulation studies, we compare different methods and demonstrate EMRP's improvements over alternatives on the bias-variance tradeoff to yield valid subpopulation inferences of interest. As an illustration, we apply EMRP to the Longitudinal Survey of Wellbeing and estimate food insecurity prevalence among vulnerable groups in New York City. We find that all EMRP estimators can correct for the bias in classical MRP while maintaining lower standard errors and narrower confidence intervals than directly imputing with the WFPBB and design-based estimates. Performances from the EMRP estimators do not differ substantially from each other, though we would generally recommend the WFPBB-MRP for its consistently high coverage rates.         _ Less","","arXiv","https://arxiv.org/abs/2205.02775","2","1","origin_of_life"
"Intra-pulse variability induced by plasmoid formation in pulsar magnetospheres","Abstract:                _the pulsar wind current sheet as a possible source of intrinsic pulse-to-pulse variability in the incoherent, high-energy emission pattern. We used a two-dimensional particle-in-cell simulation of an orthogonal pulsar magnetosphere restricted to the plane perpendicular to the star spin axis. We evolved the solution for several tens of pulsar periods to gathe_         _ More           Pulsars show irregularities in their pulsed radio emission that originate from propagation effects and the intrinsic activity of the source. In this work, we investigate the role played by magnetic reconnection and the formation of plasmoids in the pulsar wind current sheet as a possible source of intrinsic pulse-to-pulse variability in the incoherent, high-energy emission pattern. We used a two-dimensional particle-in-cell simulation of an orthogonal pulsar magnetosphere restricted to the plane perpendicular to the star spin axis. We evolved the solution for several tens of pulsar periods to gather a statistically significant sample of synthetic pulse profiles. The formation of plasmoids leads to strong pulse-to-pulse variability in the form of multiple short, bright subpulses, which appear only on the leading edge of each main pulse. These secondary peaks of emission are dominated by the dozen plasmoids that can grow up to macroscopic scales. They emerge from the high end of the hierarchical merging process occurring along the wind current layer. The flux of the subpulses is correlated with their width in phase. Although the full-scale separation is not realistic, we argue that the simulation correctly captures the demographics and the properties of the largest plasmoids, and therefore of the brightest subpulses. The prediction of subpulses at specific pulse phases provides a new observational test of the magnetic reconnection scenario as the origin of the pulsed incoherent emission. High-time-resolution observations of the Crab pulsar in the optical range may be the most promising source to target for this purpose.         _ Less","","arXiv","https://arxiv.org/abs/2205.01942","1","0","origin_of_life"
"Objective crystallographic symmetry classifications of a noisy crystal pattern with strong Fedorov type pseudosymmetries and its optimal image-quality enhancement","Abstract:                _sound crystallographic symmetry classifications are obtained with information theory based methods in the presence of approximately Gaussian distributed noise. A set of three synthetic patterns with strong Fedorov type pseudosymmetries and varying amounts of noise serve as examples. Contrary to traditional crystallographic symmetry classifications with an im_         _ More           Statistically sound crystallographic symmetry classifications are obtained with information theory based methods in the presence of approximately Gaussian distributed noise. A set of three synthetic patterns with strong Fedorov type pseudosymmetries and varying amounts of noise serve as examples. Contrary to traditional crystallographic symmetry classifications with an image processing program such as CRISP, the classification process does not need to be supervised by a human being and is free of any subjectively set thresholds in the geometric model selection process. This enables crystallographic symmetry classification of digital images that are more or less periodic in two dimensions (2D), a.k.a. crystal patterns, as recorded with sufficient structural resolution from a wide range of crystalline samples with different types of scanning probe and transmission electron microscopes. Correct symmetry classifications enable the optimal crystallographic processing of such images. That processing consists in the averaging over all asymmetric units in all unit cells in the selected image area and significantly enhances both the signal to noise ratio and the structural resolution of a microscopic study of a crystal. For sufficiently complex crystal patterns, the information-theoretic symmetry classification methods are more accurate than both visual classifications by human experts and the recommendations of one of the popular crystallographic image processing programs of electron crystallography.         _ Less","","arXiv","https://arxiv.org/abs/2204.13107","1","0","origin_of_life"
"Encapsulated bacteria deform lipid vesicles into flagellated swimmers","Abstract:                We study a synthetic system of motile Escherichia coli bacteria encapsulated inside giant lipid vesicles. Forces exerted by the bacteria on the inner side of the membrane are sufficient to extrude membrane tubes filled with one or several bacteria. We show that a physical coupling between the membrane tube and the flagella of the enclosed_         _ More           We study a synthetic system of motile Escherichia coli bacteria encapsulated inside giant lipid vesicles. Forces exerted by the bacteria on the inner side of the membrane are sufficient to extrude membrane tubes filled with one or several bacteria. We show that a physical coupling between the membrane tube and the flagella of the enclosed cells transforms the tube into an effective helical flagellum propelling the vesicle. We develop a simple theoretical model to estimate the propulsive force from the speed of the vesicles, and demonstrate the good efficiency of this coupling mechanism. Together, these results point to design principles for conferring motility to synthetic cells.         _ Less","","arXiv","https://arxiv.org/abs/2204.03721","1","2","synthetic_biology"
"Clean Implicit 3D Structure from Noisy 2D STEM Images","Abstract:                Scanning Transmission Electron Microscopes (STEMs) acquire 2D images of a 3D sample on the scale of individual cell components. Unfortunately, these 2D images can be too noisy to be fused into a useful 3D structure and facilitating good denoisers is challenging due to the lack of clean-noisy pairs. Additionally, representing a detailed 3D structure can be di_         _ More           Scanning Transmission Electron Microscopes (STEMs) acquire 2D images of a 3D sample on the scale of individual cell components. Unfortunately, these 2D images can be too noisy to be fused into a useful 3D structure and facilitating good denoisers is challenging due to the lack of clean-noisy pairs. Additionally, representing a detailed 3D structure can be difficult even for clean data when using regular 3D grids. Addressing these two limitations, we suggest a differentiable image formation model for STEM, allowing to learn a joint model of 2D sensor noise in STEM together with an implicit 3D model. We show, that the combination of these models are able to successfully disentangle 3D signal and noise without supervision and outperform at the same time several baselines on synthetic and real data.         _ Less","","arXiv","https://arxiv.org/abs/2203.15434","1","0","origin_of_life"
"Discovering dynamic laws from observations: the case of self-propelled, interacting colloids","Abstract:                Active matter spans a wide range of time and length scales, from groups of cells and synthetic self-propelled particles to schools of fish, flocks of birds, or even human crowds. The theoretical framework describing these systems has shown tremendous success at finding universal phenomenology. However, further progress_         _ More           Active matter spans a wide range of time and length scales, from groups of cells and synthetic self-propelled particles to schools of fish, flocks of birds, or even human crowds. The theoretical framework describing these systems has shown tremendous success at finding universal phenomenology. However, further progress is often burdened by the difficulty of determining the forces that control the dynamics of the individual elements within each system. Accessing this local information is key to understanding the physics dominating the system and to create the models that can explain the observed collective phenomena. In this work, we present a machine-learning model, a graph neural network, that uses the collective movement of the system to learn the active and two-body forces controlling the individual dynamics of the particles. We verify our approach using numerical simulations of active brownian particles, considering different interaction potentials and levels of activity. Finally, we apply our model to experiments of electrophoretic Janus particles, extracting the active and two-body forces that control the dynamics of the colloids. Due to this, we can uncover the physics dominating the behavior of the system. We extract an active force that depends on the electric field and also area fraction. We also discover a dependence of the two-body interaction with the electric field that leads us to propose that the dominant force between these colloids is a screened electrostatic interaction with a constant length scale. We expect that this methodology can open a new avenue for the study and modeling of experimental systems of active particles.         _ Less","","arXiv","https://arxiv.org/abs/2203.14846","1","0","origin_of_life"
"Provably Accurate and Scalable Linear Classifiers in Hyperbolic Spaces","Abstract:                _and strategic perceptrons shows that the proposed framework can be extended to general machine learning problems in hyperbolic spaces. Our experimental results, pertaining to synthetic, single-cell RNA-seq expression measurements, CIFAR10, Fashion-MNIST and mini-ImageNet, establish that all algorithms provably converge_         _ More           Many high-dimensional practical data sets have hierarchical structures induced by graphs or time series. Such data sets are hard to process in Euclidean spaces and one often seeks low-dimensional embeddings in other space forms to perform the required learning tasks. For hierarchical data, the space of choice is a hyperbolic space because it guarantees low-distortion embeddings for tree-like structures. The geometry of hyperbolic spaces has properties not encountered in Euclidean spaces that pose challenges when trying to rigorously analyze algorithmic solutions. We propose a unified framework for learning scalable and simple hyperbolic linear classifiers with provable performance guarantees. The gist of our approach is to focus on Poincar_ ball models and formulate the classification problems using tangent space formalisms. Our results include a new hyperbolic perceptron algorithm as well as an efficient and highly accurate convex optimization setup for hyperbolic support vector machine classifiers. Furthermore, we adapt our approach to accommodate second-order perceptrons, where data is preprocessed based on second-order information (correlation) to accelerate convergence, and strategic perceptrons, where potentially manipulated data arrives in an online manner and decisions are made sequentially. The excellent performance of the Poincar_ second-order and strategic perceptrons shows that the proposed framework can be extended to general machine learning problems in hyperbolic spaces. Our experimental results, pertaining to synthetic, single-cell RNA-seq expression measurements, CIFAR10, Fashion-MNIST and mini-ImageNet, establish that all algorithms provably converge and have complexity comparable to those of their Euclidean counterparts. Accompanying codes can be found at: https://github.com/thupchnsky/PoincareLinearClassification.         _ Less","","arXiv","https://arxiv.org/abs/2203.03730","1","0","origin_of_life"
"Examining quasar absorption-line analysis methods: the tension between simulations and observational assumptions key to modelling clouds","Abstract:                _dwarf galaxies and generated synthetic quasar absorption-line spectra of their CGM. For the SiII $_1260$ transition, and the CIV $_\\lambda1548, 1550$ and OVI $_\\lambda1031, 1037$ fine-structure doublets, we objectively determined which gas cells along a line-of-sight (LOS) contribute to detected absorption. We impleme_         _ More           A key assumption in quasar absorption line studies of the circumgalactic medium (CGM) is that each absorption component maps to a spatially isolated 'cloud' structure that has single valued properties (e.g. density, temperature, metallicity). We aim to assess and quantify the degree of accuracy underlying this assumption. We used adaptive mesh refinement hydrodynamic cosmological simulations of two $z=1$ dwarf galaxies and generated synthetic quasar absorption-line spectra of their CGM. For the SiII $_1260$ transition, and the CIV $_\\lambda1548, 1550$ and OVI $_\\lambda1031, 1037$ fine-structure doublets, we objectively determined which gas cells along a line-of-sight (LOS) contribute to detected absorption. We implemented a fast, efficient, and objective method to define individual absorption components in each absorption profile. For each absorption component, we quantified the spatial distribution of the absorbing gas. We studied a total of 1,302 absorption systems containing a total of 7,755 absorption components. 48% of SiII, 68% of CIV, and 72% of OVI absorption components arise from two or more spatially isolated 'cloud' structures along the LOS. Spatially isolated 'cloud' structures were most likely to have cloud-cloud LOS separations of 0.03$R_{vir}$, 0.11$R_{vir}$, and 0.13$R_{vir}$ for SiII, CIV, and OVI, respectively. There can be very little overlap between multi-phase gas structures giving rise to absorption components. If our results reflect the underlying reality of how absorption lines record CGM gas, they place tension on current observational analysis methods as they suggest that component-by-component absorption line formation is more complex than is assumed and applied for chemical-ionisation modelling.         _ Less","","arXiv","https://arxiv.org/abs/2202.12228","1","0","origin_of_life"
"Collective states of active particles with elastic dipolar interactions","Abstract:                Many types of mammalian cells exert active contractile forces and mechanically deform their elastic substrate, to accomplish biological functions such as_         _ More           Many types of mammalian cells exert active contractile forces and mechanically deform their elastic substrate, to accomplish biological functions such as cell migration. These substrate deformations provide a mechanism by which cells can sense other cells, leading to long range mechanical intercell interactions and possible self organization. Here, we treat cells as noisy motile particles that exert contractile dipolar stresses on elastic substrates as they move. By combining this minimal model for the motility of individual cells with a linear elastic model that accounts for substrate mediated cell cell interactions, we examine emergent collective states that result from the interplay of cell motility and long range elastic dipolar interactions. In particular, we show that particles self assemble into flexible, motile chains which can cluster to form diverse larger scale compact structures with polar order. By computing key structural and dynamical metrics, we distinguish between the collective states at weak and strong elastic interactions, as well as at low and high motility. We also show how these states are affected by confinement, an important characteristic of the complex mechanical microenvironment inhabited by cells. Our model predictions are generally applicable to active matter with dipolar interactions ranging from biological cells to synthetic colloids endowed with electric or magnetic dipole moments.         _ Less","","arXiv","https://arxiv.org/abs/2202.10431","1","0","origin_of_life"
"Geometric structure guided model and algorithms for complete deconvolution of gene expression data","Abstract:                _GEPs (gene expression profiles) in tissues of patients and normal controls are due to changes in cellular composition of tissue samples, or due to GEPs changes in specific cells. One of the major techniques to perform complete deconvolution is nonnegative matrix factorization (NMF), which also has a wide-range of applications in the machine learning communit_         _ More           Complete deconvolution analysis for bulk RNAseq data is important and helpful to distinguish whether the difference of disease-associated GEPs (gene expression profiles) in tissues of patients and normal controls are due to changes in cellular composition of tissue samples, or due to GEPs changes in specific cells. One of the major techniques to perform complete deconvolution is nonnegative matrix factorization (NMF), which also has a wide-range of applications in the machine learning community. However, the NMF is a well-known strongly ill-posed problem, so a direct application of NMF to RNAseq data will suffer severe difficulties in the interpretability of solutions. In this paper we develop an NMF-based mathematical model and corresponding computational algorithms to improve the solution identifiability of deconvoluting bulk RNAseq data. In our approach, we combine the biological concept of marker genes with the solvability conditions of the NMF theories, and develop a geometric structured guided optimization model. In this strategy, the geometric structure of bulk tissue data is first explored by the spectral clustering technique. Then, the identified information of marker genes is integrated as solvability constraints, while the overall correlation graph is used as manifold regularization. Both synthetic and biological data are used to validate the proposed model and algorithms, from which solution interpretability and accuracy are significantly improved.         _ Less","","arXiv","https://arxiv.org/abs/2202.08733","1","0","origin_of_life"
"Oral cancer detection and interpretation: Deep multiple instance learning versus conventional deep single instance learning","Abstract:                _we are interested in AI-based methods that reliably can detect cancer given only per-patient labels (minimizing annotation bias), and also provide information on which cells are most relevant for the diagnosis (enabling supervision and understanding). We, therefore, perform a comparison of a conventional single instance learning (SIL) approach and a modern_         _ More           The current medical standard for setting an oral cancer (OC) diagnosis is histological examination of a tissue sample from the oral cavity. This process is time consuming and more invasive than an alternative approach of acquiring a brush sample followed by cytological analysis. Skilled cytotechnologists are able to detect changes due to malignancy, however, to introduce this approach into clinical routine is associated with challenges such as a lack of experts and labour-intensive work. To design a trustworthy OC detection system that would assist cytotechnologists, we are interested in AI-based methods that reliably can detect cancer given only per-patient labels (minimizing annotation bias), and also provide information on which cells are most relevant for the diagnosis (enabling supervision and understanding). We, therefore, perform a comparison of a conventional single instance learning (SIL) approach and a modern multiple instance learning (MIL) method suitable for OC detection and interpretation, utilizing three different neural network architectures. To facilitate systematic evaluation of the considered approaches, we introduce a synthetic PAP-QMNIST dataset, that serves as a model of OC data, while offering access to per-instance ground truth. Our study indicates that on PAP-QMNIST, the SIL performs better, on average, than the MIL approach. Performance at the bag level on real-world cytological data is similar for both methods, yet the single instance approach performs better on average. Visual examination by cytotechnologist indicates that the methods manage to identify cells which deviate from normality, including malignant cells as well as those suspicious for dysplasia. We share the code as open source at https://github.com/MIDA-group/OralCancerMILvsSIL         _ Less","","arXiv","https://arxiv.org/abs/2202.01783","1","0","origin_of_life"
"Attosecond dispersion as a diagnostics tool for solid-density laser-generated plasmas","Abstract:                _through ionised solid-density targets, unlike optical pulses and, thus, have the potential to probe the interior of such plasmas on sub-femtosecond timescales. We present a synthetic diagnostic method for solid-density laser-generated plasmas based on the dispersion of an extreme-ultraviolet attosecond probe pulse, in a pump--probe scheme. We demonstrate the_         _ More           Extreme-ultraviolet pulses can propagate through ionised solid-density targets, unlike optical pulses and, thus, have the potential to probe the interior of such plasmas on sub-femtosecond timescales. We present a synthetic diagnostic method for solid-density laser-generated plasmas based on the dispersion of an extreme-ultraviolet attosecond probe pulse, in a pump--probe scheme. We demonstrate the theoretical feasibility of this approach through calculating the dispersion of an extreme-ultraviolet probe pulse propagating through a laser-generated plasma. The plasma dynamics is calculated using a particle-in-cell simulation, whereas the dispersion of the probe is calculated with an external pseudo-spectral wave solver, allowing for high accuracy when calculating the dispersion. The application of this method is illustrated on thin-film plastic and aluminium targets irradiated by a high-intensity pump pulse. By comparing the dispersion of the probe pulse at different delays relative to the pump pulse, it is possible to follow the evolution of the plasma as it disintegrates. The high-frequency end of the dispersion provides information on the line-integrated electron density, whereas lower frequencies are more affected by the highest density encountered along the path of the probe. In addition, the presence of thin-film interference could be used to study the evolution of the plasma surface.         _ Less","","arXiv","https://arxiv.org/abs/2202.00406","1","1","multiple"
"Technological Approach to Mind Everywhere (TAME): an experimentally-grounded framework for understanding diverse bodies and minds","Abstract:        Synthetic biology and bioengineering provide the opportunity to create novel embodied cognitive systems (otherwise known as minds) in a very wide variety of chimeric architectures combining evolved and designed material and software. These advances are disrupting familiar concepts in the philosophy of mind, and require new ways of thinking about and comparin_         _ More   Synthetic biology and bioengineering provide the opportunity to create novel embodied cognitive systems (otherwise known as minds) in a very wide variety of chimeric architectures combining evolved and designed material and software. These advances are disrupting familiar concepts in the philosophy of mind, and require new ways of thinking about and comparing truly diverse intelligences, whose composition and origin are not like any of the available natural model species. In this Perspective, I introduce TAME - Technological Approach to Mind Everywhere - a framework for understanding and manipulating cognition in unconventional substrates. TAME formalizes a non-binary (continuous), empirically-based approach to strongly embodied agency. When applied to regenerating/developmental systems, TAME suggests a perspective on morphogenesis as an example of basal cognition. The deep symmetry between problem-solving in anatomical, physiological, transcriptional, and 3D (traditional behavioral) spaces drives specific hypotheses by which cognitive capacities can scale during evolution. An important medium exploited by evolution for joining active subunits into greater agents is developmental bioelectricity, implemented by pre-neural use of ion channels and gap junctions to scale cell-level feedback loops into anatomical homeostasis. This architecture of multi-scale competency of biological systems has important implications for plasticity of bodies and minds, greatly potentiating evolvability. Considering classical and recent data from the perspectives of computational science, evolutionary biology, and basal cognition, reveals a rich research program with many implications for cognitive science, evolutionary biology, regenerative medicine, and artificial intelligence.         _ Less","","arXiv","https://arxiv.org/abs/2201.10346","0","5","synthetic_biology"
"Survival Prediction of Children Undergoing Hematopoietic Stem Cell Transplantation Using Different Machine Learning Classifiers by Performing Chi-squared Test and Hyper-parameter Optimization: A Retrospective Analysis","Abstract:                _manner, incorporating the Chi-squared feature selection method to address the dimensionality problem and Hyper Parameter Optimization (HPO) to increase accuracy. A synthetic dataset is generated by imputing the missing values, transforming the data using dummy variable encoding, and compressing the dataset from 59 features to the 11 most correlated features_         _ More           Bone Marrow Transplant, a gradational rescue for a wide range of disorders emanating from the bone marrow, is an efficacious surgical treatment. Several risk factors, such as post-transplant illnesses, new malignancies, and even organ damage, can impair long-term survival. Therefore, technologies like Machine Learning are deployed for investigating the survival prediction of BMT receivers along with the influences that limit their resilience. In this study, an efficient survival classification model is presented in a comprehensive manner, incorporating the Chi-squared feature selection method to address the dimensionality problem and Hyper Parameter Optimization (HPO) to increase accuracy. A synthetic dataset is generated by imputing the missing values, transforming the data using dummy variable encoding, and compressing the dataset from 59 features to the 11 most correlated features using Chi-squared feature selection. The dataset was split into train and test sets at a ratio of 80:20, and the hyperparameters were optimized using Grid Search Cross-Validation. Several supervised ML methods were trained in this regard, like Decision Tree, Random Forest, Logistic Regression, K-Nearest Neighbors, Gradient Boosting Classifier, Ada Boost, and XG Boost. The simulations have been performed for both the default and optimized hyperparameters by using the original and reduced synthetic dataset. After ranking the features using the Chi-squared test, it was observed that the top 11 features with HPO, resulted in the same accuracy of prediction (94.73%) as the entire dataset with default parameters. Moreover, this approach requires less time and resources for predicting the survivability of children undergoing BMT. Hence, the proposed approach may aid in the development of a computer-aided diagnostic system with satisfactory accuracy and minimal computation time by utilizing medical data records.         _ Less","","arXiv","https://arxiv.org/abs/2201.08987","1","1","multiple"
"Efficient Sampling-Based Bayesian Active Learning for synaptic characterization","Abstract:                _We apply our method to the problem of estimating the parameters of a chemical synapse from the postsynaptic responses to evoked presynaptic action potentials. Using synthetic data and synaptic whole-cell patch-clamp recordings, we show that our method can improve the precision of model-based inferences, thereby paving_         _ More           Bayesian Active Learning (BAL) is an efficient framework for learning the parameters of a model, in which input stimuli are selected to maximize the mutual information between the observations and the unknown parameters. However, the applicability of BAL to experiments is limited as it requires performing high-dimensional integrations and optimizations in real time: current methods are either too time consuming, or only applicable to specific models. Here, we propose an Efficient Sampling-Based Bayesian Active Learning (ESB-BAL) framework, which is efficient enough to be used in real-time biological experiments. We apply our method to the problem of estimating the parameters of a chemical synapse from the postsynaptic responses to evoked presynaptic action potentials. Using synthetic data and synaptic whole-cell patch-clamp recordings, we show that our method can improve the precision of model-based inferences, thereby paving the way towards more systematic and efficient experimental designs in physiology.         _ Less","","arXiv","https://arxiv.org/abs/2201.07539","1","0","origin_of_life"
"Time-domain deep learning filtering of structured atmospheric noise for ground-based millimeter astronomy","Abstract:                _because of deep neural networks' inherent ability to abstract non-linear patterns over a broad scale range. We propose an architecture composed of long-short term memory cells and an incremental training strategy inspired by transfer and curriculum learning. We develop a scintillation model and employ an empirical method to generate a vast catalog of atm_         _ More           The complex physics involved in atmospheric turbulence makes it very difficult for ground-based astronomy to build accurate scintillation models and develop efficient methodologies to remove this highly structured noise from valuable astronomical observations. We argue that a Deep Learning approach can bring a significant advance to treat this problem because of deep neural networks' inherent ability to abstract non-linear patterns over a broad scale range. We propose an architecture composed of long-short term memory cells and an incremental training strategy inspired by transfer and curriculum learning. We develop a scintillation model and employ an empirical method to generate a vast catalog of atmospheric noise realizations and train the network with representative data. We face two complexity axes: the signal-to-noise ratio (SNR) and the degree of structure in the noise. Hence, we train our recurrent network to recognize simulated astrophysical point-like sources embedded in three structured noise levels, with a raw-data SNR ranging from 3 to 0.1. We find that a slow and repetitive increase in complexity is crucial during training to obtain a robust and stable learning rate that can transfer information through different data contexts. We probe our recurrent model with synthetic observational data, designing alongside a calibration methodology for flux measurements. Furthermore, we implement a traditional matched filtering (MF) to compare its performance with our neural network, finding that our final trained network can successfully clean structured noise and significantly enhance the SNR compared to raw data and in a more robust way than traditional MF.         _ Less","","arXiv","https://arxiv.org/abs/2201.06672","1","0","origin_of_life"
"Statistically equivalent surrogate material models and the impact of random imperfections on elasto-plastic response","Abstract:                _interpret. The calibration of the model parameters is performed using progressive batching sub-sampled quasi-Newton minimization, using a designed distance measure between the synthetic samples and the data. Then, employing a fast sampling algorithm, an arbitrary number of_         _ More           Manufactured materials usually contain random imperfections due to the fabrication process, e.g., the 3D-printing, casting, etc. These imperfections affect significantly the effective material properties and result in uncertainties in the mechanical response. Numerical analysis of the effects of the imperfections and the uncertainty quantification (UQ) can be often done by use of digital stochastic surrogate material models. In this work, we present a new flexible class of surrogate models depending on a small number of parameters with special focus on two-phase materials. The surrogate models are constructed as the level-set of a linear combination of an intensity field representing the topological shape and a Gaussian perturbation representing the imperfections. The mathematical design parameters of the model are related to physical ones and thus easy to interpret. The calibration of the model parameters is performed using progressive batching sub-sampled quasi-Newton minimization, using a designed distance measure between the synthetic samples and the data. Then, employing a fast sampling algorithm, an arbitrary number of synthetic samples can be generated to use in Monte Carlo type methods. In particular, we illustrate the method in application to UQ of the elasto-plastic response of an imperfect octet-truss lattice which plays an important role in additive manufacturing. To this end, we study the effective material properties of the lattice unit cell under elasto-plastic deformations and investigate the sensitivity of the effective Young's modulus to the imperfections.         _ Less","","arXiv","https://arxiv.org/abs/2112.06655","1","0","origin_of_life"
"Emergent Regulatory Response and Shift of Half induction point under Resource Competition in Genetic circuits","Abstract:        Synthetic genetic circuits are implemented in living_         _ More   Synthetic genetic circuits are implemented in living cells for their operation. During gene expression, proteins are produced from the respective genes, by formation of complexes through the process of transcription and translation. In transcription the circuit uses RNAP, etc. as resource from the host cell and in translation, ribosome, tRNA and other cellular resources are supplied to the operating circuit. As the cell contains these resources in limited number, the circuit can suffer from unprecedented resource competition which might destroy the circuit functionality, or introduce some emergent responses. In this paper, we have studied a three-gene motif under resource competition where interesting behaviour, similar to regulatory responses occur due to limited supply of necessary resources. The system of interest exhibits prominent changes in behaviour which can be observed experimentally. We focus on two specific aspects, namely, dynamic range and half-induction point, which inherently describe the circuit functionalities, and can be affected by corresponding resource affinity and availability.         _ Less","","arXiv","https://arxiv.org/abs/2112.04985","1","0","origin_of_life"
"Deep Learning for Reaction-Diffusion Glioma Growth Modelling: Towards a Fully Personalised Model?","Abstract:                _tool. In this work, we investigate the ability of deep convolutional neural networks (DCNNs) to address the pitfalls commonly encountered in the field. Based on 1,200 synthetic tumours grown over real brain geometries derived from magnetic resonance (MR) data of 6 healthy subjects, we demonstrate the ability of DCNNs to reconstruct a whole tumour_         _ More           Reaction-diffusion models have been proposed for decades to capture the growth of gliomas, the most common primary brain tumours. However, severe limitations regarding the estimation of the initial conditions and parameter values of such models have restrained their clinical use as a personalised tool. In this work, we investigate the ability of deep convolutional neural networks (DCNNs) to address the pitfalls commonly encountered in the field. Based on 1,200 synthetic tumours grown over real brain geometries derived from magnetic resonance (MR) data of 6 healthy subjects, we demonstrate the ability of DCNNs to reconstruct a whole tumour cell density distribution from only two imaging contours at a single time point. With an additional imaging contour extracted at a prior time point, we also demonstrate the ability of DCNNs to accurately estimate the individual diffusivity and proliferation parameters of the model. From this knowledge, the spatio-temporal evolution of the tumour cell density distribution at later time points can ultimately be precisely captured using the model. We finally show the applicability of our approach to MR data of a real glioblastoma patient. This approach may open the perspective of a clinical application of reaction-diffusion growth models for tumour prognosis and treatment planning.         _ Less","","arXiv","https://arxiv.org/abs/2111.13404","0","2","synthetic_biology"
"Topologically Regularized Data Embeddings","Abstract:                _losses, and proposing their usage as a way for topologically regularizing data embeddings to naturally represent a prespecified model. We include thorough experiments on synthetic and real data that highlight the usefulness and versatility of this approach, with applications ranging from modeling high-dimensional single-_         _ More           Unsupervised feature learning often finds low-dimensional embeddings that capture the structure of complex data. For tasks for which prior expert topological knowledge is available, incorporating this into the learned representation may lead to higher quality embeddings. For example, this may help one to embed the data into a given number of clusters, or to accommodate for noise that prevents one from deriving the distribution of the data over the model directly, which can then be learned more effectively. However, a general tool for integrating different prior topological knowledge into embeddings is lacking. Although differentiable topology layers have been recently developed that can (re)shape embeddings into prespecified topological models, they have two important limitations for representation learning, which we address in this paper. First, the currently suggested topological losses fail to represent simple models such as clusters and flares in a natural manner. Second, these losses neglect all original structural (such as neighborhood) information in the data that is useful for learning. We overcome these limitations by introducing a new set of topological losses, and proposing their usage as a way for topologically regularizing data embeddings to naturally represent a prespecified model. We include thorough experiments on synthetic and real data that highlight the usefulness and versatility of this approach, with applications ranging from modeling high-dimensional single-cell data, to graph embedding.         _ Less","","arXiv","https://arxiv.org/abs/2110.09193","1","0","origin_of_life"
"OG-SPACE: Optimized Stochastic Simulation of Spatial Models of Cancer Evolution","Abstract:                Algorithmic strategies for the spatio-temporal simulation of multi-cellular systems are crucial to generate synthetic datasets for bioinformatics tools benchmarking, as well as to investigate experimental hypotheses on real-world systems in a variety of in-silico scenarios. In particular, efficient algorithms are needed to overcome the harsh trade-off betwee_         _ More           Algorithmic strategies for the spatio-temporal simulation of multi-cellular systems are crucial to generate synthetic datasets for bioinformatics tools benchmarking, as well as to investigate experimental hypotheses on real-world systems in a variety of in-silico scenarios. In particular, efficient algorithms are needed to overcome the harsh trade-off between scalability and expressivity, which typically limits our capability to produce realistic simulations, especially in the context of cancer evolution. We introduce the Optimized Gillespie algorithm for simulating Stochastic sPAtial models of Cancer Evolution (OG-SPACE), a computational framework for the simulation of the spatio-temporal evolution of cancer subpopulations and of the experimental procedures of both bulk andsingle-cell sequencing. OG-SPACE relies on an evolution of the Gillespie algorithm optimized to deal with large numbers of cells and is designed tohandle a variety of birth-death processes and interaction rules on arbitrary lattices. As output OG-SPACE returns: the visual snapshots of the spatial configuration of the system over time, the phylogeny of the (sampled) cells, the mutational tree, the variant allele frequency spectrum (for bulk experiments) and the cell genotypes (for single-cell experiments).OG-SPACE is freely available at:https://github.com/BIMIB-DISCo/OG-SPACE         _ Less","","arXiv","https://arxiv.org/abs/2110.06588","0","1","synthetic_biology"
"Adaptive-Resolution Field Mapping Using Gaussian Process Fusion with Integral Kernels","Abstract:                _approach for mapping terrain based on Gaussian Process fusion. A key aspect of our approach is an integral kernel encoding spatial correlation over the areas of grid cells, which enables modifying map resolution while maintaining correlations in a theoretically sound fashion. This way, we can retain details in areas of interest at higher map resolutions whil_         _ More           Unmanned aerial vehicles are rapidly gaining popularity in a variety of environmental monitoring tasks. A key requirement for their autonomous operation is the ability to perform efficient environmental mapping online, given limited onboard resources constraining operation time, travel distance, and computational capacity. To address this, we present an online adaptive-resolution approach for mapping terrain based on Gaussian Process fusion. A key aspect of our approach is an integral kernel encoding spatial correlation over the areas of grid cells, which enables modifying map resolution while maintaining correlations in a theoretically sound fashion. This way, we can retain details in areas of interest at higher map resolutions while compressing information in uninteresting areas at coarser resolutions to achieve a compact map representation of the environment. We evaluate the performance of our approach on both synthetic and real-world data. Results show that our method is more efficient in terms of mapping time and memory consumption without compromising on map quality. Finally, we integrate our mapping strategy into an adaptive path planning framework to show that it facilitates information gathering efficiency in online settings.         _ Less","","arXiv","https://arxiv.org/abs/2109.14257","1","0","origin_of_life"
"Identifiability of Chemical Reaction Networks with Intrinsic and Extrinsic Noise from Stationary Distributions","Abstract:                _network with unknown parameters. Data available to identify these parameters are often in the form of a stationary distribution, such as that obtained from measurements of a cell population. In this work, we introduce a framework for analyzing the identifiability of the reaction rate coefficients of chemical reaction networks from stationary distribution dat_         _ More           Many biological systems can be modeled as a chemical reaction network with unknown parameters. Data available to identify these parameters are often in the form of a stationary distribution, such as that obtained from measurements of a cell population. In this work, we introduce a framework for analyzing the identifiability of the reaction rate coefficients of chemical reaction networks from stationary distribution data. Working with the linear noise approximation, which is a diffusive approximation to the chemical master equation, we give a computational procedure to certify global identifiability based on Hilbert's Nullstellensatz. We present a variety of examples that show the applicability of our method to chemical reaction networks of interest in systems and synthetic biology, including discrimination between possible molecular mechanisms for the interaction between biochemical species.         _ Less","","arXiv","https://arxiv.org/abs/2109.09943","0","2","synthetic_biology"
"Microswimming in viscoelastic fluids","Abstract:                _gaits, and experiencing different hydrodynamic interactions with their surroundings. In this article, we review the fundamental physics of locomotion of biological and synthetic microswimmers in complex viscoelastic fluids. Starting from a continuum framework, we describe the main theoretical approaches developed to model microswimming in viscoelastic fluids_         _ More           The locomotion of microorganisms and spermatozoa in complex viscoelastic fluids is of critical importance in many biological processes such as fertilization, infection, and biofilm formation. Depending on their propulsion mechanisms, microswimmers display various responses to a complex fluid environment: increasing or decreasing their swimming speed and efficiency, modifying their propulsion kinematics and swimming gaits, and experiencing different hydrodynamic interactions with their surroundings. In this article, we review the fundamental physics of locomotion of biological and synthetic microswimmers in complex viscoelastic fluids. Starting from a continuum framework, we describe the main theoretical approaches developed to model microswimming in viscoelastic fluids, which typically rely on asymptotically small dimensionless parameters. We then summarise recent progress on the mobility of single cells propelled by cilia, waving flagella and rotating helical flagella in unbounded viscoelastic fluids. We next briefly discuss the impact of other physical factors, including the micro-scale heterogeneity of complex biological fluids, the role of Brownian fluctuations of the microswimmers, the effect of polymer entanglement and the influence of shear-thinning viscosity. In particular, for solutions of long polymer chains whose sizes are comparable to the radius of flagella, continuum models cannot be used and instead Brownian Dynamics for the polymers can predict the swimming dynamics. Finally, we discuss the effect of viscoelasticity on the dynamics of microswimmers in the presence of surfaces or external flows and its impact on collective cellular behavior.         _ Less","","arXiv","https://arxiv.org/abs/2109.05888","2","1","origin_of_life"
"Information-theoretic Classification Accuracy: A Criterion that Guides Data-driven Combination of Ambiguous Outcome Labels in Multi-class Classification","Abstract:                _prediction accuracy and identifying ambiguous labels. We first verify that ITCA achieves high accuracy with both search strategies in finding the correct label combinations on synthetic and real data. Then we demonstrate the effectiveness of ITCA in diverse applications including medical prognosis, cancer survival prediction, user demographics prediction, an_         _ More           Outcome labeling ambiguity and subjectivity are ubiquitous in real-world datasets. While practitioners commonly combine ambiguous outcome labels for all data points (instances) in an ad hoc way to improve the accuracy of multi-class classification, there lacks a principled approach to guide the label combination for all data points by any optimality criterion. To address this problem, we propose the information-theoretic classification accuracy (ITCA), a criterion that balances the trade-off between prediction accuracy (how well do predicted labels agree with actual labels) and classification resolution (how many labels are predictable), to guide practitioners on how to combine ambiguous outcome labels. To find the optimal label combination indicated by ITCA, we propose two search strategies: greedy search and breadth-first search. Notably, ITCA and the two search strategies are adaptive to all machine-learning classification algorithms. Coupled with a classification algorithm and a search strategy, ITCA has two uses: improving prediction accuracy and identifying ambiguous labels. We first verify that ITCA achieves high accuracy with both search strategies in finding the correct label combinations on synthetic and real data. Then we demonstrate the effectiveness of ITCA in diverse applications including medical prognosis, cancer survival prediction, user demographics prediction, and cell type classification. We also provide theoretical insights into ITCA by studying the oracle and the linear discriminant analysis classification algorithms. Python package itca (available at https://github.com/JSB-UCLA/ITCA) implements ITCA and search strategies.         _ Less","","arXiv","https://arxiv.org/abs/2109.00582","1","0","origin_of_life"
"Recent Progress on Synthesis, Characterization, and Applications of Metal Halide Perovskites@Metal Oxide","Abstract:                Metal halide perovskites (MHPs) have become a promising candidate in a myriad of applications, such as light-emitting diodes, solar cells, lasing, photodetectors, photocatalysis, transistors, etc. This is related to the synergy of their excellent features, including high photoluminescence quantum yields, narrow and tunable emission, long charge carrier lifet_         _ More           Metal halide perovskites (MHPs) have become a promising candidate in a myriad of applications, such as light-emitting diodes, solar cells, lasing, photodetectors, photocatalysis, transistors, etc. This is related to the synergy of their excellent features, including high photoluminescence quantum yields, narrow and tunable emission, long charge carrier lifetimes, broad absorption spectrum along with high extinction absorptions coefficients, among others. However, the main bottleneck is the poor stability of the MHPs under ambient conditions. This is imposing severe restrictions with respect to their industrialized applications and commercialization. In this context, metal oxide (MOx) coatings have recently emerged as an efficient strategy towards overcoming the stabilities issues as well as retain the excellent properties of the MHPs, and therefore facilitate the development of the related devices stabilities and performances.This review provides a summary of the recent progress on synthetic methods, enhanced features, the techniques to assess the MHPs-MOxcomposites, and applications of the MHPs@MOx.Specially, novel approaches to fabricate the composites and new applications of the composites are also reported in this review for the first time. This is rounded by a critical outlook about the current MHPs stability issues and the further direction to ensure a bright future of MHPs@MOx         _ Less","","arXiv","https://arxiv.org/abs/2109.00508","1","1","multiple"
"Fluorescent redox-dependent labeling of lipid droplets in cultured cells by reduced phenazine methosulfate","Abstract:                Natural and synthetic phenazines are widely used in biomedical sciences. In dehydrogenase histochemistry, phenazine methosulfate (PMS) is applied as a redox reagent for coupling reduced coenzymes to the reduction of tetrazolium salts into colored formazans. PMS is also currently used for cytotoxicity and viability assays of_         _ More           Natural and synthetic phenazines are widely used in biomedical sciences. In dehydrogenase histochemistry, phenazine methosulfate (PMS) is applied as a redox reagent for coupling reduced coenzymes to the reduction of tetrazolium salts into colored formazans. PMS is also currently used for cytotoxicity and viability assays of cell cultures using sulfonated tetrazoliums. Under UV (340 nm) excitation, aqueous solutions of the cationic PMS show green fluorescence (_em: 526 nm), whereas the reduced hydrophobic derivative (methyl-phenazine, MPH) shows blue fluorescence (_em: 465 nm). Under UV (365 nm) excitation, cultured cells (LM2, IGROV-1, BGC-1, and 3T3-L1 adipocytes) treated with PMS (5 ug/mL, 30 min) showed cytoplasmic granules with bright blue fluorescence, which correspond to lipid droplets labeled by the lipophilic methyl-phenazine. After formaldehyde fixation blue-fluorescing droplets could be stained with oil red O. Interestingly, PMS-treated 3T3-L1 adipocytes observed under UV excitation 24 h after labeling showed large lipid droplets with a weak green emission within a diffuse pale blue-fluorescing cytoplasm, whereas a strong green emission was observed in small lipid droplets. This fluorescence change from blue to green indicates that reoxidation of methyl-phenazine to PMS can occur. Regarding cell uptake and labeling mechanisms, QSAR models predict that the hydrophilic PMS is not significantly membrane-permeant, so most PMS reduction is expected to be extracellular and associated with a plasma membrane NAD(P)H reductase. Once formed, the lipophilic and blue-fluorescing methyl-phenazine enters live cells and mainly accumulates in lipid droplets. Overall, the results reported here indicate that PMS is an excellent fluorescent probe to investigate labeling and redox dynamics of lipid droplets in cultured cells.         _ Less","","arXiv","https://arxiv.org/abs/2109.00232","0","1","synthetic_biology"
"Bayesian and Algebraic Strategies to Design in Synthetic Biology","Abstract:                Innovation in synthetic biology often still depends on large-scale experimental trial-and-error, domain expertise, and ingenuity. The application of rational design engineering methods promise to make this more efficient, faster, cheaper and safer. But this requires mathematical models of cellular systems. And for these models we then have to determine if th_         _ More           Innovation in synthetic biology often still depends on large-scale experimental trial-and-error, domain expertise, and ingenuity. The application of rational design engineering methods promise to make this more efficient, faster, cheaper and safer. But this requires mathematical models of cellular systems. And for these models we then have to determine if they can meet our intended target behaviour. Here we develop two complementary approaches that allow us to determine whether a given molecular circuit, represented by a mathematical model, is capable of fulfilling our design objectives. We discuss algebraic methods that are capable of identifying general principles guaranteeing desired behaviour; and we provide an overview over Bayesian design approaches that allow us to choose from a set of models, that model which has the highest probability of fulfilling our design objectives. We discuss their uses in the context of biochemical adaptation, and then consider how robustness can and should affect our design approach.         _ Less","","arXiv","https://arxiv.org/abs/2108.07388","1","3","synthetic_biology"
"Active transport in complex environments","Abstract:                _this chapter, we describe recent progress in the study of active transport in such complex environments, focusing on two prominent biological systems -- bacteria and eukaryotic cells -- as archetypes of active matter. We review research findings highlighting how environmental factors can fundamentally alter cellular motility, hindering or promoting active tr_         _ More           The ability of many living systems to actively self-propel underlies critical biomedical, environmental, and industrial processes. While such active transport is well-studied in uniform settings, environmental complexities such as geometric constraints, mechanical cues, and external stimuli such as chemical gradients and fluid flow can strongly influence transport. In this chapter, we describe recent progress in the study of active transport in such complex environments, focusing on two prominent biological systems -- bacteria and eukaryotic cells -- as archetypes of active matter. We review research findings highlighting how environmental factors can fundamentally alter cellular motility, hindering or promoting active transport in unexpected ways, and giving rise to fascinating behaviors such as directed migration and large-scale clustering. In parallel, we describe specific open questions and promising avenues for future research. Furthermore, given the diverse forms of active matter -- ranging from enzymes and driven biopolymer assemblies, to microorganisms and synthetic microswimmers, to larger animals and even robots -- we also describe connections to other active systems as well as more general theoretical/computational models of transport processes in complex environments.         _ Less","","arXiv","https://arxiv.org/abs/2108.07011","1","2","synthetic_biology"
"Learning Orientations: a Discrete Geometry Model","Abstract:                In the mammalian brain, many neuronal ensembles are involved in representing spatial structure of the environment. In particular, there exist cells that encode the animal's location and_         _ More           In the mammalian brain, many neuronal ensembles are involved in representing spatial structure of the environment. In particular, there exist cells that encode the animal's location and cells that encode head direction. A number of studies have addressed properties of the spatial maps produced by these two populations of neurons, mainly by establishing correlations between their spiking parameters and geometric characteristics of the animal's environments. The question remains however, how the brain may intrinsically combine the direction and the location information into a unified spatial framework that enables animals' orientation. Below we propose a model of such a framework, using ideas and constructs from algebraic topology and synthetic affine geometry.         _ Less","","arXiv","https://arxiv.org/abs/2108.03532","1","0","origin_of_life"
"OncoEnrichR: cancer-dedicated gene set interpretation","Abstract:                _including ranked gene-tumor type associations, literature-supported proto-oncogene and tumor suppressor gene annotations, target druggability data, regulatory interactions, synthetic lethality predictions, as well as prognostic associations, gene aberrations, and co-expression patterns across tumor types. The software produces a structured and user-friendly_         _ More           Genome-scale screening experiments in cancer produce long lists of candidate genes that require extensive interpretation for biological insight and prioritization for follow-up studies. Interrogation of gene lists frequently represents a significant and time-consuming undertaking, in which experimental biologists typically combine results from a variety of bioinformatics resources in an attempt to portray and understand cancer relevance. As a means to simplify and strengthen the support for this endeavor, we have developed oncoEnrichR, a flexible bioinformatics tool that allows cancer researchers to comprehensively interrogate a given gene list along multiple facets of cancer relevance. oncoEnrichR differs from general gene set analysis frameworks through the integration of an extensive set of prior knowledge specifically relevant for cancer, including ranked gene-tumor type associations, literature-supported proto-oncogene and tumor suppressor gene annotations, target druggability data, regulatory interactions, synthetic lethality predictions, as well as prognostic associations, gene aberrations, and co-expression patterns across tumor types. The software produces a structured and user-friendly analysis report as its main output, where versions of all underlying data resources are explicitly logged, the latter being a critical component for reproducible science. We demonstrate the usefulness of oncoEnrichR through interrogation of two candidate lists from proteomic and CRISPR screens. oncoEnrichR is freely available as a web-based workflow hosted by the Galaxy platform (https://oncotools.elixir.no), and can also be accessed as a stand-alone R package (https://github.com/sigven/oncoEnrichR).         _ Less","","arXiv","https://arxiv.org/abs/2107.13247","1","1","multiple"
"AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned Disentangling Training","Abstract:                We consider unsupervised cell nuclei segmentation in this paper. Exploiting the recently-proposed unpaired image-to-image translation between_         _ More           We consider unsupervised cell nuclei segmentation in this paper. Exploiting the recently-proposed unpaired image-to-image translation between cell nuclei images and randomly synthetic masks, existing approaches, e.g., CycleGAN, have achieved encouraging results. However, these methods usually take a two-stage pipeline and fail to learn end-to-end in cell nuclei images. More seriously, they could lead to the lossy transformation problem, i.e., the content inconsistency between the original images and the corresponding segmentation output. To address these limitations, we propose a novel end-to-end unsupervised framework called Aligned Disentangling Generative Adversarial Network (AD-GAN). Distinctively, AD-GAN introduces representation disentanglement to separate content representation (the underling spatial structure) from style representation (the rendering of the structure). With this framework, spatial structure can be preserved explicitly, enabling a significant reduction of macro-level lossy transformation. We also propose a novel training algorithm able to align the disentangled content in the latent space to reduce micro-level lossy transformation. Evaluations on real-world 2D and 3D datasets show that AD-GAN substantially outperforms the other comparison methods and the professional software both quantitatively and qualitatively. Specifically, the proposed AD-GAN leads to significant improvement over the current best unsupervised methods by an average 17.8% relatively (w.r.t. the metric DICE) on four cell nuclei datasets. As an unsupervised method, AD-GAN even performs competitive with the best supervised models, taking a further leap towards end-to-end unsupervised nuclei segmentation.         _ Less","","arXiv","https://arxiv.org/abs/2107.11022","1","0","origin_of_life"
"A Miniaturized Programmable Multi-Fluidic Pneumatic System for precise control of Sample Preparation Environment","Abstract:                High-density microfluidics is becoming an important experimental platform for studying complex biological systems such as synthetic gene regulatory networks, molecular biocomputating of engineered cells, distributing rapid point-of-care diagnosis, and monitoring pathological environment. Imaging transient bio-chemical_         _ More           High-density microfluidics is becoming an important experimental platform for studying complex biological systems such as synthetic gene regulatory networks, molecular biocomputating of engineered cells, distributing rapid point-of-care diagnosis, and monitoring pathological environment. Imaging transient bio-chemical reactions happening in these systems at a single particle or cellular level requires precise time-dependent control of sample reaction and imaging conditions at the desired fluidic momentum. In this study, we showed our novel miniaturized and programmable electronic-based pneumatic system to meet the requirement. We demonstrated its capability to control reaction parameters such as concentrations and injection rates in a liposome production system.         _ Less","","arXiv","https://arxiv.org/abs/2107.09447","0","1","synthetic_biology"
"Cell density controls signal propagation waves in a multicellular synthetic gene circuit","Abstract:                _development, biochemical reaction networks sense and respond to mechanical forces to coordinate embryonic patterning with embryo morphogenesis. Factors such as cortical tension, cell density, and matrix mechanical properties influence differentiation and_         _ More           During organismal development, biochemical reaction networks sense and respond to mechanical forces to coordinate embryonic patterning with embryo morphogenesis. Factors such as cortical tension, cell density, and matrix mechanical properties influence differentiation and cell fate decisions by modulating gene regulatory signaling networks. A major goal in synthetic development is to construct gene regulatory circuits that program the patterning and morphogenesis of synthetic multicellular structures. However, in the synthetic context, little is known regarding how the physical properties of the growth environment impact the behavior of synthetic gene circuits. Here, we exploit physical-chemical coupling observed in a synthetic patterning circuit in order to control the size and spatial distribution of patterned synthetic cell sheets. We show that cell density attenuates the propagation of signal between neighboring cells in a multicellular sheet containing a contact-dependent patterning circuit based on the synNotch signaling system. Density-dependent attenuation leads to a signal propagation wave that exhibits distinct qualitative phases of persistent propagation, transient propagation, and no propagation. Through computational modeling, we demonstrate that cell growth parameters determine the phase of propagation observed within a growing cell sheet. Using growth-modulating drugs and spatial density gradients, we control the size of synNotch-activated cell populations and generate tissue-scale activation gradients and kinematic waves. Our study reveals that density-dependent synNotch activity can be exploited to control a synthetic multicellular patterning circuit. More broadly, we show that synthetic gene circuits can be critically impacted by their physical context, providing an alternate means for programming circuit behavior.         _ Less","","arXiv","https://arxiv.org/abs/2107.08116","0","4","synthetic_biology"
"Scalable Surface Reconstruction with Delaunay-Graph Neural Networks","Abstract:                _cope with the scale and variety of point cloud defects encountered in real-life Multi-View Stereo (MVS) acquisitions. Our method relies on a 3D Delaunay tetrahedralization whose cells are classified as inside or outside the surface by a graph neural network and an energy model solvable with a graph cut. Our model, making use of both local geometric attribute_         _ More           We introduce a novel learning-based, visibility-aware, surface reconstruction method for large-scale, defect-laden point clouds. Our approach can cope with the scale and variety of point cloud defects encountered in real-life Multi-View Stereo (MVS) acquisitions. Our method relies on a 3D Delaunay tetrahedralization whose cells are classified as inside or outside the surface by a graph neural network and an energy model solvable with a graph cut. Our model, making use of both local geometric attributes and line-of-sight visibility information, is able to learn a visibility model from a small amount of synthetic training data and generalizes to real-life acquisitions. Combining the efficiency of deep learning methods and the scalability of energy based models, our approach outperforms both learning and non learning-based reconstruction algorithms on two publicly available reconstruction benchmarks. Our code and data is available at https://github.com/raphaelsulzer/dgnn.         _ Less","","arXiv","https://arxiv.org/abs/2107.06130","1","0","origin_of_life"
"Hierarchical Semantic Segmentation using Psychometric Learning","Abstract:                _the set of classes does not fully capture the rich semantic information present in the images. For example, in medical imaging such as histology images, the different parts of cells could be grouped and sub-grouped based on the expertise of the pathologist.   To achieve such a precise semantic representation of the concepts in the image, we need access to t_         _ More           Assigning meaning to parts of image data is the goal of semantic image segmentation. Machine learning methods, specifically supervised learning is commonly used in a variety of tasks formulated as semantic segmentation. One of the major challenges in the supervised learning approaches is expressing and collecting the rich knowledge that experts have with respect to the meaning present in the image data. Towards this, typically a fixed set of labels is specified and experts are tasked with annotating the pixels, patches or segments in the images with the given labels. In general, however, the set of classes does not fully capture the rich semantic information present in the images. For example, in medical imaging such as histology images, the different parts of cells could be grouped and sub-grouped based on the expertise of the pathologist.   To achieve such a precise semantic representation of the concepts in the image, we need access to the full depth of knowledge of the annotator. In this work, we develop a novel approach to collect segmentation annotations from experts based on psychometric testing. Our method consists of the psychometric testing procedure, active query selection, query enhancement, and a deep metric learning model to achieve a patch-level image embedding that allows for semantic segmentation of images. We show the merits of our method with evaluation on the synthetically generated image, aerial image and histology image.         _ Less","","arXiv","https://arxiv.org/abs/2107.03212","1","0","origin_of_life"
"A Systematic Review of Bio-Cyber Interface Technologies and Security Issues for Internet of Bio-Nano Things","Abstract:                Advances in synthetic biology and nanotechnology have contributed to the design of tools that can be used to control, reuse, modify, and re-engineer cells' structure, as well as enabling engineers to effectively use biological cells as programmable substrates to realize Bio-N_         _ More           Advances in synthetic biology and nanotechnology have contributed to the design of tools that can be used to control, reuse, modify, and re-engineer cells' structure, as well as enabling engineers to effectively use biological cells as programmable substrates to realize Bio-Nano Things (biological embedded computing devices). Bio-NanoThings are generally tiny, non-intrusive, and concealable devices that can be used for in-vivo applications such as intra-body sensing and actuation networks, where the use of artificial devices can be detrimental. Such (nano-scale) devices can be used in various healthcare settings such as continuous health monitoring, targeted drug delivery, and nano-surgeries. These services can also be grouped to form a collaborative network (i.e., nanonetwork), whose performance can potentially be improved when connected to higher bandwidth external networks such as the Internet, say via 5G. However, to realize the IoBNT paradigm, it is also important to seamlessly connect the biological environment with the technological landscape by having a dynamic interface design to convert biochemical signals from the human body into an equivalent electromagnetic signal (and vice versa). This, unfortunately, risks the exposure of internal biological mechanisms to cyber-based sensing and medical actuation, with potential security and privacy implications. This paper comprehensively reviews bio-cyber interface for IoBNT architecture, focusing on bio-cyber interfacing options for IoBNT like biologically inspired bio-electronic devices, RFID enabled implantable chips, and electronic tattoos. This study also identifies known and potential security and privacy vulnerabilities and mitigation strategies for consideration in future IoBNT designs and implementations.         _ Less","","arXiv","https://arxiv.org/abs/2106.14273","2","3","synthetic_biology"
"Instrumental Variable Estimation for Compositional Treatments","Abstract:                Many scientific datasets are compositional in nature. Important biological examples include species abundances in ecology, cell-type compositions derived from single-_         _ More           Many scientific datasets are compositional in nature. Important biological examples include species abundances in ecology, cell-type compositions derived from single-cell sequencing data, and amplicon abundance data in microbiome research. Here, we provide a causal view on compositional data in an instrumental variable setting where the composition acts as the cause. First, we crisply articulate potential pitfalls for practitioners regarding the interpretation of compositional causes from the viewpoint of interventions and warn against attributing causal meaning to common summary statistics such as diversity indices in microbiome data analysis. We then advocate for and develop multivariate methods using statistical data transformations and regression techniques that take the special structure of the compositional sample space into account while still yielding scientifically interpretable results. In a comparative analysis on synthetic and real microbiome data we show the advantages and limitations of our proposal. We posit that our analysis provides a useful framework and guidance for valid and informative cause-effect estimation in the context of compositional data.         _ Less","","arXiv","https://arxiv.org/abs/2106.11234","1","0","origin_of_life"
"Engineered Bacteria Computationally Solve Chemically Generated 2X2 Maze Problems","Abstract:                _the sixteen different 2X2 maze problems on a chemical space. Our engineered bacteria, which consisted of six different genetic logic circuits and distributed among six cell populations processed the chemical information and solved the problems by expressing or not expressing four different fluorescent proteins. The three available solutions were visualized b_         _ More           Maze generating and solving are challenging problems in mathematics and computing. Here we generated simple 2X2 maze problems applying four chemicals and created a set of engineered bacteria, which in a mixed population worked as a computational solver for any such problem. The input-output matrices of a mathematical maze were mapped through a truth table, where the logic values of four chemical inputs determined the sixteen different 2X2 maze problems on a chemical space. Our engineered bacteria, which consisted of six different genetic logic circuits and distributed among six cell populations processed the chemical information and solved the problems by expressing or not expressing four different fluorescent proteins. The three available solutions were visualized by glowing bacteria and for the thirteen no solution cases no bacteria glowed. Thus, our system not only solved the maze problems but also showed the number of solvable and unsolvable problems. This work presented a new and abstract cellular computational way towards maze problems and may have significance in biocomputation and synthetic biology.         _ Less","","arXiv","https://arxiv.org/abs/2106.09882","1","1","multiple"
"Detecting chaos in lineage-trees: A deep learning approach","Abstract:                _in particular models of biological systems. We describe a novel method for estimating the largest Lyapunov exponent from data, based on training Deep Learning models on synthetically generated trajectories, and demonstrate that this method yields accurate and noise-robust predictions given relatively short inputs and across a range of different dynamical sy_         _ More           Many complex phenomena, from weather systems to heartbeat rhythm patterns, are effectively modeled as low-dimensional dynamical systems. Such systems may behave chaotically under certain conditions, and so the ability to detect chaos based on empirical measurement is an important step in characterizing and predicting these processes. Classifying a system as chaotic usually requires estimating its largest Lyapunov exponent, which quantifies the average rate of convergence or divergence of initially close trajectories in state space, and for which a positive value is generally accepted as an operational definition of chaos. Estimating the largest Lyapunov exponent from observations of a process is especially challenging in systems affected by dynamical noise, which is the case for many models of real-world processes, in particular models of biological systems. We describe a novel method for estimating the largest Lyapunov exponent from data, based on training Deep Learning models on synthetically generated trajectories, and demonstrate that this method yields accurate and noise-robust predictions given relatively short inputs and across a range of different dynamical systems. Our method is unique in that it can analyze tree-shaped data, a ubiquitous topology in biological settings, and specifically in dynamics over lineages of cells or organisms. We also characterize the types of input information extracted by our models for their predictions, allowing for a deeper understanding into the different ways by which chaos can be analyzed in different topologies.         _ Less","","arXiv","https://arxiv.org/abs/2106.08956","1","0","origin_of_life"
"SED-ML Validator: tool for debugging simulation experiments","Abstract:                Summary: More sophisticated models are needed to address problems in bioscience, synthetic biology, and precision medicine. To help facilitate the collaboration needed for such models, the community developed the Simulation Experiment Description Markup Language (SED-ML), a common format for describing simulations. However, the utility of SED-ML has been ham_         _ More           Summary: More sophisticated models are needed to address problems in bioscience, synthetic biology, and precision medicine. To help facilitate the collaboration needed for such models, the community developed the Simulation Experiment Description Markup Language (SED-ML), a common format for describing simulations. However, the utility of SED-ML has been hampered by limited support for SED-ML among modeling software tools and by different interpretations of SED-ML among the tools that support the format. To help modelers debug their simulations and to push the community to use SED-ML consistently, we developed a tool for validating SED-ML files. We have used the validator to correct the official SED-ML example files. We plan to use the validator to correct the files in the BioModels database so that they can be simulated. We anticipate that the validator will be a valuable tool for developing more predictive simulations and that the validator will help increase the adoption and interoperability of SED-ML.   Availability: The validator is freely available as a webform, HTTP API, command-line program, and Python package at https://run.biosimulations.org/utils/validate and https://pypi.org/project/biosimulators-utils. The validator is also embedded into interfaces to 11 simulation tools. The source code is openly available as described in the Supplementary data.   Contact: karr@mssm.edu         _ Less","","arXiv","https://arxiv.org/abs/2106.00844","0","1","synthetic_biology"
"Heavily Doped Semiconductor Nanocrystal Quantum Dots","Abstract:                _family of materials where size, composition and shape-control offer widely tunable optical and electronic properties, doping has proven elusive. This arises both from the synthetic challenge of how to introduce single impurities and from a lack of fundamental understanding of this heavily doped limit under strong quantum confinement. We develop a method to d_         _ More           Doping of semiconductors by impurity atoms enabled their widespread technological application in micro and opto-electronics. For colloidal semiconductor nanocrystals, an emerging family of materials where size, composition and shape-control offer widely tunable optical and electronic properties, doping has proven elusive. This arises both from the synthetic challenge of how to introduce single impurities and from a lack of fundamental understanding of this heavily doped limit under strong quantum confinement. We develop a method to dope semiconductor nanocrystals with metal impurities providing control of the band gap and Fermi energy. A combination of optical measurements, scanning tunneling spectroscopy and theory revealed the emergence of a confined impurity band and band-tailing. Successful control of doping and its understanding provide n- and p-doped semiconductor nanocrystals which greatly enhance the potential application of such materials in solar cells, thin-film transistors, and optoelectronic devices.         _ Less","","arXiv","https://arxiv.org/abs/2105.10877","1","0","origin_of_life"
"Dynamic Actuation of DNA-Assembled Plasmonic Nanostructures in Microfluidic Cell-Sized Compartments","Abstract:                _led to the creation of their DNA-based mimics, which can carry out complex nanoscale motion. However, such functional analogues have not yet been integrated or operated inside synthetic_         _ More           Molecular motor proteins form the basis of cellular dynamics. Recently, notable efforts have led to the creation of their DNA-based mimics, which can carry out complex nanoscale motion. However, such functional analogues have not yet been integrated or operated inside synthetic cells toward the goal of realizing artificial biological systems entirely from the bottom-up. In this Letter, we encapsulate and actuate DNA-assembled dynamic nanostructures inside cell-sized microfluidic compartments. These encapsulated DNA nanostructures not only exhibit structural reconfigurability owing to their pH-sensitive molecular switches upon external stimuli but also possess optical feedback enabled by the integrated plasmonic probes. In particular, we demonstrate the power of microfluidic compartmentalization for achieving on-chip plasmonic enantiomer separation and substrate filtration. Our work exemplifies that the two unique tools, droplet-based microfluidics and DNA technology, offering high precision on the microscale and nanoscale, respectively, can be brought together to greatly enrich the complexity and diversity of functional synthetic systems.         _ Less","","arXiv","https://arxiv.org/abs/2105.05904","0","3","synthetic_biology"
"DNA origami","Abstract:                Biological materials are self-assembled with near-atomic precision in living cells, whereas synthetic 3D structures generally lack such precision and controllability. Recently, DNA nanotechnology, especially DNA origami technology, has been useful in the bottom-up fabrication of well-defined nanostructures ranging from_         _ More           Biological materials are self-assembled with near-atomic precision in living cells, whereas synthetic 3D structures generally lack such precision and controllability. Recently, DNA nanotechnology, especially DNA origami technology, has been useful in the bottom-up fabrication of well-defined nanostructures ranging from tens of nanometres to sub-micrometres. In this Primer, we summarize the methodologies of DNA origami technology, including origami design, synthesis, functionalization and characterization. We highlight applications of origami structures in nanofabrication, nanophotonics and nanoelectronics, catalysis, computation, molecular machines, bioimaging, drug delivery and biophysics. We identify challenges for the field, including size limits, stability issues and the scale of production, and discuss their possible solutions. We further provide an outlook on next-generation DNA origami techniques that will allow in vivo synthesis and multiscale manufacturing.         _ Less","","arXiv","https://arxiv.org/abs/2104.15016","0","1","synthetic_biology"
"Chandrayaan-2 Dual-Frequency SAR (DFSAR): Performance Characterization and Initial Results","Abstract:                The Dual-Frequency synthetic aperture radar (DFSAR) system manifested on the Chandrayaan-2 spacecraft represents a significant step forward in radar exploration of solid solar system objects. It combines SAR at two wavelengths (L- and S-bands) and multiple resolutions with several polarimetric modes in one lightweight ($\\sim$ 20 kg) package. The resulting da_         _ More           The Dual-Frequency synthetic aperture radar (DFSAR) system manifested on the Chandrayaan-2 spacecraft represents a significant step forward in radar exploration of solid solar system objects. It combines SAR at two wavelengths (L- and S-bands) and multiple resolutions with several polarimetric modes in one lightweight ($\\sim$ 20 kg) package. The resulting data from DFSAR support calculation of the 2$\\times$2 complex scattering matrix for each resolution cell, which enables lunar near surface characterization in terms of radar polarization properties at different wavelengths and incidence angles. In this paper, we report on the calibration and preliminary performance characterization of DFSAR data based on the analysis of a sample set of crater regions on the Moon. Our calibration analysis provided a means to compare on-orbit performance with pre-launch measurements and the results matched with the pre-launch expected values. Our initial results show that craters in both permanently shadowed regions (PSRs) and non-PSRs that are classified as Circular Polarization Ratio (CPR)-anomalous in previous S-band radar analyses appear anomalous at L-band also. We also observe that material evolution and physical properties at their interior and proximal ejecta are decoupled. For Byrgius C crater region, we compare our analysis of dual-frequency radar data with the predicted behaviours of theoretical scattering models. If crater age estimates are available, comparison of their radar polarization properties at multiple wavelengths similar to that of the three unnamed south polar crater regions shown in this study may provide new insights into how the rockiness of craters evolves with time.         _ Less","","arXiv","https://arxiv.org/abs/2104.14259","0","1","synthetic_biology"
"A Bayesian Modified Ising Model for Identifying Spatially Variable Genes from Spatial Transcriptomics Data","Abstract:                A recent technology breakthrough in spatial molecular profiling has enabled the comprehensive molecular characterizations of single cells while preserving spatial information. It provides new opportunities to delineate how_         _ More           A recent technology breakthrough in spatial molecular profiling has enabled the comprehensive molecular characterizations of single cells while preserving spatial information. It provides new opportunities to delineate how cells from different origins form tissues with distinctive structures and functions. One immediate question in spatial molecular profiling data analysis is to identify genes whose expressions exhibit spatially correlated patterns, called spatially variable genes. Most current methods to identify spatially variable genes are built upon the geostatistical model with Gaussian process to capture the spatial patterns, which rely on ad hoc kernels that could limit the models' ability to identify complex spatial patterns. In order to overcome this challenge and capture more types of spatial patterns, we introduce a Bayesian approach to identify spatially variable genes via a modified Ising model. The key idea is to use the energy interaction parameter of the Ising model to characterize spatial expression patterns. We use auxiliary variable Markov chain Monte Carlo algorithms to sample from the posterior distribution with an intractable normalizing constant in the model. Simulation studies using both simulated and synthetic data showed that the energy-based modeling approach led to higher accuracy in detecting spatially variable genes than those kernel-based methods. When applied to two real spatial transcriptomics datasets, the proposed method discovered novel spatial patterns that shed light on the biological mechanisms. In summary, the proposed method presents a new perspective for analyzing spatial transcriptomics data.         _ Less","","arXiv","https://arxiv.org/abs/2104.13957","2","1","origin_of_life"
"Tracking Cells and their Lineages via Labeled Random Finite Sets","Abstract:                Determining the trajectories of cells and their lineages or ancestries in live-_         _ More           Determining the trajectories of cells and their lineages or ancestries in live-cell experiments are fundamental to the understanding of how cells behave and divide. This paper proposes novel online algorithms for jointly tracking and resolving lineages of an unknown and time-varying number of cells from time-lapse video data. Our approach involves modeling the cell ensemble as a labeled random finite set with labels representing cell identities and lineages. A spawning model is developed to take into account cell lineages and changes in cell appearance prior to division. We then derive analytic filters to propagate multi-object distributions that contain information on the current cell ensemble including their lineages. We also develop numerical implementations of the resulting multi-object filters. Experiments using simulation, synthetic cell migration video, and real time-lapse sequence, are presented to demonstrate the capability of the solutions.         _ Less","","arXiv","https://arxiv.org/abs/2104.10964","1","1","multiple"
"Biomaterial design inspired by membraneless organelles","Abstract:                _organelles (MOs). Membraneless organelles (MOs) are phase-separated liquid compartments that provide spatiotemporal control of biomolecules and metabolic activities inside a cell. While MOs exhibit intriguing properties such as efficient compositional regulation, thermodynamic metastability, environmental sensitivity and reversibility, their formation is dri_         _ More           Compartmentalization is ubiquitous in the broad cellular context, especially in the formation of membraneless organelles (MOs). Membraneless organelles (MOs) are phase-separated liquid compartments that provide spatiotemporal control of biomolecules and metabolic activities inside a cell. While MOs exhibit intriguing properties such as efficient compositional regulation, thermodynamic metastability, environmental sensitivity and reversibility, their formation is driven by weak non-covalent interactions derived from simple motifs of intrinsic disordered proteins (IDPs). Understanding the natural design of IDPs and the liquid-liquid phase separation behavior will not only reveal insights about the contributions of MOs to cellular physiology and disease pathology, but also provides inspirations for the de novo design of dynamic biomolecules depots, self-regulated biochemical reactors, and stimuli-responsive systems. In this article, the sequence and structural features of IDPS that contribute to the organization of MOs are reviewed. Artificial MOs formed following these principles, including self-assembling peptides, synthetic IDPs, polyelectrolytes and peptide-polymer hybrids are described. Finally, we illustrate the applications and discuss the potential of the MO-inspired biomaterials, with examples spanning biochemical reactors, synthetic biology, drug discovery and drug delivery.         _ Less","","arXiv","https://arxiv.org/abs/2104.10927","2","3","synthetic_biology"
"Modeling biological networks: from single gene systems to large microbial communities","Abstract:                In this research, we study biological networks at different scales: a gene autoregulatory network at the single-cell level and the gut microbiota at the population level.   Proteins are the main actors in_         _ More           In this research, we study biological networks at different scales: a gene autoregulatory network at the single-cell level and the gut microbiota at the population level.   Proteins are the main actors in cells, they are the building blocks, act as enzymes and antibodies. The production of proteins is mediated by transcription factors. In some cases, a protein acts as its own transcription factor, this is called autoregulation. It is known that autorepression speeds up the response and that autoactivation can lead to multiple stable equilibria. In this thesis, we study the effects of the combination of activation and repression in autoregulation, as a case study we investigate the possible dynamics of the leucine responsive protein B of the archaeon Sulfolobus solfataricus (Ss-LrpB), a protein that regulates itself in a unique and non-monotonic way via three binding boxes. We examine for which conditions this type of network leads to oscillations or bistability.   In the second part, much larger biological systems are considered. Ecological systems, among which the human gut microbiome, are characterized by heavy-tailed abundance profiles. We study how these distributions can arise from population-based models by adding saturation effects and linear noise. Moreover, we examine different characteristics of experimental time series of microbial communities, such as the noise color and neutrality of the biodiversity, and look at the influence of the parameters on these characteristics. With the first research topic we want to lay a foundation for the understanding of non-monotonic gene regulation and take the first steps toward synthetic biology in archaea. In the second part of the thesis, we investigate experimental time series from complex ecosystems and seek theoretical models reproducing all observed characteristics in view of building predictive models.         _ Less","","arXiv","https://arxiv.org/abs/2104.10082","0","2","synthetic_biology"
"Synthetic aperture interference light (SAIL) microscopy for high-throughput label-free imaging","Abstract:                _solutions to this problem involve computational phase retrieval algorithms, which are time-consuming and often suffer from convergence problems. In this article, we presented synthetic aperture interference light (SAIL) microscopy as a novel modality for high-resolution, wide field of view QPI. The proposed approach employs low-coherence interferometry to di_         _ More           Quantitative phase imaging (QPI) is a valuable label-free modality that has gained significant interest due to its wide potentials, from basic biology to clinical applications. Most existing QPI systems measure microscopic objects via interferometry or nonlinear iterative phase reconstructions from intensity measurements. However, all imaging systems compromise spatial resolution for field of view and vice versa, i.e., suffer from a limited space bandwidth product. Current solutions to this problem involve computational phase retrieval algorithms, which are time-consuming and often suffer from convergence problems. In this article, we presented synthetic aperture interference light (SAIL) microscopy as a novel modality for high-resolution, wide field of view QPI. The proposed approach employs low-coherence interferometry to directly measure the optical phase delay under different illumination angles and produces large space-bandwidth product (SBP) label-free imaging. We validate the performance of SAIL on standard samples and illustrate the biomedical applications on various specimens: pathology slides, entire insects, and dynamic live cells in large cultures. The reconstructed images have a synthetic numeric aperture of 0.45, and a field of view of 2.6 x 2.6 mm2. Due to its direct measurement of the phase information, SAIL microscopy does not require long computational time, eliminates data redundancy, and always converges.         _ Less","","arXiv","https://arxiv.org/abs/2104.07169","1","0","origin_of_life"
"Practical Resources for Enhancing the Reproducibility of Mechanistic Modeling in Systems Biology","Abstract:                _systems biology research. In turn, we believe enhanced reproducibility would accelerate the development of more sophisticated models that could inform precision medicine and synthetic biology.         _ More           Although reproducibility is a core tenet of the scientific method, it remains challenging to reproduce many results. Surprisingly, this also holds true for computational results in domains such as systems biology where there have been extensive standardization efforts. For example, Tiwari et al. recently found that they could only repeat 50% of published simulation results in systems biology. Toward improving the reproducibility of computational systems research, we identified several resources that investigators can leverage to make their research more accessible, executable, and comprehensible by others. In particular, we identified several domain standards and curation services, as well as powerful approaches pioneered by the software engineering industry that we believe many investigators could adopt. Together, we believe these approaches could substantially enhance the reproducibility of systems biology research. In turn, we believe enhanced reproducibility would accelerate the development of more sophisticated models that could inform precision medicine and synthetic biology.         _ Less","","arXiv","https://arxiv.org/abs/2104.04604","0","1","synthetic_biology"
"Topological Disclination Pump","Abstract:                _previous studies, topological pump was achieved inhomogeneous systems guaranteed by a topological invariant of the bulk band structure when time is included as an additional synthetic dimension. Recently, bulk-boundary correspondence has been generalized to the bulk-disclination correspondence, describing the emergence of topological bounded states in the cr_         _ More           A topological pump enables robust transport of quantized particles when the system parameters are varied in a cyclic process. In previous studies, topological pump was achieved inhomogeneous systems guaranteed by a topological invariant of the bulk band structure when time is included as an additional synthetic dimension. Recently, bulk-boundary correspondence has been generalized to the bulk-disclination correspondence, describing the emergence of topological bounded states in the crystallographic defects protected by the bulk topology. Here we show the topological pumping can happen between different disclination states with different chiralities in an inhomogeneous structure. Based on a generalized understanding of the charge pumping process, we explain the topological disclination pump by tracing the motion of Wannier centers in each unit cell. Besides, by constructing two disclination structures and introducing a symmetry-breaking perturbation, we achieve a topological pumping between different dislocation cores. Our result opens a route to study the topological pumping in inhomogeneous topological crystalline systems and provides a flexible platform for robust energy transport.         _ Less","","arXiv","https://arxiv.org/abs/2104.02852","1","0","origin_of_life"
"Exact Probability Landscapes of Stochastic Phenotype Switching in Feed-Forward Loops: Phase Diagrams of Multimodality","Abstract:                _Furthermore, we found that gene duplication can enlarge stable regions of specific multimodalities and enrich the phenotypic diversity of FFL networks, providing means for cells towards better adaptation to changing environment. Our results are directly applicable to analysis of behavior of FFLs in biological processes such as stem_         _ More           Feed-forward loops (FFLs) are among the most ubiquitously found motifs of reaction networks in nature. However, little is known about their stochastic behavior and the variety of network phenotypes they can exhibit. In this study, we provide full characterizations of the properties of stochastic multimodality of FFLs, and how switching between different network phenotypes are controlled. We have computed the exact steady state probability landscapes of all eight types of coherent and incoherent FFLs using the finite-butter ACME algorithm, and quantified the exact topological features of their high-dimensional probability landscapes using persistent homology. Through analysis of the degree of multimodality for each of a set of 10,812 probability landscapes, where each landscape resides over 10^5-10^6 microstates, we have constructed comprehensive phase diagrams of all relevant behavior of FFL multimodality over broad ranges of input and regulation intensities, as well as different regimes of promoter binding dynamics. Our results show that with slow binding and unbinding dynamics of transcription factor to promoter, FFLs exhibit strong stochastic behavior that is very different from what would be inferred from deterministic models. In addition, input intensity play major roles in the phenotypes of FFLs: At weak input intensity, FFL exhibit monomodality, but strong input intensity may result in up to 6 stable phenotypes. Furthermore, we found that gene duplication can enlarge stable regions of specific multimodalities and enrich the phenotypic diversity of FFL networks, providing means for cells towards better adaptation to changing environment. Our results are directly applicable to analysis of behavior of FFLs in biological processes such as stem cell differentiation and for design of synthetic networks when certain phenotypic behavior is desired.         _ Less","","arXiv","https://arxiv.org/abs/2104.02672","1","3","synthetic_biology"
"Mesoporous silica nanoparticles containing silver as novel antimycobacterial agents against Mycobacterium tuberculosis","Abstract:                _their use is limited by their relatively high toxicity, which calls for the design of nanocarriers that allow silver based nanoparticles to be safely delivered to the target cells or tissues. In this work mesoporous silica nanoparticles are used as carriers of silver based nanoparticles as antimycobacterial agent against Mtb. Two different_         _ More           Tuberculosis remains today a major public health issue with a total of 9 million new cases and 2 million deaths annually. The lack of an effective vaccine and the increasing emergence of new strains of Mycobacterium tuberculosis (Mtb) highly resistant to antibiotics, anticipate a complicated scenario in the near future. The use of nanoparticles features as an alternative to antibiotics in tackling this problem due to their potential effectiveness in resistant bacterial strains. In this context, silver nanoparticles have demonstrated high bactericidal efficacy, although their use is limited by their relatively high toxicity, which calls for the design of nanocarriers that allow silver based nanoparticles to be safely delivered to the target cells or tissues. In this work mesoporous silica nanoparticles are used as carriers of silver based nanoparticles as antimycobacterial agent against Mtb. Two different synthetic approaches have been used to afford, on the one hand, a 2D hexagonal mesoporous silica nanosystem which contains silver bromide nanoparticles distributed all through the silica network and, on the other hand, a core@shell nanosystem with metallic silver nanoparticles as core and mesoporous silica shell in a radial mesoporous rearrangement. Both materials have demonstrated good antimycobacterial capacity in in vitro test using Mtb, being lower the minimum inhibitory concentration for the nanosystem which contains silver bromide. Therefore, the interaction of this material with the mycobacterial cell has been studied by cryo-electron microscopy, establishing a direct connection between the antimycobactericidal effect observed and the damage induced in the cell envelope.         _ Less","","arXiv","https://arxiv.org/abs/2104.01649","1","0","origin_of_life"
"A Voronoi-tessellation-based approach for detection of coherent structures in sparsely-seeded flows","Abstract:                _the Voronoi tessellation of the tracers' distribution. The method examines the \\textit{neighbouring time} of tracer trajectories, defined as the total flow time two Voronoi cells share a common Voronoi edge, by converting this information into a Cartesian distance in the graph representation of the Voronoi diagram. Coherence is assigned to groups of Voro_         _ More           A novel algorithm to detect coherent structures with sparse Lagrangian particle tracking data, using Voronoi tessellation and techniques from spectral graph theory, is tested. Neighbouring tracer particles are naturally identified through the Voronoi tessellation of the tracers' distribution. The method examines the \\textit{neighbouring time} of tracer trajectories, defined as the total flow time two Voronoi cells share a common Voronoi edge, by converting this information into a Cartesian distance in the graph representation of the Voronoi diagram. Coherence is assigned to groups of Voronoi cells whose neighbouring time remains high throughout the time interval of analysis. The technique is first tested on the two-dimensional synthetic data of a double-gyre flow, and then with challenging, large-scale three-dimensional Lagrangian particle tracking data behind a bluff body at high Reynolds number. The tested technique proves to be successful at identifying coherence with realistic experimental data. Specifically, it is shown that coherent tracer motion is identifiable for mean inter-particle distances of the order of the largest length scales in the flow.         _ Less","","arXiv","https://arxiv.org/abs/2103.09884","1","0","origin_of_life"
"Effects of a mesoporous bioactive glass on osteoblasts, osteoclasts and macrophages","Abstract:                A mesoporous bioactive glass (MBG) of molar composition 75SiO2-20CaO-5P2O5 (MBG-75S) has been synthetized as a potential bioceramic for bone regeneration purposes. X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FT-IR), nitrogen adsorption studies and transmission electron microscopy (TEM) demonstrated that MBG-75Spossess a highly ordered m_         _ More           A mesoporous bioactive glass (MBG) of molar composition 75SiO2-20CaO-5P2O5 (MBG-75S) has been synthetized as a potential bioceramic for bone regeneration purposes. X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FT-IR), nitrogen adsorption studies and transmission electron microscopy (TEM) demonstrated that MBG-75Spossess a highly ordered mesoporous structure with high surface area and porosity, which would explain the high ionic exchange rate (mainly calcium and silicon soluble species) with the surrounded media. MBG-75S showed high biocompatibility in contact with Saos-2 osteoblast-like cells. Concentrations up to 1 mg/ml did not lead to significant alterations on either morphology or cell cycle. Regarding the effects on osteoclasts, MBG-75S allowed the differentiation of RAW-264.7 macrophages into osteoclast-like cells but exhibiting a decreased resorptive activity. These results point out that MBG-75S does not inhibit osteoclastogenesis but reduces the osteoclast boneresorbing capability. Finally, in vitro studies focused on the innate immune response, evidenced that MBG-75S allows the proliferation of macrophages without inducing their polarization towards the M1 pro-inflammatory phenotype. This in vitro behavior is indicative that MBG-75S would just induce the required innate immune response without further inflammatory complications under in vivo conditions. The overall behavior respect to osteoblasts, osteoclasts and macrophages, makes this MBG a very interesting candidate for bone grafting applications in osteoporotic patients.         _ Less","","arXiv","https://arxiv.org/abs/2103.08552","0","1","synthetic_biology"
"NaroNet: Discovery of tumor microenvironment elements from highly multiplexed images","Abstract:                _complexity of their spatial interactions. We present NaroNet, which uses machine learning to identify and annotate known as well as novel TMEs from self-supervised embeddings of cells, organized at different levels (local_         _ More           Many efforts have been made to discover tumor-specific microenvironment elements (TMEs) from immunostained tissue sections. However, the identification of yet unknown but relevant TMEs from multiplex immunostained tissues remains a challenge, due to the number of markers involved (tens) and the complexity of their spatial interactions. We present NaroNet, which uses machine learning to identify and annotate known as well as novel TMEs from self-supervised embeddings of cells, organized at different levels (local cell phenotypes and cellular neighborhoods). Then it uses the abundance of TMEs to classify patients based on biological or clinical features. We validate NaroNet using synthetic patient cohorts with adjustable incidence of different TMEs and two cancer patient datasets. In both synthetic and real datasets, NaroNet unsupervisedly identifies novel TMEs, relevant for the user-defined classification task. As NaroNet requires only patient-level information, it renders state-of-the-art computational methods accessible to a broad audience, accelerating the discovery of biomarker signatures.         _ Less","","arXiv","https://arxiv.org/abs/2103.05385","1","0","origin_of_life"
"Diffusive search and trajectories on spatial networks: a propagator approach","Abstract:                Several organelles in eukaryotic cells, including mitochondria and the endoplasmic reticulum, form interconnected tubule networks extending throughout the_         _ More           Several organelles in eukaryotic cells, including mitochondria and the endoplasmic reticulum, form interconnected tubule networks extending throughout the cell. These tubular networks host many biochemical pathways that rely on proteins diffusively searching through the network to encounter binding partners or localized target regions. In this work we develop both exact analytical methods to compute mean first passage times and efficient kinetic Monte Carlo algorithms to simulate trajectories of particles diffusing in a tubular network. Our approach leverages exact propagator functions for the distribution of transition times between network nodes and allows large simulation time steps determined by the network structure. The methodology is applied to both synthetic planar networks and organelle network structures, demonstrating key general features such as the heterogeneity of search times in different network regions and the functional advantage of broadly distributing target sites throughout the network. The proposed algorithms pave the way for future exploration of the interrelationship between tubular network structure and biomolecular reaction kinetics.         _ Less","","arXiv","https://arxiv.org/abs/2103.05065","0","1","synthetic_biology"
"Spatio-temporal Graph-RNN for Point Cloud Prediction","Abstract:                _layer learns topological information of point clouds as geometric features, to form representative spatio-temporal neighborhoods. This module is followed by multiple Graph-RNN cells. Each_         _ More           In this paper, we propose an end-to-end learning network to predict future frames in a point cloud sequence. As main novelty, an initial layer learns topological information of point clouds as geometric features, to form representative spatio-temporal neighborhoods. This module is followed by multiple Graph-RNN cells. Each cell learns points dynamics (i.e., RNN states) by processing each point jointly with the spatio-temporal neighbouring points. We tested the network performance with a MINST dataset of moving digits, a synthetic human bodies motions and JPEG dynamic bodies datasets. Simulation results demonstrate that our method outperforms baseline ones that neglect geometry features information.         _ Less","","arXiv","https://arxiv.org/abs/2102.07482","1","0","origin_of_life"
"Sarc-Graph: Automated segmentation, tracking, and analysis of sarcomeres in hiPSC-derived cardiomyocytes","Abstract:                A better fundamental understanding of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) has the potential to advance applications ranging from drug discovery to cardiac repair. Automated quantitative analysis of beating hiPSC-CMs is an important and fast developing component of the hiPSC-CM research pipeline. Here we introduce 'Sarc-_         _ More           A better fundamental understanding of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) has the potential to advance applications ranging from drug discovery to cardiac repair. Automated quantitative analysis of beating hiPSC-CMs is an important and fast developing component of the hiPSC-CM research pipeline. Here we introduce 'Sarc-Graph,' a computational framework to segment, track, and analyze sarcomeres in fluorescently tagged hiPSC-CMs. Our framework includes functions to segment z-discs and sarcomeres, track z-discs and sarcomeres in beating cells, and perform automated spatiotemporal analysis and data visualization. In addition to reporting good performance for sarcomere segmentation and tracking with little to no parameter tuning and a short runtime, we introduce two novel analysis approaches. First, we construct spatial graphs where z-discs correspond to nodes and sarcomeres correspond to edges. This makes measuring the network distance between each sarcomere (i.e., the number of connecting sarcomeres separating each sarcomere pair) straightforward. Second, we treat tracked and segmented components as fiducial markers and use them to compute the approximate deformation gradient of the entire tracked population. This represents a new quantitative descriptor of hiPSC-CM function. We showcase and validate our approach with both synthetic and experimental movies of beating hiPSC-CMs. By publishing Sarc-Graph, we aim to make automated quantitative analysis of hiPSC-CM behavior more accessible to the broader research community.         _ Less","","arXiv","https://arxiv.org/abs/2102.02412","1","0","origin_of_life"
"A new generalization of Parrondo's games to three players and its application in genetic switches","Abstract:                _It can also be used for genetic switches. Genetic switches are often made by two reactive elements, but the existence of more elements can lead to more existing decisions for cells. Each genetic switch can be considered a game in which the reactive elements compete to increase their molecular concentrations. We present three genetic networks based on a new_         _ More           Parrondo's paradox indicates a paradoxical situation in which a winning expectation may occur in sequences of losing games. There are many versions of the original Parrondo's games in the literature, but the games are played by two players in all of them. We introduce a new extended version of games played by three players and a three-sided biased dice instead of two players and a biased coin in this work. In the first step, we find the part of the parameters space where the games are played fairly. After adding noise to fair probabilities, we combine two games randomly, periodically, and nonlinearly and obtain the conditions under which the paradox can occur. This generalized model can be applied in all science and engineering fields. It can also be used for genetic switches. Genetic switches are often made by two reactive elements, but the existence of more elements can lead to more existing decisions for cells. Each genetic switch can be considered a game in which the reactive elements compete to increase their molecular concentrations. We present three genetic networks based on a new generalized Parrondo's games model, consisting of two noisy genetic switches. The combination of them can increase network robustness to noise. Each switch can also be used as an initial pattern to construct a synthetic switch to change undesirable cells' fate.         _ Less","","arXiv","https://arxiv.org/abs/2101.11401","0","1","synthetic_biology"
"High-Resolution Non-Invasive X-ray Diffraction Analysis of Artists Paints","Abstract:                _the Diamond Light Source synchrotron. The results of the XRD analysis of the pigments in 40 paints, commonly used by 20th century artists, are reported here. It was found that synthetic organic pigments yielded weak diffraction patterns at best, and it was not possible to unambiguously identify any of these pigments. In contrast, the majority of the paints c_         _ More           Energy-dispersive X-ray diffraction (EDXRD) is extremely insensitive to sample morphology when implemented in a back-reflection geometry. The capabilities of this non-invasive technique for cultural heritage applications have been explored at high resolution at the Diamond Light Source synchrotron. The results of the XRD analysis of the pigments in 40 paints, commonly used by 20th century artists, are reported here. It was found that synthetic organic pigments yielded weak diffraction patterns at best, and it was not possible to unambiguously identify any of these pigments. In contrast, the majority of the paints containing inorganic pigments yielded good diffraction patterns amenable to crystallographic analysis. The high resolution of the technique enables the extraction of a range of detailed information: phase identification (including solid solutions), highly accurate unit cell parameters, phase quantification, crystallite size and strain parameters and preferred orientation parameters. The implications of these results for application to real paintings are discussed, along with the possibility to transfer the technique away from the synchrotron and into the laboratory and museum through the use of state-of-the-art microcalorimeter detectors. The results presented demonstrate the exciting potential of the technique for art history and authentication studies, based on the non-invasive acquisition of very high quality crystallographic data.         _ Less","","arXiv","https://arxiv.org/abs/2101.11297","1","0","origin_of_life"
"Growth and site-specific organization of micron-scale biomolecular devices on living mammalian cells","Abstract:                Mesoscale molecular assemblies on the cell surface, such as cilia and filopodia, integrate information, control transport and amplify signals._         _ More           Mesoscale molecular assemblies on the cell surface, such as cilia and filopodia, integrate information, control transport and amplify signals. Synthetic devices mimicking these structures could sensitively monitor these cellular functions and direct new ones. The challenges in creating such devices, however are that they must be integrated with cells in a precise kinetically controlled process and a device's structure and its precisely structured cell interface must then be maintained during active cellular function. Here we report the ability to integrate synthetic micro-scale filaments, DNA nanotubes, into a cell's architecture by anchoring them by their ends to specific receptors on the surfaces of mammalian cells. These filaments can act as shear stress meters: how anchored nanotubes bend at the cell surface quantitatively indicates the magnitude of shear stresses between 0-2 dyn per cm2, a regime important for cell signaling. Nanotubes can also grow while anchored to cells, thus acting as dynamic components of cells. This approach to cell surface engineering, in which synthetic biomolecular assemblies are organized within existing cellular architecture, could make it possible to build new types of sensors, machines and scaffolds that can interface with, control and measure properties of cells.         _ Less","","arXiv","https://arxiv.org/abs/2101.07764","1","1","multiple"
"Microfluidic production of porous polymer cell-mimics capable of gene expression","Abstract:                Engineering simple, artificial models of living cells allows_         _ More           Engineering simple, artificial models of living cells allows synthetic biologists to study cellular functions under well-controlled conditions. Reconstituting multicellular behaviors with synthetic cell-mimics is still a challenge because it requires efficient communication between individual compartments in large populations. This protocol presents a microfluidic method to produce large quantities of cell-mimics with highly porous, stable and chemically modifiable polymer membranes that can be programmed on demand with nucleus-like DNA-hydrogel compartments for gene expression. We describe expression of genes encoded in the hydrogel compartment and communication between neighboring cell-mimics through diffusive protein signals.         _ Less","","arXiv","https://arxiv.org/abs/2101.07135","0","1","synthetic_biology"
"Private Tabular Survey Data Products through Synthetic Microdata Generation","Abstract:                We propose two synthetic microdata approaches to generate private tabular survey data products for public release. We adapt a pseudo posterior mechanism that downweights by-record likelihood contributions with weights $\\in [0,1]$ based on their identification disclosure risks to producing tabular products for survey data. Our method applied to an observed su_         _ More           We propose two synthetic microdata approaches to generate private tabular survey data products for public release. We adapt a pseudo posterior mechanism that downweights by-record likelihood contributions with weights $\\in [0,1]$ based on their identification disclosure risks to producing tabular products for survey data. Our method applied to an observed survey database achieves an asymptotic global probabilistic differential privacy guarantee. Our two approaches synthesize the observed sample distribution of the outcome and survey weights, jointly, such that both quantities together possess a privacy guarantee. The privacy-protected outcome and survey weights are used to construct tabular cell estimates (where the cell inclusion indicators are treated as known and public) and associated standard errors to correct for survey sampling bias. Through a real data application to the Survey of Doctorate Recipients public use file and simulation studies motivated by the application, we demonstrate that our two microdata synthesis approaches to construct tabular products provide superior utility preservation as compared to the additive-noise approach of the Laplace Mechanism. Moreover, our approaches allow the release of microdata to the public, enabling additional analyses at no extra privacy cost.         _ Less","","arXiv","https://arxiv.org/abs/2101.06188","1","1","multiple"
"Phase separation and protein partitioning in compartmentalized cell-free expression reactions","Abstract:                Liquid-liquid phase separation (LLPS) is important to control a wide range of reactions from gene expression to protein degradation in a cell-sized space. To bring a better understanding of the compatibility of such phase-separated structures with protein synthesis, we study emergent LLPS in a_         _ More           Liquid-liquid phase separation (LLPS) is important to control a wide range of reactions from gene expression to protein degradation in a cell-sized space. To bring a better understanding of the compatibility of such phase-separated structures with protein synthesis, we study emergent LLPS in a cell-free transcription-translation (TXTL) reaction. When the TXTL reaction composed of many proteins is concentrated, the uniformly mixed state becomes unstable, and membrane-less phases form spontaneously. This LLPS droplet formation is induced when the TXTL reaction is enclosed in water-in-oil emulsion droplets, in which water evaporates from the surface. As the emulsion droplets shrink, smaller LLPS droplets appear inside the emulsion droplets and coalesce into large phase-separated domains that partition the localization of synthesized reporter proteins. The presence of PEG in the TXTL reaction is important not only for versatile cell-free protein synthesis but also for the formation of two large domains capable of protein partitioning. Our results may shed light on the dynamic interplay of LLPS formation and cell-free protein synthesis toward the construction of synthetic organelles.         _ Less","","arXiv","https://arxiv.org/abs/2101.05184","1","1","multiple"
"Maximizing Information Gain for the Characterization of Biomolecular Circuits","Abstract:                Quantitatively predictive models of biomolecular circuits are important tools for the design of synthetic biology and molecular communication circuits. The information content of typical time-lapse single-_         _ More           Quantitatively predictive models of biomolecular circuits are important tools for the design of synthetic biology and molecular communication circuits. The information content of typical time-lapse single-cell data for the inference of kinetic parameters is not only limited by measurement uncertainty and intrinsic stochasticity, but also by the employed perturbations. Novel microfluidic devices enable the synthesis of temporal chemical concentration profiles. The informativeness of a perturbation can be quantified based on mutual information. We propose an approximate method to perform optimal experimental design of such perturbation profiles. To estimate the mutual information we perform a multivariate log-normal approximation of the joint distribution over parameters and observations and scan the design space using Metropolis-Hastings sampling. The method is demonstrated by finding optimal perturbation sequences for synthetic case studies on a gene expression model with varying reporter characteristics.         _ Less","","arXiv","https://arxiv.org/abs/2101.02924","1","1","multiple"
"Adhesion as a trigger of droplet polarization in flowing emulsions","Abstract:                Tissues are subjected to large external forces and undergo global deformations during morphogenesis. We use synthetic analogues of tissues to study the impact of cell-cell adhesion on the response of cohesive cellular assemblies under such stresses. In particular, we use biomimet_         _ More           Tissues are subjected to large external forces and undergo global deformations during morphogenesis. We use synthetic analogues of tissues to study the impact of cell-cell adhesion on the response of cohesive cellular assemblies under such stresses. In particular, we use biomimetic emulsions in which the droplets are functionalized in order to exhibit specific droplet-droplet adhesion. We flow these emulsions in microfluidic constrictions and study their response to this forced deformation via confocal microscopy. We find that the distributions of avalanche sizes are conserved between repulsive and adhesive droplets. However, adhesion locally impairs the rupture of droplet-droplet contacts, which in turn pulls on the rearranging droplets. As a result, adhesive droplets are a lot more deformed along the axis of elongation in the constriction. This finding could shed light on the origin of polarization processes during morphogenesis.         _ Less","","arXiv","https://arxiv.org/abs/2101.02604","1","0","origin_of_life"
"A redox-responsive hyaluronic acid-based hydrogel for chronic wound management","Abstract:                _to assist clinical decision-making at the point of care and deliver on the vision of patient-personalised wound management. To explore this challenge, we present a one-step synthetic strategy to realise a redox-responsive, hyaluronic acid (HA)-based hydrogel that is sensitive to wound environment-related variations in glutathione (GSH) concentration. By sele_         _ More           Polymer-based hydrogels have been widely applied for chronic wound therapeutics, due to their well-acclaimed wound exudate management capability. At the same time, there is still an unmet clinical need for simple wound diagnostic tools to assist clinical decision-making at the point of care and deliver on the vision of patient-personalised wound management. To explore this challenge, we present a one-step synthetic strategy to realise a redox-responsive, hyaluronic acid (HA)-based hydrogel that is sensitive to wound environment-related variations in glutathione (GSH) concentration. By selecting aminoethyl disulfide (AED) as a GSH-sensitive crosslinker and considering GSH concentration variations in active and non-self-healing wounds, we investigated the impact of GSH-induced AED cleavage on hydrogel dimensions, aiming to build GSH-size relationships for potential point-of-care wound diagnosis. The hydrogel was also found to be non-cytotoxic and aided L929 fibroblast growth and proliferation over seven days in vitro. Such a material offers a very low-cost tool for the visual detection of a target analyte that varies dependent on the status of the cells and tissues (wound detection) and may be further exploited as an implant for fibroblast growth and tissue regeneration (wound repair).         _ Less","","arXiv","https://arxiv.org/abs/2101.01638","0","1","synthetic_biology"
"Synergistic effect of shear and ADP on platelet growth on ZTA and Ti6Al4V surfaces","Abstract:                _an increasingly common, life-saving therapy for advanced heart-failure patients, but elevate the risk of thrombosis due to a combination of non-physiological hemodynamics and synthetic biomaterials. Limited work has been done to address platelet adhesion and aggregation on artificial surfaces under flow with sub-threshold concentrations of weak agonists. We_         _ More           Continuous-flow ventricular assist devices (VADs) have been an increasingly common, life-saving therapy for advanced heart-failure patients, but elevate the risk of thrombosis due to a combination of non-physiological hemodynamics and synthetic biomaterials. Limited work has been done to address platelet adhesion and aggregation on artificial surfaces under flow with sub-threshold concentrations of weak agonists. We perfused a blood analog containing hemoglobin-depleted red blood cells and fluorescently labeled platelets across a titanium alloy (Ti6Al4V) and zirconia-toughened alumina (ZTA) surface at shear rates of 400 and 1000 s-1. Upstream of the specimen, sub-threshold concentrations of ADP were uniformly introduced at concentrations of 0, 5, and 10 nM. Time-lapse videos of depositing platelets were recorded, and the percentage of the surface covered was quantified. Surface coverage percentages at 400 s-1and 1000 s-1were compared for each concentration of ADP and material surface combination. We observed a threshold concentration of ADP that expedites platelet deposition that is dependent on both shear and material surface chemistry. Additionally, we observed embolization when thrombus areas exceeded 300_m2, which was dependent on the combination of shear, ADP concentration, and material surface. This work is the first to simultaneously examine the three key contributing factors leading to thrombotic events. Our findings assist in considering alternative material choices constituting VADs and the need to address material reactivity in assessing antiplatelet agent tests.         _ Less","","arXiv","https://arxiv.org/abs/2012.05827","0","1","synthetic_biology"
"Learning Vector Quantized Shape Code for Amodal Blastomere Instance Segmentation","Abstract:                _an occlusion map to integrate occlusion information with a backbone feature. As such, our network faithfully detects bounding boxes of amodal objects. On an internal embryo cell image benchmark, the proposed method outperforms previous state-of-the-art methods. To show generalizability, we show segmentation results on the public KINS natural image benchmark._         _ More           Blastomere instance segmentation is important for analyzing embryos' abnormality. To measure the accurate shapes and sizes of blastomeres, their amodal segmentation is necessary. Amodal instance segmentation aims to recover the complete silhouette of an object even when the object is not fully visible. For each detected object, previous methods directly regress the target mask from input features. However, images of an object under different amounts of occlusion should have the same amodal mask output, which makes it harder to train the regression model. To alleviate the problem, we propose to classify input features into intermediate shape codes and recover complete object shapes from them. First, we pre-train the Vector Quantized Variational Autoencoder (VQ-VAE) model to learn these discrete shape codes from ground truth amodal masks. Then, we incorporate the VQ-VAE model into the amodal instance segmentation pipeline with an additional refinement module. We also detect an occlusion map to integrate occlusion information with a backbone feature. As such, our network faithfully detects bounding boxes of amodal objects. On an internal embryo cell image benchmark, the proposed method outperforms previous state-of-the-art methods. To show generalizability, we show segmentation results on the public KINS natural image benchmark. To examine the learned shape codes and model design choices, we perform ablation studies on a synthetic dataset of simple overlaid shapes. Our method would enable accurate measurement of blastomeres in in vitro fertilization (IVF) clinics, which potentially can increase IVF success rate.         _ Less","","arXiv","https://arxiv.org/abs/2012.00985","1","0","origin_of_life"
"Critical behavior in the Artificial Axon","Abstract:                The Artificial Axon is a unique synthetic system, based on biomolecular components, which supports action potentials. Here we examine, experimentally and theoretically, the properties of the threshold for firing in this system. As in real neurons, this threshold corresponds to the critical point of a saddle-node bifurcation. We measure the delay time for fir_         _ More           The Artificial Axon is a unique synthetic system, based on biomolecular components, which supports action potentials. Here we examine, experimentally and theoretically, the properties of the threshold for firing in this system. As in real neurons, this threshold corresponds to the critical point of a saddle-node bifurcation. We measure the delay time for firing as a function of the distance to threshold, recovering the expected scaling exponent of $- 1/2$. We introduce a minimal model of the Morris-Lecar type, validate it on the experiments, and use it to extend analytical results obtained in the limit of 'fast' ion channel dynamics. In particular, we discuss the dependence of the firing threshold on the number of channels. The Artificial Axon is a simplified system, an Ur-neuron, relying on only one ion channel species for functioning. Nonetheless, universal properties such as the action potential behavior near threshold are the same as in real neurons. Thus we may think of the Artificial Axon as a cell-free breadboard for electrophysiology research.         _ Less","","arXiv","https://arxiv.org/abs/2012.00221","0","1","synthetic_biology"
"Cyberbiosecurity: DNA Injection Attack in Synthetic Biology","Abstract:                Today arbitrary synthetic DNA can be ordered online and delivered within several days. In order to regulate both intentional and unintentional generation of dangerous substances, most_         _ More           Today arbitrary synthetic DNA can be ordered online and delivered within several days. In order to regulate both intentional and unintentional generation of dangerous substances, most synthetic gene providers screen DNA orders. A weakness in the Screening Framework Guidance for Providers of Synthetic Double-Stranded DNA allows screening protocols based on this guidance to be circumvented using a generic obfuscation procedure inspired by early malware obfuscation techniques. Furthermore, accessibility and automation of the synthetic gene engineering workflow, combined with insufficient cybersecurity controls, allow malware to interfere with biological processes within the victim's lab, closing the loop with the possibility of an exploit written into a DNA molecule presented by Ney et al. in USENIX Security'17. Here we present an end-to-end cyberbiological attack, in which unwitting biologists may be tricked into generating dangerous substances within their labs. Consequently, despite common biosecurity assumptions, the attacker does not need to have physical contact with the generated substance. The most challenging part of the attack, decoding of the obfuscated DNA, is executed within living cells while using primitive biological operations commonly employed by biologists during in-vivo gene editing. This attack scenario underlines the need to harden the synthetic DNA supply chain with protections against cyberbiological threats. To address these threats we propose an improved screening protocol that takes into account in-vivo gene editing.         _ Less","","arXiv","https://arxiv.org/abs/2011.14224","0","1","synthetic_biology"
"Attention-Based Transformers for Instance Segmentation of Cells in Microstructures","Abstract:                _Examples range from detecting lesions on functional magnetic resonance images, to the detection of tumours in histopathological images and extracting quantitative single-cell information from microscopy imagery, where_         _ More           Detecting and segmenting object instances is a common task in biomedical applications. Examples range from detecting lesions on functional magnetic resonance images, to the detection of tumours in histopathological images and extracting quantitative single-cell information from microscopy imagery, where cell segmentation is a major bottleneck. Attention-based transformers are state-of-the-art in a range of deep learning fields. They have recently been proposed for segmentation tasks where they are beginning to outperforming other methods. We present a novel attention-based cell detection transformer (Cell-DETR) for direct end-to-end instance segmentation. While the segmentation performance is on par with a state-of-the-art instance segmentation method, Cell-DETR is simpler and faster. We showcase the method's contribution in a the typical use case of segmenting yeast in microstructured environments, commonly employed in systems or synthetic biology. For the specific use case, the proposed method surpasses the state-of-the-art tools for semantic segmentation and additionally predicts the individual object instances. The fast and accurate instance segmentation performance increases the experimental information yield for a posteriori data processing and makes online monitoring of experiments and closed-loop optimal experimental design feasible.         _ Less","","arXiv","https://arxiv.org/abs/2011.09763","1","1","multiple"
"Multiclass Yeast Segmentation in Microstructured Environments with Deep Learning","Abstract:        Cell segmentation is a major bottleneck in extracting quantitative single-_         _ More   Cell segmentation is a major bottleneck in extracting quantitative single-cell information from microscopy data. The challenge is exasperated in the setting of microstructured environments. While deep learning approaches have proven useful for general cell segmentation tasks, existing segmentation tools for the yeast-microstructure setting rely on traditional machine learning approaches. Here we present convolutional neural networks trained for multiclass segmenting of individual yeast cells and discerning these from cell-similar microstructures. We give an overview of the datasets recorded for training, validating and testing the networks, as well as a typical use-case. We showcase the method's contribution to segmenting yeast in microstructured environments with a typical synthetic biology application in mind. The models achieve robust segmentation results, outperforming the previous state-of-the-art in both accuracy and speed. The combination of fast and accurate segmentation is not only beneficial for a posteriori data processing, it also makes online monitoring of thousands of trapped cells or closed-loop optimal experimental design feasible from an image processing perspective.         _ Less","","arXiv","https://arxiv.org/abs/2011.08062","2","2","multiple"
"CellCycleGAN: Spatiotemporal Microscopy Image Synthesis of Cell Populations using Statistical Shape Models and Conditional GANs","Abstract:                _of such image data, but heavily depend on the amount and quality of provided training data to perform well. To this end, we developed a new method for realistic generation of synthetic 2D+t microscopy image data of fluorescently labeled cellular nuclei. The method combines spatiotemporal statistical shape models of different_         _ More           Automatic analysis of spatio-temporal microscopy images is inevitable for state-of-the-art research in the life sciences. Recent developments in deep learning provide powerful tools for automatic analyses of such image data, but heavily depend on the amount and quality of provided training data to perform well. To this end, we developed a new method for realistic generation of synthetic 2D+t microscopy image data of fluorescently labeled cellular nuclei. The method combines spatiotemporal statistical shape models of different cell cycle stages with a conditional GAN to generate time series of cell populations and provides instance-level control of cell cycle stage and the fluorescence intensity of generated cells. We show the effect of the GAN conditioning and create a set of synthetic images that can be readily used for training and benchmarking of cell segmentation and tracking approaches.         _ Less","","arXiv","https://arxiv.org/abs/2010.12011","0","1","synthetic_biology"
"Towards an Automatic Analysis of CHO-K1 Suspension Growth in Microfluidic Single-cell Cultivation","Abstract:                Motivation: Innovative microfluidic systems carry the promise to greatly facilitate spatio-temporal analysis of single cells under well-defined environmental conditions, allowing novel insights into population heterogeneity and opening new opportunities for fundamental and applied biotechnology. Microfluidics experiments, however, are accompanied by vast amo_         _ More           Motivation: Innovative microfluidic systems carry the promise to greatly facilitate spatio-temporal analysis of single cells under well-defined environmental conditions, allowing novel insights into population heterogeneity and opening new opportunities for fundamental and applied biotechnology. Microfluidics experiments, however, are accompanied by vast amounts of data, such as time series of microscopic images, for which manual evaluation is infeasible due to the sheer number of samples. While classical image processing technologies do not lead to satisfactory results in this domain, modern deep learning technologies such as convolutional networks can be sufficiently versatile for diverse tasks, including automatic cell tracking and counting as well as the extraction of critical parameters, such as growth rate. However, for successful training, current supervised deep learning requires label information, such as the number or positions of cells for each image in a series; obtaining these annotations is very costly in this setting. Results: We propose a novel Machine Learning architecture together with a specialized training procedure, which allows us to infuse a deep neural network with human-powered abstraction on the level of data, leading to a high-performing regression model that requires only a very small amount of labeled data. Specifically, we train a generative model simultaneously on natural and synthetic data, so that it learns a shared representation, from which a target variable, such as the cell count, can be reliably estimated.         _ Less","","arXiv","https://arxiv.org/abs/2010.10124","1","1","multiple"
"Parameter Estimation in an SPDE Model for Cell Repolarisation","Abstract:                As a concrete setting where stochastic partial differential equations (SPDEs) are able to model real phenomena, we propose a stochastic Meinhardt model for cell repolarisation and study how parameter estimation techniques developed for simple linear SPDE models apply in this situation. We establish the existence of mild SPDE solutions and we investigate the_         _ More           As a concrete setting where stochastic partial differential equations (SPDEs) are able to model real phenomena, we propose a stochastic Meinhardt model for cell repolarisation and study how parameter estimation techniques developed for simple linear SPDE models apply in this situation. We establish the existence of mild SPDE solutions and we investigate the impact of the driving noise process on pattern formation in the solution. We then pursue estimation of the diffusion term and show asymptotic normality for our estimator as the space resolution becomes finer. The finite sample performance is investigated for synthetic and real data.         _ Less","","arXiv","https://arxiv.org/abs/2010.06340","1","0","origin_of_life"
"Metal (boro-) hydrides for high energy density storage and relevant emerging technologies","Abstract:                _systems with high energy density and eminent regeneration and cycling efficiency. Metal hydrides are potential candidates for generalized energy storage, when coupled with fuel cell units and/or batteries. An overview of ongoing research is reported and discussed in this review work on the light of application as hydrogen and heat storage matrices, as well a_         _ More           The current energy transition imposes a rapid implementation of energy storage systems with high energy density and eminent regeneration and cycling efficiency. Metal hydrides are potential candidates for generalized energy storage, when coupled with fuel cell units and/or batteries. An overview of ongoing research is reported and discussed in this review work on the light of application as hydrogen and heat storage matrices, as well as thin films for hydrogen optical sensors. These include a selection of single-metal hydrides, Ti-V(Fe) based intermetallics, multi-principal element alloys (high-entropy alloys), and a series of novel synthetically accessible metal borohydrides. Metal hydride materials can be as well of important usefulness for MH-based electrodes with high capacity (e.g. MgH2 ~ 2000 mAh g-1) and solid-state electrolytes displaying high ionic conductivity suitable, respectively, for Li-ion and Li/Mg battery technologies. To boost further research and development directions some characterization techniques dedicated to the study of M-H interactions, their equilibrium reactions, and additional quantification of hydrogen concentration in thin film and bulk hydrides are presented at the end of this manuscript.         _ Less","","arXiv","https://arxiv.org/abs/2010.04432","2","2","multiple"
"MIA-Prognosis: A Deep Learning Framework to Predict Therapy Response","Abstract:                _Assessment (MIA) information to predict therapy response, where a Simple Temporal Attention (SimTA) module is developed to process the asynchronous time series. Experiments on synthetic dataset validate the superiory of SimTA over standard RNN-based approaches. Furthermore, we experiment the proposed method on an in-house, retrospective dataset of real-world_         _ More           Predicting clinical outcome is remarkably important but challenging. Research efforts have been paid on seeking significant biomarkers associated with the therapy response or/and patient survival. However, these biomarkers are generally costly and invasive, and possibly dissatifactory for novel therapy. On the other hand, multi-modal, heterogeneous, unaligned temporal data is continuously generated in clinical practice. This paper aims at a unified deep learning approach to predict patient prognosis and therapy response, with easily accessible data, e.g., radiographics, laboratory and clinical information. Prior arts focus on modeling single data modality, or ignore the temporal changes. Importantly, the clinical time series is asynchronous in practice, i.e., recorded with irregular intervals. In this study, we formalize the prognosis modeling as a multi-modal asynchronous time series classification task, and propose a MIA-Prognosis framework with Measurement, Intervention and Assessment (MIA) information to predict therapy response, where a Simple Temporal Attention (SimTA) module is developed to process the asynchronous time series. Experiments on synthetic dataset validate the superiory of SimTA over standard RNN-based approaches. Furthermore, we experiment the proposed method on an in-house, retrospective dataset of real-world non-small cell lung cancer patients under anti-PD-1 immunotherapy. The proposed method achieves promising performance on predicting the immunotherapy response. Notably, our predictive model could further stratify low-risk and high-risk patients in terms of long-term survival.         _ Less","","arXiv","https://arxiv.org/abs/2010.04062","1","0","origin_of_life"
"Inferring Microbial Biomass Yield and Cell Weight using Probabilistic Macrochemical Modeling","Abstract:                _used in microbiology studies to understand how microbial species respond to changes in the environment. Of these, biomass yield estimates are typically obtained using cell counts and measurements of the feed substrate. These quantities are perturbed with measurement noise however. Perhaps most crucially, estimating biomass from_         _ More           Growth rates and biomass yields are key descriptors used in microbiology studies to understand how microbial species respond to changes in the environment. Of these, biomass yield estimates are typically obtained using cell counts and measurements of the feed substrate. These quantities are perturbed with measurement noise however. Perhaps most crucially, estimating biomass from cell counts, as needed to assess yields, relies on an assumed cell weight. Noise and discrepancies on these assumptions can lead to significant changes in conclusions regarding the microbes' response. This article proposes a methodology to address these challenges using probabilistic macrochemical models of microbial growth. It is shown that a model can be developed to fully use the experimental data, relax assumptions and greatly improve robustness to a priori estimates of the cell weight, and provides uncertainty estimates of key parameters. This methodology is demonstrated in the context of a specific case study and the estimation characteristics are validated in several scenarios using synthetically generated microbial growth data.         _ Less","","arXiv","https://arxiv.org/abs/2010.02759","0","1","synthetic_biology"
"Unbalanced Sobolev Descent","Abstract:                _The first one implements the reaction step with mirror descent on the weights, while the second implements it through a birth-death process of particles. We show on synthetic examples that USD transports distributions with or without conservation of mass faster than previous particle descent algorithms, and finally demonstrate its use for molecular biology_         _ More           We introduce Unbalanced Sobolev Descent (USD), a particle descent algorithm for transporting a high dimensional source distribution to a target distribution that does not necessarily have the same mass. We define the Sobolev-Fisher discrepancy between distributions and show that it relates to advection-reaction transport equations and the Wasserstein-Fisher-Rao metric between distributions. USD transports particles along gradient flows of the witness function of the Sobolev-Fisher discrepancy (advection step) and reweighs the mass of particles with respect to this witness function (reaction step). The reaction step can be thought of as a birth-death process of the particles with rate of growth proportional to the witness function. When the Sobolev-Fisher witness function is estimated in a Reproducing Kernel Hilbert Space (RKHS), under mild assumptions we show that USD converges asymptotically (in the limit of infinite particles) to the target distribution in the Maximum Mean Discrepancy (MMD) sense. We then give two methods to estimate the Sobolev-Fisher witness with neural networks, resulting in two Neural USD algorithms. The first one implements the reaction step with mirror descent on the weights, while the second implements it through a birth-death process of particles. We show on synthetic examples that USD transports distributions with or without conservation of mass faster than previous particle descent algorithms, and finally demonstrate its use for molecular biology analyses where our method is naturally suited to match developmental stages of populations of differentiating cells based on their single-cell RNA sequencing profile. Code is available at https://github.com/ibm/usd .         _ Less","","arXiv","https://arxiv.org/abs/2009.14148","0","1","synthetic_biology"
"Variational Temporal Deep Generative Model for Radar HRRP Target Recognition","Abstract:                _belief network (rGBN) for radar automatic target recognition (RATR) based on high-resolution range profile (HRRP), which characterizes the temporal dependence across the range cells of HRRP. The proposed rGBN adopts a hierarchy of gamma distributions to build its temporal deep generative model. For scalable training and fast out-of-sample prediction, we prop_         _ More           We develop a recurrent gamma belief network (rGBN) for radar automatic target recognition (RATR) based on high-resolution range profile (HRRP), which characterizes the temporal dependence across the range cells of HRRP. The proposed rGBN adopts a hierarchy of gamma distributions to build its temporal deep generative model. For scalable training and fast out-of-sample prediction, we propose the hybrid of a stochastic-gradient Markov chain Monte Carlo (MCMC) and a recurrent variational inference model to perform posterior inference. To utilize the label information to extract more discriminative latent representations, we further propose supervised rGBN to jointly model the HRRP samples and their corresponding labels. Experimental results on synthetic and measured HRRP data show that the proposed models are efficient in computation, have good classification accuracy and generalization ability, and provide highly interpretable multi-stochastic-layer latent structure.         _ Less","","arXiv","https://arxiv.org/abs/2009.13011","1","0","origin_of_life"
"Microtubule-based actin transport and localization in a spherical cell","Abstract:                The interaction between actin filaments and microtubules is crucial for many eukaryotic cellular processes, such as, among others, cell polarization,_         _ More           The interaction between actin filaments and microtubules is crucial for many eukaryotic cellular processes, such as, among others, cell polarization, cell motility and cellular wound healing. The importance of this interaction has long been recognised, yet very little is understood about both the underlying mechanisms and the consequences for the spatial (re)organization of the cellular cytoskeleton. At the same time, understanding the causes and the consequences of the interaction between different biomolecular components are key questions for \\emph{in vitro} research involving reconstituted biomolecular systems, especially in the light of current interest in creating minimal synthetic cells. In this light, recent \\emph{in vitro} experiments have shown that the actin-microtubule interaction mediated by the cytolinker TipAct, which binds to actin lattice and microtubule tip, causes the directed transport of actin filaments. We develop an analytical theory of dynamically unstable microtubules, nucleated from the center of a spherical cell, in interaction with actin filaments. We show that, depending on the balance between the diffusion of unbound actin filaments and propensity to bind microtubules, actin is either concentrated in the center of the cell, where the density of microtubules is highest, or becomes localized to the cell cortex.         _ Less","","arXiv","https://arxiv.org/abs/2009.12248","0","1","synthetic_biology"
"Objective, Probabilistic, and Generalized Noise Level Dependent Classifications of sets of more or less 2D Periodic Images into Plane Symmetry Groups","Abstract:                _instead of more powerful and computationally efficient Fourier space methods. This is because the proper functioning of those methods requires more periodic repeats of a unit cell motif than are commonly present in images analyzed by the computer vision community. We demonstrate a novel approach to plane symmetry group classifications that is enabled by Keni_         _ More           Crystallographic symmetry classifications from real-world images with periodicities in two dimensions (2D) are of interest to crystallographers and practitioners of computer vision studies alike. Currently, these classifications are typically made by both communities in a subjective manner that relies on arbitrary thresholds for judgments, and are reported under the pretense of being definitive, which is impossible. Moreover, the computer vision community tends to use direct space methods to make such classifications instead of more powerful and computationally efficient Fourier space methods. This is because the proper functioning of those methods requires more periodic repeats of a unit cell motif than are commonly present in images analyzed by the computer vision community. We demonstrate a novel approach to plane symmetry group classifications that is enabled by Kenichi Kanatani's Geometric Akaike Information Criterion and associated Geometric Akaike weights. Our approach leverages the advantages of working in Fourier space, is well suited for handling the hierarchic nature of crystallographic symmetries, and yields probabilistic results that are generalized noise level dependent. The latter feature means crystallographic symmetry classifications can be updated when less noisy image data and more accurate processing algorithms become available. We demonstrate the ability of our approach to objectively estimate the plane symmetry and pseudosymmetries of sets of synthetic 2D-periodic images with varying amounts of red-green-blue and spread noise. Additionally, we suggest a simple solution to the problem of too few periodic repeats in an input image for practical application of Fourier space methods. In doing so, we effectively solve the decades-old and heretofore intractable problem from computer vision of symmetry detection and classification from images in the presence of noise.         _ Less","","arXiv","https://arxiv.org/abs/2009.08539","1","0","origin_of_life"
"On the estimation of spatial density from mobile network operator data","Abstract:                _from Mobile Network Operator (MNO) data, namely Call Detail Record (CDR) or signalling data. The process of transforming MNO data to a density map requires geolocating radio cells to determine their spatial footprint. Traditional geolocation solutions rely on Voronoi tessellations and approximate_         _ More           We tackle the problem of estimating the spatial distribution of mobile phones from Mobile Network Operator (MNO) data, namely Call Detail Record (CDR) or signalling data. The process of transforming MNO data to a density map requires geolocating radio cells to determine their spatial footprint. Traditional geolocation solutions rely on Voronoi tessellations and approximate cell footprints by mutually disjoint regions. Recently, some pioneering work started to consider more elaborate geolocation methods with partially overlapping (non-disjoint) cell footprints coupled with a probabilistic model for phone-to-cell association. Estimating the spatial density in such a probabilistic setup is currently an open research problem and is the focus of the present work. We start by reviewing three different estimation methods proposed in literature and provide novel analytical insights that unveil some key aspects of their mutual relationships and properties. Furthermore, we develop a novel estimation approach for which a closed-form solution can be given. Numerical results based on semi-synthetic data are presented to assess the relative accuracy of each method. Our results indicate that the estimators based on overlapping cells have the potential to improve spatial accuracy over traditional approaches based on Voronoi tessellations.         _ Less","","arXiv","https://arxiv.org/abs/2009.05410","1","1","multiple"
"Mediating Ribosomal Competition by Splitting Pools","Abstract:        Synthetic biology constructs often rely upon the introduction of 'circuit' genes into host cells, in order to express novel proteins and thus endow the host with a desired behavior. The expression of these new genes 'consumes' existing resources in the cell, such_         _ More   Synthetic biology constructs often rely upon the introduction of 'circuit' genes into host cells, in order to express novel proteins and thus endow the host with a desired behavior. The expression of these new genes 'consumes' existing resources in the cell, such as ATP, RNA polymerase, amino acids, and ribosomes. Ribosomal competition among strands of mRNA may be described by a system of nonlinear ODEs called the Ribosomal Flow Model (RFM). The competition for resources between host and circuit genes can be ameliorated by splitting the ribosome pool by use of orthogonal ribosomes, where the circuit genes are exclusively translated by mutated ribosomes. In this work, the RFM system is extended to include orthogonal ribosome competition. This Orthogonal Ribosomal Flow Model (ORFM) is proven to be stable through the use of Robust Lyapunov Functions. The optimization problem of maximizing the weighted protein translation rate by adjusting allocation of ribosomal species is formulated and implemented.         _ Less","","arXiv","https://arxiv.org/abs/2009.00539","0","1","synthetic_biology"
"Modelling Elastically-Mediated Liquid-Liquid Phase Separation","Abstract:                _Phase diagrams in the space of (fluid constitution, mixture interaction, network modulus) are provided, which can help to understand similar phase separations in biological cells and also to guide fabrications of synthetic cells with desired phase properties.         _ More           We propose a continuum theory of the liquid-liquid phase separation in an elastic network where phase-separated microscopic droplets rich in one fluid component can form as an interplay of fluids mixing, droplet nucleation, network deformation, thermodynamic fluctuation, \\emph{etc}. We find that the size of the phase separated droplets decreases with the shear modulus of the elastic network in the form of $\\sim[\\mathrm{modulus}]^{-1/3}$ and the number density of the droplet increases almost linearly with the shear modulus $\\sim[\\mathrm{modulus}]$, which are verified by the experimental observations. Phase diagrams in the space of (fluid constitution, mixture interaction, network modulus) are provided, which can help to understand similar phase separations in biological cells and also to guide fabrications of synthetic cells with desired phase properties.         _ Less","","arXiv","https://arxiv.org/abs/2008.08771","1","1","multiple"
"Weak carbohydrate-carbohydrate interactions in membrane adhesion are fuzzy and generic","Abstract:                Carbohydrates such as the trisaccharide motif LeX are key constituents of cell surfaces. Despite intense research, the interactions between carbohydrates of apposing_         _ More           Carbohydrates such as the trisaccharide motif LeX are key constituents of cell surfaces. Despite intense research, the interactions between carbohydrates of apposing cells or membranes are not well understood. In this article, we investigate carbohydrate-carbohydrate interactions in membrane adhesion as well as in solution with extensive atomistic molecular dynamics simulations that exceed the simulation times of previous studies by orders of magnitude. For LeX, we obtain association constants of soluble carbohydrates, adhesion energies of lipid-anchored carbohydrates, and maximally sustained forces of carbohydrate complexes in membrane adhesion that are in good agreement with experimental results in the literature. Our simulations thus appear to provide a realistic, detailed picture of LeX-LeX interactions in solution and during membrane adhesion. In this picture, the LeX-LeX interactions are fuzzy, i.e. LeX pairs interact in a large variety of short-lived, bound conformations. For the synthetic tetrasaccharide Lac 2, which is composed of two lactose units, we observe similarly fuzzy interactions and obtain association constants of both soluble and lipid-anchored variants that are comparable to the corresponding association constants of LeX. The fuzzy, weak carbohydrate-carbohydrate interactions quantified in our simulations thus appear to be a generic feature of small, neutral carbohydrates such as LeX and Lac 2.         _ Less","","arXiv","https://arxiv.org/abs/2008.01470","1","0","origin_of_life"
"Multiscale assay of unlabeled neurite dynamics using phase imaging with computational specificity (PICS)","Abstract:                _of neurons make them challenging to study - with phenotypic differences expressed as subtle changes in neuronal arborization rather than easy to assay features such as cell count. The need to analyze morphology, growth, and intracellular transport has motivated the development of increasingly sophisticated microscopes and image analysis techniques. Due to it_         _ More           Primary neuronal cultures have been widely used to study neuronal morphology, neurophysiology, neurodegenerative processes, and molecular mechanism of synaptic plasticity underlying learning and memory. Yet, the unique behavioral properties of neurons make them challenging to study - with phenotypic differences expressed as subtle changes in neuronal arborization rather than easy to assay features such as cell count. The need to analyze morphology, growth, and intracellular transport has motivated the development of increasingly sophisticated microscopes and image analysis techniques. Due to its high-contrast, high-specificity output, many assays rely on confocal fluorescence microscopy, genetic methods, or antibody staining techniques. These approaches often limit the ability to measure quantitatively dynamic activity such as intracellular transport and growth. In this work, we describe a method for label-free live-cell cell imaging with antibody staining specificity by estimating the associated fluorescent signals via quantitative phase imaging and deep convolutional neural networks. This computationally inferred fluorescence image is then used to generate a semantic segmentation map, annotating subcellular compartments of live unlabeled neural cultures. These synthetic fluorescence maps were further applied to study the time-lapse development of hippocampal neurons, highlighting the relationships between the cellular dry mass production and the dynamic transport activity within the nucleus and neurites. Our implementation provides a high-throughput strategy to analyze neural network arborization dynamically, with high specificity and without the typical phototoxicity and photobleaching limitations associated with fluorescent markers.         _ Less","","arXiv","https://arxiv.org/abs/2008.00626","0","1","synthetic_biology"
"Signal metrics analysis of oscillatory patterns in bacterial multi-omic networks","Abstract:                _the branches of Systems Biology is focused on a deep understanding of underlying regulatory networks through the analysis of the biomolecules oscillations and their interplay. Synthetic Biology exploits gene or/and protein regulatory networks towards the design of oscillatory networks for producing useful compounds. Therefore, at different levels of applicat_         _ More           Motivation: One of the branches of Systems Biology is focused on a deep understanding of underlying regulatory networks through the analysis of the biomolecules oscillations and their interplay. Synthetic Biology exploits gene or/and protein regulatory networks towards the design of oscillatory networks for producing useful compounds. Therefore, at different levels of application and for different purposes, the study of biomolecular oscillations can lead to different clues about the mechanisms underlying living cells. It is known that network-level interactions involve more than one type of biomolecule as well as biological processes operating at multiple omic levels. Combining network/pathway-level information with genetic information it is possible to describe well-understood or unknown bacterial mechanisms and organism-specific dynamics. Results: Network multi-omic integration has led to the discovery of interesting oscillatory signals. Following the methodologies used in signal processing and communication engineering, a new methodology is introduced to identify and quantify the extent of the multi-omic oscillations of the signal. New signal metrics are designed to allow further biotechnological explanations and provide important clues about the oscillatory nature of the pathways and their regulatory circuits. Our algorithms designed for the analysis of multi-omic signals are tested and validated on 11 different bacteria for thousands of multi-omic signals perturbed at the network level by different experimental conditions. Information on the order of genes, codon usage, gene expression, and protein molecular weight is integrated at three different functional levels. Oscillations show interesting evidence that network-level multi-omic signals present a synchronized response to perturbations and evolutionary relations along with taxa.         _ Less","","arXiv","https://arxiv.org/abs/2008.00263","1","2","synthetic_biology"
"Simulation of coupled multiphase flow and geomechanics in porous media with embedded discrete fractures","Abstract:                _This non-conforming approach significantly alleviates meshing challenges. EDFM considers fractures as lower dimension finiten volumes which exchange fluxes with the rock matrix cells. The EFEM method provides, instead, a local enrichment of the finite-element space inside each matrix_         _ More           In fractured natural formations, the equations governing fluid flow and geomechanics are strongly coupled. Hydrodynamical properties depend on the mechanical configuration, and they are therefore difficult to accurately resolve using uncoupled methods. In recent years, significant research has focused on discretization strategies for these coupled systems, particularly in the presence of complicated fracture network geometries. In this work, we explore a finite-volume discretization for the multiphase flow equations coupled with a finite-element scheme for the mechanical equations. Fractures are treated as lower dimensional surfaces embedded in a background grid. Interactions are captured using the Embedded Discrete Fracture Model (EDFM) and the Embedded Finite Element Method (EFEM) for the flow and the mechanics, respectively. This non-conforming approach significantly alleviates meshing challenges. EDFM considers fractures as lower dimension finiten volumes which exchange fluxes with the rock matrix cells. The EFEM method provides, instead, a local enrichment of the finite-element space inside each matrix cell cut by a fracture element. Both the use of piecewise constant and piecewise linear enrichments are investigated. They are also compared to an Extended Finite Element (XFEM) approach. One key advantage of EFEM is the element-based nature of the enrichment, which reduces the geometric complexity of the implementation and leads to linear systems with advantageous properties. Synthetic numerical tests are presented to study the convergence and accuracy of the proposed method. It is also applied to a realistic scenario, involving a heterogeneous reservoir with a complex fracture distribution, to demonstrate its relevance for field applications.         _ Less","","arXiv","https://arxiv.org/abs/2007.05069","1","0","origin_of_life"
"Advancing Drug Resistance Research Through Quantitative Modeling and Synthetic Biology","Abstract:                _if unmitigated, threatens to kill 10 million people per year worldwide by 2050. Research over the last decade has demonstrated that the differences between genetically identical cells in the same environment can lead to drug resistance. Fluctuations in gene expression, modulated by gene regulatory networks, can lead to non-genetic heterogeneity that results_         _ More           Antimicrobial resistance is an emerging global health crisis that is undermining advances in modern medicine and, if unmitigated, threatens to kill 10 million people per year worldwide by 2050. Research over the last decade has demonstrated that the differences between genetically identical cells in the same environment can lead to drug resistance. Fluctuations in gene expression, modulated by gene regulatory networks, can lead to non-genetic heterogeneity that results in the fractional killing of microbial populations causing drug therapies to fail; this non-genetic drug resistance can enhance the probability of acquiring genetic drug resistance mutations. Mathematical models of gene networks can elucidate general principles underlying drug resistance, predict the evolution of resistance, and guide drug resistance experiments in the laboratory. Cells genetically engineered to carry synthetic gene networks regulating drug resistance genes allow for controlled, quantitative experiments on the role of non-genetic heterogeneity in the development of drug resistance. In this perspective article, we emphasize the contributions that mathematical, computational, and synthetic gene network models play in advancing our understanding of antimicrobial resistance to discover effective therapies against drug-resistant infections.         _ Less","","arXiv","https://arxiv.org/abs/2007.03186","0","2","synthetic_biology"
"Calibration of Biophysical Models for tau-Protein Spreading in Alzheimer's Disease from PET-MRI","Abstract:                Aggregates of misfolded tau proteins (or just 'tau' for brevity) play a crucial role in the progression of Alzheimer's disease (AD) as they correlate with cell death and accelerated tissue atrophy. Longitudinal positron emission tomography (PET) scans can be used quantify the extend of abnormal tau spread. Such PET-based image biomarkers are a pr_         _ More           Aggregates of misfolded tau proteins (or just 'tau' for brevity) play a crucial role in the progression of Alzheimer's disease (AD) as they correlate with cell death and accelerated tissue atrophy. Longitudinal positron emission tomography (PET) scans can be used quantify the extend of abnormal tau spread. Such PET-based image biomarkers are a promising technology for AD diagnosis and prognosis. Here, we propose to calibrate an organ-scale biophysical mathematical model using longitudinal PET scans to extract characteristic growth patterns and spreading of tau. The biophysical model is a reaction-advection-diffusion partial differential equation (PDE) with only two scalar unknown parameters, one representing the spreading (the diffusion part of the PDE) and the other one the growth of tau (the reaction part of the PDE). The advection term captures tissue atrophy and is obtained from diffeomorphic registration of longitudinal magnetic resonance imaging (MRI) scans. We describe the method, present a numerical scheme for the calibration of the growth and spreading parameters, perform a sensitivity study using synthetic data, and we perform a preliminary evaluation on clinical scans from the ADNI dataset. We study whether such model calibration is possible and investigate the sensitivity of such calibration to the time between consecutive scans and the presence of atrophy. Our findings show that despite using only two calibration parameters, the model can reconstruct clinical scans quite accurately. We discovered that small time intervals between scans and the presence of background noise create difficulties. Our reconstructed model fits the data well, yet the study on clinical data also reveals shortcomings of the simplistic model. Interestingly, the parameters show significant variability across patients, an indication that these parameters could be useful biomarkers.         _ Less","","arXiv","https://arxiv.org/abs/2007.01236","0","1","synthetic_biology"
"Neural Cellular Automata Manifold","Abstract:                _accomplish this by introducing dynamic convolutions inside an Auto-Encoder architecture, for the first time used to join two different sources of information, the encoding and cells environment information. In biological terms, our approach would play the role of the transcription factors, modulating the mapping of genes into specific proteins that drive cel_         _ More           Very recently, the Neural Cellular Automata (NCA) has been proposed to simulate the morphogenesis process with deep networks. NCA learns to grow an image starting from a fixed single pixel. In this work, we show that the neural network (NN) architecture of the NCA can be encapsulated in a larger NN. This allows us to propose a new model that encodes a manifold of NCA, each of them capable of generating a distinct image. Therefore, we are effectively learning an embedding space of CA, which shows generalization capabilities. We accomplish this by introducing dynamic convolutions inside an Auto-Encoder architecture, for the first time used to join two different sources of information, the encoding and cells environment information. In biological terms, our approach would play the role of the transcription factors, modulating the mapping of genes into specific proteins that drive cellular differentiation, which occurs right before the morphogenesis. We thoroughly evaluate our approach in a dataset of synthetic emojis and also in real images of CIFAR10. Our model introduces a general-purpose network, which can be used in a broad range of problems beyond image generation.         _ Less","","arXiv","https://arxiv.org/abs/2006.12155","1","0","origin_of_life"
"Algorithmic Design for Embodied Intelligence in Synthetic Cells","Abstract:                _that is distributed away from a central processor and instead embodied in the physical body of a robot. The method is demonstrated by computationally optimizing a simulated synthetic cell.         _ More           In nature, biological organisms jointly evolve both their morphology and their neurological capabilities to improve their chances for survival. Consequently, task information is encoded in both their brains and their bodies. In robotics, the development of complex control and planning algorithms often bears sole responsibility for improving task performance. This dependence on centralized control can be problematic for systems with computational limitations, such as mechanical systems and robots on the microscale. In these cases we need to be able to offload complex computation onto the physical morphology of the system. To this end, we introduce a methodology for algorithmically arranging sensing and actuation components into a robot design while maintaining a low level of design complexity (quantified using a measure of graph entropy), and a high level of task embodiment (evaluated by analyzing the Kullback-Leibler divergence between physical executions of the robot and those of an idealized system). This approach computes an idealized, unconstrained control policy which is projected onto a limited selection of sensors and actuators in a given library, resulting in intelligence that is distributed away from a central processor and instead embodied in the physical body of a robot. The method is demonstrated by computationally optimizing a simulated synthetic cell.         _ Less","","arXiv","https://arxiv.org/abs/2006.07244","1","1","multiple"
"Turing Patterning in Stratified Domains","Abstract:                _layered media arise in several scientific domains such as pattern-forming E. coli on agar substrates, epidermal-mesenchymal coupling in development, and symmetry-breaking in cell polarisation. We develop a modelling framework for bi-layer reaction-diffusion systems and relate it to a range of existing models. We derive conditions for diffusion-driven instabi_         _ More           Reaction-diffusion processes across layered media arise in several scientific domains such as pattern-forming E. coli on agar substrates, epidermal-mesenchymal coupling in development, and symmetry-breaking in cell polarisation. We develop a modelling framework for bi-layer reaction-diffusion systems and relate it to a range of existing models. We derive conditions for diffusion-driven instability of a spatially homogeneous equilibrium analogous to the classical conditions for a Turing instability in the simplest nontrivial setting where one domain has a standard reaction-diffusion system, and the other permits only diffusion. Due to the transverse coupling between these two regions, standard techniques for computing eigenfunctions of the Laplacian cannot be applied, and so we propose an alternative method to compute the dispersion relation directly. We compare instability conditions with full numerical simulations to demonstrate impacts of the geometry and coupling parameters on patterning, and explore various experimentally-relevant asymptotic regimes. In the regime where the first domain is suitably thin, we recover a simple modulation of the standard Turing conditions, and find that often the broad impact of the diffusion-only domain is to reduce the ability of the system to form patterns. We also demonstrate complex impacts of this coupling on pattern formation. For instance, we exhibit non-monotonicity of pattern-forming instabilities with respect to geometric and coupling parameters, and highlight an instability from a nontrivial interaction between kinetics in one domain and diffusion in the other. These results are valuable for informing design choices in applications such as synthetic engineering of Turing patterns, but also for understanding the role of stratified media in modulating pattern-forming processes in developmental biology and beyond.         _ Less","","arXiv","https://arxiv.org/abs/2006.06619","1","0","origin_of_life"
"Computer-aided whole-cell design: taking a holistic approach by integrating synthetic with systems biology","Abstract:                Computer-aided design for synthetic biology promises to accelerate the rational and robust engineering of biological systems; it requires both detailed and quantitative mathematical and experimental models of the processes to (re)design, and software and tools for genetic engineering and DNA assembly. Ultimately, the increased precision in the design phase w_         _ More           Computer-aided design for synthetic biology promises to accelerate the rational and robust engineering of biological systems; it requires both detailed and quantitative mathematical and experimental models of the processes to (re)design, and software and tools for genetic engineering and DNA assembly. Ultimately, the increased precision in the design phase will have a dramatic impact on the production of designer cells and organisms with bespoke functions and increased modularity. Computer-aided design strategies require quantitative representations of cells, able to capture multiscale processes and link genotypes to phenotypes. Here, we present a perspective on how whole-cell, multiscale models could transform design-build-test-learn cycles in synthetic biology. We show how these models could significantly aid in the design and learn phases while reducing experimental testing by presenting case studies spanning from genome minimization to cell-free systems, and we discuss several challenges for the realization of our vision. The possibility to describe and build in silico whole-cells offers an opportunity to develop increasingly automatized, precise and accessible computer-aided design tools and strategies throughout novel interdisciplinary collaborations.         _ Less","","arXiv","https://arxiv.org/abs/2006.02720","0","1","synthetic_biology"
"Unsupervised Discretization by Two-dimensional MDL-based Histogram","Abstract:                _multi-dimensional case is far less studied: current methods consider the dimensions one at a time (if not independently), which result in discretizations based on rectangular cells of adaptive size. Unfortunately, this approach is unable to adequately characterize dependencies among dimensions and/or results in discretizations consisting of more_         _ More           Unsupervised discretization is a crucial step in many knowledge discovery tasks. The state-of-the-art method for one-dimensional data infers locally adaptive histograms using the minimum description length (MDL) principle, but the multi-dimensional case is far less studied: current methods consider the dimensions one at a time (if not independently), which result in discretizations based on rectangular cells of adaptive size. Unfortunately, this approach is unable to adequately characterize dependencies among dimensions and/or results in discretizations consisting of more cells (or bins) than is desirable.   To address this problem, we propose an expressive model class that allows for far more flexible partitions of two-dimensional data. We extend the state of the art for the one-dimensional case to obtain a model selection problem based on the normalized maximum likelihood, a form of refined MDL. As the flexibility of our model class comes at the cost of a vast search space, we introduce a heuristic algorithm, named PALM, which Partitions each dimension ALternately and then Merges neighboring regions, all using the MDL principle. Experiments on synthetic data show that PALM 1) accurately reveals ground truth partitions that are within the model class (i.e., the search space), given a large enough sample size; 2) approximates well a wide range of partitions outside the model class; 3) converges, in contrast to the state-of-the-art multivariate discretization method IPD. Finally, we apply our algorithm to three spatial datasets, and we demonstrate that, compared to kernel density estimation (KDE), our algorithm not only reveals more detailed density changes, but also fits unseen data better, as measured by the log-likelihood.         _ Less","","arXiv","https://arxiv.org/abs/2006.01893","1","1","multiple"
"Synaptic Channel Modeling for DMC: Neurotransmitter Uptake and Spillover in the Tripartite Synapse","Abstract:                _molecules. Synaptic signaling, as a natural implementation of this paradigm, encompasses functional components that, once understood, can facilitate the development of synthetic DMC systems. To unleash this potential, however, a thorough understanding of the synaptic communication channel based on biophysical principles is needed. Since synaptic transmission_         _ More           In Diffusive Molecular Communication (DMC), information is transmitted by diffusing molecules. Synaptic signaling, as a natural implementation of this paradigm, encompasses functional components that, once understood, can facilitate the development of synthetic DMC systems. To unleash this potential, however, a thorough understanding of the synaptic communication channel based on biophysical principles is needed. Since synaptic transmission critically depends also on non-neural cells, such understanding requires the consideration of the so-called tripartite synapse. In this paper, we develop a comprehensive channel model of the tripartite synapse encompassing a three-dimensional, finite-size spatial model of the synaptic cleft, molecule uptake at the presynaptic neuron and at glial cells, reversible binding to individual receptors at the postsynaptic neuron, and spillover to the extrasynaptic space. Based on this model, we derive analytical time domain expressions for the channel impulse response (CIR) of the synaptic DMC system and for the number of molecules taken up at the presynaptic neuron and at glial cells, respectively. These expressions provide insight into the impact of macroscopic physical channel parameters on the decay rate of the CIR and the reuptake rate, and reveal fundamental limits for synaptic signal transmission induced by chemical reaction kinetics and the channel geometry. Adapted to realistic parameters, our model produces plausible results when compared to experimental and simulation studies and we provide results from particle-based computer simulations to further validate the analytical model. The proposed comprehensive channel model admits a wide range of synaptic configurations making it suitable for the investigation of many practically relevant questions, such as the impact of glial cell uptake and spillover on signal transmission in the tripartite synapse.         _ Less","","arXiv","https://arxiv.org/abs/2005.09108","2","2","multiple"
"Optimal Experimental Design for Mathematical Models of Hematopoiesis","Abstract:                The hematopoietic system has a highly regulated and complex structure in which cells are organized to successfully create and maintain new blood_         _ More           The hematopoietic system has a highly regulated and complex structure in which cells are organized to successfully create and maintain new blood cells. Feedback regulation is crucial to tightly control this system, but the specific mechanisms by which control is exerted are not completely understood. In this work, we aim to uncover the underlying mechanisms in hematopoiesis by conducting perturbation experiments, where animal subjects are exposed to an external agent in order to observe the system response and evolution. Developing a proper experimental design for these studies is an extremely challenging task. To address this issue, we have developed a novel Bayesian framework for optimal design of perturbation experiments. We model the numbers of hematopoietic stem and progenitor cells in mice that are exposed to a low dose of radiation. We use a differential equations model that accounts for feedback and feedforward regulation. A significant obstacle is that the experimental data are not longitudinal, rather each data point corresponds to a different animal. This model is embedded in a hierarchical framework with latent variables that capture unobserved cellular population levels. We select the optimum design based on the amount of information gain, measured by the Kullback-Leibler divergence between the probability distributions before and after observing the data. We evaluate our approach using synthetic and experimental data. We show that a proper design can lead to better estimates of model parameters even with relatively few subjects. Additionally, we demonstrate that the model parameters show a wide range of sensitivities to design options. Our method should allow scientists to find the optimal design by focusing on their specific parameters of interest and provide insight to hematopoiesis. Our approach can be extended to more complex models where latent components are used.         _ Less","","arXiv","https://arxiv.org/abs/2004.09065","1","1","multiple"
"Prediction of cellular burden with host-circuit models","Abstract:                Heterologous gene expression draws resources from host cells. These resources include vital components to sustain growth and replication, and the resulting cellular burden is a widely recognised bottleneck in the design of robust circuits. In this tutorial we discuss the use of computational models that integrate gene circuits and the physiology of host_         _ More           Heterologous gene expression draws resources from host cells. These resources include vital components to sustain growth and replication, and the resulting cellular burden is a widely recognised bottleneck in the design of robust circuits. In this tutorial we discuss the use of computational models that integrate gene circuits and the physiology of host cells. Through various use cases, we illustrate the power of host-circuit models to predict the impact of design parameters on both burden and circuit functionality. Our approach relies on a new generation of computational models for microbial growth that can flexibly accommodate resource bottlenecks encountered in gene circuit design. Adoption of this modelling paradigm can facilitate fast and robust design cycles in synthetic biology.         _ Less","","arXiv","https://arxiv.org/abs/2004.00995","0","3","synthetic_biology"
"3-D Printed Swimming Microtori for Cargo Transport and Flow Manipulation","Abstract:                _mastered unique swimming behaviors to thrive in complex fluid environments. Limitations in nanofabrication have thus far hindered the ability to design and program synthetic swimmers with the same abilities. Here we encode multi-behavioral responses in artificial swimmers such as microscopic, self-propelled tori using nanoscale 3D printing. We show experimen_         _ More           Through billions of years of evolution, microorganisms mastered unique swimming behaviors to thrive in complex fluid environments. Limitations in nanofabrication have thus far hindered the ability to design and program synthetic swimmers with the same abilities. Here we encode multi-behavioral responses in artificial swimmers such as microscopic, self-propelled tori using nanoscale 3D printing. We show experimentally and theoretically that the tori continuously transition between two primary swimming modes in response to a magnetic field. The tori also manipulate and transport other artificial swimmers, bimetallic nanorods, as well as passive colloidal particles. In the first behavioral mode, the tori accumulate and transport nanorods; in the second mode, nanorods align along the tori's self-generated streamlines. Our results indicate that such shape-programmed microswimmers have the potential to manipulate biological active matter, e.g. bacteria or cells.         _ Less","","arXiv","https://arxiv.org/abs/2004.00615","0","1","synthetic_biology"
